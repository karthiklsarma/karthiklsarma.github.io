"V1","V2","V3","V4"
"NaN","NaN","  5038","<p><br>
I'm experimenting with R and found that an anova() needs an object of type lm. But why should I continue with an anova after this:</p>

<pre><code>&gt; x &lt;- data.frame(rand=rnorm(100), factor=sample(c(""A"",""B"",""C""),100,replace=TRUE))
&gt; head(x)
        rand factor
1  0.9640502      B
2 -0.5038238      C
3 -1.5699734      A
4 -0.8422324      B
5  0.2489113      B
6 -1.4685439      A

&gt; model &lt;- lm(x$rand ~ x$factor))
&gt; summary(model)

Call:
lm(formula = x$rand ~ x$factor)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.74118 -0.89259  0.02904  0.59726  3.19762 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  -0.1878     0.1845  -1.018    0.311
x$factorB    -0.1284     0.2689  -0.477    0.634
x$factorC     0.4246     0.2689   1.579    0.118

Residual standard error: 1.107 on 97 degrees of freedom
Multiple R-squared: 0.04345, Adjusted R-squared: 0.02372 
F-statistic: 2.203 on 2 and 97 DF,  p-value: 0.1160
</code></pre>

<p>This tells me everything I need, or does it not? I'm curious why you want to continue with an anova(model)</p>
"
"0.189466186686268","0.188501975914996","  8545","<p>I have some problems in using (and finding) the Chow test for structural breaks in a regression analysis using R. I want to find out if there are some structural changes including another variable (represents 3 spatial subregions).</p>

<p>Namely, is the regression with the subregions better than the overall model. Therefore I need some statistical validation. </p>

<p>I hope my problem is clear, isn't it?</p>

<p>Kind regards<br>
marco</p>

<p>Toy example in R:</p>

<pre><code>library(mlbench) # dataset
data(""BostonHousing"")

# data preparation
BostonHousing$region &lt;- ifelse(BostonHousing$medv &lt;= 
                               quantile(BostonHousing$medv)[2], 1, 
                        ifelse(BostonHousing$medv &lt;= 
                               quantile(BostonHousing$medv)[3], 2,
                        ifelse(BostonHousing$medv &gt; 
                               quantile(BostonHousing$medv)[4], 3, 1)))

BostonHousing$region &lt;- as.factor(BostonHousing$region)

# regression without any subregion 
reg1&lt;- lm(medv ~ crim + indus + rm, data=BostonHousing)

summary(reg1)

# are there structural breaks using the factor ""region"" which
# indicates 3 spatial subregions
reg2&lt;- lm(medv ~ crim + indus + rm + region, data=BostonHousing)
</code></pre>

<p>------- subsequent entry</p>

<p>I struggled with your suggested package ""strucchange"", not knowing how to use the ""from"" and ""to"" arguments correctly with my factor ""region"". Nevertheless, I found one hint to calculate it by hand (https://stat.ethz.ch/pipermail/r-help/2007-June/133540.html). This results in the following output, but now I am not sure if my interpetation is valid. The results from the example above below.</p>

<p>Does this mean that region 3 is significant different from region 1? Contrary, region 2 is not? Further, each parameter (eg region1:crim) represents the beta for each regime and the model for this region respectively? Finally, the ANOVA states that there is a signif. difference between these models and that the consideration of regimes leads to a better model?</p>

<p>Thank you for your advices!
Best Marco</p>

<pre><code>fm0 &lt;- lm(medv ~ crim + indus + rm, data=BostonHousing)
summary(fm0)
fm1 &lt;- lm(medv  ~ region / (crim + indus + rm), data=BostonHousing)
summary(fm1)
anova(fm0, fm1)
</code></pre>

<p>Results:</p>

<pre><code>Call:
lm(formula = medv ~ region/(crim + indus + rm), data = BostonHousing)

Residuals:
       Min         1Q     Median         3Q        Max 
-21.079383  -1.899551   0.005642   1.745593  23.588334 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    12.40774    3.07656   4.033 6.38e-05 ***
region2         6.01111    7.25917   0.828 0.408030    
region3       -34.65903    4.95836  -6.990 8.95e-12 ***
region1:crim   -0.19758    0.02415  -8.182 2.39e-15 ***
region2:crim   -0.03883    0.11787  -0.329 0.741954    
region3:crim    0.78882    0.22454   3.513 0.000484 ***
region1:indus  -0.34420    0.04314  -7.978 1.04e-14 ***
region2:indus  -0.02127    0.06172  -0.345 0.730550    
region3:indus   0.33876    0.09244   3.665 0.000275 ***
region1:rm      1.85877    0.47409   3.921 0.000101 ***
region2:rm      0.20768    1.10873   0.187 0.851491    
region3:rm      7.78018    0.53402  14.569  &lt; 2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 4.008 on 494 degrees of freedom
Multiple R-squared: 0.8142,     Adjusted R-squared: 0.8101 
F-statistic: 196.8 on 11 and 494 DF,  p-value: &lt; 2.2e-16

&gt; anova(fm0, fm1)
Analysis of Variance Table

Model 1: medv ~ crim + indus + rm
Model 2: medv ~ region/(crim + indus + rm)
  Res.Df     RSS Df Sum of Sq     F    Pr(&gt;F)    
1    502 18559.4                                 
2    494  7936.6  8     10623 82.65 &lt; 2.2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>
"
"0.0506369683541833","0.0503792721859878","  8877","<p>My <a href=""http://stats.stackexchange.com/questions/8846/kruskal-wallis-test-data-considerations"">struggle</a> with non-parametric methods continues... I'd like to apply a median polish instead of two-way ANOVA (normality and homoscedascity assumptions are violated, and $ n_{ij} $ are small, so I can't use CLT as an excuse). I've never used median polish so far, and our course in statistics taught us to worship ANOVA and forget about robust methods if basic assumptions are not met. I saw <a href=""http://stats.stackexchange.com/questions/3634/multi-way-nonparametric-anova"">this post</a> and it seems that median polish can be applied for two-way factorial design. Which technique do you find appropriate in case of violation of ANOVA assumptions?</p>

<p>Now, what are the basic data considerations for median polish (or any other technique you find appropriate in this case)? Same shape, homoscedascity? Any resource (link/reference) is appreciated. </p>

<p><hr />
P.S.</p>

<p>Note that I'm aware of <code>medpolish</code> function in R. </p>
"
"0.21483446221183","0.213741149963729"," 20026","<p>I'm familiar with post-hoc testing with <code>ANOVA</code> for exploring differences between a sequence of groups, but recently I've been reading about Change Point Analysis (especially the <code>R</code> packages <code>bcp</code>, <code>changepoint</code> and <code>strucchange</code>). </p>

<p>It looks like those packages only handle data where there is one data point per unit of time. I'm curious if they can be used with data where there are multiple data points per unit of time. Here's some example data representing the measurement of a single continuous variable on a number of specimens that have been dated to specific moments in time (no repeated measurements):</p>

<pre><code>a&lt;-data.frame(time=""1000"",x=rnorm(10,12,3))
b&lt;-data.frame(time=""2000"",x=rnorm(50,13,4))
c&lt;-data.frame(time=""3500"",x=rnorm(50,12,4))
d&lt;-data.frame(time=""5000"",x=rnorm(7,14,5))
e&lt;-data.frame(time=""7000"",x=rnorm(20,10,3))
f&lt;-data.frame(time=""7500"",x=rnorm(15,11,3))
g&lt;-data.frame(time=""9000"",x=rnorm(15,10,5))
h&lt;-data.frame(time=""9500"",x=rnorm(35,30,2))
i&lt;-data.frame(time=""10000"",x=rnorm(30,28,4))
a2i&lt;-rbind(a,b,c,d,e,f,g,h,i) 

library(ggplot2)
a2i$time&lt;-as.numeric(levels(a2i$time))[a2i$time] 
ggplot(a2i,aes(time,x))+stat_smooth()+geom_point()
</code></pre>

<p><img src=""http://i.stack.imgur.com/cASXS.png"" alt=""enter image description here""></p>

<p>Here's what I'd be most grateful for some advice on...</p>

<p>Q1. Would it be valid to do the Change Point Analysis on a vector like the means or medians of the groups? That would allow me to start with a 'one data point per unit of time' input format which would suit the <code>R</code> packages, as I understand them. I've seen it done with environmental data like monthly gas concentrations (from daily observations), but I thought I'd check.  </p>

<p>Q2. Is there a kind of Change Point Analysis that I can do on the raw data in <code>a2g</code> that will give me some measures of the probabilities of changes across the sequence? For example, something that will detect the change from time=9000 to time=9500, using all the data points in the sample? I'm guessing that if it was possible, someone would already have implemented and I just need a pointer to the relevant function.</p>

<p>Q3. In case Q2 can be answered 'yes', would the method change if the distribution of each group's values was non-normal (unlike my sample data)?</p>

<p>Q4. If Change Point Analysis is completely the wrong approach here, please let me know. I'm basically just curious about methods other than <code>ANOVA</code> for these kinds of data. Any other suggestions would be most welcome.</p>
"
"0.124034734589208","0.123403510468459"," 21692","<p>Please help!
I have recently been criticized for using pairwise comparisons to explain all three levels of a factor within a negative binomial GLM rather than all levels at once. I was told that it is ""long-winded"" and ""uneccessary"". I was under the impression that in GLMs one cannot bulk all levels of a factor together to obtain a test statistic and corresponding p-value.</p>

<p>Obviously if a factor is ""insignificant"" at any level then carrying out a post-hoc analysis is pointless. My levels all have there own p-values therefore I discussed these values from the below global model. I was told to do an ANOVA instead which I don't believe is suitable for overdispersed, zero-inflated data.</p>

<p>p-value for all levels of a factor anyone?</p>

<p>(Below, lower field layer 0, upper field layer 1 and change1 is in intercept)</p>

<pre><code>    Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
   -2.4284  -0.7956  -0.3862   0.4045   2.4233  

    Coefficients:
                            Estimate Std. Error z value Pr(&gt;|z|)   
    (Intercept)                    4.3410884  1.8219786   2.383  0.01719 * 
    Height                         0.0373584  0.0119929   3.115  0.00184 **
    Width                         -0.0007891  0.0008246  -0.957  0.33859   
    MeanMin                       -0.1731877  0.1404434  -1.233  0.21752   
    as.factor(Site_Treat)2        -0.4080256  0.2480438  -1.645  0.09998 . 
    as.factor(Change)2            -0.4940398  0.1755487  -2.814  0.00489 **
    as.factor(Change)3            -0.1613766  0.1763677  -0.915  0.36019   
    as.factor(Lower_Field_Layer)1  0.4873488  0.2931585   1.662  0.09643 . 
    as.factor(Lower_Field_Layer)2 -0.3292409  0.3717863  -0.886  0.37585   
    as.factor(Upper_Field_Layer)2 -0.0081040  0.3257734  -0.025  0.98015   
    ---
    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

   (Dispersion parameter for Negative Binomial(4.7795) family taken to be 1)

    Null deviance: 96.392  on 46  degrees of freedom
    Residual deviance: 47.968  on 37  degrees of freedom
    AIC: 403.94
</code></pre>

<p>Best wishes,
Platypezid</p>
"
"0.202547873416733","0.201517088743951"," 29981","<p>Let's have some linear model, for example just simple ANOVA:</p>

<pre><code># data generation
set.seed(1.234)                      
Ng &lt;- c(41, 37, 42)                    
data &lt;- rnorm(sum(Ng), mean = rep(c(-1, 0, 1), Ng), sd = 1)      
fact &lt;- as.factor(rep(LETTERS[1:3], Ng)) 

m1 = lm(data ~ 0 + fact)
summary(m1)
</code></pre>

<p>Result is as follows:</p>

<pre><code>Call:
lm(formula = data ~ 0 + fact)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.30047 -0.60414 -0.04078  0.54316  2.25323 

Coefficients:
      Estimate Std. Error t value Pr(&gt;|t|)    
factA  -0.9142     0.1388  -6.588 1.34e-09 ***
factB   0.1484     0.1461   1.016    0.312    
factC   1.0990     0.1371   8.015 9.25e-13 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 0.8886 on 117 degrees of freedom
Multiple R-squared: 0.4816,     Adjusted R-squared: 0.4683 
F-statistic: 36.23 on 3 and 117 DF,  p-value: &lt; 2.2e-16 
</code></pre>

<p>Now I try two different methods to estimate confidence interval of these parameters</p>

<pre><code>c = coef(summary(m1))

# 1st method: CI limits from SE, assuming normal distribution
cbind(low = c[,1] - qnorm(p = 0.975) * c[,2], 
    high = c[,1] + qnorm(p = 0.975) * c[,2])

# 2nd method
confint(m1)
</code></pre>

<h2>Questions:</h2>

<ol>
<li>What is the distribution of estimated linear regression coefficients? Normal or $t$?</li>
<li>Why do both methods yield different results? Assuming normal distribution and correct SE, I'd expect both methods to have the same result.</li>
</ol>

<p>Thank you very much!</p>

<p>data ~ 0 + fact</p>

<p><strong>EDIT after an answer</strong>:</p>

<p>The answer is exact, this will give exactly the same result as <code>confint(m1)</code>!</p>

<pre><code># 3rd method
cbind(low = c[,1] - qt(p = 0.975, df = sum(Ng) - 3) * c[,2], 
    high = c[,1] + qt(p = 0.975, df = sum(Ng) - 3) * c[,2])
</code></pre>
"
"0.336205574067695","0.334494593118811"," 32040","<p>I'm trying to analyze effect of Year on variable logInd for particular group of individuals (I have 3 groups). <strong>The simplest model:</strong></p>

<pre><code>&gt; fix1 = lm(logInd ~ 0 + Group + Year:Group, data = mydata)
&gt; summary(fix1)

Call:
lm(formula = logInd ~ 0 + Group + Year:Group, data = mydata)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.5835 -0.3543 -0.0024  0.3944  4.7294 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
Group1       4.6395740  0.0466217  99.515  &lt; 2e-16 ***
Group2       4.8094268  0.0534118  90.044  &lt; 2e-16 ***
Group3       4.5607287  0.0561066  81.287  &lt; 2e-16 ***
Group1:Year -0.0084165  0.0027144  -3.101  0.00195 ** 
Group2:Year  0.0032369  0.0031098   1.041  0.29802    
Group3:Year  0.0006081  0.0032666   0.186  0.85235    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 0.7926 on 2981 degrees of freedom
Multiple R-squared: 0.9717,     Adjusted R-squared: 0.9716 
F-statistic: 1.705e+04 on 6 and 2981 DF,  p-value: &lt; 2.2e-16 
</code></pre>

<p>We can see the Group1 is significantly declining, the Groups2 and 3 increasing but not significantly so.</p>

<p><strong>Clearly the individual should be random effect, so I introduce random intercept effect for each individual:</strong></p>

<pre><code>&gt; mix1a = lmer(logInd ~ 0 + Group + Year:Group + (1|Individual), data = mydata)
&gt; summary(mix1a)
Linear mixed model fit by REML 
Formula: logInd ~ 0 + Group + Year:Group + (1 | Individual) 
   Data: mydata 
  AIC  BIC logLik deviance REMLdev
 4727 4775  -2356     4671    4711
Random effects:
 Groups     Name        Variance Std.Dev.
 Individual (Intercept) 0.39357  0.62735 
 Residual               0.24532  0.49530 
Number of obs: 2987, groups: Individual, 103

Fixed effects:
              Estimate Std. Error t value
Group1       4.6395740  0.1010868   45.90
Group2       4.8094268  0.1158095   41.53
Group3       4.5607287  0.1216522   37.49
Group1:Year -0.0084165  0.0016963   -4.96
Group2:Year  0.0032369  0.0019433    1.67
Group3:Year  0.0006081  0.0020414    0.30

Correlation of Fixed Effects:
            Group1 Group2 Group3 Grp1:Y Grp2:Y
Group2       0.000                            
Group3       0.000  0.000                     
Group1:Year -0.252  0.000  0.000              
Group2:Year  0.000 -0.252  0.000  0.000       
Group3:Year  0.000  0.000 -0.252  0.000  0.000
</code></pre>

<p>It had an expected effect - the SE of slopes (coefficients Group1-3:Year) are now lower and the residual SE is also lower.</p>

<p><strong>The individuals are also different in slope so I also introduced the random slope effect:</strong></p>

<pre><code>&gt; mix1c = lmer(logInd ~ 0 + Group + Year:Group + (1 + Year|Individual), data = mydata)
&gt; summary(mix1c)
Linear mixed model fit by REML 
Formula: logInd ~ 0 + Group + Year:Group + (1 + Year | Individual) 
   Data: mydata 
  AIC  BIC logLik deviance REMLdev
 2941 3001  -1461     2885    2921
Random effects:
 Groups     Name        Variance  Std.Dev. Corr   
 Individual (Intercept) 0.1054790 0.324775        
            Year        0.0017447 0.041769 -0.246 
 Residual               0.1223920 0.349846        
Number of obs: 2987, groups: Individual, 103

Fixed effects:
              Estimate Std. Error t value
Group1       4.6395740  0.0541746   85.64
Group2       4.8094268  0.0620648   77.49
Group3       4.5607287  0.0651960   69.95
Group1:Year -0.0084165  0.0065557   -1.28
Group2:Year  0.0032369  0.0075105    0.43
Group3:Year  0.0006081  0.0078894    0.08

Correlation of Fixed Effects:
            Group1 Group2 Group3 Grp1:Y Grp2:Y
Group2       0.000                            
Group3       0.000  0.000                     
Group1:Year -0.285  0.000  0.000              
Group2:Year  0.000 -0.285  0.000  0.000       
Group3:Year  0.000  0.000 -0.285  0.000  0.000
</code></pre>

<h3><strong>But now, contrary to the expectation, the SE of slopes (coefficients Group1-3:Year) are now much higher, even higher than with no random effect at all!</strong></h3>

<p>How is this possible? I would expect that the random effect will ""eat"" the unexplained variability and increase ""sureness"" of the estimate!</p>

<p>However, the residual SE behaves as expected - it is lower than in the random intercept model.</p>

<p><a href=""http://artax.karlin.mff.cuni.cz/~ttel5535/pub/my_so_question_data.R"" rel=""nofollow"">Here is the data</a> if needed.</p>

<h2>Edit</h2>

<p>Now I realized astonishing fact. If I do the linear regression for each individual separately and then run ANOVA on the resultant slopes, <strong>I get exactly the same result as the random slope model!</strong> Would you know why?</p>

<pre><code>indivSlope = c()
for (indiv in 1:103) {
    mod1 = lm(logInd ~ Year, data = mydata[mydata$Individual == indiv,])
    indivSlope[indiv] = coef(mod1)['Year']
}

indivGroup = unique(mydata[,c(""Individual"", ""Group"")])[,""Group""]


anova1 = lm(indivSlope ~ 0 + indivGroup)
summary(anova1)

Call:
lm(formula = indivSlope ~ 0 + indivGroup)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.176288 -0.016502  0.004692  0.020316  0.153086 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)
indivGroup1 -0.0084165  0.0065555  -1.284    0.202
indivGroup2  0.0032369  0.0075103   0.431    0.667
indivGroup3  0.0006081  0.0078892   0.077    0.939

Residual standard error: 0.04248 on 100 degrees of freedom
Multiple R-squared: 0.01807,    Adjusted R-squared: -0.01139 
F-statistic: 0.6133 on 3 and 100 DF,  p-value: 0.6079 
</code></pre>

<p><a href=""http://artax.karlin.mff.cuni.cz/~ttel5535/pub/my_so_question_data.R"" rel=""nofollow"">Here is the data</a> if needed.</p>
"
"0.143222974807887","0.142494099975819"," 35072","<p>I made a model using repeated measures univariate ANOVA in R.</p>

<pre><code>&gt; g &lt;- aov(bis ~ x1 + x2 + bg.sol + x1:x2:I(bg.sol * k1) + Error(subject), coded)
&gt; summary.lm(g$Within)
Call:
NULL

Residuals:
     Min       1Q   Median       3Q      Max 
-24.7459  -4.8055  -0.1518   5.1696  17.6015 

Coefficients:
                     Estimate Std. Error t value Pr(&gt;|t|)    
x1                     3.1170     0.8444   3.691 0.000275 ***
x2                    -1.0906     0.1230  -8.864  &lt; 2e-16 ***
I(bg.sol * k1)         2.0522     1.0216   2.009 0.045645 *  
x1:x2:I(bg.sol * k1)  -0.3191     0.1254  -2.545 0.011543 *  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 7.256 on 246 degrees of freedom
Multiple R-squared: 0.2743, Adjusted R-squared: 0.2654 
F-statistic: 30.99 on 3 and 246 DF,  p-value: &lt; 2.2e-16 
</code></pre>

<p>I calculated confidence limit for each estimates. I thought SE * critical value would work. In case of <code>x1</code> (continuous variable) 95% confidence limit was,</p>

<pre><code>&gt; 0.8444 * qt(0.975, df = 1)
[1] 10.72912
</code></pre>

<p>I'm wondering whether the calculated value is real confidence limit for <code>x1</code>. The estimates for <code>x1</code> is 3.1170, and the limit is 10.72912. Plus-minus it includes zero value. But P-value showed value less than 0.05!</p>

<p>I want to know where I made an error!</p>
"
"0.124034734589208","0.123403510468459"," 37466","<p>I am taking a graduate course in Applied Statistics that uses the following textbook (to give you a feel for the level of the material being covered): <a href=""http://amzn.com/0471072044"">Statistical Concepts and Methods</a>, by G. K. Bhattacharyya and R. A. Johnson.</p>

<p>The Professor requires us to use SAS for the homeworks. </p>

<p>My question is that: is there a Java library(ies), that can be used instead of SAS for problems typically seen in such classes.</p>

<p>I am currently trying to make do with <a href=""http://commons.apache.org/math/"">Apache Math Commons</a> and though I am impressed with the library (it's ease of use and understandability) it seems to lack even simple things such as the ability to draw histograms (thinking of combining it with a charting library).</p>

<p>I have looked at Colt, but my initial interest died down pretty quickly. </p>

<p>Would appreciate any input -- and I've looked at similar questions on Stackoverflow but have not found anything compelling.</p>

<p>NOTE: I am aware of R, SciPy and Octave and java libraries that make calls to them -- I am looking for a Java native library or set of libraries that can together provide the features I'm looking for.</p>

<p>NOTE: The topics covered in such a class typically include: one-samle and two-sample tests and confidence intervals for means and medians, descriptive statistics, goodness-of-fit tests, one- and two-way ANOVA, simultaneous inference, testing variances, regression analysis, and categorical data analysis.</p>
"
"0.175411603861406","0.174518918148945"," 51826","<p>I have a question on how a statistician would normally interpret an anova output. Say I have anova output from R.</p>

<pre><code>&gt; summary(fitted_data)

Call:
lm(formula = V1 ~ V2)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.74004 -0.33827  0.04062  0.44064  1.22737 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.11405    0.32089   6.588  1.3e-09 ***
V2           0.03883    0.01277   3.040  0.00292 ** 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 0.6231 on 118 degrees of freedom
Multiple R-squared: 0.07262,    Adjusted R-squared: 0.06476 
F-statistic:  9.24 on 1 and 118 DF,  p-value: 0.002917 

&gt; anova(fit)
Analysis of Variance Table

Response: V1
           Df Sum Sq Mean Sq F value   Pr(&gt;F)   
V2          1  3.588  3.5878  9.2402 0.002917 **
Residuals 118 45.818  0.3883                    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
</code></pre>

<p>From the above, I guess the most important value is Pr(>F), right? So this Pr, is less than 0.05 (95% level). How should my ""explain"" this? Do I explain it in ""association"", ie, V2 and V1 are associated (or not) ? or in terms of ""significance""? I always felt that I couldn't understand when people say ""This value is significant...."". So what is ""significant""? Is there a more intuitive form of explanation? like ""I am 95% confident that ...."" . </p>

<p>Also, is the Pr value the only important piece of information? or can i also look at residuals and the rest of the output to ""explain"" the result? thanks</p>
"
"0.286445949615773","0.267176437454661"," 58321","<p>I need some help with the statistical analysis of a study of a particular surgery to remove a particular cancer. I am using the statistical program R to conduct my analysis. My data are saved in the object <code>study_data</code>.</p>

<h3>Data</h3>

<pre><code># Create reproducible example data
set.seed(50)

study_data &lt;- data.frame(
              Patient_ID = 1:500,
              Institution = sample(c(""New York"",""San Francisco"",""Houston"",""Chicago""),500,T),
              Gender = sample(c(""Male"",""Female""),500,T),
              Race = sample(c(""White"",""Black"",""Hispanic"",""Asian""),500,T),
              Tumor_grade = sample(c(""One"",""Two"",""Three"",""Four""),500,T),
              Pathologic_stage = sample(c(""P0"",""Pa"",""Pis"",""P1"",""P2a"",""P2b"",""P3a"",""P3b"",""P4a"",""P4b""),500,T),
              Treatment_arm = sample(c(""One"",""Two"",""Three"",""Four""),500,T),
              Surgery_age = round(runif(500,20,100)),
              Nodes_removed = round(runif(500,1,130)))
</code></pre>

<p>Here is what the data look like:</p>

<pre><code># Peak at the first six lines of the data
head(study_data)

  Patient_ID   Institution Gender     Race Tumor_grade Pathologic_stage Treatment_arm Surgery_age Nodes_removed
1          1       Houston   Male Hispanic         One              P2b           Two          77           130
2          2 San Francisco Female Hispanic       Three               Pa           Two          38           112
3          3      New York Female    Black        Four               P0          Four          90            90
4          4       Chicago   Male Hispanic         Two              Pis          Four          46             4
5          5       Houston Female    Black        Four              P2a          Four          96           114
6          6      New York   Male    Black       Three              P3b          Four          92             7
</code></pre>

<h3>My interest</h3>

<p>I am interested in learning more about what variables are associated with the number of lymph nodes removed during the surgery. My first thought was to simply stratify the data by a particular variable and then calculate the median number of nodes removed.</p>

<p>For example, to see if the institution at which the surgery was performed mattered, I could write:</p>

<pre><code>cbind(do.call(rbind, by(study_data$Nodes_removed, study_data$Institution, summary)))

              Min. 1st Qu. Median  Mean 3rd Qu. Max.
Chicago          1   25.50   65.5 64.48   98.75  129
Houston          1   40.00   71.0 69.26  100.00  130
New York         4   36.00   67.0 67.96  100.00  129
San Francisco    3   36.75   61.0 65.76   99.00  127
</code></pre>

<p>This lets me compare the median nodes removed in each institutional city.</p>

<h3>My question</h3>

<p>I would like to fully examine the association between all of my variables and the outcome <code>Nodes_removed</code>.</p>

<ol>
<li>Should I just do these simple summary statistics for all of my variables?</li>
<li>Do I need to perform some sort of hypothesis test for all of the associations to say whether or not the summary statistics differ? For example, should I calculate a median and a confidence interval for each comparison?</li>
<li>Or should I be using t-tests to compare one group to another?</li>
<li>In the case of a multi-level variable, should I use ANOVA?</li>
<li>Is there any role for linear regression analysis here? </li>
<li>If I wanted to build a single model that includes every possible predictor variable, what method should I use?</li>
</ol>

<p>For example, say that I am most interested in the association between the age at which the surgery was performed, <code>Surgery_age</code>, and <code>Nodes_removed</code>. However, I would like to adjust this association for potential confounders like gender, race, tumor grade, treatment arm, etc. What is the best way for me to do this?</p>

<p>Thanks for any advice you can give!</p>
"
"0.190963966410515","0.213741149963729"," 58700","<p>I am having some trouble running an Anova on categorical variables in R and matching SPSS output. What I need to do is run an anova on the dataset below (its a made up data set).  But, I need to know if the mean of each category is significantly from the total mean of all races.  </p>

<pre><code>Satisfaction    Race
3   Asian
4   Cacasion
5   African American
2   Other 
5   African American
3   African American
4   African American
5   African American
2   Asian
3   African American
1   Cacasion
1   Cacasion
1   Cacasion
5   Other 
5   Other 
5   Other 
5   African American
5   Asian
4   Asian
5   Other 
5   Other 
5   Other 
1   Cacasion
4   Cacasion
</code></pre>

<p>For example, the mean of all races is 3.5 :</p>

<pre><code>&gt; mean(test$Satisfaction)
[1] 3.5 
</code></pre>

<p>What I would like to know is if the mean score for each race is significantly different from the total mean of 3.5 and the p-value.</p>

<p>I ran an Anova in R with the following model, but R will set one catagory as the refernce and test is against the others :</p>

<pre><code>&gt; lm.test &lt;- lm(test$Satisfaction ~ test$Race)
&gt; summary(lm.test)

Call:
lm(formula = test$Satisfaction ~ test$Race)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.5714 -1.0000  0.4286  0.8482  2.0000 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         3.8571     0.5023   7.679 2.18e-07 ***
test$RaceAsian     -0.6071     0.8330  -0.729   0.4745    
    test$RaceCacasion  -1.8571     0.7394  -2.512   0.0207 *  
test$RaceOther      0.7143     0.7103   1.006   0.3266    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

Residual standard error: 1.329 on 20 degrees of freedom
Multiple R-squared: 0.391,  Adjusted R-squared: 0.2997 
F-statistic:  4.28 on 3 and 20 DF,  p-value: 0.01732 
</code></pre>

<p>The output is telling me that the mean for African American is 3.8571 and is significantly different from the mean of the caucasian group.  It is not different from the mean of group Asian and Other.  </p>

<p>Is there a way for me to set the intercept to 3.5 in R and get significant compared to the mean and not the reference group.  Or should I be using another tests altogether?  My stats isn't that great so if its another tests a brief explain on which test and how to run it in R would be great.  </p>
"
"0.146176336551172","0.174518918148945"," 62756","<p>I have 3 within-subject factors, namely <code>offset</code> (1px, ..., 5px), <code>side</code> (left, right) and <code>color</code> (red, green), which define the characteristics of the stimulus in a reaction time experiment. The DV is reaction time <code>RT</code>. The design is fully balanced. </p>

<p>I ran a repeated measures ANOVA in R, like this: </p>

<pre><code>options(contrasts = c(""contr.helmert"", ""contr.poly""))

simon.aov &lt;- aov(median.RT ~ color*side*offset + Error(VP / (color*side*offset)), data=dfa)
</code></pre>

<p>The results revealed a significant main effect of the <code>color</code>, as well as a significant interaction <code>color x side</code> and a significant 3-way interaction <code>color x side x offset</code>.<br>
My primary focus lies on the interactions. <strong>Specifically, I want to know on which of the 5 offsets (i.e. on which levels of the third factor) the 2-way interaction <code>color x side</code> reaches significance.</strong> </p>

<p>I am by no means familiar with post-hoc contrasts and multiple comparisons, but this question is the gist of the thesis that I'm working on. So my progress depends on an adequate test to examine this question. </p>

<p>I highly appreciate any help on which test to run, and how to do this most efficiently in R. </p>

<h2>Edit:</h2>

<p>I'm sorry I didn't provide any plots earlier.  </p>

<p>@John: Here is the plot you requested.</p>

<p><img src=""http://i.stack.imgur.com/Z6alg.png"" alt=""Plot 1 of 3-way anova results""> </p>

<p>However, I believe, that this following plot rather clarifies my question: </p>

<p><img src=""http://i.stack.imgur.com/wCtKH.png"" alt=""Plot 2 of 3-way anova results""></p>

<p>It seems like there is no <code>color x side</code> interaction at the first 3 levels of <code>offset</code>, but this interaction emerges at <code>offset</code> 4 and 5. This is what the plot seems to imply, however I don't know how to prove it statistically. </p>
"
"0.177229389239642","0.201517088743951"," 63913","<p>I conducted an experiment in a factorial design: I measured light (PAR) in three herbivore treatments as well as six nutrient treatments. The experiment was blocked.</p>

<p>I've run the linear model as follows (you can download the data from my website to replicate)</p>

<pre><code>dat &lt;- read.csv('http://www.natelemoine.com/testDat.csv')
mod1 &lt;- lm(light ~ Nutrient*Herbivore + BlockID, dat)
</code></pre>

<p>The residual plots look pretty good</p>

<pre><code>par(mfrow=c(2,2))
plot(mod1)
</code></pre>

<p>When I look at the ANOVA table, I see main effects of Nutrient and Herbivore. </p>

<pre><code>anova(mod1)

Analysis of Variance Table 

Response: light 
                    Df  Sum Sq Mean Sq F value    Pr(&gt;F)     
Nutrient             5  4.5603 0.91206  7.1198 5.152e-06 *** 
Herbivore            2  2.1358 1.06791  8.3364 0.0003661 *** 
BlockID              9  5.6186 0.62429  4.8734 9.663e-06 *** 
Nutrient:Herbivore  10  1.7372 0.17372  1.3561 0.2058882     
Residuals          153 19.5996 0.12810                       
--- 
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
</code></pre>

<p>However, the regression table shows non-significant main effects and significant interactions.</p>

<pre><code>summary(mod1)

Call: 
lm(formula = light ~ Nutrient * Herbivore + BlockID, data = dat) 

Residuals: 
     Min       1Q   Median       3Q      Max  
-0.96084 -0.19573  0.01328  0.24176  0.74200  

Coefficients: 
                           Estimate Std. Error t value Pr(&gt;|t|)     
(Intercept)                1.351669   0.138619   9.751  &lt; 2e-16 *** 
Nutrientb                  0.170548   0.160064   1.066  0.28833     
Nutrientc                 -0.002172   0.160064  -0.014  0.98919     
Nutrientd                 -0.163537   0.160064  -1.022  0.30854     
Nutriente                 -0.392894   0.160064  -2.455  0.01522 *   
Nutrientf                  0.137610   0.160064   0.860  0.39129     
HerbivorePaired           -0.074901   0.160064  -0.468  0.64049     
HerbivoreZebra            -0.036931   0.160064  -0.231  0.81784     
... 
Nutrientb:HerbivorePaired  0.040539   0.226364   0.179  0.85811     
Nutrientc:HerbivorePaired  0.323127   0.226364   1.427  0.15548     
Nutrientd:HerbivorePaired  0.642734   0.226364   2.839  0.00513 **  
Nutriente:HerbivorePaired  0.454013   0.226364   2.006  0.04665 *   
Nutrientf:HerbivorePaired  0.384195   0.226364   1.697  0.09168 .   
Nutrientb:HerbivoreZebra   0.064540   0.226364   0.285  0.77594     
Nutrientc:HerbivoreZebra   0.279311   0.226364   1.234  0.21913     
Nutrientd:HerbivoreZebra   0.536160   0.226364   2.369  0.01911 *   
Nutriente:HerbivoreZebra   0.394504   0.226364   1.743  0.08338 .   
Nutrientf:HerbivoreZebra   0.324598   0.226364   1.434  0.15362     
--- 
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.3579 on 153 degrees of freedom 
Multiple R-squared:  0.4176,    Adjusted R-squared:  0.3186  
F-statistic: 4.219 on 26 and 153 DF,  p-value: 8.643e-09 
</code></pre>

<p>I know that this question has been previously <a href=""http://stats.stackexchange.com/questions/20002/regression-vs-anova-discrepancy"">asked and answered</a> in <a href=""http://stats.stackexchange.com/questions/28938/why-do-linear-regression-and-anova-give-different-p-value-in-case-of-consideri"">multiple posts</a>. In the earlier posts, the issue revolved around the different types of SS used in anova() and lm(). However, I don't think that is the issue here. First of all, the design is balanced:</p>

<pre><code>with(dat, tapply(light, list(Nutrient, Herbivore), length))
</code></pre>

<p>Second, using the Anova() option doesn't change the anova table. This isn't a surprise because the design is balanced.</p>

<pre><code>Anova(mod1, type=2)
Anova(mod1, type=3)
</code></pre>

<p>Changing the contrast doesn't change the results (qualitatively). I still get pretty much backwards intepretations from anova() vs. summary().</p>

<pre><code>options(contrasts=c(""contr.sum"",""contr.poly""))
mod2 &lt;- lm(light ~ Nutrient*Herbivore + BlockID, dat)
anova(mod2)
summary(mod2)
</code></pre>

<p>I'm confused because everything I've read on regression not agreeing with ANOVA implicates differences in the way R uses SS for summary() and anova() functions. However, in the balanced design, the SS types are equivalent, and the results here don't change. How can I have completely opposite interpretations depending on which output I use?</p>
"
"0.30697030675746","0.334494593118811"," 64010","<p>I am wondering what the exact relationship between partial $R^2$ and coefficients in a linear model is and whether I should use only one or both to illustrate the importance and influence of factors.</p>

<p>As far as I know, with <code>summary</code> I get estimates of the coefficients, and with <code>anova</code> the sum of squares for each factor - the proportion of the sum of squares of one factor divided by the sum of the sum of squares plus residuals is partial $R^2$ (the following code is in <code>R</code>).</p>

<pre><code>library(car)
mod&lt;-lm(education~income+young+urban,data=Anscombe)
    summary(mod)

Call:
lm(formula = education ~ income + young + urban, data = Anscombe)

Residuals:
    Min      1Q  Median      3Q     Max 
-60.240 -15.738  -1.156  15.883  51.380 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -2.868e+02  6.492e+01  -4.418 5.82e-05 ***
income       8.065e-02  9.299e-03   8.674 2.56e-11 ***
young        8.173e-01  1.598e-01   5.115 5.69e-06 ***
urban       -1.058e-01  3.428e-02  -3.086  0.00339 ** 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 26.69 on 47 degrees of freedom
Multiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 
F-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12

anova(mod)
Analysis of Variance Table

Response: education
          Df Sum Sq Mean Sq F value    Pr(&gt;F)    
income     1  48087   48087 67.4869 1.219e-10 ***
young      1  19537   19537 27.4192 3.767e-06 ***
urban      1   6787    6787  9.5255  0.003393 ** 
Residuals 47  33489     713                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>The size of the coefficients for 'young' (0.8) and 'urban' (-0.1, about 1/8 of the former, ignoring '-') does not match the explained variance ('young' ~19500 and 'urban' ~6790, i.e. around 1/3).</p>

<p>So I thought I would need to scale my data because I assumed that if a factor's range is much wider than another factor's range their coefficients would be hard to compare:</p>

<pre><code>Anscombe.sc&lt;-data.frame(scale(Anscombe))
mod&lt;-lm(education~income+young+urban,data=Anscombe.sc)
summary(mod)

Call:
lm(formula = education ~ income + young + urban, data = Anscombe.sc)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.29675 -0.33879 -0.02489  0.34191  1.10602 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.084e-16  8.046e-02   0.000  1.00000    
income       9.723e-01  1.121e-01   8.674 2.56e-11 ***
young        4.216e-01  8.242e-02   5.115 5.69e-06 ***
urban       -3.447e-01  1.117e-01  -3.086  0.00339 ** 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.5746 on 47 degrees of freedom
Multiple R-squared:  0.6896,    Adjusted R-squared:  0.6698 
F-statistic: 34.81 on 3 and 47 DF,  p-value: 5.337e-12

anova(mod)
Analysis of Variance Table

Response: education
          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
income     1 22.2830 22.2830 67.4869 1.219e-10 ***
young      1  9.0533  9.0533 27.4192 3.767e-06 ***
urban      1  3.1451  3.1451  9.5255  0.003393 ** 
Residuals 47 15.5186  0.3302                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1    
</code></pre>

<p>But that doesn't really make a difference, partial $R^2$ and the size of the coefficients (these are now <em>standardized coefficients</em>) still do not match:</p>

<pre><code>22.3/(22.3+9.1+3.1+15.5)
# income: partial R2 0.446, Coeff 0.97
9.1/(22.3+9.1+3.1+15.5)
# young:  partial R2 0.182, Coeff 0.42
3.1/(22.3+9.1+3.1+15.5)
# urban:  partial R2 0.062, Coeff -0.34
</code></pre>

<p><strong>So is it fair to say that 'young' explains three times as much variance as 'urban' because partial $R^2$ for 'young' is three times that of 'urban'?</strong> Why is the coefficient of 'young' then not three times that of 'urban' (ignoring the sign)?</p>

<p>I suppose the answer for this question will then also tell me the answer to my initial query: Should I use partial $R^2$ or coefficients to illustrate the relative importance of factors? (Ignoring direction of influence - sign - for the time being.)</p>

<p><strong>Edit:</strong></p>

<p>Partial eta-squared appears to be another name for what I called partial $R^2$. <a href=""http://www.inside-r.org/packages/cran/heplots/docs/etasq"">etasq {heplots}</a> is a useful function that produces similar results:</p>

<pre><code>etasq(mod)
          Partial eta^2
income        0.6154918
young         0.3576083
urban         0.1685162
Residuals            NA
</code></pre>
"
"0.175411603861406","0.174518918148945"," 81368","<p>I'm reproducing an example from <a href=""http://rads.stackoverflow.com/amzn/click/0470073713"">Generalized, Linear, and Mixed Models</a>. My MWE is below:</p>

<pre><code>Dilution &lt;- c(1/128, 1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4)
NoofPlates &lt;- rep(x=5, times=10)
NoPositive &lt;- c(0, 0, 2, 2, 3, 4, 5, 5, 5, 5)
Data &lt;- data.frame(Dilution,  NoofPlates, NoPositive)

fm1 &lt;- glm(formula=NoPositive/NoofPlates~log(Dilution), family=binomial(""logit""), data=Data)
summary(object=fm1)
</code></pre>

<hr>

<p><strong>Output</strong></p>

<hr>

<pre><code>Call:
glm(formula = NoPositive/NoofPlates ~ log(Dilution), family = binomial(""logit""), 
    data = Data)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-0.38326  -0.20019   0.00871   0.15607   0.48505  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)      4.174      2.800   1.491    0.136
log(Dilution)    1.623      1.022   1.587    0.112

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 8.24241  on 9  degrees of freedom
Residual deviance: 0.64658  on 8  degrees of freedom
AIC: 6.8563

Number of Fisher Scoring iterations: 6
</code></pre>

<hr>

<p><strong>Code</strong></p>

<hr>

<pre><code>anova(object=fm1, test=""Chisq"")
</code></pre>

<hr>

<p><strong>Output</strong></p>

<hr>

<pre><code>Analysis of Deviance Table

Model: binomial, link: logit

Response: NoPositive/NoofPlates

Terms added sequentially (first to last)


              Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)   
NULL                              9     8.2424            
log(Dilution)  1   7.5958         8     0.6466  0.00585 **
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<hr>

<p><strong>Code</strong></p>

<hr>

<pre><code>library(aod)
wald.test(b=coef(object=fm1), Sigma=vcov(object=fm1), Terms=2)
</code></pre>

<hr>

<p><strong>Output</strong></p>

<hr>

<pre><code>Wald test:
----------

Chi-squared test:
X2 = 2.5, df = 1, P(&gt; X2) = 0.11
</code></pre>

<p>Estimated coefficients are perfectly matching with the results given in the book but SE's are far apart. Based on LRT test the slope  is significant but based on Wald and Z-test slope coefficient is insignificant. I wonder if I miss something basic. Thanks in advance for your help.</p>
"
"0.189466186686268","0.188501975914996"," 85563","<p>I am trying to fit a negative binomial GLM to fish catch data with month of the year (factor) as my explanatory variable. I have selected the month with the greatest number of catches as my reference level and fitted the model using the <code>glm.nb()</code> function from the MASS package.</p>

<pre><code>model1&lt;-glm.nb(catch~month+offset(log(Duration_hours*NumberHooksDeployed)),
 catchdata)
</code></pre>

<p>Using <code>anova(model1)</code> shows that the factor <code>month</code> is significant and my pseudo $R^2$ is about 55%. The problem I have is that months with no catches at all have p-values greater than 0.05 (close to 1), even though I would expect them to be significantly lower than the reference level. Months with only very few catches are significant on the other hand. The output from the <code>predict()</code> function makes sense, so I think the model should be fine.
Is there a problem with the likelihood test R uses, or am I fitting the wrong model to my data? From other posts I figured that I might have to use a likelihood ratio rather than Wald's test; any suggestions on how to do that in R?
Any help would be greatly appreciated. See model output below, the months with 0 catches are May and June:</p>

<pre><code>Call:
glm.nb(formula = NumCaught ~ factor(month) + offset(log(Effort_mins * 
Nhooks)), data = f[f$Area == ""PW"", ], init.theta = 1.181267049, 
link = log)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-1.8445  -0.7766  -0.2148   0.0000   1.5386  

Coefficients:
                     Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)            -2.647e+00  3.192e-01  -8.292  &lt; 2e-16 ***
factor(month)May       -2.754e+01  1.024e+05   0.000 0.999785    
factor(month)June      -2.790e+01  3.122e+05   0.000 0.999929    
factor(month)September -2.516e+00  6.516e-01  -3.861 0.000113 ***
factor(month)December  -1.112e-01  4.403e-01  -0.253 0.800543    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for Negative Binomial(1.1813) family taken to be 1)

Null deviance: 80.420  on 45  degrees of freedom
Residual deviance: 36.178  on 41  degrees of freedom
AIC: 140.81

Number of Fisher Scoring iterations: 1


          Theta:  1.181 
      Std. Err.:  0.525 

2 x log-likelihood:  -128.815 
</code></pre>
"
"0.202547873416733","0.201517088743951"," 89692","<p>My data has 3 major inputs: <code>BLDDAY</code> (a factor), <code>BLDMNT</code> (a factor), and <code>D_BLD_SER</code> (days as an integer variable).  The output is whether input variable has any impact on failure.  My model is: <code>model = glm(FAILED~BLDDAY+BLDMNT+D_BLD_SER, family=""binomial"", data=data_list)</code>.  (I used <a href=""http://www.ats.ucla.edu/stat/r/dae/logit.htm"" rel=""nofollow"">UCLA's statistics help site's guide to logistic regression in R</a> to build this model.)  </p>

<p>Output: </p>

<pre><code>Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.3282  -0.9123  -0.8128   1.4056   2.1053  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)     -0.7672583  0.1317132  -5.825 5.70e-09 ***
BLDDAYMonday    -0.1545646  0.0839380  -1.841  0.06556 .  
BLDDAYSaturday  -0.1257976  0.2028259  -0.620  0.53511    
BLDDAYSunday    -0.1183008  0.1868713  -0.633  0.52669    
BLDDAYThursday  -0.2007452  0.0772653  -2.598  0.00937 ** 
BLDDAYTuesday    0.0480453  0.0758603   0.633  0.52651    
BLDDAYWednesday -0.0358585  0.0760027  -0.472  0.63707    
BLDMNTAug        0.3009445  0.1405545   2.141  0.03226 *  
BLDMNTDec        0.5562170  0.1338467   4.156 3.24e-05 ***
BLDMNTFeb        0.3334978  0.2133475   1.563  0.11801    
BLDMNTJan        0.4076504  0.2277978   1.790  0.07353 .  
BLDMNTJul        0.1306585  0.1415302   0.923  0.35591    
BLDMNTJun       -0.0357361  0.1428105  -0.250  0.80241    
BLDMNTMar        0.4570491  0.1949815   2.344  0.01907 *  
BLDMNTMay       -0.2292620  0.1614577  -1.420  0.15562    
BLDMNTNov        0.3060012  0.1334034   2.294  0.02180 *  
BLDMNTOct        0.2390501  0.1341877   1.781  0.07484 .  
BLDMNTSep        0.2481405  0.1384901   1.792  0.07317 .  
D_BLD_SER       -0.0020960  0.0003367  -6.225 4.82e-10 ***

(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 10288  on 8182  degrees of freedom
Residual deviance: 10154  on 8164  degrees of freedom
AIC: 10192
Number of Fisher Scoring iterations: 4
</code></pre>

<p>The ANOVA table is the following:</p>

<pre><code>anova(model, test=""Chisq"")
Analysis of Deviance Table
Model: binomial, link: logit
Response: FAILED
Terms added sequentially (first to last)

          Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                       8182      10288              
BLDDAY     6   20.392      8176      10268  0.002357 ** 
BLDMNT    11   70.662      8165      10197 9.142e-11 ***
D_BLD_SER  1   43.797      8164      10154 3.642e-11 ***
</code></pre>

<p>My questions are:</p>

<ol>
<li><p>Although the p-values for all three components are less than 0.05, which can be considered as significant, the deviance reduced due to each component is less than 1% of the total deviance. <strong>Normally the interpretation of output like this is input parameter affects output and it's better to use this parameter then using noting.</strong> But does it really make sense of taking this parameter as significant input?</p></li>
<li><p>The p-values for <code>BLDDAY</code> and <code>BLDMNT</code> given by <code>anova()</code> is the overall p-value,  which is significant, but <code>summary()</code> gives detailed impact of each factor level. If I consider the p-values for each factor overall <code>BLDDAY</code> is significant but individually only <code>BLDDAYThursday</code> is significant. I am bit confused not as whether to consider <code>BLDDAY</code> as significant input, or Thursday only, or Thursday &amp; Friday both.</p></li>
</ol>
"
"0.277350098112615","0.275938638069581"," 92284","<p>I have asked a similar question here: <a href=""http://stackoverflow.com/questions/22648335/interpretation-of-interaction-term-in-r-lm-l-q"">stackoverflow</a> I am puzzled by the interpretation for an interaction term. In my data my Y is an interval variable with the health outcome of an experiment. I have used an interaction term in which I have interacted the condition with the predisposition of the subject considering health status at base level. They are both categorical variables (factor variables in R).</p>

<p>Now it gets complicated because the Condition was two treatments: in treatment A subjects got the placebo first and then the real medicine whereas in treatment B they go the real medicine first and the placebo second. All it changes is the order. </p>

<pre><code>Health outcome = a + Condition * Health.Base
</code></pre>

<p>I have the worst state of health at the base level as my reference category I find that interaction with the Condition is statistically significant but I am not sure how to interpret this.</p>

<p>I use the <code>lm()</code> function of R (although my design looks more like an ANOVA) and in the output I get the b coefficient in an output that looks like this:</p>

<pre><code>ConditionB:Health.Base.So.and.So         (Beta and p-value)
ConditionB:Health.Base.Excellent         (Beta and p-value)
</code></pre>

<p>A statistically significant interaction term for those in Excellent health at baseline would mean that they are affected by the Condition B more than Condition A compared to the reference category people (Poor health at baseline). Is this right? What does the beta-coefficient represent? </p>

<p>If I would like to examine for each Health category at the base line separately without comparing to a reference category I would have to code each category as a dummy variable. However, in this case I would compare whether membership to a specific health status at the base line significantly changes between conditions compared to those who belong to the other health statuses at the base line. Is this right? Again, what does the beta-coefficient represent?</p>

<p>Would it be right to assume that the choice of the interaction between the Condition and the dummy variables is easier to interpret?</p>

<p>--- EDIT ---
R output:</p>

<pre><code>Call:
lm(formula = HealthOutcome ~ Condition * HealthStatus, 
    data = datA)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.5957 -0.5942 -0.2640  0.4423  2.4423 

Coefficients:
                                       Estimate Std. Error t value     Pr(&gt;|t|)    
(Intercept)                            2.595652   0.053044  48.934  &lt; 2e-16 ***
ConditionCondB                        -0.001449   0.077071  -0.019    0.985    
HealthStatusSo.and.So                 -0.331693   0.078094  -4.247  2.35e-05 ***
HealthStatusExcellent                 -0.836724   0.092692  -9.027  &lt; 2e-16 ***
ConditionCondB:HealthStatusSo.and.So   0.137490   0.110612   1.243    0.214    
ConditionCondB:HealthStatusExcellent  -0.199787   0.133943  -1.492    0.136    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.8045 on 1059 degrees of freedom
  (68 observations deleted due to missingness)
Multiple R-squared:   0.16, Adjusted R-squared:  0.156 
F-statistic: 40.33 on 5 and 1059 DF,  p-value: &lt; 2.2e-16
</code></pre>
"
"0.202547873416733","0.201517088743951","110917","<p>Suppose I create a dummy scenario as such:</p>

<pre><code>&gt; A &lt;- rnorm(10000) 
&gt; B &lt;- rnorm(10000) 
&gt; C &lt;- rnorm(10000) 
&gt; Y &lt;- A*B + rnorm(10000,sd=0.1)
</code></pre>

<p>Doing a simple ANOVA correctly identifies that none of the variables are significantly predictive of the outcome:</p>

<pre><code>&gt; anova(lm(Y~A+B+C))
Analysis of Variance Table

Response: Y
            Df  Sum Sq Mean Sq F value Pr(&gt;F)
A            1     1.5 1.54411  1.4209 0.2333
B            1     0.3 0.28909  0.2660 0.6060
C            1     1.6 1.62425  1.4946 0.2215
Residuals 9996 10862.8 1.08672    
</code></pre>

<p>But not let's say I decide to include the interaction terms:</p>

<pre><code>&gt; anova(lm(Y~A*B*C))
Analysis of Variance Table

Response: Y
           Df  Sum Sq Mean Sq    F value    Pr(&gt;F)    
A            1     1.5     1.5 1.5281e+02 &lt; 2.2e-16 ***
B            1     0.3     0.3 2.8610e+01  9.05e-08 ***
C            1     1.6     1.6 1.6074e+02 &lt; 2.2e-16 ***
A:B          1 10761.8 10761.8 1.0650e+06 &lt; 2.2e-16 ***
A:C          1     0.0     0.0 9.8700e-02    0.7534    
B:C          1     0.0     0.0 1.5062e+00    0.2197    
A:B:C        1     0.0     0.0 1.6790e-01    0.6820    
Residuals 9992   101.0     0.0                         
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>It has correctly identified the interaction between A and B as being the most significant, but now for some reason the individual terms A and B have also gained significance... and C which had nothing at all to do with creating the model is significant as well?  Either I have not written the test correctly or I am completely misunderstanding how a Two-Way ANOVA with interaction terms works</p>

<p>Using a simple linear model gives expected results:</p>

<pre><code>&gt; summary(lm(Y~A*B*C))

Call:
lm(formula = Y ~ A * B * C)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29566 -0.06667 -0.00092  0.06665  0.33620 

Coefficients:
              Estimate Std. Error  t value Pr(&gt;|t|)    
(Intercept) -0.0003212  0.0009707   -0.331    0.741    
A            0.0003483  0.0009613    0.362    0.717    
B            0.0003184  0.0009619    0.331    0.741    
C           -0.0003213  0.0009702   -0.331    0.741    
A:B          1.0008711  0.0009370 1068.214   &lt;2e-16 ***
A:C         -0.0014855  0.0009588   -1.549    0.121    
B:C          0.0008860  0.0009561    0.927    0.354    
A:B:C       -0.0002489  0.0009085   -0.274    0.784    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.09705 on 9992 degrees of freedom
Multiple R-squared:  0.9913,    Adjusted R-squared:  0.9913 
F-statistic: 1.634e+05 on 7 and 9992 DF,  p-value: &lt; 2.2e-16
</code></pre>
"
"0.343735139538928","0.356235249939548","115065","<p>I am working with data from a computer task which has 288 total trials, each of which can be categorically classified according to <strong>Trial Type</strong>, <strong>Number of Stimuli</strong>, and <strong>Probe Location</strong>.  Because I want to also examine a continuous variable, the total Cartesian <strong>Distance</strong> between stimuli per trial (divided by number of stimuli to control for varying numbers), I have opted to use a mixed linear model with repeated measures.  In addition to each of these task variables, I am also interested in whether folks in various diagnostic groups perform differently on the task, as well as whether or not there is a <strong>Dx</strong> interaction with any of the above variables.  Thus (if I'm not mistaken), I have the following effects in my model:</p>

<p><strong>Trial Type</strong>, a fixed effect
<strong>Number of Stimuli</strong>, a fixed effect
<strong>Probe Location</strong>, a fixed effect
<strong>Dist</strong>(ance), a fixed effect
<strong>Dx</strong>, a fixed effect
<strong>Dx*Trial Type</strong>, a fixed effect
<strong>Dx*Number of Stimuli</strong>, a fixed effect
<strong>Dx*Probe Location</strong>, a fixed effect
<strong>Dx*Dist</strong>, a fixed effect
<strong>Trial</strong>, a random effect, nested within
<strong>SubID</strong>, a random effect</p>

<p>Based on my examination of documentation, it seems that the nesting of random effects does not seem to be important to lme4, and so I specify my model as follows:</p>

<p><code>tab.lmer &lt;- lmer(Correct ~  Dx+No_of_Stim+Trial_Type+Probe_Loc+Dist+Dx*No_of_Stim+Dx*Trial_Type+Dx*Probe_Loc+Dx*Dist+(1|Trial)+(1|SubID),data=bigdf)</code></p>

<p>This would be my first question: <strong>1) Is the above model specification correct?</strong></p>

<p>Assuming so, I am a bit troubled by my results, but as I read and recall my instruction on such models, I am wondering if interpretation of particular coefficients is bad practice in this case:</p>

<pre><code>Linear mixed model fit by REML ['merModLmerTest']
Formula: Correct ~ Dx + No_of_Stim + Trial_Type + Probe_Loc + Dist + Dx *  
    No_of_Stim + Dx * Trial_Type + Dx * Probe_Loc + Dx * Dist +  
    (1 | Trial) + (1 | SubID)
   Data: bigdf

REML criterion at convergence: 13600.4

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-2.89810 -0.03306  0.27004  0.55363  2.81656 

Random effects:
 Groups   Name        Variance Std.Dev.
 Trial    (Intercept) 0.013256 0.11513 
 SubID    (Intercept) 0.006299 0.07937 
 Residual             0.131522 0.36266 
Number of obs: 15840, groups:  Trial, 288; SubID, 55

Fixed effects:
                         Estimate Std. Error         df t value Pr(&gt;|t|)    
(Intercept)             4.196e-01  4.229e-02  4.570e+02   9.922  &lt; 2e-16 ***
DxPROBAND               8.662e-02  4.330e-02  2.920e+02   2.000  0.04640 *  
DxRELATIVE              9.917e-02  4.009e-02  2.920e+02   2.474  0.01394 *  
No_of_Stim3            -9.281e-02  1.999e-02  4.520e+02  -4.642 4.53e-06 ***
Trial_Type1             3.656e-02  2.020e-02  4.520e+02   1.810  0.07097 .  
Probe_Loc1              3.502e-01  2.266e-02  4.520e+02  15.456  &lt; 2e-16 ***
Probe_Loc2              3.535e-01  3.110e-02  4.520e+02  11.369  &lt; 2e-16 ***
Dist                    1.817e-01  2.794e-02  4.520e+02   6.505 2.06e-10 ***
DxPROBAND:No_of_Stim3  -1.744e-02  1.759e-02  1.548e+04  -0.992  0.32144    
DxRELATIVE:No_of_Stim3 -2.886e-02  1.628e-02  1.548e+04  -1.773  0.07628 .  
DxPROBAND:Trial_Type1  -9.250e-03  1.777e-02  1.548e+04  -0.521  0.60267    
DxRELATIVE:Trial_Type1  1.336e-02  1.645e-02  1.548e+04   0.812  0.41682    
DxPROBAND:Probe_Loc1   -8.696e-02  1.993e-02  1.548e+04  -4.363 1.29e-05 ***
DxRELATIVE:Probe_Loc1  -4.287e-02  1.845e-02  1.548e+04  -2.323  0.02018 *  
DxPROBAND:Probe_Loc2   -1.389e-01  2.735e-02  1.548e+04  -5.079 3.83e-07 ***
DxRELATIVE:Probe_Loc2  -8.036e-02  2.532e-02  1.548e+04  -3.173  0.00151 ** 
DxPROBAND:Dist         -3.920e-02  2.457e-02  1.548e+04  -1.595  0.11066    
DxRELATIVE:Dist        -1.485e-02  2.275e-02  1.548e+04  -0.653  0.51390    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>In general, these results make sense to me.  The troubling portion, however, comes in the positive, significant (yes, I am using LmerTest) p-value for DxProband, particularly in light of the fact that in terms of performance means, Probands are performing worse than Controls.  So, this mismatch concerns me.  Examining the corresponding ANOVA:</p>

<pre><code>&gt; anova(tab.lmer)
Analysis of Variance Table of type 3  with  Satterthwaite 
approximation for degrees of freedom
               Sum Sq Mean Sq NumDF   DenDF F.value    Pr(&gt;F)    
Dx             0.8615  0.4308     2   159.0   1.412   0.24662    
No_of_Stim     0.6984  0.6984     1   283.5  37.043 3.741e-09 ***
Trial_Type     8.3413  8.3413     1   283.5   4.456   0.03565 *  
Probe_Loc     25.7223 12.8612     2   283.5 116.405 &lt; 2.2e-16 ***
Dist           5.8596  5.8596     1   283.5  43.399 2.166e-10 ***
Dx:No_of_Stim  1.4103  0.7051     2 15483.7   1.590   0.20395    
Dx:Trial_Type  2.0323  1.0162     2 15483.7   0.841   0.43128    
Dx:Probe_Loc   3.5740  0.8935     4 15483.7   7.299 7.224e-06 ***
Dx:Dist        0.3360  0.1680     2 15483.7   1.277   0.27885    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>...the results seem to more or less line up with the regression, with the exception of the <strong>Dx</strong> variable.  So, my second question is <strong>2) Can anyone clarify what is going on with the Dx variable? Is interpreting individual coefficients from the regression model bad practice in this case?</strong></p>

<p>Finally, as a basic (and somewhat embarrassing) afterthought, <strong>3) If I attempt to reduce the model, I should favor the model with the <em>lower</em> REML, yes?</strong></p>

<p>In summation,
<strong>1) Is the above model specification correct?</strong>
<strong>2) Can anyone clarify what is going on with the Dx variable? Is interpreting individual coefficients from the regression model bad practice in this case?</strong>
<strong>3) If I attempt to reduce the model, I should favor the model with the <em>lower</em> REML, yes?</strong></p>

<p><strong>ADDENDUM</strong></p>

<p>By request, I'll describe the task and data a little further.  The data come from a computer task in which participants are presented a number of stimuli, either two or three, in various locations about the screen.  These stimuli can either be ""targets"" or ""distractors"".  After these stimuli, a probe stimulus is presented; if it appears in a position where a previous target has appeared, participants should respond ""yes""; if it appears in the position of a previous distractor or elsewhere, the correct answer is ""no.""  There are 288 trials of this nature; some have two stimuli and some have three, and some lack distractors entirely.  The variables in my model, then, can be elaborated as follows:</p>

<p><strong>Number of Stimuli:</strong> 2 or 3 (2 levels)</p>

<p><strong>Trial Type:</strong> No Distractor (0) or Distractor (1) (2 levels)</p>

<p><strong>Probe Location:</strong> Probe at Target (1), Probe at Distractor (2), or Probe Elsewhere (0) (3 levels)</p>

<p><strong>Distance:</strong> Total Cartesian distance between stimuli, divided by number of stimuli per trial (Continuous)</p>

<p><strong>Dx:</strong> Participant's clinical categorization</p>

<p><strong>Sub ID:</strong> Unique subject identifier (random effect)</p>

<p><strong>Trial:</strong> Trial number (1:288) (random effect)</p>

<p><strong>Correct:</strong> Response classification, either incorrect (0) or correct (1) per trial</p>

<p>Note that the task design makes it inherently imbalanced, as trials without distractors cannot have Probe Location ""Probe at Distractor""; this makes R mad when I try to run RM ANOVAs, and it is another reason I opted for a regression.</p>

<p>Below is a sample of my data (with SubID altered, just in case anyone might get mad):</p>

<pre><code>     SubID      Dx Correct No_of_Stim Trial_Type Probe_Loc      Dist Trial
1 99999999 PROBAND       1          3          0         1 0.9217487     1
2 99999999 PROBAND       0          3          0         0 1.2808184     2
3 99999999 PROBAND       1          3          0         0 1.0645292     3
4 99999999 PROBAND       1          3          1         2 0.7838786     4
5 99999999 PROBAND       0          3          0         0 1.0968788     5
6 99999999 PROBAND       1          3          1         1 1.3076598     6
</code></pre>

<p>Hopefully, with the above variable descriptions these data should be self-explanatory.</p>

<p>Any assistance that people can provide in this matter is very much appreciated.</p>

<p>Sincerely,
peteralynn</p>
"
"0.238337436689687","0.256884891956954","115304","<p>I am learning about building linear regression models by looking over someone elses R code.  Here is the example data I am using:</p>

<pre><code>v1  v2  v3  response
0.417655013 -0.012026453    -0.528416414    48.55555556
-0.018445979    -0.460809371    0.054017873 47.76666667
-0.246110341    0.092230159 0.057435968 49.14444444
-0.521980295    -0.428499038    0.119640369 51.08888889
0.633310578 -0.224215856    -0.153917427    48.97777778
0.41522316  0.050609412 -0.642394965    48.5
-0.07349941 0.547128578 -0.539018121    53.95555556
-0.313950353    0.207853678 0.713903994 48.16666667
0.404643796 -0.326782199    -0.785848428    47.7
0.028246796 -0.424323318    0.289313911 49.34444444
0.720822953 -0.166712488    0.323246062 50.78888889
-0.430825851    -0.308119827    0.543823856 52.65555556
-0.964175294    0.661700584 -0.11905972 51.03333333
-0.178955757    -0.11148414 -0.151179885    48.28888889
0.488388035 0.515903257 -0.087738159    48.68888889
-0.097527627    0.188292773 0.207321867 49.86666667
0.481853599 0.21142728  -0.226700254    48.38888889
1.139561277 -0.293574756    0.574855693 54.55555556
0.104077762 0.16075114  -0.131124443    48.61111111
</code></pre>

<p>I read in the data and use a call to <code>lm()</code> to build a model:</p>

<pre><code>&gt; my_data&lt;- read.table(""data.csv"", header = T, sep = "","")
&gt; my_lm &lt;- lm(response~v1 + v2 + v3 + v1:v2 + v1:v3 + v2:v3, data=my_data)
&gt; summary(my_lm)

Call:
lm(formula = response ~ v1 + v2 + v3 + v1:v2 + v1:v3 + v2:v3, 
data = my_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.0603 -0.6615 -0.1891  1.0395  1.8280 

Coefficients:
         Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  49.33944    0.42089 117.226  &lt; 2e-16 ***
v1            0.06611    0.82320   0.080  0.93732    
v2           -0.36725    1.06359  -0.345  0.73585    
v3            0.72741    1.00973   0.720  0.48508    
v1:v2        -2.54544    2.21663  -1.148  0.27321    
v1:v3         0.80641    2.77603   0.290  0.77640    
v2:v3       -12.16017    3.62473  -3.355  0.00573 ** 
--- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 1.375 on 12 degrees of freedom
Multiple R-squared:  0.697, Adjusted R-squared:  0.5455 
F-statistic:   4.6 on 6 and 12 DF,  p-value: 0.01191
</code></pre>

<p>Following along with their code I then use a call to <code>anova()</code>:</p>

<pre><code>&gt; my_lm_anova &lt;- anova(my_lm)
&gt; my_lm_anova
Analysis of Variance Table

Response: response
          Df  Sum Sq Mean Sq F value   Pr(&gt;F)   
v1         1  0.0010  0.0010  0.0005 0.982400   
v2         1  0.2842  0.2842  0.1503 0.705036   
v3         1  9.8059  9.8059  5.1856 0.041891 * 
v1:v2      1  4.3653  4.3653  2.3084 0.154573   
v1:v3      1 16.4582 16.4582  8.7034 0.012141 * 
v2:v3      1 21.2824 21.2824 11.2545 0.005729 **
Residuals 12 22.6921  1.8910                    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>However, I am not sure:</p>

<ol>
<li>Why I would use the call to ANOVA in this situation, and</li>
<li>What the ANOVA table is telling me about the predictor variables.</li>
</ol>

<p>From the code they appear to use the ANOVA table as follows.  For predictor variable v1, the result of </p>

<ul>
<li>Adding the 'Sum Sq' entry for v1 together with half of the 'Sum Sq' entry for v1:v2 and half of the 'Sum Sq' entry for v1:v3, </li>
<li>Dividing by the sum of the entire 'Sum Sq' column, and</li>
<li>Multiplying by 100</li>
</ul>

<p>gives the percent of variance of the response variable that is explained by predictor variable v1 in the <code>lm()</code> model.  I don't see why this is nor why half of the 'Sum Sq' entry for v1:v2 is attributed to v1 and half to v2.  Is this just convenience?</p>
"
"0.250030523167198","0.295400237744099","120549","<p>It is a basic question but I could not find clear answer on my reading. I am trying to find independent predictors of Infant.Mortality in data frame 'swiss' in R. </p>

<pre><code>&gt; head(swiss)
             Fertility Agriculture Examination Education Catholic Infant.Mortality
Courtelary        80.2        17.0          15        12     9.96             22.2
Delemont          83.1        45.1           6         9    84.84             22.2
Franches-Mnt      92.5        39.7           5         5    93.40             20.2
Moutier           85.8        36.5          12         7    33.77             20.3
Neuveville        76.9        43.5          17        15     5.16             20.6
Porrentruy        76.1        35.3           9         7    90.57             26.6
</code></pre>

<p>Following are the results using lm and I find only Fertility to be a significant predictor: </p>

<pre><code>&gt; fit = lm(Infant.Mortality~., data=swiss)
&gt; summary(fit)

Call:
lm(formula = Infant.Mortality ~ ., data = swiss)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.2512 -1.2860  0.1821  1.6914  6.0937 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  8.667e+00  5.435e+00   1.595  0.11850
Fertility    1.510e-01  5.351e-02   2.822  0.00734    #  &lt;&lt;&lt;&lt; NOTE P VALUE HERE
Agriculture -1.175e-02  2.812e-02  -0.418  0.67827
Examination  3.695e-02  9.607e-02   0.385  0.70250
Education    6.099e-02  8.484e-02   0.719  0.47631
Catholic     6.711e-05  1.454e-02   0.005  0.99634

Residual standard error: 2.683 on 41 degrees of freedom
Multiple R-squared:  0.2439,    Adjusted R-squared:  0.1517 
F-statistic: 2.645 on 5 and 41 DF,  p-value: 0.03665
</code></pre>

<p>Following are the graphs:</p>

<pre><code>plot(fit)
</code></pre>

<p><img src=""http://i.stack.imgur.com/lopHb.png"" alt=""enter image description here""></p>

<p>On performing stepwise regression, following are the results: </p>

<pre><code>&gt; step &lt;- stepAIC(fit, direction=""both""); 
Start:  AIC=98.34
Infant.Mortality ~ Fertility + Agriculture + Examination + Education + 
    Catholic

              Df Sum of Sq    RSS     AIC
- Catholic     1     0.000 295.07  96.341
- Examination  1     1.065 296.13  96.511
- Agriculture  1     1.256 296.32  96.541
- Education    1     3.719 298.79  96.930
&lt;none&gt;                     295.07  98.341
- Fertility    1    57.295 352.36 104.682

Step:  AIC=96.34
Infant.Mortality ~ Fertility + Agriculture + Examination + Education

              Df Sum of Sq    RSS     AIC
- Examination  1     1.320 296.39  94.551
- Agriculture  1     1.395 296.46  94.563
- Education    1     5.774 300.84  95.252
&lt;none&gt;                     295.07  96.341
+ Catholic     1     0.000 295.07  98.341
- Fertility    1    72.609 367.68 104.681

Step:  AIC=94.55
Infant.Mortality ~ Fertility + Agriculture + Education

              Df Sum of Sq    RSS     AIC
- Agriculture  1     4.250 300.64  93.220
- Education    1     6.875 303.26  93.629
&lt;none&gt;                     296.39  94.551
+ Examination  1     1.320 295.07  96.341
+ Catholic     1     0.255 296.13  96.511
- Fertility    1    79.804 376.19 103.758

Step:  AIC=93.22
Infant.Mortality ~ Fertility + Education

              Df Sum of Sq    RSS     AIC
&lt;none&gt;                     300.64  93.220
- Education    1    21.902 322.54  94.525
+ Agriculture  1     4.250 296.39  94.551
+ Examination  1     4.175 296.46  94.563
+ Catholic     1     2.318 298.32  94.857
- Fertility    1    85.769 386.41 103.017
&gt; 
&gt; 
&gt; step$anova
Stepwise Model Path 
Analysis of Deviance Table

Initial Model:
Infant.Mortality ~ Fertility + Agriculture + Examination + Education + 
    Catholic

Final Model:
Infant.Mortality ~ Fertility + Education


           Step Df     Deviance Resid. Df Resid. Dev      AIC
1                                      41   295.0662 98.34145
2    - Catholic  1 0.0001533995        42   295.0663 96.34147
3 - Examination  1 1.3199421028        43   296.3863 94.55125
4 - Agriculture  1 4.2499886025        44   300.6363 93.22041
&gt; 
&gt; 
</code></pre>

<p>Summary shows Education also has trend towards significant association: </p>

<pre><code>summary(step)

Call:
lm(formula = Infant.Mortality ~ Fertility + Education, data = swiss)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.6927 -1.4049  0.2218  1.7751  6.1685 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  8.63758    3.33524   2.590 0.012973
Fertility    0.14615    0.04125   3.543 0.000951
Education    0.09595    0.05359   1.790 0.080273

Residual standard error: 2.614 on 44 degrees of freedom
Multiple R-squared:  0.2296,    Adjusted R-squared:  0.1946 
F-statistic: 6.558 on 2 and 44 DF,  p-value: 0.003215
</code></pre>

<p>What do I conclude? Is Education an important predictor or not?</p>

<p>Also, do the graphs using plot(fit) add any significant information?</p>

<p>Thanks for your help.</p>

<hr>

<p>Edit: 
I ran shapiro test on all columns and found 2 are not normally distributed: </p>

<pre><code>Fertility : P= 0.3449466 (Normally distributed) 
Agriculture : P= 0.1930223 (Normally distributed) 
Examination : P= 0.2562701 (Normally distributed) 
Education : P= 1.31202e-07 (--- NOT Normally distributed! ---) 
Catholic : P= 1.20461e-07 (--- NOT Normally distributed! ---) 
Infant.Mortality : P= 0.4978056 (Normally distributed) 
</code></pre>

<p>Does that make a difference? </p>
"
"0.226455406828919","0.225302954529666","120768","<p>I'm using <code>glmer()</code> with a binomial response variable. My optimal model has two fixed effects (flow and DNA) which in summary() show a non-significant p value but when I remove each fixed effect in turn from the model the likelihood ratio test comparing the two models shows a significant p value. I'm struggling to understand (1) if this is normal, and (2) how to report the results if the explanatory variables ""flow"" and ""DNA"" are important but their p values in the model are well above 0.05?</p>

<p>Optimal model:</p>

<pre><code>a25 &lt;- glmer(Status_qpcr~(1|Root)+Flow+DNA,
             family=binomial, data=spore)
summary(a25)

Generalized linear mixed model fit by maximum likelihood (Laplace
Approximation) ['glmerMod']  
Family: binomial  ( logit ) 
Formula: Status_qpcr ~ (1 | Root) + Flow + DNA   
Data: spore
      AIC      BIC   logLik deviance df.resid 
     72.9     81.0    -32.4     64.9       52 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.9318 -0.8163  0.4435  0.6848  1.6133 

Random effects:  
  Groups Name        Variance Std.Dev.  
  Root   (Intercept) 0.3842   0.6199   
  Number of obs: 56, groups:  Root, 9

Fixed effects:
Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept) -0.97752    0.79252  -1.233    0.217   
Flow         3.82779    2.27165   1.685    0.092 . 
DNA          0.01616    0.01039   1.556    0.120  
--- 
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
     (Intr) Flow   Flow -0.775        
     DNA    -0.576  0.227
</code></pre>

<p>Likelihood ratio test:</p>

<pre><code>a26 &lt;- update(a25,~.-DNA)
anova(a25,a26)

Data: spore 
Models: 
    a26: Status_qpcr ~ (1 | Root) + Flow 
    a25: Status_qpcr ~ (1 | Root) + Flow + DNA
    Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)   
a26  3 74.802 80.878 -34.401   68.802                            
a25  4 72.897 80.998 -32.448   64.897 3.9049      1    0.04815 *

a27 &lt;- update(a25,~.-Flow)
anova(a25,a27)

Data: spore 
Models: 
    a27: Status_qpcr ~ (1 | Root) + DNA 
    a25: Status_qpcr ~ (1 | Root) + Flow + DNA
    Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)
a27  3 78.440 84.723 -36.220   72.440                             
a25  4 72.897 80.998 -32.448   64.897 7.5427      1   0.006025 **
</code></pre>
"
"0.227397013413549","0.226239769192175","121517","<p>I have two models:</p>

<pre><code>frm.mE &lt;- glm(frm ~ age + education + socialrole + countedmembers +
            offset(log(words)), family=quasipoisson, data=daten.alle.kom)
frm.oE &lt;- glm(frm ~ age + socialrole + countedmembers +
                 offset(log(words)), family=quasipoisson, data=daten.alle.kom)
</code></pre>

<p>now I want to know which model is the better one, but because of quasipoisson, AIC don't work</p>

<pre><code>summary(frm.mE)
Call:
glm(formula = frm ~ age + education + socialrole + countedmembers + 
offset(log(words)), family = quasipoisson, data = daten.alle.kom)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-6.7040  -1.6727  -0.2329   1.0003   7.4897  

Coefficients:
           Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    -3.95362    0.21432 -18.448  &lt; 2e-16 ***
age             0.01293    0.07041   0.184  0.85454    
education1      0.11532    0.11647   0.990  0.32367    
socialrole1    -0.28367    0.23685  -1.198  0.23287    
socialrole2    -0.80474    0.29054  -2.770  0.00629 ** 
countedmembers -0.03716    0.06120  -0.607  0.54461    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for quasipoisson family taken to be 5.792638)

Null deviance: 909.51  on 160  degrees of freedom
Residual deviance: 841.35  on 155  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5
</code></pre>

<p>and the second model:</p>

<pre><code>Call:
glm(formula = frm ~ age + socialrole + countedmembers + offset(log(words)), 
family = quasipoisson, data = daten.alle.kom)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-6.4844  -1.6613  -0.3583   1.1036   7.1557  

Coefficients:
           Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)    -3.89079    0.20350 -19.119  &lt; 2e-16 ***
age             0.00540    0.06966   0.078  0.93832    
socialrole1    -0.33991    0.22947  -1.481  0.14054    
socialrole2    -0.75470    0.28553  -2.643  0.00905 ** 
countedmembers -0.02634    0.05996  -0.439  0.66104    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for quasipoisson family taken to be 5.761264)

Null deviance: 909.51  on 160  degrees of freedom
Residual deviance: 847.08  on 156  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 5
</code></pre>

<p>is there another way to compare them? or to know if I should keep the variable ""education""?
thanks for any help!</p>

<p>I tried a F test, but not sure if it makes sense:</p>

<pre><code> anova(frm.mE, frm.oE, test=""F"")
Analysis of Deviance Table

Model 1: frm ~ age + education + socialrole + countedmembers + offset(log(words))
Model 2: frm ~ age + socialrole + countedmembers + offset(log(words))
Resid. Df Resid. Dev Df Deviance      F Pr(&gt;F)
1       155     841.35                          
2       156     847.08 -1  -5.7368 0.9904 0.3212
</code></pre>

<p>but I'm not sure how to understand it, does it mean that I should keep ""education"" because model 2 has a too big p-value?</p>
"
"0.378932373372537","0.377003951829993","127479","<p>I'm using a mixed effects model with logistic link function (using lme4 version 1.1-7 in R).  However, I noticed that the estimates of significance for fixed effects change depending on the order of the rows in the dataset.  </p>

<p>That is, if I run a model on a dataset, I get certain estimate for my fixed effect and it has a certain p-value.  I run the model again, and I get the same estimate and p-value.  Now, I shuffle the order of rows (the data is not mixed, just the rows are in a different order).  Running the model a third time, the p-value is very different.</p>

<p>For the data I have, the estimated p-value for the fixed effect can be between p=0.001 and p=0.08.  Obviously, these are crucial differences given conventional significance levels. </p>

<p>I understand that the estimates are just estimated, and there will be differences between values for a number of reasons.  However, the magnitude of the differences for my data seem large to me, and I wouldn't expect the order of my dataframe to have this effect (we discovered this problem by chance when a colleague ran the same model but got different results.  It turned out they had ordered their data frame.).  </p>

<p>Here is the output of my script:
(X and Y are binary variables which are contrast-coded and centred, Group and SubGroup are categorical variables)</p>

<pre><code>&gt; # Fit model
&gt; m1 = glmer(X ~Y+(1+Y|Group)+(1+Y|SubGroup),family=binomial(link='logit'),data=d)
&gt; # Shuffle order of rows
&gt; d = d[sample(1:nrow(d)),]
&gt; # Fit model again
&gt; m2 = glmer(X ~Y+(1+Y|Group)+(1+Y|SubGroup),family=binomial(link='logit'),data=d)
&gt; summary(m1)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) 
      ['glmerMod']
 Family: binomial  ( logit )
Formula: X ~ Y + (1 + Y | Group) + (1 + Y | SubGroup)
   Data: d

      AIC       BIC    logLik  deviance  df.resid 
 200692.0  200773.2 -100338.0  200676.0    189910 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.1368 -0.5852 -0.4873 -0.1599  6.2540 

Random effects:
 Groups       Name        Variance Std.Dev. Corr 
 SubGroup     (Intercept) 0.2939   0.5421        
              Y1          0.1847   0.4298   -0.79
 Group        (Intercept) 0.2829   0.5319        
              Y1          0.4640   0.6812   -0.07
Number of obs: 189918, groups:  SubGroup, 15; Group, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.0886     0.1325  -8.214   &lt;2e-16 ***
Y1            0.3772     0.2123   1.777   0.0756 .  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
     (Intr)
Y1 0.112 
&gt;
&gt; # -----------------
&gt; summary(m2)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) 
      ['glmerMod']
 Family: binomial  ( logit )
Formula: X ~ Y + (1 + Y | Group) + (1 + Y | SubGroup)
   Data: d

      AIC       BIC    logLik  deviance  df.resid 
 200692.0  200773.2 -100338.0  200676.0    189910 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.1368 -0.5852 -0.4873 -0.1599  6.2540 

Random effects:
 Groups       Name        Variance Std.Dev. Corr 
 SubGroup     (Intercept) 0.2939   0.5422        
              Y1          0.1846   0.4296   -0.79
 Group        (Intercept) 0.2829   0.5318        
              Y1          0.4641   0.6813   -0.07
Number of obs: 189918, groups:  SubGroup, 15; Group, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.0886     0.1166  -9.334  &lt; 2e-16 ***
Y1            0.3773     0.1130   3.339 0.000841 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
     (Intr)
Y1 0.074 
</code></pre>

<p>I'm afraid that I can't attach the data due to privacy reasons. </p>

<p>Both models converge.  The difference appears to be in the standard errors, while the differences in coefficient estimates are smaller.  The model fit (AIC etc.) are the same, so maybe there are multiple optimal convergences, and the order of the data pushes the optimiser into different ones.  However, I get slightly different estimates every time I shuffle the data frame (not just two or three unique estimates).  In one case (not shown above), the model did not converge simply because of a shuffling of the rows.</p>

<p>I suspect that the problem lies with the structure of my particular data.  It's reasonably large (nearly 200,000 cases), and has nested random effects.  I have tried centering the data, using contrast coding and feeding starting values to lmer based on a previous fit.  This seems to help somewhat, but I still get reasonably large differences in p-values.  I also tried using different ways of calculating p-values, but I got the same problem.</p>

<p>Below, I've tried to replicate this problem with synthesised data.  The differences here aren't as big as with my real data, but it gives an idea of the problem.</p>

<pre><code>library(lme4)
set.seed(999)

# make a somewhat complex data frame
x = c(rnorm(10000),rnorm(10000,0.1))
x = sample(x)
y = jitter(x,amount=10)
a = rep(1:20,length.out=length(x))
y[a==1] = jitter(y[a==1],amount=3)
y[a==2] = jitter(x[a==2],amount=1)
y[a&gt;3 &amp; a&lt;6] = rnorm(sum(a&gt;3 &amp; a&lt;6))
# convert to binary variables
y = y &gt;0
x = x &gt;0
# make a data frame
d = data.frame(x1=x,y1=y,a1=a)

# run model 
m1 = glmer(x1~y1+(1+y1|a1),data=d,family=binomial(link='logit'))

# shuffle order of rows
d = d[sample(nrow(d)),]

# run model again
m2 = glmer(x1~y1+(1+y1|a1),data=d,family=binomial(link='logit'))

# show output
summary(m1)
summary(m2)
</code></pre>

<p>One solution to this is to run the model multiple times with different row orders, and report the range of p-values.  However, this seems inelegant and potentially quite confusing.</p>

<p>The problem does not affect model comparison estimates (using anova), since these are based on differences in model fit.  The fixed effect coefficient estimates are also reasonably robust.  Therefore, I could just report the effect size, confidence intervals and the p-value from a model comparison with a null model, rather than the p-values from within the main model.</p>

<p>Anyway, has anyone else had this problem?  Any advice on how to proceed?</p>
"
"0.226455406828919","0.225302954529666","131152","<p>Let say I've ran this linear regression:</p>

<pre><code>lm_mtcars &lt;- lm(mpg ~ wt + vs, mtcars)
</code></pre>

<p>I can use <code>anova()</code> to see the amount of variance in the dependent variable accounted for by the two predictors:</p>

<pre><code>anova(lm_mtcars)

Analysis of Variance Table

Response: mpg
          Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
wt         1 847.73  847.73 109.7042 2.284e-11 ***
vs         1  54.23   54.23   7.0177   0.01293 *  
Residuals 29 224.09    7.73                       
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>Lets say I now add a random intercept for <code>cyl</code>:</p>

<pre><code>library(lme4)
lmer_mtcars &lt;- lmer(mpg ~ wt + vs + (1 | cyl), mtcars)
summary(lmer_mtcars)

Linear mixed model fit by REML ['lmerMod']
Formula: mpg ~ wt + vs + (1 | cyl)
   Data: mtcars

REML criterion at convergence: 148.8

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-1.67088 -0.68589 -0.08363  0.48294  2.16959 

Random effects:
 Groups   Name        Variance Std.Dev.
 cyl      (Intercept) 3.624    1.904   
 Residual             6.784    2.605   
Number of obs: 32, groups:  cyl, 3

Fixed effects:
            Estimate Std. Error t value
(Intercept)  31.4788     2.6007  12.104
wt           -3.8054     0.6989  -5.445
vs            1.9500     1.4315   1.362

Correlation of Fixed Effects:
   (Intr) wt    
wt -0.846       
vs -0.272  0.006
</code></pre>

<p>The variance accounted for by each fixed effect now drops because the random intercept for <code>cyl</code> is now accounting for some of the variance in <code>mpg</code>:</p>

<pre><code>anova(lmer_mtcars)

Analysis of Variance Table
   Df  Sum Sq Mean Sq F value
wt  1 201.707 201.707 29.7345
vs  1  12.587  12.587  1.8555
</code></pre>

<p>But in <code>lmer_mtcars</code>, how can I tell what proportion of the variance is being accounted for by <code>wt</code>, <code>vs</code> and the random intecept for <code>cyl</code>?</p>
"
"0.267945650822833","0.266582050873114","131459","<p>I'm trying to implement a joint test of the two coefficients comprising a quadratic term in a 2-stage least squares regression.  The quadratic term is endogenous.  I'm using <code>AER</code> in R, and <code>ivreg</code>'s <code>anova</code> method is not giving me the same result as the manual Wald test that I'm checking it with.  I'd basically like to know whether my own manual method is correct or not.  If not, why not, and if so, what <code>AER</code> is doing differently.</p>

<pre><code>1&gt; rm(list=ls())
1&gt; set.seed(1)
1&gt; N &lt;- 100
1&gt; z &lt;- rnorm(N) #The instrument
1&gt; u &lt;- rnorm(N) #The error term
1&gt; x &lt;- 1 + z - .1*z^2 + u + rnorm(N) # x is correlated with the error term u (endogeneity) and the instrument z
1&gt; ex &lt;- 1 + rnorm(N) #an exogenous variable
1&gt; y &lt;- 1 + x-.1*x^2  + ex + u 
1&gt; x2 &lt;- x^2
1&gt; z2 &lt;- z^2
1&gt; summary(lm(y~x+x2+ex))

Call:
lm(formula = y ~ x + x2 + ex)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.91064 -0.57302  0.04697  0.43678  1.62413 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  0.51137    0.13751   3.719 0.000337 ***
x            1.22946    0.05578  22.042  &lt; 2e-16 ***
x2          -0.03512    0.02145  -1.637 0.104893    
ex           0.97401    0.07933  12.278  &lt; 2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.7699 on 96 degrees of freedom
Multiple R-squared:  0.8952,    Adjusted R-squared:  0.892 
F-statistic: 273.5 on 3 and 96 DF,  p-value: &lt; 2.2e-16
</code></pre>

<p>BIAS</p>

<pre><code> 1&gt; library(AER)

1&gt; miv = ivreg(y~x+x2+ex|z+z2+ex)
1&gt; summary(miv)

Call:
ivreg(formula = y ~ x + x2 + ex | z + z2 + ex)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.1212 -0.7533 -0.2623  0.6458  3.5927 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   1.4767     0.4785   3.086  0.00265 ** 
x             1.0678     0.1351   7.902 4.58e-12 ***
x2           -0.2185     0.1014  -2.154  0.03373 *  
ex            0.8690     0.1409   6.167 1.65e-08 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 1.245 on 96 degrees of freedom
Multiple R-Squared: 0.7259, Adjusted R-squared: 0.7173 
Wald test: 43.79 on 3 and 96 DF,  p-value: &lt; 2.2e-16 
</code></pre>

<p>MUCH BETTER WITH THE VALID INSTRUMENTS</p>

<p>Wald test using built-in method, versus manual Wald test:</p>

<pre><code>1&gt; mnull = ivreg(y~ex)
        1&gt; anova(miv,mnull,vcov=vcov(miv))
        Wald test

        Model 1: y ~ x + x2 + ex | z + z2 + ex
        Model 2: y ~ ex
          Res.Df Df      F    Pr(&gt;F)    
        1     96                        
        2     98 -2 31.512 3.011e-11 ***
        ---
        Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

        1&gt; #Wald test
        1&gt; B = coef(miv)
        1&gt; r = matrix(c(0,0),2)
        1&gt; R = t(matrix(c(   0,1,0,0
        1+      ,0,0,1,0),4))
        1&gt; V = vcov(miv)
        1&gt; W = t(R%*%B -r) %*% solve(R%*%V%*%t(R)) %*% (R%*%B -r)
        1&gt; W/2
                [,1]
        [1,] 31.5123
</code></pre>

<p>Why is my wald statistic twice the one given by the method?</p>

<pre><code>    1&gt; 1-pf(W/2,nrow(R),N-nrow(R))
                 [,1]
    [1,] 2.706191e-11
</code></pre>

<p>And why are the p-values similar, but not identical?</p>
"
"0.143222974807887","0.142494099975819","136983","<p>I am trying to figure out what is the estimated variance (i.e. the estimated ""error"") of residuals around a fitted line. </p>

<pre><code>&gt; summary(model)

Call:
lm(formula = fecundity ~ Organic)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.2909 -1.6439 -0.4606  1.5121  3.7273 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  47.6667     1.4907   31.98 9.97e-10 ***
Organic      -8.6788     0.4805  -18.06 9.06e-08 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 2.182 on 8 degrees of freedom
Multiple R-squared:  0.9761,    Adjusted R-squared:  0.9731 
F-statistic: 326.2 on 1 and 8 DF,  p-value: 9.063e-08

&gt; anova(model)
Analysis of Variance Table

Response: fecundity
          Df Sum Sq Mean Sq F value    Pr(&gt;F)    
Organic    1 1553.5 1553.50  326.22 9.063e-08 ***
Residuals  8   38.1    4.76                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>
"
"0.24880667576406","0.247540475810749","141820","<p>I want to find which soil variables better explain plant productivity, using a database that contains information for about 100 forests plots across Europe.
These plots have only one species per plot, but overall there are 4 different species in the dataset. These plots also have different climate conditions (temperature, precipitation,...). My final goal is finding out which combination of the more than 20 different soil variables better explain plant productivity. However, both climate and species may confound the analysis because both affect plant growth (some species grow more than others, and plants grown in warmer climates may grow more). I am only interested in plant growth due to soil characteristics, so I need to get rid of the species and climate effects on plant productivity that may confound the analysis. According to what I have read I could just include all variables in the model: soil, climate and species (factor of 4 levels), like this:</p>

<pre><code>fit &lt;- lm(scale(IVMean)~scale(SILT)+scale(SAND)+scale(PHCACL2)+scale(OC)+
                        scale(EXCHCA)+scale(EXCHK)+scale(EXCHMG)+scale(EXCHMN)+
                        scale(EXCHNA)+scale(EXCHAL)+scale(EXCHFE)+scale(N_NO3)+
                        scale(S_SO4)+scale(N_NH4)+scale(BS)+scale(CN)+scale(Temp)+
                        scale(Precip)+scale(Rad)+scale(PET)+species)
</code></pre>

<p>IVMean = mean stem volume increment (productivity). Note climate variables (temperature, precipitation, radiation and potential evapotranspiration -PET-) and species at the end, and the standardisation of all variables with <code>scale()</code>.</p>

<p>After this, I could run a stepwise regression analysis to preliminarily find which variables are the most important explaining plant productivity.</p>

<pre><code>library(MASS)
step &lt;- stepAIC(fit, direction=""backward"")
step$anova # display results
</code></pre>

<p>Which renders the following best minimal model:</p>

<pre><code>Final Model:
scale(IVMean) ~ scale(PHCACL2) + scale(EXCHCA) + scale(EXCHMG) + 
    scale(EXCHMN) + scale(BS) + scale(Temp) + scale(PET) + species

&gt; model &lt;- lm(scale(IVMean) ~ scale(PHCACL2) + scale(EXCHCA) + scale(EXCHMG) + 
+               scale(EXCHMN) + scale(BS) + scale(Temp) + scale(PET) + species, 
+             data = icp)
&gt; summary(model)

Call:
lm(formula = scale(IVMean) ~ scale(PHCACL2) + scale(EXCHCA) + 
    scale(EXCHMG) + scale(EXCHMN) + scale(BS) + scale(Temp) + 
    scale(PET) + species, data = icp)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.13836 -0.41522 -0.02816  0.35094  1.65587 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)        -0.37587    0.16967  -2.215 0.030897 *  
scale(PHCACL2)      0.58776    0.20617   2.851 0.006128 ** 
scale(EXCHCA)      -0.38061    0.19025  -2.001 0.050381 .  
scale(EXCHMG)      -0.37374    0.14686  -2.545 0.013769 *  
scale(EXCHMN)       0.13102    0.09970   1.314 0.194241    
scale(BS)           0.39502    0.19428   2.033 0.046871 *  
scale(Temp)         1.34654    0.32033   4.204 9.74e-05 ***
scale(PET)         -0.62177    0.29749  -2.090 0.041250 *  
speciesoak         -1.24553    0.34788  -3.580 0.000726 ***
speciespicea_abies  1.38679    0.25031   5.540 8.79e-07 ***
speciesscots_pine   0.02627    0.25960   0.101 0.919769    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.6411 on 55 degrees of freedom
Multiple R-squared:  0.6522,    Adjusted R-squared:  0.5889 
F-statistic: 10.31 on 10 and 55 DF,  p-value: 1.602e-09
</code></pre>

<p>The final model includes 5 soil variables, 2 out of 4 climate variables, and species. So far so good?</p>

<p>However, this seems to be not good enough for my supervisor. Rather, he asked me to do an analysis of the residuals to â€œget rid of climate and species effectsâ€! To be honest, I have no idea what he is talking about, and I was afraid to ask because he sounded like something I should know since my childhood. Perhaps he meant I should study which SOIL variables can explain the residuals of productivity ~ climate * species? Please, help me find out which type of analysis of the residuals would make sense to focus on soil effects eliminating climate and species effects.</p>

<p>This is the only thing I can think of:  </p>

<pre><code># Study the importance of confounding effects:
confounding     &lt;- IVMean ~ (Temp + Precip + PET + Rad) * species 
confounding.res &lt;- residuals(confounding)
lm(confounding.res ~scale(SILT)+scale(SAND)+scale(PHCACL2)+scale(OC)+scale(EXCHCA)+
                    scale(EXCHK)+scale(EXCHMG)+scale(EXCHMN)+scale(EXCHNA)+
                    scale(EXCHAL)+scale(EXCHFE)+scale(N_NO3)+scale(S_SO4)+
                    scale(N_NH4)+scale(BS)+scale(CN))
</code></pre>

<p>This way maybe I could study which soil variables explain what climate and species effects could not explain? I donâ€™t know if it makes any sense. I am open to suggestions and alternatives. </p>
"
"NaN","NaN","148794","<p>I try to compare samples in function of a different treatment (x).<br>
The design possess inner-replicate (b) nested in replicate (a).<br>
Thus, i want to take account  of the inner-replicate as random effect.<br>
I had performed Mixed Effect Model and General Linear Mixed Model, but the Normal distribution of the residuals and the homoscedasticity of the residuals are not respected.<br>
What test can i use in this situation ?<br>
I'm specially interested in median comparisons.  </p>

<p>Here a R reproducible example:</p>

<pre><code>data &lt;- read.table(text = ""y,x,a,b
3.8535461,1,1,1
3.7672284,1,1,2
4.3958063,1,1,3
2.6762155,1,2,1
4.5604866,1,2,2
1.5892352,1,2,3
2.4078456,1,3,1
3.0846585,1,3,2
3.8501476,1,3,3
1.2837078,2,1,1
1.4770487,2,1,2
0.6881346,2,1,3
3.4812401,2,2,1
4.2177414,2,2,2
3.6936182,2,2,3
1.3323660,2,3,1
0.5364934,2,3,2
2.7027026,2,3,3
2.7258901,3,1,1
2.2834023,3,1,2
3.1254439,3,1,3
2.8741295,3,2,1
2.4544474,3,2,2
3.2790297,3,2,3
2.2481289,3,3,1
2.6108048,3,3,2
1.6789640,3,3,3
2.0489823,4,1,1
3.6704609,4,1,2
2.0028304,4,1,3
1.4445633,4,2,1
0.0000000,4,2,2
2.1329823,4,2,3
1.7065646,4,3,1
0.0000000,4,3,2
0.9242589,4,3,3
2.4239174,5,1,1
1.0919233,5,1,2
0.0000000,5,1,3
2.4501427,5,2,1
2.2731563,5,2,2
1.8855533,5,2,3
0.3576744,5,3,1
1.3190856,5,3,2
1.7817091,5,3,3"",
sep = ',', header = TRUE)

data$x=as.factor(data$x)
data$a=as.factor(data$a)
data$b=as.factor(data$b)

library(nlme)

lme2 = lme(fixed= y ~ x,random= ~ 1|a/b,data=data)
summary(lme2)
anova(lme2)
shapiro.test(residuals(lme2))
bartlett.test(residuals(lme2), data$x)
</code></pre>
"
"0.277350098112615","0.275938638069581","154782","<p>I'm attempting logistic regression in R for a survey for 613 students. I'm looking to see if there is an association between my <strong>Dependent Variable</strong> (called 'BinaryShelter', coded as 0 or 1, signifying whether students took shelter during a tornado warning) and my <strong>5 independent/predictor variables</strong>. My categorical IV's have anywhere from 3 to 11 distinct levels/categories within them. The other two IV's are binary coded as 0 or 1. The first 10 surveys and R output are given below: </p>

<pre><code>    Survey  KSCat   WSCat   PlanHome    PlanWork    KLNKVulCat  BinaryShelter
    1       J       B       1           1           A           1
    2       A       B       1           0           NA          1
    3       B       B       1           1           C           1
    4       B       D       1           1           A           0
    5       B       D       1           1           A           1
    6       G       E       1           1           A           0
    7       A       A       1           1           B           1
    8       C       F       NA          1           C           0
    9       B       B       1           1           A           1
    10      C       B       0           0           NA          1



Call:
glm(formula = BinaryShelter ~ KSCat + WSCat + PlanHome + PlanWork + 
KLNKVulCat, family = binomial(""logit""), data = mydata)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-2.0583  -1.3564   0.7654   0.8475   1.6161  

Coefficients:
              Estimate   St. Error  z val   Pr(&gt;|z|)  
(Intercept)    0.98471    0.43416   2.268   0.0233 *
KSCatB        -0.63288    0.34599  -1.829   0.0674 .
KSCatC        -0.14549    0.27880  -0.522   0.6018  
KSCatD         0.59855    1.12845   0.530   0.5958  
KSCatE        15.02995 1028.08167   0.015   0.9883  
KSCatF         0.61015    0.68399   0.892   0.3724  
KSCatG        -1.60723    1.54174  -1.042   0.2972  
KSCatH        -1.57777    1.26621  -1.246   0.2127  
KSCatI        -2.06763    1.18469  -1.745   0.0809 .
KSCatJ        -0.23560    0.65723  -0.358   0.7200  
WSCatB        -0.30231    0.28752  -1.051   0.2931  
WSCatC        -0.49467    1.26400  -0.391   0.6955  
WSCatD         0.52501    0.71082   0.739   0.4601  
WSCatE        -0.32153    0.63091  -0.510   0.6103  
WSCatF        -0.51699    0.74680  -0.692   0.4888  
WSCatG        -0.64820    0.39537  -1.639   0.1011  
WSCatH        -0.05866    0.89820  -0.065   0.9479  
WSCatI       -17.07156 1455.39758  -0.012   0.9906  
WSCatJ       -16.31078  662.38939  -0.025   0.9804  
PlanHome       0.27095    0.28121   0.964   0.3353  
PlanWork       0.24983    0.24190   1.033   0.3017  
KLNKVulCatB    0.17280    0.42353   0.408   0.6833  
KLNKVulCatC   -0.12551    0.24777  -0.507   0.6125  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 534.16  on 432  degrees of freedom
Residual deviance: 502.31  on 410  degrees of freedom
  (180 observations deleted due to missingness)
AIC: 548.31

Number of Fisher Scoring iterations: 14

&gt; Anova(ShelterYorN, Test = ""LR"")
Analysis of Deviance Table (Type II tests)

Response: BinaryShelter
          LR Chisq Df Pr(&gt;Chisq)
KSCat       13.3351  9     0.1480
WSCat       14.3789  9     0.1095
PlanHome     0.9160  1     0.3385
PlanWork     1.0583  1     0.3036
KLNKVulCat   0.7145  2     0.6996
</code></pre>

<p>My questions are:</p>

<p><strong>1)</strong> Does a very large St. Deviation (like the one for KSCatE) indicate that I should not use that level of that categorical IV if I want the model to fit the data better? The ones that had such large St. Deviations were from small groups. Should I not include data from very small groups? For instance if only 2 or 3 people picked category 'E' for KSCat, should I exclude that data?</p>

<p><strong>2)</strong> When using factors for my categorical data, or when adding in more than one IV, sometimes my beta coefficients flip signs. Does this mean I should test for interaction and then try to conduct some form of a PCA or jump straight to doing a PCA?</p>

<p>These next questions may be better asked on stack overflow, but I figured I'd give it a shot here:</p>

<p><strong>3)</strong> I do not want a particular level of the categorical variables to be the reference level. I know that R automatically picks the reference level (A if letters, and the first one if numbers). As in the answer to this question (<a href=""http://stats.stackexchange.com/questions/60817/significance-of-categorical-predictor-in-logistic-regression"">Significance of categorical predictor in logistic regression</a>), I tried fitting the model without an intercept by adding - 1 to the formula to see all coefficients directly. But when I do this, the results only show the 'A' level of the first variable and none of the others. For example, I can see results for 'KSCatA' but not 'WSCatA' or 'KLNKVulCatA'. </p>

<p><strong>4)</strong> How does R handle missing observations for logistic regression? For example survey #10 was missing the 'KLNKVulCat' Variable, but not any of the other IV's. Would R or any other statistical languages not use any of the information for this particular person, or just that particular variable?</p>

<p>Any help is greatly appreciated, thank you.</p>
"
"0.267945650822833","0.266582050873114","164228","<p>GLM (family=binomial) is foucusd on when the response is dichotomous(yes/no, male/female, etc..). I'm wondering how to judge if the model we built is good eough? As we know, in OLS regression some criterion like R^2 and adjusted R^2 can tell us how much variations are explained but not for GLM. See example I performed:</p>

<pre><code>    &gt; summary(fit.full)
    Call:
    glm(formula = ynaffair ~ gender + age + yearsmarried + children + 
    +religiousness + education + occupation + rating, family = binomial(), 
    data = Affairs)

    Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
    -1.6575  -0.7459  -0.5714  -0.2552   2.5099  

    Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
    (Intercept)    0.71792    0.96165   0.747 0.455336    
    gendermale     0.28665    0.23973   1.196 0.231811    
    age           -0.04494    0.01831  -2.454 0.014142 *  
    yearsmarried   0.09686    0.03236   2.993 0.002758 ** 
    childrenyes    0.37088    0.29466   1.259 0.208147    
    religiousness -0.32230    0.09003  -3.580 0.000344 ***
    education      0.01795    0.05088   0.353 0.724329    
    occupation     0.03210    0.07194   0.446 0.655444    
    rating2       -0.02312    0.58177  -0.040 0.968303    
    rating3       -0.84532    0.57619  -1.467 0.142354    
    rating4       -1.13916    0.55740  -2.044 0.040981 *  
    rating5       -1.61050    0.56649  -2.843 0.004470 ** 
    ---
    Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

    (Dispersion parameter for binomial family taken to be 1)

    Null deviance: 675.38  on 600  degrees of freedom
    Residual deviance: 608.22  on 589  degrees of freedom
    AIC: 632.22
</code></pre>

<p>After removed the insignificant variables, the reduced model look like below,although the AIC decreasd, we still do not know if this is the model with the lowest AIC we can achieved:</p>

<pre><code>    &gt; summary(fit.reduced)
    Call:
    glm(formula = ynaffair ~ age + yearsmarried + religiousness + 
        +rating, family = binomial(), data = Affairs)

    Deviance Residuals: 
    Min        1Q      Median      3Q      Max  
   -1.5117  -0.7541  -0.5722  -0.2592   2.4123  

    Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
    (Intercept)    1.10220    0.71849   1.534 0.125014    
    age           -0.03588    0.01740  -2.062 0.039224 *  
    yearsmarried   0.10113    0.02933   3.448 0.000565 ***
    religiousness -0.32571    0.08971  -3.631 0.000282 ***
    rating2        0.11848    0.57258   0.207 0.836068    
    rating3       -0.70168    0.56671  -1.238 0.215658    
    rating4       -0.96190    0.54230  -1.774 0.076109 .  
    rating5       -1.49502    0.55550  -2.691 0.007118 ** 
    ---
    Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

    (Dispersion parameter for binomial family taken to be 1)

    Null deviance: 675.38  on 600  degrees of freedom
    Residual deviance: 613.63  on 593  degrees of freedom
    AIC: 629.63
</code></pre>

<p>And we perform the ANOVA, suggesting that the reduced model with
four predictors fits as well as the full model:</p>

<pre><code>    &gt; anova(fit.reduced, fit.full, test=""Chisq"")
    Analysis of Deviance Table

    Model 1: ynaffair ~ age + yearsmarried + religiousness + +rating
    Model 2: ynaffair ~ gender + age + yearsmarried + children + 
             +religiousness + education + occupation + rating
    Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
     1       593     613.63                     
     2       589     608.22  4   5.4124   0.2475
</code></pre>
"
"0.226455406828919","0.225302954529666","164705","<p>I'm working on analyzing a time series of physical variables in many lakes in Florida for an associate, and I've run into an issue. I'm attempting to run a regression for each time series of physical variables in each lake. I can get regression results in R easily, but they don't match up with my coworker's JMP results. Anyway, here's a sample from the data:</p>

<pre><code>Year = seq(1987,2015)
TP = c(14, 12, 14, 14, 17, 16, 15, 12, 18, 14, 15, 18, 18, 21, 21, 17, 17, 20, 19, 17, 18, 18, 26, 20, 18, 21, 21, 20, 18)
summary(lm(TP~Year))
</code></pre>

<p>gives </p>

<pre><code>Call:
lm(formula = TP ~ Year)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.7310 -1.3724 -0.4305  0.9685  6.3675 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -502.90542   98.13981  -5.124 2.18e-05 ***
Year           0.26010    0.04904   5.303 1.35e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 2.21 on 27 degrees of freedom
Multiple R-squared:  0.5102,    Adjusted R-squared:  0.4921 
F-statistic: 28.12 on 1 and 27 DF,  p-value: 1.35e-05
</code></pre>

<p>His JMP analysis spits out the following:</p>

<pre><code>Parameter Estimates
Term        Estimate    Std Error   t Ratio Prob&gt;|t|
Intercept   -500.4634   96.74332    -5.17   &lt;.0001*
Year        0.2588707   0.048347    5.35    &lt;.0001*
</code></pre>

<p>For all lakes and all parameters of interest, the SS, slope estimates, etc. are all slightly off. I have looked into different types of Sum of Squares for ANOVA, but changing to different types (e.g. Type III using Anova()) still doesn't get the results to match up. What am I missing? Any assistance would be appreciated.</p>

<p>Edit: Thanks for y'all's help. Sorry for the belated response, I had to meet up with my colleague. To address the questions:</p>

<ul>
<li>I have hardcoded the data in my question, but it's merely a subset of a much larger dataset from Excel. We are using the same data and the remainder of my code is working properly. <a href=""https://www.dropbox.com/s/k21v38sfdbm0ola/LWFormatted.csv?dl=0"" rel=""nofollow"">Here's what the actual data look like.</a></li>
<li>I know OLS isn't great, but it's being used for some really basic trend descriptions for informing stakeholders. I may pursue a better option in the future.</li>
<li>The JMP model is setup using Y by X with the Bivariate option, then applying a linear regression. Below is a screenshot.</li>
</ul>

<p>Thanks again for your help!</p>

<p><a href=""http://i.stack.imgur.com/ndtBr.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ndtBr.jpg"" alt=""JMP Input""></a></p>
"
"0.189466186686268","0.188501975914996","165110","<p>I'm struggling with the interpretation of a regression model where a categorial variable (5 levels) is dummy coded. Here is the result of my calculation in R:</p>

<pre><code>Call:
lm(formula = DV ~ Age + Gender + factor(Categorial) + 
Continuous 1 + Continuous 2 + Continuous 3, 
data = dat)

Residuals:
 Min       1Q   Median       3Q      Max 
-1.30058 -0.25326  0.00349  0.28123  1.49877 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)           -0.42367    0.30694  -1.380  0.16842   
Age                   -0.05949    0.02026  -2.936  0.00356 **
Gender                -0.01800    0.04828  -0.373  0.70952   
factor(Categorial)2   -0.30625    0.12645  -2.422  0.01596 * 
factor(Categorial)3   -0.03441    0.07752  -0.444  0.65736   
factor(Categorial)4   -0.12603    0.09914  -1.271  0.20453   
factor(Categorial)5   -0.08417    0.13269  -0.634  0.52630    
Continuous 1           0.12080    0.04346   2.779  0.00575 **
Continuous 2          -0.06592    0.04383  -1.504  0.13354   
Continuous 3          -0.06230    0.03475  -1.793  0.07392 . 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 0.4259 on 336 degrees of freedom
  (6 observations deleted due to missingness)
Multiple R-squared:  0.1315,    Adjusted R-squared:  0.1057 
F-statistic: 5.089 on 10 and 336 DF,  p-value: 6.353e-07
</code></pre>

<p>Ok. Age, Factor 2 of the categorial variable and the first continuous variable are significant predictors of the dependent variable. so far so good. </p>

<p>What I'm not understanding is:</p>

<ol>
<li><p>The reference category of the dummy coded categorial variable is the intercept and the first category of the categorial variable. right? How do I interpret this? </p></li>
<li><p>When doing an anova with the categorial variable as a independent variable, this factor is a significant predictor. With the results of the linear model, one could conclude that this is only due to category 2, right?</p></li>
<li><p>Can I test contrasts with this linear regression model (e.g. Category1 vs. Category2)?</p></li>
<li><p>Should I include interactions?</p></li>
</ol>

<p>I'd be glad for any help :-)</p>
"
"0.101273936708367","0.100758544371976","167109","<p>I'm new to R and trying to run some two-way ANOVAs to test treatment effects in an ecology study.
I've just tested my data using the Levene function:</p>

<pre><code>&gt; leveneTest(ant.richness~Treatment, data= PFants)
Levene's Test for Homogeneity of Variance (center = median)
       Df F value   Pr(&gt;F)   
group   1  8.6603 0.003917 **
      118                    
---
</code></pre>

<p>And then went on the Log transform the data because it fails the assumptions of ANOVA:</p>

<blockquote>
  <p>antlog&lt;- log10(ant.richness)</p>
</blockquote>

<p>However I am getting a lot of
 -Inf
in the resulting dataset, which means I can't run an ANOVA....</p>

<p>Any ideas? (Probably a dumb question! I'm not very good with stats/ R)
Thanks very much!!!</p>
"
"0.226455406828919","0.225302954529666","167946","<p><a href=""http://i.stack.imgur.com/p1woC.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/p1woC.png"" alt=""residue normality and data boxplots""></a>  </p>

<p>I have a data set from 7 groups, with 20 fish in each group. Measurement of a parameter is made on 25 cells from each fish (so each observation in the data-set is completely independent, right?). One of the groups functions as the control group while other 6 are treatment groups. So we have a total of 25*20*7 measurements. This is how the data looks like (a boxplot of all 7 groups is attached):</p>

<pre><code>samples subjects groups response
    1        1      1     4.85
    2        1      1     3.77 ..
    25       1      1     4.71
    26       2      1     4.51 ..
    500      20     1     4.21
    501      1      2     4.11 ..
    3500     20     7     4.19
</code></pre>

<p>I wish to run an ANOVA and the expectation is that a couple of groups should differ from the control group in regards to the parameter under observation. Here are a few questions:</p>

<ol>
<li><p>Is the following R code appropriate? (It shows there is no significant difference between groups.)</p>

<pre><code>n = 20
k = 25
g = 7
subjects = gl(n,   k, n*k*g)
groups   = gl(g, n*k, n*k*g)

study1 = data.frame(c(1:(n*k*g)), subjects, groups, r11)
colnames(study1) = c(""samples"", ""subjects"", ""groups"", ""response"")

fit = lm(response~groups + samples*subjects, data=study1) # or aov?
anova(fit)

Analysis of Variance Table

Response: response
                   Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
groups              6  846.8 141.134 122.2864 &lt; 2.2e-16 ***
samples             1   13.1  13.055  11.3114 0.0007787 ***
subjects           19  119.5   6.289   5.4493 2.078e-13 ***
samples:subjects   19  149.6   7.872   6.8206 &lt; 2.2e-16 ***
Residuals        3454 3986.4   1.154                       
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre></li>
<li><p>The attached qqplot shows normal residues, however the Shapiro-Wilk test always fails on all groups. (Is my sample size of 3500 too big and problematic?)</p>

<pre><code>shapiro.test(study1$response[study1$groups==1])

data:  study1$response[study1$groups == 1] W = 0.9818, p-value =
6.648e-06
</code></pre>

<p>And so does the Levene for equality of variance:</p>

<pre><code>leveneTest(lm(response ~ groups, data=study1))
Levene's Test for Homogeneity of Variance (center = median)
        Df F value    Pr(&gt;F)    
group    6   19.37 &lt; 2.2e-16 ***
      3493    
</code></pre></li>
</ol>

<p>Please guide me as to how should I proceed. Should I keep on using ANOVA and disregard the fact that the normality and equality of variance assumptions are being violated? Should I remove the outliers from my data? Should I transform data somehow to be 'more' normal? Should I switch to non parametric or rank based tests? The end goal is to identify groups that differ significantly from the control group. </p>
"
"0.24880667576406","0.247540475810749","172943","<p>I'm trying to understand the output of <code>glm</code> when a categorical variable has more than 2 categories.</p>

<p>I'm analysing if age affects death. Age is a categorical variable with 4 categories</p>

<p>I use the following code in R:</p>

<pre><code>mydata &lt;- read.delim(""Data.txt"", header = TRUE)
mydata$Agecod &lt;- factor(mydata$Agecod)
mylogit &lt;- glm(Death ~ Agecod, data = mydata, family = ""binomial"")
summary(mylogit)
</code></pre>

<p>Obtaining the following output: </p>

<pre><code>Call:
glm(formula = Death ~ Agecod, family = ""binomial"", data = mydata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.4006  -0.8047  -0.8047   1.2435   2.0963  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.5108     0.7303   0.699   0.4843  
Agecod2      -0.6650     0.7715  -0.862   0.3887  
Agecod3      -1.4722     0.7658  -1.922   0.0546 .
Agecod4      -2.5903     1.0468  -2.474   0.0133 *

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 237.32  on 184  degrees of freedom
Residual deviance: 223.73  on 181  degrees of freedom
  (1 observation deleted due to missingness)
AIC: 231.73

Number of Fisher Scoring iterations: 4
</code></pre>

<p>Since I have p-values for <code>Agecod2</code>, <code>Agecod3</code> and <code>Agecod4</code> and only <code>Agecod4</code> has a significant p-value my questions are:</p>

<ol>
<li>Is really <code>Age</code> associated with death?</li>
<li>Is only the 4th age category associated with death?</li>
<li>What happens with the first category since I don't have its p-value?</li>
</ol>

<p>Update:</p>

<p>Since Antoni Parellada says â€œIt seems as though you have proven that old age is a good predictor of deathâ€ and Gung points â€œYou cannot tell from your output if Age is associated with deathâ€ Iâ€™m still confused.</p>

<p>I understand that â€œInterceptâ€ is representing Agecod1 and is the â€œreference levelâ€. According to Gung â€œThe Estimates for the rest are the differences between the indicated level and the reference level. The associated p-values are for the tests of the indicated level vs. the reference level in isolation.â€ </p>

<p>My question now is: </p>

<p>Since Agecod4 p-value (0.0133) is significantly different from Agecod1 (reference lelvel) it doesnâ€™t mean that age is associated with death?</p>

<p>I have also tried to perform a nested test with the following command:</p>

<pre><code>anova(mylogit, test=""LRT"")
</code></pre>

<p>Obtaining:</p>

<pre><code>       Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)   
NULL                     184     237.32            
Agecod  3   13.583       181     223.73 0.003531 *
</code></pre>

<p>Does it mean that Age is definitively associated with death?</p>

<p>Update2:</p>

<p>I have solved my problem using binary logistic regression in SPSS. The output is the same than â€œmylogitâ€ but with SPSS I obtain a global p-value for the overall variable Agecod which is 0.008.</p>

<p>I donâ€™t know if is possible to obtain this â€œglobal p-valueâ€ with R, but since I know that I can use SPSS is not a big problem for me.</p>
"
"0.160128153805087","0.159313246969292","173207","<p>I have a dataset gpa2 ddata that can be found here <a href=""https://www.dropbox.com/s/7rphi1k9pxert1a/ddata.csv?dl=1"" rel=""nofollow"">https://www.dropbox.com/s/7rphi1k9pxert1a/ddata.csv?dl=1</a></p>

<p>I estimate the model colgpa = athelte.</p>

<pre><code>gpa2 &lt;- read.csv(~""/path/ddata.csv"")
model1 &lt;- lm(formula = colgpa ~ athlete, data = gpa2)
summary(model1)
</code></pre>

<p>And now I want to see if I can get <strong>Std.Error by this formula</strong>
$$se(\beta_j) = \frac{\hat \sigma_u}{SST_j(1âˆ’R_j^2)}$$
where $$SST_j = \sum_{i=1}^n (x_{ij} - \bar x_j)^2$$ is the total sample variation in $x_j$
and $R_j^2$ is the $R^2$ from regressing $x_j$ on all the other independent variables.</p>

<p>From this answer 
<a href=""http://stats.stackexchange.com/questions/44838/how-are-the-standard-errors-of-coefficients-calculated-in-a-regression"">How are the standard errors of coefficients calculated in a regression?</a>
we know that the standard error of the estimated slope, $se(\beta_1)$ in our case, is
$$\sqrt{\widehat{\textrm{Var}}(\hat{b})} = \sqrt{[\hat{\sigma}^2  (\mathbf{X}^{\prime} \mathbf{X})^{-1}]_{22}} = \sqrt{\frac{n \hat{\sigma}^2}{n\sum x_i^2 - (\sum x_i)^2}}.$$</p>

<p>I do this with an anova-table, and try to </p>

<pre><code>anova(model1) # the anova table
# now I take out elements of the anova
model1_hatsigmau &lt;- anova(model1)[[3]][2] #takes row 3 column 2 in the anova-table.
model1_MSathlete &lt;- anova(model1)[[3]][1]
model1_SSathlete &lt;- anova(model1)[[2]][1]
numerator &lt;- n*model1_hatsigmau
meanathlete &lt;- mean(gpa2$athlete)
denominator &lt;- n*model1_SSathlete - (n*meanathlete)^2 
sqrt(numerator /  denominator) # should be se(beta_1) for model1. 
</code></pre>

<p>But I get </p>

<pre><code>&gt; sqrt(numerator /  denominator) # should be se(beta_1) for model1.
[1] 0.270643
</code></pre>

<p>And not $0.04824$ as in the summary-output (see below). So the problem is that $$0.270643 \neq 0.04824$$</p>

<pre><code>&gt; summary(model1)

Call:
lm(formula = colgpa ~ athlete, data = gpa2)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.66603 -0.43603  0.00397  0.46397  1.61851 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.66603    0.01045 255.212  &lt; 2e-16 ***
athlete     -0.28453    0.04824  -5.898 3.97e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.656 on 4135 degrees of freedom
Multiple R-squared:  0.008343,  Adjusted R-squared:  0.008104 
F-statistic: 34.79 on 1 and 4135 DF,  p-value: 3.966e-09
</code></pre>
"
"0.295718434854086","0.2942134966636","185391","<p>I am using the Titanic dataset to understand glm model. These are the two models,</p>

<pre><code>titanic.glm       &lt;- glm(survived ~ pclass,         family=binomial, data=titanic.train)
titanic.glm.title &lt;- glm(survived ~ pclass + title, family=binomial, data=titanic.train)
</code></pre>

<p>I have two summaries. Since it has categorical variables, I am not able to interpret it properly and compare it. Can anybody help me in comparing both the models and find out which one is better? following is the summaries of both the models,</p>

<pre><code>&gt; summary(titanic.glm)

Call:
glm(formula = survived ~ pclass, family = binomial, data = titanic.train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.3652  -0.7779  -0.7779   1.0006   1.6388  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.4313     0.1272   3.391 0.000696 ***
pclass2      -0.7086     0.1852  -3.826 0.000130 ***
pclass3      -1.4715     0.1593  -9.237  &lt; 2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1393.6  on 1046  degrees of freedom
Residual deviance: 1301.5  on 1044  degrees of freedom
AIC: 1307.5

Number of Fisher Scoring iterations: 4

&gt; summary(titanic.glm.title)

Call:
glm(formula = survived ~ pclass + title, family = binomial, data = titanic.train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2066  -0.6462  -0.4263   0.6521   2.2106  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)    1.5336     0.3356   4.570 4.88e-06 ***
pclass2       -0.9028     0.2259  -3.997 6.41e-05 ***
pclass3       -1.7950     0.2037  -8.814  &lt; 2e-16 ***
titleMiss      0.4701     0.3207   1.466 0.142706    
titleMr.      -2.0911     0.3131  -6.679 2.40e-11 ***
titleMrs.      0.8092     0.3507   2.308 0.021011 *  
titleNothing  -1.7024     0.5157  -3.301 0.000964 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1393.58  on 1046  degrees of freedom
Residual deviance:  990.66  on 1040  degrees of freedom
AIC: 1004.7

Number of Fisher Scoring iterations: 4
</code></pre>

<p>I tried the following,</p>

<pre><code>anova(titanic.glm,titanic.glm.title, test = ""Chisq"")

Analysis of Deviance Table

Model 1: survived ~ pclass
Model 2: survived ~ pclass + title
  Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
1      1044    1301.47                          
2      1040     990.66  4   310.81 &lt; 2.2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>I am not able to compare both the models. I read somewhere AIC is one of the parameter to compare it. Can anybody help in comparing both the models and decide which one is better? Also how can we find whether a particular model is stable or not?</p>
"
"0.366083452257944","0.364220420051379","188361","<p>I'm pretty new in using <code>lmer</code> and be confused about different p-values in Tukey post hoc tests associated with exactly the same estimates. I built a linear mixed model with monetary contributions of human subjects as response variable and their wealth and number of children as explanatory variables. The experiment was designed in a way to contribute for future generations. I don't have repeated measurements of the same individual but some individuals played within the same group. There are several subsets and additional random factors but here I only want to consider the following model where <code>totalcontSubject</code> means contribution of a subject over the entire game, <code>poverty</code> is a factor with 2 levels (rich and poor), and <code>children</code> is a factor with 2 levels (child or noChild). Particularly I'm interested in understanding the fixed effects part of the model.</p>

<pre><code> &gt; summary(TC1)
Linear mixed model fit by REML ['lmerMod']
Formula: totalcontSubject ~ poverty * children + (1 | group_2)
   Data: data

REML criterion at convergence: 414.6

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-2.42955 -0.45554 -0.09361  0.45228  2.33159 

Random effects:
 Groups   Name        Variance  Std.Dev. 
 group_2  (Intercept) 8.611e-15 9.280e-08
 Residual             1.042e+02 1.021e+01
Number of obs: 58, groups:  group_2, 10

Fixed effects:
                             Estimate Std. Error t value
(Intercept)                    16.200      3.228   5.019
povertyrich                     8.600      3.953   2.175
childrennoChild                 2.800      4.565   0.613
povertyrich:childrennoChild    -4.489      5.642  -0.796

Correlation of Fixed Effects:
            (Intr) pvrty chldrC
povertyrch  -0.816              
chldrnnChld -0.707  0.577       
pvrtyrch:C   0.572 -0.701 -0.809
</code></pre>

<p>If I interpret fixed effects of the summary table in the right way, my intercept denotes poor people with children. The estimate also corresponds to the mean value of this combination in my data. According to my calculations the difference to rich people (shown as <code>povertyrich</code>) actually shows the difference of the intercept to rich people with children, even if not explicitly mentioned by <code>povertyrich</code>. This is the first issue I'm a bit confused. A reduced model only with fixed factor poverty is significant better by <code>anova()</code> but it seems data including children are used for this evaluation.</p>

<p>If I run a Tukey post hoc test by means of my TC1 model, I get a significant difference between rich and poor. But the estimates in the summary actually include children. Estimates of intercept and slope are the means of poor people with children and the difference to rich people with children. They don't correspond to the means of poor or rich data irrespective of parenthood. </p>

<pre><code>summary(glht(TC1, linfct=mcp(povertry=""Tukey"")))

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = totalcontSubject ~ poverty * children + (1 | 
    group_2), data = data)

Linear Hypotheses:
                 Estimate Std. Error z value Pr(&gt;|z|)  
rich - poor == 0    8.600      3.953   2.175   0.0296 *
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
(Adjusted p values reported -- single-step method)
</code></pre>

<p>I get even more confused when I run a Tukey post hoc test for a subset where I coded interactions in a column such as poor people with children and rich people with children. In this output I have exactly the same estimates and parameters for these categories (like in the summary shown before for rich poor people exclusively) but the p-values are different. A visual check indicates that there is a significant difference between <code>richChild</code> and <code>poorChild</code> but outputs of <code>glht</code> <code>Interak</code> shows me it is not. Also, a comparison between models <code>anova()</code> with fixed factor poverty vs. fixed factors poverty and children indicates that I can get rid of the variable children in my model. Before I do so, I would like to understand the outputs better. I also worry about the high value for Residual and the correlations in the summary table. </p>

<pre><code>&gt; summary(glht(TC1_2, linfct=mcp(Interak=""Tukey"")))

         Simultaneous Tests for General Linear Hypotheses

Multiple Comparisons of Means: Tukey Contrasts


Fit: lmer(formula = totalcontSubject ~ Interak + (1 | group_2), data = data)

Linear Hypotheses:
                               Estimate Std. Error z value Pr(&gt;|z|)
poorNoChild - poorChild == 0      2.800      4.565   0.613    0.927
richChild - poorChild == 0        8.600      3.953   2.175    0.129
richNoChild - poorChild == 0      6.911      4.026   1.717    0.312
richChild - poorNoChild == 0      5.800      3.953   1.467    0.454
richNoChild - poorNoChild == 0    4.111      4.026   1.021    0.735
richNoChild - richChild == 0     -1.689      3.316  -0.509    0.956
(Adjusted p values reported -- single-step method)
</code></pre>
"
"0.258198889747161","0.256884891956954","189396","<p><strong>Introduction</strong></p>

<p>I'm doing a small pilot research in bird aggression in a colonising frontier regarding their breeding ground.</p>

<p><strong>Background</strong></p>

<p>The study was conducted over multiple years, presenting the colonising (south) and settled (north) collared flycatcher males with conspecific and pied flycatcher males. Scoring their behaviour based upon a quantifiable set aggressive actions. They have found this Island 60 years ago and are steadily spreading from one point in their breeding ground and pushing their relative pied flycatcher away from the more insect bearing territories. In previous studies it was shown that more aggressive males are at the front of such colonising action. In the north sites there is a near 100% collared and the south still has a mixed population.</p>

<p><strong>Hypothesises</strong></p>

<p>In the south location male collared flycatcher will act with higher aggression towards both species. Males will react in the north relatively more to conspecifics than they would in the south.</p>

<p><strong>Problem</strong></p>

<p>After having scored all the interactions I'm now at a loss at what test to use to present the data. Many people give different advice for <code>lm</code> or simple <code>Anova</code> etc. I have been learning R and statistics at the same time but many terms still confuse me and questions and answers found on the internet I found difficult to interpret to my data. </p>

<p><strong>Question</strong></p>

<p>What test out of the following three could be best used to show that there is or is not a statistical significance?</p>

<ul>
<li><code>Anova(lm(score~dummy_species*location))</code></li>
<li><code>summary(aov(score~dummy_species*location))</code></li>
<li><code>summary(lm(score~dummy_species*location))</code></li>
</ul>

<p><strong>Data structure</strong></p>

<p>The data is unfortunately unbalanced.</p>

<p>The amount of conspecific trials was 104 of which 77 were in the northern test area and 27 in the south.  Similarly of the 50 pied flycatcher dummy tests 36 were in the north and 14 in the south.</p>

<pre><code>'data.frame':   154 obs. of  8 variables:
 $ location        : Factor w/ 2 levels ""N"",""S"": 1 1 1 1 1 1 1 1 2 1 ...
 $ score           : int  1 4 0 1 1 8 9 9 4 3 ...
 $ dummy_species   : Factor w/ 2 levels ""CF"",""PF"": 1 1 2 2 1 1 1 1 1 2 ...
</code></pre>

<p>Location is north and south</p>

<p>Score is 0 to 7 with 7 being the highest score for aggressive behaviour. Dummy species represents conspecific and heterospecific types. So dependent variable has two two level independent factors</p>

<pre><code>model.tables(aov(scoreCF$score~scoreCF$location),""means"")

Tables of means
Grand mean
2.993506

 dummy_species 
     CF    PF
  3.529  1.88

rep 104.000 50.00

 location 
      N      S
      2.742  3.686
rep 113.000 41.000

 dummy_species:location 
         location
dummy_species N     S    
      CF   3.19  4.48
      rep 77.00 27.00
      PF   1.81  2.07
      rep 36.00 14.00

TukeyHSD(aov(score~dummy_species*location))

Tukey multiple comparisons of means
95% family-wise confidence level

Fit: aov(formula = score ~ dummy_species * location)

$dummy_species
       diff       lwr        upr     p adj
PF-CF -1.648846 -2.613568 -0.6841239 0.0009332

$location
     diff         lwr    upr     p adj
S-N 0.9440487 -0.07800284 1.9661 0.0699746

$`dummy_species:location`
           diff        lwr        upr     p adj
PF:N-CF:N -1.389250 -2.8774793 0.09898005 0.0766924
CF:S-CF:N  1.286676 -0.3619293 2.93528192 0.1824646
PF:S-CF:N -1.123377 -3.2649782 1.01822492 0.5246337
CF:S-PF:N  2.675926  0.7993571 4.55249475 0.0016744
PF:S-PF:N  0.265873 -2.0557788 2.58752484 0.9908082
PF:S-CF:S -2.410053 -4.8376320 0.01752615 0.0524523
</code></pre>

<p><strong>Results</strong></p>

<pre><code>Anova(lm(score~dummy_species*location))
Anova Table (Type II tests)

Response: score
                    Sum Sq  Df F value    Pr(&gt;F)  
dummy_species            93.91   1 11.6673 0.0008186 ***
location                 26.82   1  3.3326 0.0699100 .  
dummy_species:location    6.98   1  0.8675 0.3531437    
Residuals              1207.39 150         

summary(aov(score~dummy_species*location))*

                    Df Sum Sq Mean Sq F value   Pr(&gt;F)    
dummy_species            1   91.8   91.80  11.405 0.000933 ***
location                 1   26.8   26.82   3.333 0.069910 .  
dummy_species:location   1    7.0    6.98   0.868 0.353144    
Residuals              150 1207.4    8.05          

summary(lm(score~dummy_species*location))
Call:
lm(formula = score ~ dummy_species * location)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.4815 -2.1948 -0.8056  2.1280  6.9286 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)                 3.1948     0.3233   9.881   &lt;2e-16 ***
dummy_speciesPF            -1.3892     0.5728  -2.425   0.0165 *  
locationS                   1.2867     0.6346   2.028   0.0444 *  
dummy_speciesPF:locationS  -1.0208     1.0960  -0.931   0.3531    

Residual standard error: 2.837 on 150 degrees of freedom
Multiple R-squared:  0.09423,   Adjusted R-squared:  0.07611 
F-statistic: 5.202 on 3 and 150 DF,  p-value: 0.001909
</code></pre>

<p>Ideally given the time investment (in the field and behind the screen) I would love to have it that male aggression is likely influenced by both location and species. But only if the lm approach would be relevant.</p>
"
"0.290084787862418","0.318988364008573","192173","<p>I'm working on the similarity of categorical regression with exclusively  dummy variables and ANOVA. There are lots of references, like Gujarati &amp; Porter (2009), which have mentioned that those two are equivalent. Everything is okay when distribution of residuals is normal, variances are homogeneous and regression model is significant. My questions are there. We have a category with 3 levels (red,blue,green), a numeric variable ""allscore""( -5 &lt;= allscore &lt;= +5). I played with R and made data and ran models (regression and variance).</p>

<pre><code># creating data 
bluescore  &lt;- rnorm(n=100, mean=-1, sd=1)
redscore   &lt;- rnorm(n=100, mean=2,  sd=1)
greenscore &lt;- rnorm(n=100, mean=.1, sd=2)
for (i in 1:100) {
  if (bluescore[i] &lt; -5)  bluescore[i]  &lt;- -5
  if (bluescore[i] &gt; 5)   bluescore[i]  &lt;-  5
  if (redscore[i] &lt; -5)   redscore[i]   &lt;- -5
  if (redscore[i] &gt; 5)    redscore[i]   &lt;-  5
  if (greenscore[i] &lt; -5) greenscore[i] &lt;- -5
  if (greenscore[i] &gt; 5)  greenscore[i] &lt;-  5
}
color &lt;- as.factor(c(rep(1,100), rep(2,100), rep(3,100)))
allscore &lt;- c(bluescore, redscore, greenscore)
table &lt;- data.frame(color, allscore)
randtable &lt;- table[sample(nrow(table)),]
finaltable &lt;- data.frame(randtable$color, randtable$allscore)
colnames(finaltable) &lt;- c(""color"", ""score"")
# plot
plot(randtable$allscore ~ randtable$color, data=finaltable)
# saving data for SPSS
library(rio)
export(finaltable, ""dummy.sav"")
write.csv(finaltable, ""finaltable.csv"")
# making dummy variables
dummyred   &lt;- NULL
dummygreen &lt;- NULL
dummyblue  &lt;- NULL
for(i in 1:NROW(finaltable)) {
  if (randtable$color[i]==2) dummyred[i]=1 else dummyred[i]=0
      if (randtable$color[i]==3) dummygreen[i]=1 else dummygreen[i]=0
  if (randtable$color[i]==1) dummyblue[i]=1 else dummyblue[i]=0
}
t1 = cbind(randtable, dummyred, dummygreen)
# run regression model 
mosel.1 &lt;- lm(formula = allscore~dummyred + dummygreen + dummyblue -1, data=t1)
ttt &lt;- summary(mosel.1)
ttt

# **test of homogenity**
# Bartlettâ€™s test
bartlett.test(randtable$allscore ~ randtable$color, data=finaltable)
# Leveneâ€™s test
library(car)

leveneTest(randtable$allscore ~ randtable$color, data=finaltable)
# Fligner-Killeen test
fligner.test(randtable$allscore ~ randtable$color, data=finaltable)
# ANOVA mode
hh &lt;- aov(randtable$allscore ~ randtable$color, data=finaltable)
hh
summary(hh)
# post hoc test
TukeyHSD(hh)
</code></pre>

<p>Output would be something like this:  </p>

<p><a href=""http://i.stack.imgur.com/v0o8x.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/v0o8x.png"" alt=""enter image description here""></a></p>

<pre><code>Call:
lm(formula = allscore ~ dummyred + dummygreen + dummyblue - 1, 
    data = t1)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.0152 -0.7880  0.0043  0.8088  3.3731 

Coefficients:
           Estimate Std. Error t value Pr(&gt;|t|)    
dummyred    2.02102    0.13273  15.227  &lt; 2e-16 ***
dummygreen  0.01525    0.13273   0.115    0.909    
dummyblue  -1.04294    0.13273  -7.858 7.24e-14 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 1.327 on 297 degrees of freedom
Multiple R-squared:  0.4971,    Adjusted R-squared:  0.4921 
F-statistic: 97.87 on 3 and 297 DF,  p-value: &lt; 2.2e-16

&gt;  
&gt; # test of homogenity
&gt; # Bartlettâ€™s test
&gt; bartlett.test(randtable$allscore ~ randtable$color, data=finaltable)

    Bartlett test of homogeneity of variances

data:  randtable$allscore by randtable$color
Bartlett's K-squared = 94.825, df = 2, p-value &lt; 2.2e-16

&gt; # Leveneâ€™s test
&gt; library(car)
&gt; 
&gt; leveneTest(randtable$allscore ~ randtable$color, data=finaltable)
Levene's Test for Homogeneity of Variance (center = median)
       Df F value    Pr(&gt;F)    
group   2  43.995 &lt; 2.2e-16 ***
      297                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
&gt; # Fligner-Killeen test
&gt; fligner.test(randtable$allscore ~ randtable$color, data=finaltable)

    Fligner-Killeen test of homogeneity of variances

data:  randtable$allscore by randtable$color
Fligner-Killeen:med chi-squared = 66.204, df = 2, p-value = 4.207e-15

&gt; # ANOVA mode
&gt; hh &lt;- aov(randtable$allscore ~ randtable$color, data=finaltable)
&gt; hh
Call:
   aov(formula = randtable$allscore ~ randtable$color, data = finaltable)

Terms:
                randtable$color Residuals
Sum of Squares         484.3572  523.2176
Deg. of Freedom               2       297

Residual standard error: 1.327281
Estimated effects may be unbalanced
&gt; summary(hh)
                 Df Sum Sq Mean Sq F value Pr(&gt;F)    
randtable$color   2  484.4  242.18   137.5 &lt;2e-16 ***
Residuals       297  523.2    1.76                   
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
&gt; # post hoc test
&gt; TukeyHSD(hh)
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = randtable$allscore ~ randtable$color, data = finaltable)

$`randtable$color`
         diff        lwr       upr p adj
2-1  3.063958  2.6218117  3.506104 0e+00
3-1  1.058184  0.6160382  1.500330 1e-07
3-2 -2.005774 -2.4479195 -1.563628 0e+00
</code></pre>

<ul>
<li>Is variance homogeneity check essential for regression model as assumption (because it compares means and equivalent to ANOVA)?</li>
<li>What is assumption for this regression model?</li>
<li>How can I interpret ""greendummy"" variable insignificance? Can I omit it from model? What theory support this omission? Is it means green color has no effect on scores? Is it equivalent to heterogeneity of variances?</li>
<li>How about ANOVA model, what can I say about the results?  </li>
<li>Can I remove green level from ANOVA?</li>
</ul>

<blockquote>
  <p>Gujarati, Damodar N.; Porter, Dawn C. (2009): Basic econometrics. 5th
  ed. Boston: McGraw-Hill Irwin (The McGraw-Hill series, economics).</p>
</blockquote>
"
"0.304243492229666","0.286763844544725","198484","<p>Consider this example:</p>

<pre><code>foo &lt;-data.frame(x=c(0.010355057,0.013228936,0.016313905,0.019261687,0.021710159,0.023973474,0.025968176,0.027767232,0.029459730,0.030213807,0.023582566,0.008689883,0.006558429,0.005144958),
                 y=c(971.3800,1025.2271,1104.1505,1034.2607,902.6324,713.9053,621.4824,521.7672,428.9838,381.4685,741.7900, 979.7046,1065.5245,1118.0616))
Model3 &lt;- lm(y~poly(x,3),data=foo)
Model4 &lt;- lm(y~poly(x,4),data=foo)
</code></pre>

<p>For <code>Model3</code>, the <code>poly(x,3)</code> term is not significant:</p>

<pre><code>&gt; summary(Model3)

Call:
lm(formula = y ~ poly(x, 3), data = foo)

Residuals:
   Min     1Q Median     3Q    Max 
-76.47 -51.61  -0.55  38.22 100.57 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   829.31      17.85  46.463 5.14e-13 ***
poly(x, 3)1  -819.37      66.78 -12.269 2.37e-07 ***
poly(x, 3)2  -373.05      66.78  -5.586 0.000232 ***
poly(x, 3)3   -87.85      66.78  -1.315 0.217740    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 66.78 on 10 degrees of freedom
Multiple R-squared:  0.9483,    Adjusted R-squared:  0.9328 
F-statistic: 61.15 on 3 and 10 DF,  p-value: 9.771e-07
</code></pre>

<p>However, for <code>Model4</code> it is:</p>

<pre><code>&gt; summary(Model4)

Call:
lm(formula = y ~ poly(x, 4), data = foo)

Residuals:
    Min      1Q  Median      3Q     Max 
-34.344 -19.982   1.229  18.499  33.116 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  829.310      7.924 104.655 3.37e-15 ***
poly(x, 4)1 -819.372     29.650 -27.635 5.16e-10 ***
poly(x, 4)2 -373.052     29.650 -12.582 5.14e-07 ***
poly(x, 4)3  -87.846     29.650  -2.963 0.015887 *  
poly(x, 4)4  191.543     29.650   6.460 0.000117 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 29.65 on 9 degrees of freedom
Multiple R-squared:  0.9908,    Adjusted R-squared:  0.9868 
F-statistic: 243.1 on 4 and 9 DF,  p-value: 3.695e-09
</code></pre>

<p>Why does this happen? Note that the estimate of all coefficients is the same in both cases, since the polynomials are orthogonal. However, the significance is not. This seems to me difficult to understand: if I performed a degree 3 regression, it looks like I could drop the <code>poly(x, 4)3</code> term, thus reverting to a degree 2 orthogonal regression. However, if I performed a degree 4 regression, I shouldn't, even though the coefficients of the common terms have exactly the same estimate. What do I conclude? Probably that one should never trust subset selection :) An <code>anova</code> analysis says that the difference among the degree 2, degree 3 and degree 4 models is significant:</p>

<pre><code>&gt; Model2 &lt;- lm(y~poly(x,2),data=foo)     
&gt; anova(Model2,Model3,Model4)
Analysis of Variance Table

Model 1: y ~ poly(x, 2)
Model 2: y ~ poly(x, 3)
Model 3: y ~ poly(x, 4)
  Res.Df   RSS Df Sum of Sq       F    Pr(&gt;F)    
1     11 52318                                   
2     10 44601  1      7717  8.7782 0.0158868 *  
3      9  7912  1     36689 41.7341 0.0001167 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>EDIT: following a suggestion in comments, I add the residual vs fitted plots for <code>Model2</code>, <code>Model3</code> and <code>Model4</code></p>

<p><a href=""http://i.stack.imgur.com/9ZU8h.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/9ZU8h.png"" alt=""enter image description here""></a>` </p>

<p>It's true that the maximum residual error is more or less the same for <code>Model2</code> and <code>Model3</code>, and it becomes nearly one third going from <code>Model3</code> to <code>Model4</code>. There seems to be still some kind of trend in the residuals, though it is less evident than for <code>Model2</code> and <code>Model3</code>. However, why does this invalidate the <em>p</em>-values? Which hypothesis of the linear model paradigm is violated here? I seem to remember that the residuals only had to be uncorrelated with the predictor. However, if they also have to uncorrelated among themselves, then clearly this assumption is violated and the <em>p</em>-values based on the t-test are invalid.</p>
"
"0.101273936708367","0.100758544371976","203717","<p>I am trying to do model simplification looking at how different factors may affect distance. So I have snails kept in several habitats and I wanted to see if that affects how closely another snail may follow that snail. So I start off with this model: </p>

<pre><code>  model1 &lt;- lmer(sqrt(dist+6)~  (1|snail)+food+stress+food:stress+
       weight+OriginalL+FollowedL)
summary(model1)
</code></pre>

<p>and the summary is this: </p>

<pre><code>  Linear mixed model fit by REML ['lmerMod']
  Formula: sqrt(dist + 6) ~ (1 | snail) + food + stress + food:stress +  
weight + OriginalL + FollowedL

REML criterion at convergence: 561.1

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.2941 -0.7698 -0.3347  0.7515  1.9564 

Random effects:
 Groups   Name        Variance Std.Dev.
 snail    (Intercept) 0.000    0.000   
 Residual             2.334    1.528   
Number of obs: 148, groups:  snail, 37

Fixed effects:
                               Estimate Std. Error t value
(Intercept)                    4.960927   0.662947   7.483
foodSweetPotato               -0.219039   0.357768  -0.612
stressshelter                 -0.246649   0.355999  -0.693
weight                         0.002520   0.063259   0.040
OriginalL                      0.015549   0.013072   1.189
FollowedL                     -0.008044   0.005972  -1.347
foodSweetPotato:stressshelter -0.300143   0.503215  -0.596

Correlation of Fixed Effects:
            (Intr) fdSwtP strsss weight OrgnlL FllwdL
foodSwetPtt -0.309                                   
stressshltr -0.315  0.502                            
weight      -0.615  0.008  0.009                     
OriginalL   -0.617 -0.021  0.032  0.123              
FollowedL   -0.470  0.118  0.059  0.087 -0.004       
fdSwtPtt:st  0.230 -0.707 -0.708 -0.008 -0.024 -0.055
</code></pre>

<p>Should I remove the least significant factor or remove the interactions first?</p>

<p>And after this is it a simple anova between my first model and most simplified model?</p>
"
"0.237508434398142","0.214817938390538","205160","<p>I have subjects that each provide arbitrary number of ratings (on a scale 0-5) to songs of 20 different genres. Each of the subjects can be of one of the five personality types (A, B, C, D, E) with scores ranging from 1-7 for each of the five types. I am interested in finding the relationship between personality and ratings for each genre, and here is what I tried so far and what concerns I have:</p>

<ol>
<li><p>Since there are repeated measures per subject, for each genre, I first tried to take just one measurement per subject, i.e., median rating for that genre. I also tried to categorize the personality scores into two categories high (4-7) and low (1-4). For each genre I tried to compare median rating of high and low groups using a wilcox test. But I felt aggregation was killing the signal since most users have about the same median rating. </p></li>
<li><p>I want to use repeated measures of ratings by subjects as they are, but still see how users with high and low personality scores on any one personality type compare against each other. Because there is imbalance in the number of ratings each individual subject can produce, I'm assuming I should go with repeated-measures ANOVA with imbalance - something like an lmer? So is something like this correct in R, where A1 is A transformed into high and low scale from 1-7 scale.</p>

<pre><code> lmer(subj_rating ~ A1 + (1 | subjId), data=dat.jazz.A)   
</code></pre></li>
</ol>

<p>Since similar ratings can be produced by users for different songs, should I also include (1|songId) in the expression above?</p>

<ol start=""3"">
<li><p>Is there a way I can do #2 above, without making that conversion of A to A1, i.e, as a continuous variable. Which statistical approach should I then use?</p></li>
<li><p>Because I am trying to run multiple individual tests for each genre and personality, is this the case of a multiple-comparison problem? Do I need any adjustments?</p></li>
</ol>

<p>Here is how my sample data looks like (filtered for one genre, songId skipped)</p>

<pre><code>subjId, rating, A, A1
38675, 3.5, 6.0, 1
38675, 3.0, 6.0, 1
38675, 2.5, 6.0, 1
38676, 4.0, 5.5, 1
38676, 2.0, 5.5, 1
38683, 5.0, 3.5, 0
38683, 4.5, 3.5, 0
38683, 4.0, 3.5, 0
38683, 4.0, 3.5, 0
38683, 3.5, 3.5, 0
38683, 4.0, 3.5, 0
...
</code></pre>
"
"0.335887649103853","0.334178286104219","208273","<p>I want to analyse the effect of different treatment types (<code>control, treatment1, ..., treatment4</code>) on the surface of specimens made of certain materials (<code>plastic, metal</code>). The undamaged area of the surface is measured <code>before</code> and <code>after</code> the treatment.</p>

<p>According to this design I specified a mixed model using lme4 as follows:</p>

<pre><code>require(""lme4"")
data &lt;- read.csv(""http://pastebin.com/raw/G4D8dh1f"")
mm1  &lt;- lmer(undamaged_area ~ time*material*treatment + (1|specimen_id), data)
</code></pre>

<p><strong>Questions:</strong> </p>

<ol>
<li><p>Is the mixed model the optimal choice in this case? I found some hints that an ANCOVA (something like <code>lm(undamaged_area_after ~ material*treatment + undamaged_area_before, data)</code>) might be an alternative approach.</p>

<p>A closer look on the diagnostic plots of the mixed model makes me very suspicious:</p>

<pre><code>plot(mm1); require(""lattice""); qqmath(mm1)  
</code></pre>

<p><a href=""http://i.stack.imgur.com/LDxEY.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/LDxEY.png"" alt=""diagnostic plots""></a></p></li>
<li><p>Does the plots actually indicate a violation of model assumptions? Does the strange pattern come from a misspecification of the model? </p></li>
</ol>

<p><strong>Progress after <a href=""http://stats.stackexchange.com/a/208463/112794"">donlelek's answer</a> (=mixed model not required):</strong></p>

<p>Just to be clear: The treatments were measured in different pieces of metal/plastic. So every piece is exactly measured twice - before and after the treatment. Thus, we are aiming for the ANOVA on damage, I guess. I had the impression to lose informations by just substracting the pre-post values. I did further research in the literature (with my limited knowledge in statistics). But according to <a href=""https://pdfs.semanticscholar.org/b764/e331525ec9ba814b51ee890aea7f663e175d.pdf"" rel=""nofollow"">""Pretest-posttest designs and measurement of
change""</a> the use of such gain scores seems to be ok:</p>

<blockquote>
  <p>""First, contrary to the
  traditional misconception, the reliability of gain scores is high in many practical situations, particularly when the pre- and posttest scores do not have equal variance and equal reliability.""</p>
</blockquote>

<p>so we have the following model:</p>

<pre><code>library(tidyr)
library(dplyr)

data &lt;- read.csv(""http://pastebin.com/raw/G4D8dh1f"")    
data_wide  &lt;- data %&gt;% 
  spread(time, undamaged_area) %&gt;% 
  separate(specimen_id, c(""mat"", ""id"", ""tx"")) %&gt;% 
  mutate(damage = before - after, 
         unique_id = paste(mat, id, sep = ""_"")) %&gt;% 
  select(-mat, -tx, -id)

# model for full factorial with replications
mm2  &lt;- lm(damage ~ material * treatment , data = data_wide)
</code></pre>

<p>The variance problem still remains. Confirmed by Levene's test:</p>

<pre><code>library(car)
leveneTest(damage ~ material * treatment, data_wide)

# Levene's Test for Homogeneity of Variance (center = median)
#       Df F value    Pr(&gt;F)    
# group  9  4.8619 2.646e-05 ***
#       90                      
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1    
</code></pre>

<p>Following the link suggested by donlelek I found different approaches for <a href=""http://stats.stackexchange.com/questions/91872/alternatives-to-one-way-anova-for-heteroskedastic-data/91881#91881"">anovas with heteroskedastic data</a>. I tried to stabilize the variance by using log-transformation. Then Levene's test says that heterogeneity of the variance diappears:</p>

<pre><code>data_wide &lt;- within(data_wide, log_damage &lt;- log(damage+1))
leveneTest(log_damage ~ material * treatment, data_wide)

# Levene's Test for Homogeneity of Variance (center = median)
#       Df F value Pr(&gt;F)
# group  9  0.6916 0.7147
#       90
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1   
</code></pre>

<p>The diagnostic plots seems not to be as weird as the previous ones (see <a href=""http://stats.stackexchange.com/a/208463/112794"">donlelek's answer</a>):</p>

<pre><code>mm3 &lt;- lm(log_damage ~ material * treatment, data_wide)
plot(fitted(mm3), residuals(mm3, type = ""pearson""))
qqnorm(residuals(mm3, type = ""pearson""))
</code></pre>

<p><a href=""http://i.stack.imgur.com/NDTAj.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/NDTAj.png"" alt=""enter image description here""></a></p>

<p>The anova table gives the following output:</p>

<pre><code>anova(mm3)

# Analysis of Variance Table
#
# Response: log_damage
#                    Df Sum Sq Mean Sq F value    Pr(&gt;F)    
# material            1  0.436  0.4362  0.7462      0.39    
# treatment           4 83.652 20.9129 35.7786 &lt; 2.2e-16 ***
# material:treatment  4 20.213  5.0532  8.6452 5.966e-06 ***
# Residuals          90 52.606  0.5845                      
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>Just for double checking:</p>

<p>The <code>Anova</code> function from <code>car</code> package offers an option for heteroscedasticity correction. Interestingly, this function generates a roughly similar table for the ""non-transformed"" <code>mm2</code>:</p>

<pre><code>Anova(mm2, white.adjust=TRUE)

# Analysis of Deviance Table (Type II tests)
# 
# Response: damage
#                    Df       F    Pr(&gt;F)    
# material            1  1.4251    0.2357    
# treatment           4 28.2422 3.329e-15 ***
# material:treatment  4  9.5739 1.701e-06 ***
# Residuals          90                      
# ---
# Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p><strong>New questions:</strong> </p>

<p>This double check gives me more confidence in the results. But do you think that the log-transformation is a reasonable approach? Can I trust the model now?</p>
"
"0.286445949615773","0.284988199951639","212199","<p>I would really appreciate some help with a few models I am trying to run. Essentially my data looks at how often a subject was visited depending on treatment and subject type across two years. The data looks like this:</p>

<pre><code>Year    | Subject | SubjectType | Treatment | BlockNum | NumberOfVisits | DurationOfVisits
--------+---------+-------------+-----------+----------+----------------+---------------+
1       | 1       | Type1       | Treatment1| 1        | 14             | 15.6
2       | 1       | Type1       | Treatment1| 1        | 0              | 0
1       | 2       | Type2       | Treatment2| 2        | 3              | 4.3
2       | 2       | Type2       | Treatment2| 2        | 0              | 0
</code></pre>

<p>and so on for 200 subjects with a measurement for each year.</p>

<p>Essentially I want to create a model that tests if the number of visits / duration of visits are different between treatment and subject across both years, and if there are any interactions. BlockNum refers to the experimental design being split into three randomised blocks (three blocks of plants growing in a greenhouse). I have tried a bunch of different models and cant seem to get a good resolution:</p>

<p>Repeated Measures ANOVA:</p>

<pre><code>model1 &lt;- aov(NumberOfVisits ~ SubjectType*Treatment*Year*BlockNum + Error(Subject/Year), data=dframe1)
</code></pre>

<p>However, the issue with this is that the data is left skewed with zeros in it (so log wont work), and I cannot successfully transform with any of the following:</p>

<pre><code>trans_Y &lt;- (dframe1$NumberOfVisits)^3
trans_Y &lt;- (dframe1$NumberOfVisits)^(1/9) 
trans_Y &lt;- log(dframe1$NumberOfVisits) 
trans_Y &lt;- log(dframe1$NumberOfVisits+0.1)
trans_Y &lt;- log(dframe1$NumberOfVisits+0.000001)
trans_Y &lt;- log10(dframe1$NumberOfVisits) 
trans_Y &lt;- exp(dframe1$NumberOfVisits) 
trans_Y &lt;- abs(dframe1$NumberOfVisits) 
trans_Y &lt;- sin(dframe1$NumberOfVisits) 
trans_Y &lt;- asin(dframe1$NumberOfVisits) 
</code></pre>

<p>As such I then tried a Generalised GLMM:</p>

<pre><code>library(lme4)

model1 &lt;- glmer(NumberOfVisits ~ SubjectType*Treatment*BlockNum + (1|Year), family = gaussian (link = inverse), data = dframe1)    
</code></pre>

<p>However this returns:</p>

<pre><code>    Warning message:
In glmer(NumberOfVisits ~ SubjectType*Treatment*BlockNum + (1 | Year),  :
  calling glmer() with family=gaussian (identity link) as a shortcut to lmer() is deprecated; please call lmer() directly
</code></pre>

<p>And so trying lmer:</p>

<pre><code>model1 &lt;- lmer(NumberOfVisits ~ SubjectType*Treatment*BlockNum + (1|Year), family = gaussian (link = identity), data = dframe1)    
Warning in lme4::lmer(formula = NumberOfVisits ~ SubjectType * Treatment * BlockNum +  :
  passing control as list is deprecated: please use lmerControl() instead
Error in (function (optimizer = ""bobyqa"", restart_edge = TRUE, boundary.tol = 1e-05,  : 
  unused arguments (tolPwrss = 1e-07, compDev = TRUE, nAGQ0initStep = TRUE, checkControl = list(check.nobs.vs.rankZ = ""ignore"", check.nobs.vs.nlev = ""stop"", check.nlev.gtreq.5 = ""ignore"", check.nlev.gtr.1 = ""stop"", check.nobs.vs.nRE = ""stop"", check.rankX = ""message+drop.cols"", check.scaleX = ""warning"", check.formula.LHS = ""stop"", check.response.not.const = ""stop""), checkConv = list(check.conv.grad = list(action = ""warning"", tol = 0.001, relTol = NULL), check.conv.singular = list(action = ""ignore"", tol = 1e-04), 
    check.conv.hess = list(action = ""warning"", tol = 1e-06)))
In addition: Warning messages:
1: In lmer(NumberOfVisits ~ SubjectType * Treatment * BlockNum + (1 | Year),  :
  calling lmer with 'family' is deprecated; please use glmer() instead
2: In lme4::glmer(formula = NumberOfVisits ~ SubjectType * Treatment * BlockNum +  :
  calling glmer() with family=gaussian (identity link) as a shortcut to lmer() is deprecated; please call lmer() directly
</code></pre>

<p>And when I a log/inverse link function (I presume this wont work because of the zeros?):</p>

<pre><code>model1 &lt;- glmer(NumberOfVisits ~ SubjectType*Treatment*BlockNum + (1|Year), family = gaussian (link = log), data = dframe1)    # random intercept
Error in eval(expr, envir, enclos) : 
  cannot find valid starting values: please specify some
</code></pre>

<p>The following will work for 'Number of visits', but not 'Duration of visits' (as it is non-integer values)</p>

<pre><code>model1 &lt;- glmer(DurationOfVisits ~ SubjectType*Treatment*BlockNum + (1|Year), family = poisson, data = dframe1)
</code></pre>

<p>However this returns the following, which doesn't tell me the significance of 'Treatment' itself, but rather the significance of each subset within treatment:</p>

<pre><code>summary(model1): 

 Call:
lm(formula = DurationOfVisits ~ SubjectType*Treatment*BlockNum, data = dframe1)

Residuals:
    Min      1Q  Median      3Q     Max 
-8.3251 -3.9093 -0.5325  2.1748 18.9394 

Coefficients:
                                          Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)                                 3.9967     1.6053   2.490   0.0138 *
Treatment2                                  3.1750     2.1018   1.511   0.1328  
Treatment3                                  0.1306     2.1018   0.062   0.9505  
Treatment4                                 -0.7279     2.1018  -0.346   0.7295  
</code></pre>

<p>...    </p>

<p>I would really appreciate some help with this. I feel like I'm missing something obvious here, it has been quite a number of long days deep in R and my brain is a bit frazzled.</p>

<p>I'm relatively new to R, so explanations in relatively simple terms would be appreciated!</p>

<p>Thanks a lot ahead of time!</p>
"
"0.258860091571774","0.275938638069581","212397","<p>I would like to test the effect of a treatment (""crop"") on species richness. I would rather use a glm for richness as it is a kind of count data.</p>

<p>Besides, I have a nested sampling design (5 values per plot, 5 plot per treatment). Thus I should use a GLMM.</p>

<p>So I write my model :</p>

<pre><code>&gt; GLMM_ric = glmer(richness ~ Crop + (1| Plot),  family=poisson)
&gt; summary(GLMM_ric)

Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [
 glmerMod]
 Family: poisson ( log )
 Formula: richness ~ Crop + (1 | Plot)
 Data: Com_agg

 AIC      BIC   logLik deviance df.resid 
433.8    446.9   -211.9    423.8       95 

Scaled residuals: 
   Min       1Q   Median       3Q      Max 
-1.33174 -0.41445 -0.08382  0.39853  1.73324 

Random effects:
 Groups Name        Variance Std.Dev.
  Plot   (Intercept) 0.08432  0.2904  
 Number of obs: 100, groups: Plot, 20

 Fixed effects:
             Estimate Std. Error z value Pr(&gt;|z|)    
 (Intercept)   1.9621     0.1503  13.056   &lt;2e-16 ***
 CropM        -0.5351     0.2211  -2.420   0.0155 *  
 CropYR       -0.3814     0.2181  -1.748   0.0804 .  
 CropOR       -0.3393     0.2175  -1.560   0.1188    
 ---
 Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

 Correlation of Fixed Effects:
        (Intr) CropM  CropYR
 CropM  -0.678              
 CropYR -0.686  0.467       
 CropOR -0.687  0.468  0.475
</code></pre>

<p>and then a simpler model to compare with :</p>

<pre><code> &gt; GLMM_ric0 = glmer(richness ~ (1| Plot), data=Com_agg, family=poisson,    glmerControl(optimizer=""bobyqa"", optCtrl = list(maxfun = 100000)))

 &gt;summary(GLMM_ric0)

 Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [ glmerMod]
  Family: poisson ( log )
 Formula: richness ~ (1 | Plot)
    Data: Com_agg
 Control: glmerControl(optimizer = ""bobyqa"", optCtrl = list(maxfun = 1e+05))

 AIC      BIC   logLik deviance df.resid 
 433.3    438.5   -214.7    429.3       98 

 Scaled residuals: 
 Min       1Q   Median       3Q      Max 
 -1.27211 -0.39830 -0.03309  0.38204  1.66734 

 Random effects:
  Groups Name        Variance Std.Dev.
  Plot   (Intercept) 0.1251   0.3537  
 Number of obs: 100, groups: Plot, 20

 Fixed effects:
        Estimate Std. Error z value Pr(&gt;|z|)    
 (Intercept)  1.64739    0.09114   18.07   &lt;2e-16 ***
 ---
 Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>And then I compare both models :</p>

<pre><code>&gt; anova(GLMM_ric0, GLMM_ric)
Data: Com_agg
Models:
GLMM_ric0: richness ~ (1 | Plot)
GLMM_ric: richness ~ Crop + (1 | Plot)
              Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)
GLMM_ric0  2 433.32 438.53 -214.66   429.32                         
GLMM_ric   5 433.84 446.86 -211.92   423.84 5.4851      3     0.1395
</code></pre>

<p>So according to my anova, the factor ""crop"" is not significant. Yet in the summary of my model some of the modalities appear to be significant. How should I interpret this ?</p>

<p>I have looked around for a while (e.g. <a href=""http://stats.stackexchange.com/questions/9587/glmm-test-of-significance"">here</a> or <a href=""http://glmm.wikidot.com/faq"" rel=""nofollow"">here</a>) but I could not find much for this precise situation.</p>
"
"0.358322566591047","0.356499030242215","212533","<p>Third Update: Output from suggested code:</p>

<pre><code>&gt; fit1&lt;- lm(cbind(Risk_Pct, PCT_Stocks_MF_1) ~ US_Born, regdata)
&gt; summary(fit1)
Response Risk_Pct :
</code></pre>

<p>Call:
lm(formula = Risk_Pct ~ US_Born, data = regdata)</p>

<p>Residuals:
   Min     1Q Median     3Q    Max 
-6.527 -1.319  0.681  1.681 91.681 </p>

<p>Coefficients:
            Estimate Std. Error t value Pr(>|t|)<br>
(Intercept)  6.26699    0.05146 121.777   &lt;2e-16 ***</p>

<h2>US_Born      0.05210    0.03113   1.673   0.0943 .</h2>

<p>Signif. codes:  0 â€˜<strong><em>â€™ 0.001 â€˜</strong>â€™ 0.01 â€˜</em>â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1</p>

<p>Residual standard error: 2.289 on 5041 degrees of freedom</p>

<p>(10957 observations deleted due to missingness)
Multiple R-squared:  0.0005551, Adjusted R-squared:  0.0003569 
F-statistic:   2.8 on 1 and 5041 DF,  p-value: 0.09432</p>

<p>Response PCT_Stocks_MF_1 :</p>

<p>Call:
lm(formula = PCT_Stocks_MF_1 ~ US_Born, data = regdata)</p>

<p>Residuals:
   Min     1Q Median     3Q    Max 
-229.2 -155.2 -130.2 -130.2  812.7 </p>

<p>Coefficients:
            Estimate Std. Error t value Pr(>|t|)<br>
(Intercept)  241.195      7.577  31.831   &lt;2e-16 ***</p>

<h2>US_Born      -10.976      4.584  -2.394   0.0167 *</h2>

<p>Signif. codes:  0 â€˜<strong><em>â€™ 0.001 â€˜</strong>â€™ 0.01 â€˜</em>â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1</p>

<p>Residual standard error: 337 on 5041 degrees of freedom
  (10957 observations deleted due to missingness)
Multiple R-squared:  0.001136,  Adjusted R-squared:  0.0009379 
F-statistic: 5.733 on 1 and 5041 DF,  p-value: 0.01668</p>

<p><strong>I think a problem with this may be that in the raw data for ""PCT_Stocks_MF_1 there codes for ""don't know"" and ""refused to answer"" are given values of 998/999 which brings up the mean and messes with the results since no one actually has 998% of their assets invested in stocks</strong></p>

<hr>

<p>Second Update: Sample of 100 rows of the data</p>

<pre><code> regdata &lt;- data.frame(HHID, US_Born, Born_In_US, Risk_Pct, PCT_Stocks_MF_1, Stocks_Pct, age, gender, Own_Home, Marital_Status, current_job_status,Total_Wealth,stock_market_expectations )
</code></pre>

<blockquote>
<pre><code>head(regdata, n = 100)
</code></pre>
</blockquote>

<pre><code>      HHID US_Born Born_In_US Risk_Pct PCT_Stocks_MF_1 Stocks_Pct
1   010004       1         NA        7              50         NA
2   010013       1         NA       10              NA         50
3   010038       1         NA        8              40         65
4   010038       1         NA        8              40         NA
5   010038       1         NA        8              40         85
6   010050       1         NA        5             998        998
7   010050       1         NA        5             998         NA
8   010325       1         NA        2             998         NA
9   010397       1         NA        3              75         NA
10  010397       1         NA        3              75        100
11  010433       1         NA        5              NA         NA
12  010451       5         NA        6              NA         50
13  010451       5         NA        6              NA         50
14  010451       5         NA        2              NA         NA
15  010481       1         NA        5             998         NA
16  010481       1         NA        5             998         NA
17  010481       1         NA        5             998         NA
18  010565       1         NA        7              NA         NA
19  010565       1         NA        7              NA         NA
20  010565       1         NA        7              NA         NA
21  010577       1         NA        5              NA         NA
22  010592       5         NA        8              NA         NA
23  010592       5         NA        8              NA         NA
24  010611       1         NA        0              NA         NA
25  010645       1         NA        4              NA         NA
26  010645       1         NA        4              NA         NA
27  010648       1         NA        3              NA         NA
28  010648       1         NA        5              NA         NA
29  010696       5         NA       NA              NA         NA
30  010769       1         NA        4              60         NA
31  010769       1         NA        4              60         50
32  010773       5         NA        2              50         NA
33  010773       5         NA        7              50          0
34  010773       5         NA        7              50         NA
35  010893       1         NA        6              NA         30
36  010893       1         NA        6              NA        100
37  010893       1         NA        6              NA         NA
38  010893       1         NA        6              NA         NA
39  010893       1         NA        6              NA         NA
40  010962       1         NA        5              NA         NA
41  010989       1         NA        4              NA         NA
42  010989       1         NA        4              NA         NA
43  011067       1         NA        8             998         NA
44  011256       1         NA        5              NA         NA
45  011332       1         NA        2              NA         NA
46  011341       1         NA        5              80        998
47  011341       1         NA        5              80         NA
48  011377       1         NA        5              NA        998
49  011377       1         NA        5              NA         NA
50  011377       1         NA        5              NA         NA
51  011377       1         NA        5              NA         NA
52  011378       5         NA        5              NA         NA
53  011466       1         NA        6              NA         NA
54  011620       1         NA        8             100        100
55  011620       1         NA        8             100         NA
56  011620       1         NA        8             100         NA
57  011620       1         NA        8             100         60
58  011620       1         NA        8             100         60
59  011626       5         NA        3              NA         NA
60  011626       5         NA        3              NA        998
61  011802       1         NA       10              NA         NA
62  011802       1         NA       10              NA         NA
63  011802       1         NA        8              NA        100
64  011802       1         NA        8              NA         NA
65  011802       1         NA        8              NA         NA
66  011810       1         NA       10              NA        999
67  011810       1         NA       10              NA         NA
68  011841       1         NA       10              NA        998
69  011881       5         NA        5              NA        100
70  011881       5         NA        5              NA        998
71  011902       1         NA        0              NA        999
72  011902       1         NA        0              NA         NA
73  011902       1         NA        0              NA         NA
74  011911       1         NA        7              NA        998
75  011911       1         NA        7              NA         NA
76  011911       1         NA        7              NA        998
77  011911       1         NA        7              NA         NA
78  011936       1         NA        6              NA          0
79  011936       1         NA        6              NA          0
80  011936       1         NA        6              NA         NA
81  011983       1         NA        8              NA         25
82  011983       1         NA        8              NA         NA
83  011999       1         NA        7              NA         NA
84  012005       1         NA        5              NA         NA
85  012005       1         NA        5              NA        998
86  012009       1         NA        3             998         50
87  012009       5         NA        6             998        998
88  012009       5         NA        6             998         NA
89  012033       1         NA        5             998         NA
90  012033       1         NA        0              NA          0
91  012104       1         NA        5              NA        998
92  012104       1         NA        5              NA          0
93  012112       1         NA        6              NA          0
94  012112       1         NA        6              NA        998
95  012161       1         NA        2              NA         NA
96  012161       1         NA        2              NA         NA
97  012161       1         NA        2              NA         NA
98  012166       1         NA       NA              NA         NA
99  012166       1         NA       NA              NA         NA
100 012166       1         NA        6              NA         NA
age gender Own_Home Marital_Status current_job_status
1    68      2        1              5                  5
2    76      1        2              4                  5
3    71      2        1              1                  1
4    71      2        1              1                  1
5    71      2        1              1                  1
6    73      2        1              5                  1
7    73      2        1              5                  1
8    75      2        2              5                  5
9    73      1        1              5                  1
10   73      1        1              5                  1
11   80      2        3              5                  5
12   76      2        1              1                  5
13   76      2        1              1                  5
14   74      1        1              1                  5
15   74      2        2              1                  5
16   74      2        2              1                  5
17   74      2        2              1                  5
18   82      1        7              5                  7
19   82      1        7              5                  7
20   82      1        7              5                  7
21   75      2        1              5                  5
22   77      2        1              6                  4
23   77      2        1              6                  4
24   73      2        2              6                  5
25   67      2        2              5                  5
26   67      2        2              5                  5
27   73      1        1              1                  5
28   74      2        1              1                  5
29   73      2        1              4                  5
30   58      2        1              5                  6
31   58      2        1              5                  6
32   77      2        1              1                  5
33   86      1        1              1                  5
34   86      1        1              1                  5
35   74      2        1              4                  1
36   74      2        1              4                  1
37   74      2        1              4                  1
38   74      2        1              4                  1
39   74      2        1              4                  1
40   74      2        1              5                  1
41   73      2        1              1                  5
42   73      2        1              1                  5
43   72      1        1              1                  5
44   73      1        2              1                  1
45   74      2        1              4                  5
46   75      2        1              5                  2
47   75      2        1              5                  2
48   68      2        1              1                  3
49   68      2        1              1                  3
50   68      2        1              1                  3
51   68      2        1              1                  3
52   77      1       NA              3                  5
53   62      2        2              6                  4
54   73      1       NA              1                  5
55   73      1       NA              1                  5
56   55      2       NA              1                  1
57   55      2       NA              1                  1
58   55      2       NA              1                  1
59   65      2        1              1                  6
60   65      2        1              1                  6
61   80      1        1              1                  5
62   80      1        1              1                  5
63   58      2        1              1                  1
64   58      2        1              1                  1
65   58      2        1              1                  1
66   76      1        1              1                  5
67   76      1        1              1                  5
68   78      1        1              1                  5
69   69      2        1              4                  6
70   69      2        1              4                  6
71   66      2        2              6                  5
72   66      2        2              6                  5
73   66      2        2              6                  5
74   75      1        1              1                  1
75   75      1        1              1                  1
76   75      1        1              1                  1
77   75      1        1              1                  1
78   75      2       NA              4                  5
79   75      2       NA              4                  5
80   75      2       NA              4                  5
81   71      1        1              1                  5
82   71      1        1              1                  5
83   77      1        1              1                  5
84   81      2        2              5                  1
85   81      2        2              5                  1
86   74      2        1              1                  6
87   87      1        1              1                  5
88   87      1        1              1                  5
89   73      1       NA              3                  5
90   73      2       NA              3                  5
91   79      2        1              5                  6
92   79      2        1              5                  6
93   66      2        2              5                  5
94   66      2        2              5                  5
95   76      2        7              5                  5
96   76      2        7              5                  5
97   76      2        7              5                  5
98   76      1        1              1                  5
99   76      1        1              1                  5
100  69      2        1              1                  5
    Total_Wealth stock_market_expectations
1         901001                        NA
2           2000                        NA
3             NA                        NA
4             NA                        NA
5             NA                        NA
6        1224150                        75
7        1224150                        75
8          20000                        NA
9        1390000                        30
10       1390000                        30
11        196000                        50
12        194000                         5
13        194000                         5
14            NA                        80
15            NA                        10
16            NA                        10
17            NA                        10
18         51500                        NA
19         51500                        NA
20         51500                        NA
21         -2955                        NA
22        372000                        NA
23        372000                        NA
24          -925                        NA
25          4400                       100
26          4400                       100
27        303000                        20
28            NA                        50
29            NA                        NA
30            NA                        NA
31            NA                        NA
32            NA                        NA
33        304000                        NA
34        304000                        NA
35       1701000                        NA
36       1701000                        NA
37       1701000                        NA
38       1701000                        NA
39       1701000                        NA
40        -80500                         0
41            NA                        50
42            NA                        50
43       1072000                        60
44         22050                        NA
45            NA                        NA
46        135740                        NA
47        135740                        NA
48            NA                        NA
49            NA                        NA
50            NA                        NA
51            NA                        NA
52        112500                        50
53             0                        NA
54        400012                       100
55        400012                       100
56            NA                        NA
57            NA                        NA
58            NA                        NA
59        153700                        NA
60        153700                        NA
61        106000                        40
62        106000                        40
63            NA                       100
64            NA                       100
65            NA                       100
66            NA                        80
67            NA                        80
68         20000                        60
69            NA                        NA
70            NA                        NA
71            NA                        NA
72            NA                        NA
73            NA                        NA
74        353000                        50
75        353000                        50
76        353000                        50
77        353000                        50
78            NA                        30
79            NA                        30
80            NA                        30
81        771500                        NA
82        771500                        NA
83        100000                        75
84         42200                        40
85         42200                        40
86       1760500                        50
87            NA                        NA
88            NA                        NA
89         49000                        NA
90        -10500                        NA
91         17500                        NA
92         17500                        NA
93         54000                        NA
94         54000                        NA
95        -31000                        10
96        -31000                        10
97        -31000                        10
98            NA                        NA
99            NA                        NA
100           NA                        50    
</code></pre>

<hr>

<p>Update:I tried to run a ""MANOVA"" but am not entirely sure if I did this correct. 
Risk_Pct is the raw data risk measure 1 and PCT_Stocks_MF_1 is the raw data risk measure 2 </p>

<pre><code>&gt; y&lt;-cbind(Risk_Pct, PCT_Stocks_MF_1)

&gt; fit.manova&lt;-manova(y ~ US_Born)
 summary(fit.manova, test = ""Pillai"")
        Df    Pillai approx F num Df
US_Born      1 0.0016159   4.0788      2
Residuals 5041                          
      den Df  Pr(&gt;F)  
US_Born     5040 0.01698 *
Residuals                 
---
Signif. codes:  
  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1
  â€˜ â€™ 1
&gt; summary(fit.manova, test = ""Roy"")
            Df       Roy approx F num Df
US_Born      1 0.0016186   4.0788      2
Residuals 5041                          
          den Df  Pr(&gt;F)  
US_Born     5040 0.01698 *
Residuals                 
---
Signif. codes:  
  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1
</code></pre>

<h2>Also, if I have some variables I want to hold constant (such as ""wealth"") is it possible to do that in MANOVA? If so, how?</h2>

<p>Original post:
I'm trying to determine if immigration status is a significant determinant of risk preferences. In order to do this, I'm using two different measures of risk.</p>

<p>The first measure of risk has participants rate their level of risk on a scale from 0-10. I then divide that scale into 5 categories of risk: ""no"", ""low"", ""some"", ""high"", and ""substantial"" risk tolerance. 
  The second measure of risk is based on the percentage(0-100%) of assets participants invest in stocks. They are also divided into the same 5 categories of risk: ""no"", ""low"", ""some"", ""high"", and ""substantial"" risk tolerance.
In my preliminary analysis I found that using the first measure of risk I found that for both immigrants and natives the category with the most respondents was the ""high"" risk tolerance. Meanwhile, with the second measure of risk I found that for both immigrants and natives the category with the most respondents was ""substantial"" risk tolerance.
 How can I determine if there is a significant difference between these two measures of risk? I knew typically to find a significant difference you would use a t-test, but since they variables are categorical I can't find the mean. Even if I used the original data, not my groupings into risk tolerance data, the first variable is on  a scale from 0-10 and the second variable is on a scale of 0-100 so the means are totally different. I am using ""R"" to do my analysis.</p>

<p>If it helps, here is a table of the the breakdown of risk measure 1, by immigration status and risk tolerance group:</p>

<pre><code>             No     Low     Some    High    Substantial     Total
Native      4.5     3.54    31.74   52.11   8.11            100
Immigrant   9.34    3.67    23.19   47.71   16.08           99.99
</code></pre>

<p>And the same table, for risk measure 2:</p>

<pre><code>            No      Low     Some     High   Substantial DK/RF   Total
Native      0.08%   1.81%   6.51%   17.38%  57.64%      16.58%  100.00%
Immigrant   0.00%   4.32%   14.59%  20.27%  48.65%      12.16%  99.99%
</code></pre>

<ul>
<li>I don't think the tables show correctly when printed like this, so the attached image is of these two tables <a href=""http://i.stack.imgur.com/HsK74.png"" rel=""nofollow"">enter image description here</a>
Thanks so much for any help on this situation</li>
</ul>
"
"0.435595672319629","0.409953000327728","220603","<p>I have some measurements (concentration) made in 4 groups (W, X, Y, Z) and time is my covariate. I make a linear model:</p>

<pre><code>fit &lt;- lm(concentration~group*year, data=data)
</code></pre>

<p>The results are as follows: ANOVA table:</p>

<pre><code>anova(fit)

Analysis of Variance Table

Response: concentration
           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
group       3 3600.7 1200.22 32.6132 4.081e-10 *** #!
year        1  559.7  559.71 15.2087 0.0004311 ***
group:year  3   97.3   32.42  0.8809 0.4607155    
Residuals  34 1251.3   36.80                      
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<p>and pairwise comparison:</p>

<pre><code>summary(fit)
Call:
lm(formula = concentration ~ group * year, data = data)

Residuals:
   Min     1Q Median     3Q    Max 
-8.818 -4.019 -0.276  4.181 13.097 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  -433.0108   828.4293  -0.523    0.605
groupX      -1574.0090  1170.3741  -1.345    0.188 #!
groupY      -1666.3673  1170.3741  -1.424    0.164 #!
groupZ      -1201.2766  1170.3891  -1.026    0.312 #!
year            0.2418     0.4128   0.586    0.562
groupX:year     0.7937     0.5831   1.361    0.182
groupY:year     0.8409     0.5831   1.442    0.158
groupZ:year     0.6104     0.5831   1.047    0.303

Residual standard error: 6.066 on 34 degrees of freedom
Multiple R-squared:  0.7729,    Adjusted R-squared:  0.7261 
F-statistic: 16.53 on 7 and 34 DF,  p-value: 2.852e-09
</code></pre>

<p>Now I have a problem in the interpretation of this data. As far as I understand, since the interaction in the ANOVA table is nonsignificant, I can check the group effect, and it is significant. This means that the intercept in different groups should be [significantly] different. But when I look to the summary table, there is no significant difference, at least â€“ between group W and others (groupX, groupY and groupZ are nonsignificant). If I change the compared group from W to X or Y or Z the comparison results are still nonsignificant:</p>

<pre><code>data2 &lt;- data
data2$group[data2$group==""X""] &lt;-""A""
fit &lt;- lm(concentration~group*year, data=data2)
summary(fit)

Call:
lm(formula = concentration ~ group * year, data = data2)

Residuals:
   Min     1Q Median     3Q    Max 
-8.818 -4.019 -0.276  4.181 13.097 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) -2.007e+03  8.267e+02  -2.428   0.0206 *
groupW       1.574e+03  1.170e+03   1.345   0.1876 #! 
groupY      -9.236e+01  1.169e+03  -0.079   0.9375 #! 
groupZ       3.727e+02  1.169e+03   0.319   0.7518 #!
year         1.035e+00  4.119e-01   2.514   0.0168 *
groupW:year -7.937e-01  5.831e-01  -1.361   0.1824  
groupY:year  4.717e-02  5.825e-01   0.081   0.9359  
groupZ:year -1.834e-01  5.825e-01  -0.315   0.7549  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 6.066 on 34 degrees of freedom
Multiple R-squared:  0.7729,    Adjusted R-squared:  0.7261 
F-statistic: 16.53 on 7 and 34 DF,  p-value: 2.852e-09

data2 &lt;- data
data2$group[data2$group==""Y""] &lt;-""A""
fit &lt;- lm(concentration~group*year, data=data2)
summary(fit)

Call:
lm(formula = concentration ~ group * year, data = data2)

Residuals:
   Min     1Q Median     3Q    Max 
-8.818 -4.019 -0.276  4.181 13.097 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) -2.099e+03  8.267e+02  -2.539   0.0158 *
groupW       1.666e+03  1.170e+03   1.424   0.1636 #! 
groupX       9.236e+01  1.169e+03   0.079   0.9375 #! 
groupZ       4.651e+02  1.169e+03   0.398   0.6933 #! 
year         1.083e+00  4.119e-01   2.628   0.0128 *
groupW:year -8.409e-01  5.831e-01  -1.442   0.1584  
groupX:year -4.717e-02  5.825e-01  -0.081   0.9359  
groupZ:year -2.305e-01  5.825e-01  -0.396   0.6948  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Residual standard error: 6.066 on 34 degrees of freedom
Multiple R-squared:  0.7729,    Adjusted R-squared:  0.7261 
F-statistic: 16.53 on 7 and 34 DF,  p-value: 2.852e-09

data2 &lt;- data
data2$group[data2$group==""Z""] &lt;-""A""
fit &lt;- lm(concentration~group*year, data=data2)
summary(fit)

Call:
lm(formula = concentration ~ group * year, data = data2)

Residuals:
   Min     1Q Median     3Q    Max 
-8.818 -4.019 -0.276  4.181 13.097 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)  -433.0108   828.4293  -0.523    0.605
groupX      -1574.0090  1170.3741  -1.345    0.188 #!
groupY      -1666.3673  1170.3741  -1.424    0.164 #!
groupZ      -1201.2766  1170.3891  -1.026    0.312 #!
year            0.2418     0.4128   0.586    0.562
groupX:year     0.7937     0.5831   1.361    0.182
groupY:year     0.8409     0.5831   1.442    0.158
groupZ:year     0.6104     0.5831   1.047    0.303

Residual standard error: 6.066 on 34 degrees of freedom
Multiple R-squared:  0.7729,    Adjusted R-squared:  0.7261 
F-statistic: 16.53 on 7 and 34 DF,  p-value: 2.852e-09
</code></pre>

<p>How is it possible that there are no significant difference between any two groups when there is a significant group effect? Apparently my interpretation that significant group effect means that at least one group differ significantly from other in the intercept value is incorrect. So what is the correct interpretation of the significant group effect?  </p>
"
"0.202547873416733","0.201517088743951","228267","<p>I hope someone can help me with this.</p>

<p>I am analyzing my data through a GLM model using R. I have a dataset that comprises participants' data (gender and age) and binary answers to questions described by factors (order of presentation, basic situation, variation, and so on). I have been able to run the GLM model, which looks ok to me:</p>

<pre><code>    Call:
glm(formula = Dec ~ Gen + Age + Order + Base_con * Var, family = binomial, 
    data = todos, subset = todos$Type == 2)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.29181  -0.57367  -0.00012   0.73115   2.13377  

Coefficients:
                 Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)      2.828601   0.725236   3.900 9.61e-05 ***
Gen2            -0.041962   0.385212  -0.109   0.9133    
Age             -0.002255   0.012317  -0.183   0.8547    
Order           -0.221136   0.185756  -1.190   0.2339    
Base_con2       -1.119705   0.564189  -1.985   0.0472 *  
Base_con3       -4.239539   0.643922  -6.584 4.58e-11 ***
Var1            -1.369926   0.561884  -2.438   0.0148 *  
Base_con2:Var1  -0.634918   0.701871  -0.905   0.3657    
Base_con3:Var1 -15.252434 901.787913  -0.017   0.9865    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 448.71  on 323  degrees of freedom
Residual deviance: 267.60  on 315  degrees of freedom
AIC: 285.6

Number of Fisher Scoring iterations: 17
</code></pre>

<p>Now, the issue is that I cannot report a single z-values for the <code>Base_con</code> factor, nor for the interaction. Using <code>drop1</code> will not work as there is no way to remove a factor and not the interaction, so the output of trying that is:</p>

<pre><code>Single term deletions

Model:
Dec ~ Gen + Age + Order + Base_con * Var
             Df Deviance    AIC     LRT Pr(&gt;Chi)
&lt;none&gt;            267.60 285.60                 
Gen           1   267.61 283.61 0.01186   0.9133
Age           1   267.63 283.63 0.03354   0.8547
Order         1   269.03 285.03 1.42912   0.2319
Base_con:Var  2   270.51 284.51 2.90979   0.2334
</code></pre>

<p>So the problem is that I don't know how to report effects for the factors with over two levels, or the interaction for such a case.</p>

<p>Is there a way to resolve this issue? </p>

<p>Thanks to all.</p>

<p>EDIT: I removed the <code>anova</code> output as it was an incorrect approach, as noted by user @mdewey. I also changed the thread title according to advances in the question.</p>
"
"0.226455406828919","0.225302954529666","228316","<p>I want to predict a binary response variable <code>y</code> using logistic regression. <code>x1</code> to <code>x4</code> are the log  of continuous variables and <code>x5</code> to <code>x7</code> are binary variables. </p>

<pre><code>Call:
glm(formula = y ~ x1 + x2 + x3 + x4 + x5 + 
    x6 + x7, family = binomial(), data = df)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6604  -0.5712   0.4691   0.6242   2.4095  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -2.84633    0.31609  -9.005  &lt; 2e-16 ***
x1             0.14196    0.04828   2.940  0.00328 ** 
x2             4.05937    0.22702  17.881  &lt; 2e-16 ***
x3            -0.83492    0.08330 -10.023  &lt; 2e-16 ***
x4             0.05679    0.02109   2.693  0.00709 ** 
x5             0.08741    0.18955   0.461  0.64467    
x6            -2.21632    0.53202  -4.166  3.1e-05 ***
x7             0.25282    0.15716   1.609  0.10769    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1749.5  on 1329  degrees of freedom
Residual deviance: 1110.5  on 1322  degrees of freedom
AIC: 1126.5

Number of Fisher Scoring iterations: 5
</code></pre>

<p>The output of the GLM shows that most of my variables are significant for my model, but the various goodness of fit test I have done:</p>

<pre><code>anova &lt;- anova(model, test = ""Chisq"")   # Anova
1 - pchisq(sum(anova$Deviance, na.rm = TRUE),df = 7) # Null Model vs Most Complex Model
1 - pchisq(model$null.deviance - model$deviance, 
           df = (model$df.null - model$df.residual )) # Null Deviance - Residual Deviance ~ X^2
hoslem.test(model$y, model$fitted.values, g = 8)     # Homer Lemeshow test
pR2(model)                                            # Pseudo-R^2
</code></pre>

<p>tell me that there is a lack of evidence to support my model.</p>

<p>More over, I have a bimodal deviance plot. I suspect the bimodal distribution is caused by the sparsity of my binary variables.
 <a href=""http://i.stack.imgur.com/J27fL.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/J27fL.png"" alt=""enter image description here""></a></p>

<p>So I calculated the absolute error <code>abs(y - y_hat)</code>, and obtained the following:</p>

<ul>
<li>77% of my absolute errors were in [0;0.25], which I think is very good!</li>
</ul>

<p>On the following plot, Y=1 is red, and Y=0 is green. This model is better at predicting when Y will be 1 than 0.</p>

<p><a href=""http://i.stack.imgur.com/ZEGuv.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ZEGuv.png"" alt=""enter image description here""></a></p>

<p>My question is thus the following:</p>

<p>The goodness of fit tests all assume that my null hypothesis follows a Chi square distribution of some sort. Is it correct to conclude that based on my absolute error, my model's prediction is OK, it's just that it doesn't follow a Chi square distribution and thus perform poorly with these tests? </p>
"
"0.226455406828919","0.225302954529666","231258","<p>After using weight of evidence &amp; Information value mechanism, of the 40 odd   variables I am left with 8 variables which are highly or moderately significant.<br>
One of the independent variable which is categorical has 60+ categories. This is a very highly predictable variable hence please suggest as to how should I<br>
use this variable in the model.<br>
When I add this variable in the model my null deviance and AIC decreases   and makes other predictors loose their predictive power.<br>
Then another model without this variable my null deviance and AIC improves.<br>
What could be the reason. Is this variable collinear with some other predictor.   </p>

<p><em>Please see the syntax: &lt; Without that Categorical Var></em>  </p>

<pre><code>m1.logit&lt;- glm(survey ~ region+ know + repS+ und+ case_status, family = binomial(logit), data = a1 )
m1.logit  
summary(m1.logit)

Call:  
glm(formula = survey ~ region + know + repS + und + case_status, 
    family = binomial(logit), data = a1)  

Deviance Residuals:   
     ` Min       1Q   Median    3Q     Max`
    -2.579    0.271   0.290   0.336   2.895    

Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 2553.5  on 2540  degrees of freedom
Residual deviance: 1287.7  on 2526  degrees of freedom
AIC: 1318    
Number of Fisher Scoring iterations: 13
</code></pre>

<p>Also ran an anova test to analyze the table of deviance  </p>

<pre><code>anova(m1.logit, test=""Chisq"")   
Analysis of Deviance Table  

Model: binomial, link: logit  
Response: survey  

Terms added sequentially (first to last)  

             Df Deviance Resid. Df Resid. Dev             Pr(&gt;Chi)     
 NULL                         2540       2554                           
 region       5       13      2535       2540                0.022 *    
 know         1      507      2534       2033 &lt; 0.0000000000000002 ***  
 repS         1      715      2533       1319 &lt; 0.0000000000000002 ***  
 und          1        3      2532       1316                0.109        
 case_status  6       28      2526       1288             0.000078 ***    

 Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  
</code></pre>

<p>Please suggest as to how to deal with this predictor variable with 50+ categories  </p>
"
"0.320256307610174","0.318626493938583","235168","<p>I'm studying Design and Analysis of Experiments, 8th Edition. Douglas C. Montgomery is the author. I'm trying to replicate the first example he gives in Chapter 13, Experiments with Random Factors.</p>

<p>In this example, there are measurements in a critical dimension on a part. 20 parts are randomly selected and measured by 3 operators, also selected at random. I want to fit two models to this data. The first one I call full model and it is given by</p>

<p>$$y_{ijk} = \mu + \tau_i + \beta_j + (\tau\beta)_{ij} + \varepsilon_{ijk}$$</p>

<p>The other model I call reduced model ant it is given by</p>

<p>$$y_{ijk} = \mu + \tau_i + \beta_j + \varepsilon_{ijk}$$</p>

<p>Both $\tau_i, i=1, \cdots, 20$ and $\beta_j, j=1, 2, 3$ are random effects. The code I'm using to analyze my problem is below:</p>

<pre><code>gauge &lt;- structure(list(part = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L), operator = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), replication = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L), measurement = c(21L, 24L, 20L, 27L, 
19L, 23L, 22L, 19L, 24L, 25L, 21L, 18L, 23L, 24L, 29L, 26L, 20L, 
19L, 25L, 19L, 20L, 23L, 21L, 27L, 18L, 21L, 21L, 17L, 23L, 23L, 
20L, 19L, 25L, 24L, 30L, 26L, 20L, 21L, 26L, 19L, 20L, 24L, 19L, 
28L, 19L, 24L, 22L, 18L, 25L, 26L, 20L, 17L, 25L, 23L, 30L, 25L, 
19L, 19L, 25L, 18L, 20L, 24L, 21L, 26L, 18L, 21L, 24L, 20L, 23L, 
25L, 20L, 19L, 25L, 25L, 28L, 26L, 20L, 19L, 24L, 17L, 19L, 23L, 
20L, 27L, 18L, 23L, 22L, 19L, 24L, 24L, 21L, 18L, 25L, 24L, 31L, 
25L, 20L, 21L, 25L, 19L, 21L, 24L, 22L, 28L, 21L, 22L, 20L, 18L, 
24L, 25L, 20L, 19L, 25L, 25L, 30L, 27L, 20L, 23L, 25L, 17L)), .Names = c(""part"", 
""operator"", ""replication"", ""measurement""), class = ""data.frame"", row.names = c(NA, 
-120L))

###############
# full model
fit.full &lt;- lmer(measurement ~ (1|part) + (1|operator) + (1|part:operator), data=montgomery)
summary(fit.full)
Linear mixed model fit by REML ['lmerMod']
Formula: measurement ~ (1 | part) + (1 | operator) + (1 | part:operator)
   Data: montgomery

REML criterion at convergence: 409.4

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.0313 -0.6595  0.1270  0.5374  2.7345 

Random effects:
 Groups        Name        Variance Std.Dev.
 part:operator (Intercept)  0.00000 0.0000  
 part          (Intercept) 10.25127 3.2018  
 operator      (Intercept)  0.01063 0.1031  
 Residual                   0.88316 0.9398  
Number of obs: 120, groups:  part:operator, 60; part, 20; operator, 3

Fixed effects:
            Estimate Std. Error t value
(Intercept)  22.3917     0.7235   30.95

###############
# reduced model
fit.reduced &lt;- lmer(measurement ~ (1|part) + (1|operator), data=montgomery)
summary(fit.reduced)
Linear mixed model fit by REML ['lmerMod']
Formula: measurement ~ (1 | part) + (1 | operator)
   Data: montgomery

REML criterion at convergence: 409.4

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.0313 -0.6595  0.1270  0.5374  2.7345 

Random effects:
 Groups   Name        Variance Std.Dev.
 part     (Intercept) 10.25127 3.2018  
 operator (Intercept)  0.01063 0.1031  
 Residual              0.88316 0.9398  
Number of obs: 120, groups:  part, 20; operator, 3

Fixed effects:
            Estimate Std. Error t value
(Intercept)  22.3917     0.7235   30.95    
</code></pre>

<p>However, I'm getting different estimates from the ones in the book. Montgomery used Minitab to fit its model and here are his results for the full model:</p>

<p><a href=""http://i.stack.imgur.com/1aeGL.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/1aeGL.png"" alt=""Anova Table for the Full Model""></a></p>

<p>They are different from mine. Notice how his <code>part*operator</code> has a negative estimation, while mine is zero. However, his estimates for the reduced model are the same as mine:</p>

<p><a href=""http://i.stack.imgur.com/SaGVu.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/SaGVu.png"" alt=""Anova Table for the Reduced Model""></a></p>

<p>So, my question about his problem are:</p>

<ol>
<li><p>Why our estimates differ for the full model? I understand that I can't have a negative variance like the one he got, but why does Minitab doesn't set it to zero? </p></li>
<li><p>Using R, where (or how) can I get an ANOVA table like the one Minitab presents? I couldn't test my hypothesis in this problem because I can't find the p-values associated with the parameters I'm testing.</p></li>
</ol>
"
