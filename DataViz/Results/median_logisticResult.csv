"V1","V2","V3","V4"
"0.191439846060547","0.191942973987479","  5304","<p>Dear everyone - I've noticed something strange that I can't explain, can you? In summary: the manual approach to calculating a confidence interval in a logistic regression model, and the R function <code>confint()</code> give different results.</p>

<p>I've been going through Hosmer &amp; Lemeshow's <em>Applied logistic regression</em> (2nd edition).  In the 3rd chapter there is an example of calculating the odds ratio and 95% confidence interval.  Using R, I can easily reproduce the model:</p>

<pre><code>Call:
glm(formula = dataset$CHD ~ as.factor(dataset$dich.age), family = ""binomial"")

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.734  -0.847  -0.847   0.709   1.549  

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                   -0.8408     0.2551  -3.296  0.00098 ***
as.factor(dataset$dich.age)1   2.0935     0.5285   3.961 7.46e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 136.66  on 99  degrees of freedom
Residual deviance: 117.96  on 98  degrees of freedom
AIC: 121.96

Number of Fisher Scoring iterations: 4
</code></pre>

<p>However, when I calculate the confidence intervals of the parameters, I get a different interval to the one given in the text:</p>

<pre><code>&gt; exp(confint(model))
Waiting for profiling to be done...
                                 2.5 %     97.5 %
(Intercept)                  0.2566283  0.7013384
as.factor(dataset$dich.age)1 3.0293727 24.7013080
</code></pre>

<p>Hosmer &amp; Lemeshow suggest the following formula:</p>

<p>$$
e^{[\hat\beta_1\pm z_{1-\alpha/2}\times\hat{\text{SE}}(\hat\beta_1)]}
$$
</p>

<p>and they calculate the confidence interval for <code>as.factor(dataset$dich.age)1</code> to be (2.9, 22.9).</p>

<p>This seems straightforward to do in R:</p>

<pre><code># upper CI for beta
exp(summary(model)$coefficients[2,1]+1.96*summary(model)$coefficients[2,2])
# lower CI for beta
exp(summary(model)$coefficients[2,1]-1.96*summary(model)$coefficients[2,2])
</code></pre>

<p>gives the same answer as the book.</p>

<p>However, any thoughts on why <code>confint()</code> seems to give different results?  I've seen lots of examples of people using <code>confint()</code>.</p>
"
"0.144714921058484","0.145095250022002","  5354","<p>I've got some data about airline flights (in a data frame called <code>flights</code>) and I would like to see if the flight time has any effect on the probability of a significantly delayed arrival (meaning 10 or more minutes). I figured I'd use logistic regression, with the flight time as the predictor and whether or not each flight was significantly delayed (a bunch of Bernoullis) as the response. I used the following code...</p>

<pre><code>flights$BigDelay &lt;- flights$ArrDelay &gt;= 10
delay.model &lt;- glm(BigDelay ~ ArrDelay, data=flights, family=binomial(link=""logit""))
summary(delay.model)
</code></pre>

<p>...but got the following output.</p>

<pre><code>&gt; flights$BigDelay &lt;- flights$ArrDelay &gt;= 10
&gt; delay.model &lt;- glm(BigDelay ~ ArrDelay, data=flights, family=binomial(link=""logit""))
Warning messages:
1: In glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,  :
  algorithm did not converge
2: In glm.fit(x = X, y = Y, weights = weights, start = start, etastart = etastart,  :
  fitted probabilities numerically 0 or 1 occurred
&gt; summary(delay.model)

Call:
glm(formula = BigDelay ~ ArrDelay, family = binomial(link = ""logit""),
    data = flights)

Deviance Residuals:
       Min          1Q      Median          3Q         Max
-3.843e-04  -2.107e-08  -2.107e-08   2.107e-08   3.814e-04

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)  -312.14     170.26  -1.833   0.0668 .
ArrDelay       32.86      17.92   1.833   0.0668 .
---
Signif. codes:  0 Ã¢***Ã¢ 0.001 Ã¢**Ã¢ 0.01 Ã¢*Ã¢ 0.05 Ã¢.Ã¢ 0.1 Ã¢ Ã¢ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2.8375e+06  on 2291292  degrees of freedom
Residual deviance: 9.1675e-03  on 2291291  degrees of freedom
AIC: 4.0092

Number of Fisher Scoring iterations: 25
</code></pre>

<p>What does it mean that the algorithm did not converge? I thought it be because the <code>BigDelay</code> values were <code>TRUE</code> and <code>FALSE</code> instead of <code>0</code> and <code>1</code>, but I got the same error after I converted everything. Any ideas?</p>
"
"0.164091296623326","0.191942973987479","  8511","<p>Christopher Manning's <a href=""http://nlp.stanford.edu/~manning/courses/ling289/logistic.pdf"" rel=""nofollow"">writeup on logistic regression in R</a> shows a logistic regression in R as follows:</p>

<pre><code>ced.logr &lt;- glm(ced.del ~ cat + follows + factor(class), 
  family=binomial)
</code></pre>

<p>Some output:</p>

<pre><code>&gt; summary(ced.logr)
Call:
glm(formula = ced.del ~ cat + follows + factor(class),
    family = binomial(""logit""))
Deviance Residuals:
Min            1Q    Median       3Q      Max
-3.24384 -1.34325   0.04954  1.01488  6.40094

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)   -1.31827    0.12221 -10.787 &lt; 2e-16
catd          -0.16931    0.10032  -1.688 0.091459
catm           0.17858    0.08952   1.995 0.046053
catn           0.66672    0.09651   6.908 4.91e-12
catv          -0.76754    0.21844  -3.514 0.000442
followsP       0.95255    0.07400  12.872 &lt; 2e-16
followsV       0.53408    0.05660   9.436 &lt; 2e-16
factor(class)2 1.27045    0.10320  12.310 &lt; 2e-16
factor(class)3 1.04805    0.10355  10.122 &lt; 2e-16
factor(class)4 1.37425    0.10155  13.532 &lt; 2e-16
(Dispersion parameter for binomial family taken to be 1)
Null deviance: 958.66 on 51 degrees of freedom
Residual deviance: 198.63 on 42 degrees of freedom
AIC: 446.10
Number of Fisher Scoring iterations: 4
</code></pre>

<p>He then goes into some detail about how to interpret coefficients, compare different models, and so on.  Quite useful.</p>

<p>However, how much variance does the model account for?  A <a href=""http://www.ats.ucla.edu/stat/stata/output/old/lognoframe.htm"" rel=""nofollow"">Stata page on logistic regression</a> says:</p>

<blockquote>
  <p>Technically, R2 cannot be computed the same way in logistic regression as it is in OLS regression. The pseudo-R2, in logistic regression, is defined as 1 - L1/L0, where L0 represents the log likelihood for the ""constant-only"" model and L1 is the log likelihood for the full model with constant and predictors. </p>
</blockquote>

<p>I understand this at the high level. The constant-only model would be without any of the parameters (only the intercept term).  Log likelihood is a measure of how closely the parameters fit the data.  In fact, Manning sort of hints that the deviance might be -2 log L. Perhaps null deviance is constant-only and residual deviance is -2 log L of the model?  However, I'm not crystal clear on it.</p>

<p>Can someone verify how one actually computes the pseudo-R^2 in R using this example?</p>
"
"0.208877996572178","0.209426954145848"," 11107","<p>I need to do a logistic regression using R on my data. My response variable (<code>y</code>) is survival at weaning (<code>surv=0</code>; did not <code>surv=1</code>) and I have several independent variables which are binary and categoricals in nature.</p>

<p>I am following some examples on this website <a href=""http://www.ats.ucla.edu/stat/r/dae/logit.htm"" rel=""nofollow"">http://www.ats.ucla.edu/stat/r/dae/logit.htm</a> and trying to run some models.</p>

<p>Running the model: </p>

<pre><code>&gt; mysurv2 &lt;- glm(surv~as.factor(PTEM) + as.factor(pshiv) + as.factor(presp) + 
                 as.factor(pmtone), family=binomial(link=""logit""), data=ap)
&gt; summary(mysurv2)

Call:
glm(formula = surv ~ as.factor(PTEM) + as.factor(pshiv) + as.factor(presp) + 
    as.factor(pmtone), family = binomial(link = ""logit""), data = ap)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.2837  -0.5121  -0.5121  -0.5058   2.0590  

Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.01135    0.23613  -0.048  0.96166    
as.factor(PTEM)2   -0.74642    0.24482  -3.049  0.00230 ** 
as.factor(PTEM)3   -1.95401    0.23259  -8.401  &lt; 2e-16 ***
as.factor(pshiv)2  -0.02638    0.06784  -0.389  0.69738    
as.factor(presp)2   0.74549    0.10532   7.079 1.46e-12 ***
as.factor(presp)3   0.66793    0.66540   1.004  0.31547    
as.factor(pmtone)2  0.54699    0.09678   5.652 1.58e-08 ***
as.factor(pmtone)3  1.82337    0.75409   2.418  0.01561 *  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 7892.6  on 8791  degrees of freedom
Residual deviance: 7252.8  on 8784  degrees of freedom
  (341 observations deleted due to missingness)
AIC: 7268.8

Number of Fisher Scoring iterations: 4
</code></pre>

<p>Adding the <code>na.action=na.pass</code> at the end of the model gave me an error message. I thought that this would take care NA's in my independent variables.</p>

<pre><code>&gt; mysurv &lt;- glm(surv~as.factor(PTEM) + as.factor(pshiv) + as.factor(presp) + 
                as.factor(pmtone), family=binomial(link=""logit""), data=ap, 
                na.action=na.pass)
Error: NA/NaN/Inf in foreign function call (arg 1)
</code></pre>

<p>Since this is my first time to venture into logistic regression, I am wondering whether there is any package in R that would be more suitable?</p>

<p>I am also tryng to understand the regression coefficients. The independent variables used in the model are:</p>

<ol>
<li><p>rectal temperature: </p>

<ul>
<li><code>(PTEM)1</code> = newborns with rectal temp. below 35.4 0C</li>
<li><code>(PTEM)2</code> = newborns with rectal temp. between 35.4 to 36.9 0C</li>
<li><code>(PTEM)3</code> = newborns with rectal temp. above 37.0 0C</li>
</ul></li>
<li><p>shivering:</p>

<ul>
<li><code>(pshiv)1</code> = newborns that were not shivering</li>
<li><code>(pshiv)2</code> = newborns that were shivering</li>
</ul></li>
<li><p>respiration:</p>

<ul>
<li><code>(presp)1</code> = newborns with normal respiration</li>
<li><code>(presp)2</code> = newborns with slight respiration problem</li>
<li><code>(presp)3</code> = newborns with poor respiration</li>
</ul></li>
<li><p>muscle tone:</p>

<ul>
<li><code>(pmtone)1</code> = newborns with normal muscle tone</li>
<li><code>(pmtone)2</code> = newborns with moderate muscle tone</li>
<li><code>(pmtone)1</code> = newborns with poor muscle tone</li>
</ul></li>
</ol>

<p>Looking at the coefficients, I got the following:</p>

<pre><code>                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.01135    0.23613  -0.048  0.96166    
as.factor(PTEM)2   -0.74642    0.24482  -3.049  0.00230 ** 
as.factor(PTEM)3   -1.95401    0.23259  -8.401  &lt; 2e-16 ***
as.factor(pshiv)2  -0.02638    0.06784  -0.389  0.69738    
as.factor(presp)2   0.74549    0.10532   7.079 1.46e-12 ***
as.factor(presp)3   0.66793    0.66540   1.004  0.31547    
as.factor(pmtone)2  0.54699    0.09678   5.652 1.58e-08 ***
as.factor(pmtone)3  1.82337    0.75409   2.418  0.01561 *  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 
</code></pre>

<p>In my other analysis, I found that newborns:  </p>

<p>a) with higher rectal temperature<br>
b) do not shiver<br>
c) good respiration and<br>
d) good muscle tone at birth were more likely to survive.  </p>

<p>I am a bit confused with the coefficients I am getting above. I am wondering whether whether I am not interpreting the results correctly or is it something else?</p>
"
"0.097077720253586","0.12977713690461"," 11178","<blockquote>
  <p><strong>Possible Duplicate:</strong><br>
  <a href=""http://stats.stackexchange.com/questions/8661/logistic-regression-in-r-odds-ratio"">Logistic Regression in R (Odds Ratio)</a>  </p>
</blockquote>



<p>I need to do a logistic regression in R. My response variable is <code>surv=0</code>; <code>surv=1</code> and I have about 18 predictor variables.</p>

<p>After reading my model, I got the table of Coefficients below and I need to go through some steps, which I am not familiar with, until I get to the odds ratios.</p>

<p>This is my first time to do a logistic regression in R and your help would be appreciated.</p>

<pre><code>Call:
glm(formula = surv ~ as.factor(tdate) + as.factor(line) + as.factor(wt) + 
    as.factor(crump) + as.factor(pind) + as.factor(pcscore) + 
    as.factor(ptem) + as.factor(pshiv) + as.factor(pincis) + 
    as.factor(presp) + as.factor(pmtone) + as.factor(pscolor) + 
    as.factor(ppscore) + as.factor(pmstain) + as.factor(pbse) + 
    as.factor(psex) + as.factor(pgf), family = binomial(link = ""logit""), 
    data = ap)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.9772  -0.5896  -0.4419  -0.3154   2.8264  

Coefficients:
                           Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                -0.59796    0.27024  -2.213 0.026918 *  
as.factor(tdate)2009-09-08  0.43918    0.19876   2.210 0.027130 *  
as.factor(tdate)2009-09-11  0.27613    0.20289   1.361 0.173514    
as.factor(tdate)2009-09-15  0.58733    0.19232   3.054 0.002259 ** 
as.factor(tdate)2009-09-18  0.52823    0.20605   2.564 0.010360 *  
as.factor(tdate)2009-09-22  0.45661    0.19929   2.291 0.021954 *  
as.factor(tdate)2009-09-25 -0.09189    0.21740  -0.423 0.672526    
as.factor(tdate)2009-09-29 -0.15696    0.28369  -0.553 0.580076    
as.factor(tdate)2010-01-26  1.39260    0.21049   6.616 3.69e-11 ***
as.factor(tdate)2010-01-29  1.67827    0.21099   7.954 1.80e-15 ***
as.factor(tdate)2010-02-02  1.35442    0.21292   6.361 2.00e-10 ***
as.factor(tdate)2010-02-05  1.36856    0.21439   6.383 1.73e-10 ***
as.factor(tdate)2010-02-09  1.18159    0.21951   5.383 7.33e-08 ***
as.factor(tdate)2010-02-12  1.40457    0.22001   6.384 1.73e-10 ***
as.factor(tdate)2010-02-16  1.01063    0.21783   4.639 3.49e-06 ***
as.factor(tdate)2010-02-19  1.54992    0.21535   7.197 6.14e-13 ***
as.factor(tdate)2010-02-23  0.85695    0.33968   2.523 0.011641 *  
as.factor(line)2           -0.26311    0.07257  -3.625 0.000288 ***
as.factor(line)5            0.06766    0.11162   0.606 0.544387    
as.factor(line)6           -0.30409    0.12130  -2.507 0.012176 *  
as.factor(wt)2             -0.33904    0.10708  -3.166 0.001544 ** 
as.factor(wt)3             -0.28976    0.13217  -2.192 0.028359 *  
as.factor(wt)4             -0.50470    0.16264  -3.103 0.001915 ** 
as.factor(wt)5             -0.74870    0.20067  -3.731 0.000191 ***
as.factor(crump)2           0.07537    0.10751   0.701 0.483280    
as.factor(crump)3          -0.14050    0.13217  -1.063 0.287768    
as.factor(crump)4          -0.20131    0.16689  -1.206 0.227724    
as.factor(crump)5          -0.23963    0.20778  -1.153 0.248803    
as.factor(pind)2           -0.29893    0.10752  -2.780 0.005434 ** 
as.factor(pind)3           -0.40828    0.12436  -3.283 0.001027 ** 
as.factor(pind)4           -0.73021    0.14947  -4.885 1.03e-06 ***
as.factor(pind)5           -0.68878    0.17650  -3.902 9.52e-05 ***
as.factor(pcscore)2        -0.52667    0.13606  -3.871 0.000108 ***
as.factor(ptem)2           -0.72600    0.08964  -8.099 5.52e-16 ***
as.factor(ptem)3           -0.79145    0.10503  -7.536 4.86e-14 ***
as.factor(ptem)4           -0.89956    0.10331  -8.707  &lt; 2e-16 ***
as.factor(ptem)5           -0.90181    0.10721  -8.412  &lt; 2e-16 ***
as.factor(pshiv)2           0.25236    0.07713   3.272 0.001068 ** 
as.factor(pincis)2          0.02327    0.07216   0.323 0.747041    
as.factor(presp)2           0.43746    0.11598   3.772 0.000162 ***
as.factor(pmtone)2          0.34515    0.11178   3.088 0.002016 ** 
as.factor(pscolor)2         0.53469    0.26851   1.991 0.046443 *  
as.factor(ppscore)2         0.25664    0.08751   2.933 0.003361 ** 
as.factor(pmstain)2        -0.48619    0.84408  -0.576 0.564611    
as.factor(pbse)2           -0.28248    0.07335  -3.851 0.000117 ***
as.factor(psex)2           -0.18240    0.06385  -2.857 0.004280 ** 
as.factor(pgf)12            0.10329    0.14314   0.722 0.470554    
as.factor(pgf)21           -0.06481    0.10772  -0.602 0.547388    
as.factor(pgf)22            0.39584    0.12740   3.107 0.001890 ** 
as.factor(pgf)31            0.18820    0.10082   1.867 0.061936 .  
as.factor(pgf)32            0.39662    0.13963   2.841 0.004504 ** 
as.factor(pgf)41            0.09178    0.10413   0.881 0.378106    
as.factor(pgf)42            0.21056    0.14906   1.413 0.157787    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 7812.9  on 8714  degrees of freedom
Residual deviance: 6797.4  on 8662  degrees of freedom
  (418 observations deleted due to missingness)
AIC: 6903.4

Number of Fisher Scoring iterations: 5
</code></pre>
"
"0.144714921058484","0.145095250022002"," 21067","<p>It's been a while since I've thought about or used a robust logistic regression model. However, I ran a few logits yesterday and realized that my probability curve was being affected by some 'extreme' values, and particularly low ones. However, when I went to run a robust logit model, I got the same results as I did in my logit model.</p>

<p>Under what circumstances should a robust logit produce different results from a traditional logit model? (in terms of coefficients)</p>

<p>R Code:</p>

<pre><code>&gt; library(Design)
&gt; ddist&lt;- datadist(dlmydat)
&gt; options(datadist='ddist')
&gt; me = lrm(factor(dlstatus) ~ dlour_bid, data=dlmydat)
&gt; me

Logistic Regression Model

lrm(formula = factor(dlstatus) ~ dlour_bid, data = dlmydat)


Frequencies of Responses
  1   2 
906 154 

       Obs  Max Deriv Model L.R.       d.f.          P          C        Dxy      Gamma      Tau-a         R2      Brier 
      1060      3e-05     170.11          1          0       0.81      0.619      0.621      0.154      0.263      0.105 

          Coef      S.E.      Wald Z P
Intercept -5.233549 0.3731235 -14.03 0
dlour_bid  0.005367 0.0004925  10.90 0

&gt; library(car)
&gt; dlmod = glm(factor(dlstatus) ~ dlour_bid, data=dlmydat, family=binomial(link=""logit""))
&gt; summary(dlmod)

Call:
glm(formula = factor(dlstatus) ~ dlour_bid, family = binomial(link = ""logit""), 
    data = dlmydat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.2345  -0.5687  -0.3059  -0.1739   2.6999  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -5.2335492  0.3731235  -14.03   &lt;2e-16 ***
dlour_bid    0.0053667  0.0004925   10.90   &lt;2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 878.61  on 1059  degrees of freedom
Residual deviance: 708.50  on 1058  degrees of freedom
AIC: 712.5

Number of Fisher Scoring iterations: 6
</code></pre>
"
"0.129436960338115","0.12977713690461"," 25839","<p>First off, I'll say I am a biologist and new to the statistics side of things so excuse my ignorance</p>

<p>I have a data set that consists of a binary outcome and then a bunch of trinary explanatory variables that looks something like this:</p>

<pre><code>head()
 Category block21_hap1 block21_hap2 block21_hap3 block21_check
1        1            1            1            0             2
2        1            2            0            0             2
3        1            1            0            1             2
4        1            1            0            1             2
5        1            1            1            0             2
6        1            1            1            0             2
</code></pre>

<p>A quick summary of the data</p>

<pre><code>summary()
Category block21_hap1 block21_hap2 block21_hap3 block21_check
 1:718    0:293        0:777        0:1026       2:1467       
 0:749    1:709        1:577        1: 390                    
          2:465        2:113        2:  51  
</code></pre>

<p>and another summary grouped by outcome levels</p>

<pre><code>by(hap.ped.final, hap.ped.final$Category, summary)
hap.ped.final$Category: 1
 block21_hap1 block21_hap2 block21_hap3 block21_check
 0:146        0:374        0:518        2:718        
 1:336        1:286        1:174                     
 2:236        2: 58        2: 26                     
---------------------------------------------------------------------------- 
hap.ped.final$Category: 0
 block21_hap1 block21_hap2 block21_hap3 block21_check
 0:147        0:403        0:508        2:749        
 1:373        1:291        1:216                     
 2:229        2: 55        2: 25          
</code></pre>

<p>So I am trying to run logistic regression on this data. When I do this:</p>

<pre><code>fit = glm(Category~ block21_hap1 + block21_hap2 + block21_hap3, data = hap.ped.final ,family = ""binomial"")
summary(fit)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.301  -1.177   1.059   1.177   1.200  

Coefficients: (1 not defined because of singularities)
                             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)                 -0.039221   0.280110  -0.140    0.889
hap.ped.final$block21_hap11  0.123555   0.183087   0.675    0.500
hap.ped.final$block21_hap12  0.009111   0.295069   0.031    0.975
hap.ped.final$block21_hap21 -0.084334   0.183087  -0.461    0.645
hap.ped.final$block21_hap22 -0.013889   0.337468  -0.041    0.967
hap.ped.final$block21_hap31  0.201113   0.183087   1.098    0.272
hap.ped.final$block21_hap32        NA         NA      NA       NA

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2033  on 1466  degrees of freedom
Residual deviance: 2028  on 1461  degrees of freedom
AIC: 2040

Number of Fisher Scoring iterations: 3
</code></pre>

<p>So I don't really know what a singularity is or what's going wrong here that is throwing up NA's as a result of my analysis. Is it my data, or what I'm doing to it.
I tried googling the warning (or whatever you might call it) and I got some pages talking about collinearity and multilinearity, which I do not understand at all. 
Again, sorry for lack of knowledge here. I wish I had done more maths in undergrad. </p>
"
"0.144714921058484","0.145095250022002"," 26288","<p>I'm trying to understand how to interpret log odds ratios in logistic regression. Let's say I have the following output:</p>

<pre><code>&gt; mod1 = glm(factor(won) ~ bid, data=mydat, family=binomial(link=""logit""))
&gt; summary(mod1)

Call:
glm(formula = factor(won) ~ bid, family = binomial(link = ""logit""), 
    data = mydat)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5464  -0.6990  -0.6392  -0.5321   2.0124  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -2.133e+00  1.947e-02 -109.53   &lt;2e-16 ***
bid          2.494e-03  5.058e-05   49.32   &lt;2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 83081  on 80337  degrees of freedom
Residual deviance: 80645  on 80336  degrees of freedom
AIC: 80649

Number of Fisher Scoring iterations: 4
</code></pre>

<p>So my equation would look like:
$$\Pr(Y=1) = \frac{1}{1 + \exp\left(-[-2.13 + 0.002\times(\text{bid})]\right)}$$</p>

<p>From here I calculated probabilities from all bid levels. 
<img src=""http://i.stack.imgur.com/5mLa9.png"" alt=""enter image description here""></p>

<p>I have been using this graph to say that at a 1000 bid, the probability of winning is x. At any given bid level, the probability of winning is x.</p>

<p>I have a feeling that my interpretation is wrong because I'm not considering that these are log-odds. How should I really be interpreting this plot/these results?</p>
"
"0.307412780803022","0.291998558035373"," 27830","<p>In a previous post Iâ€™ve wondered how to <a href=""http://stats.stackexchange.com/questions/22494/is-using-a-questionnaire-score-euroqols-eq-5d-with-a-bimodal-distribution-as"">deal with EQ-5D scores</a>. Recently I stumbled upon logistic quantile regression suggested by <a href=""http://www.ncbi.nlm.nih.gov.proxy.kib.ki.se/pubmed/19941281"">Bottai and McKeown</a> that introduces an elegant way to deal with bounded outcomes.
The formula is simple:</p>

<p>$logit(y)=log(\frac{y-y_{min}}{y_{max}-y})$</p>

<p>To avoid log(0) and division by 0 you extend the range by a small value, $\epsilon$. This gives an environment that respects the boundaries of the score. </p>

<p>The problem is that any $\beta$ will be in the logit scale and that makes doesnâ€™t make any sense unless transformed back into the regular scale but that means that the $\beta$ will be non-linear. For graphing purposes this doesnâ€™t matter but not with more $\beta$:s this will be very inconvenient. </p>

<p>My question:</p>

<p><strong>How do you suggest to report a logit $\beta$ without reporting the full span?</strong></p>

<hr>

<h2>Implementation example</h2>

<p>For testing the implementation Iâ€™ve written a simulation based on this basic function:</p>

<p>$outcome=\beta_0+\beta_1* xtest^3+\beta_2*sex$</p>

<p>Where $\beta_0 = 0$, $\beta_1 = 0.5$ and $\beta_2 = 1$. Since there is a ceiling in scores Iâ€™ve set any outcome value above 4 and any below -1 to the max value.</p>

<h3>Simulate the data</h3>

<pre><code>set.seed(10)
intercept &lt;- 0
beta1 &lt;- 0.5
beta2 &lt;- 1
n = 1000
xtest &lt;- rnorm(n,1,1)
gender &lt;- factor(rbinom(n, 1, .4), labels=c(""Male"", ""Female""))
random_noise  &lt;- runif(n, -1,1)

# Add a ceiling and a floor to simulate a bound score
fake_ceiling &lt;- 4
fake_floor &lt;- -1

# Just to give the graphs the same look
my_ylim &lt;- c(fake_floor - abs(fake_floor)*.25, 
             fake_ceiling + abs(fake_ceiling)*.25)
my_xlim &lt;- c(-1.5, 3.5)

# Simulate the predictor
linpred &lt;- intercept + beta1*xtest^3 + beta2*(gender == ""Female"") + random_noise
# Remove some extremes
linpred[linpred &gt; fake_ceiling + abs(diff(range(linpred)))/2 |
    linpred &lt; fake_floor - abs(diff(range(linpred)))/2 ] &lt;- NA
#limit the interval and give a ceiling and a floor effect similar to scores
linpred[linpred &gt; fake_ceiling] &lt;- fake_ceiling
linpred[linpred &lt; fake_floor] &lt;- fake_floor
</code></pre>

<p>To plot the above:</p>

<pre><code>library(ggplot2)
# Just to give all the graphs the same look
my_ylim &lt;- c(fake_floor - abs(fake_floor)*.25, 
             fake_ceiling + abs(fake_ceiling)*.25)
my_xlim &lt;- c(-1.5, 3.5)
qplot(y=linpred, x=xtest, col=gender, ylab=""Outcome"")
</code></pre>

<p>Gives this image:</p>

<p><img src=""http://i.stack.imgur.com/luZGu.png"" alt=""Scatterplot from simulation""></p>

<h3>The regressions</h3>

<p>In this section I create the regular linear regression, quantile regression (using the median) and logistic quantile regression. All estimates are based on bootstrapped values using the bootcov() function.</p>

<pre><code>library(rms)

# Regular linear regression
fit_lm &lt;- Glm(linpred~rcs(xtest, 5)+gender, x=T, y=T)
boot_fit_lm &lt;- bootcov(fit_lm, B=500)
p &lt;- Predict(boot_fit_lm, xtest=seq(-2.5, 3.5, by=.001), gender=c(""Male"", ""Female""))
lm_plot &lt;- plot.Predict(p, 
             se=T, 
             col.fill=c(""#9999FF"", ""#BBBBFF""), 
             xlim=my_xlim, ylim=my_ylim)

# Quantile regression regular
fit_rq &lt;- Rq(formula(fit_lm), x=T, y=T)
boot_rq &lt;- bootcov(fit_rq, B=500)
# A little disturbing warning:
# In rq.fit.br(x, y, tau = tau, ...) : Solution may be nonunique

p &lt;- Predict(boot_rq, xtest=seq(-2.5, 3.5, by=.001), gender=c(""Male"", ""Female""))
rq_plot &lt;- plot.Predict(p, 
             se=T, 
             col.fill=c(""#9999FF"", ""#BBBBFF""), 
             xlim=my_xlim, ylim=my_ylim)

# The logit transformations
logit_fn &lt;- function(y, y_min, y_max, epsilon)
    log((y-(y_min-epsilon))/(y_max+epsilon-y))


antilogit_fn &lt;- function(antiy, y_min, y_max, epsilon)
    (exp(antiy)*(y_max+epsilon)+y_min-epsilon)/
        (1+exp(antiy))


epsilon &lt;- .0001
y_min &lt;- min(linpred, na.rm=T)
y_max &lt;- max(linpred, na.rm=T)
logit_linpred &lt;- logit_fn(linpred, 
                          y_min=y_min,
                          y_max=y_max,
                          epsilon=epsilon)

fit_rq_logit &lt;- update(fit_rq, logit_linpred ~ .)
boot_rq_logit &lt;- bootcov(fit_rq_logit, B=500)


p &lt;- Predict(boot_rq_logit, xtest=seq(-2.5, 3.5, by=.001), gender=c(""Male"", ""Female""))

# Change back to org. scale
transformed_p &lt;- p
transformed_p$yhat &lt;- antilogit_fn(p$yhat,
                                    y_min=y_min,
                                    y_max=y_max,
                                    epsilon=epsilon)
transformed_p$lower &lt;- antilogit_fn(p$lower, 
                                     y_min=y_min,
                                     y_max=y_max,
                                     epsilon=epsilon)
transformed_p$upper &lt;- antilogit_fn(p$upper, 
                                     y_min=y_min,
                                     y_max=y_max,
                                     epsilon=epsilon)

logit_rq_plot &lt;- plot.Predict(transformed_p, 
             se=T, 
             col.fill=c(""#9999FF"", ""#BBBBFF""), 
             xlim=my_xlim, ylim=my_ylim)
</code></pre>

<h3>The plots</h3>

<p>To compare with the base function Iâ€™ve added this code:</p>

<pre><code>library(lattice)
# Calculate the true lines
x &lt;- seq(min(xtest), max(xtest), by=.1)
y &lt;- beta1*x^3+intercept
y_female &lt;- y + beta2
y[y &gt; fake_ceiling] &lt;- fake_ceiling
y[y &lt; fake_floor] &lt;- fake_floor
y_female[y_female &gt; fake_ceiling] &lt;- fake_ceiling
y_female[y_female &lt; fake_floor] &lt;- fake_floor

tr_df &lt;- data.frame(x=x, y=y, y_female=y_female)
true_line_plot &lt;- xyplot(y  + y_female ~ x, 
                         data=tr_df,
                         type=""l"", 
                         xlim=my_xlim, 
                         ylim=my_ylim, 
                         ylab=""Outcome"", 
                         auto.key = list(
                           text = c(""Male"","" Female""),
                           columns=2))


# Just for making pretty graphs with the comparison plot
compareplot &lt;- function(regr_plot, regr_title, true_plot){
  print(regr_plot, position=c(0,0.5,1,1), more=T)
  trellis.focus(""toplevel"")
  panel.text(0.3, .8, regr_title, cex = 1.2, font = 2)
  trellis.unfocus()
  print(true_plot, position=c(0,0,1,.5), more=F)
  trellis.focus(""toplevel"")
  panel.text(0.3, .65, ""True line"", cex = 1.2, font = 2)
  trellis.unfocus()
}

compareplot(lm_plot, ""Linear regression"", true_line_plot)
compareplot(rq_plot, ""Quantile regression"", true_line_plot)
compareplot(logit_rq_plot, ""Logit - Quantile regression"", true_line_plot)
</code></pre>

<p><img src=""http://i.stack.imgur.com/74Uid.png"" alt=""Linear regression for bounded outcome""></p>

<p><img src=""http://i.stack.imgur.com/xHRtF.png"" alt=""Quantile regression for bounded outcome""></p>

<p><img src=""http://i.stack.imgur.com/XfLy8.png"" alt=""Logistic quantile regression for bounded outcome""></p>

<h3>The contrast output</h3>

<p>Now I've tried to get the contrast and it's almost ""right"" but it varies along the span as expected:</p>

<pre><code>&gt; contrast(boot_rq_logit, list(gender=levels(gender), 
+                              xtest=c(-1:1)), 
+          FUN=function(x)antilogit_fn(x, epsilon))
   gender xtest Contrast   S.E.       Lower      Upper       Z      Pr(&gt;|z|)
   Male   -1    -2.5001505 0.33677523 -3.1602179 -1.84008320  -7.42 0.0000  
   Female -1    -1.3020162 0.29623080 -1.8826179 -0.72141450  -4.40 0.0000  
   Male    0    -1.3384751 0.09748767 -1.5295474 -1.14740279 -13.73 0.0000  
*  Female  0    -0.1403408 0.09887240 -0.3341271  0.05344555  -1.42 0.1558  
   Male    1    -1.3308691 0.10810012 -1.5427414 -1.11899674 -12.31 0.0000  
*  Female  1    -0.1327348 0.07605115 -0.2817923  0.01632277  -1.75 0.0809  

Redundant contrasts are denoted by *

Confidence intervals are 0.95 individual intervals
</code></pre>
"
"NaN","NaN"," 32239","<p>As described in Merlo et al (<a href=""http://www.ncbi.nlm.nih.gov/pubmed/16537344"" rel=""nofollow"">J Epidem Comm Health 2006</a>), the 95% credible interval for MOR is calculated using MCMC. MOR is defined as $\exp(\sqrt{2\sigma^2}\times 0.675)$, where $\sigma$ is the level-2 variance of the random intercept $u$ from a null model of a hierarchical logistic regression.  </p>

<p>Does anyone have an idea of how to write a program for an Markov chain Monte Carlo to calculate the standard error of the  median odds ratio (MOR) using <a href=""http://cran.r-project.org/web/packages/rjags/index.html"" rel=""nofollow"">rjags</a>?<br>
My dependent variable is outcome(alive/dead) and the clustering (level2)variable is Hospital. There are 140 hospitals and would like to see variations in outcome between hospitals. Other risk factors will be included later as independent level1 variables.</p>
"
"0.161796200422643","0.162221421130763"," 43315","<p>The model that I created in R is:</p>

<blockquote>
  <p>fit &lt;- lm(hired ~ educ + exper + sex, data=data)</p>
</blockquote>

<p>what I am unsure of is how to fit to model to predict probability of interest where p = pr(hiring = 1).</p>

<p>Any help would be appreciated thanks,
Clay </p>

<p><strong>Edit:</strong>
This is the computer output for what I have computed so far. I am unsure if this is even a step in the right direction to find the answer to this question.</p>

<p>What I am trying to do is, Fit a logistic regression model to predict the probability of being hired using years of education, years of experience and sex of job applicants.</p>

<pre><code> &gt; test&lt;-glm(hired ~ educ + exper + sex, data=data, family=binomial(link=""logit""))
 &gt; summary(test)

 Call:
 glm(formula = hired ~ educ + exper + sex, family = binomial(link = ""logit""), 
     data = data)

 Deviance Residuals: 
     Min       1Q   Median       3Q      Max  
 -1.4380  -0.4573  -0.1009   0.1294   2.1804  

 Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)  
 (Intercept) -14.2483     6.0805  -2.343   0.0191 *
 educ          1.1549     0.6023   1.917   0.0552 .
 exper         0.9098     0.4293   2.119   0.0341 *
 sex           5.6037     2.6028   2.153   0.0313 *
 ---
 Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

 (Dispersion parameter for binomial family taken to be 1)

     Null deviance: 35.165  on 27  degrees of freedom
 Residual deviance: 14.735  on 24  degrees of freedom
 AIC: 22.735

 Number of Fisher Scoring iterations: 7
</code></pre>
"
"0.228814380978138","0.229415733870562"," 48766","<p>My logistic model <a href=""http://stats.stackexchange.com/q/48739/5509"">has been suspicious</a> due to enormous coefficients, so I tried to do a crossvalidation, and also do a crossvalidation of simplified model, to confirm the fact that the original model is overspecified, as <a href=""http://stats.stackexchange.com/a/48741/5509"">James suggested</a>. However, I don't know how to interpret the result (this is the model from the linked question):</p>

<pre><code>&gt; summary(m5)

Call:
glm(formula = cbind(ml, ad) ~ rok + obdobi + kraj + resid_usili2 + 
    rok:obdobi + rok:kraj + obdobi:kraj + kraj:resid_usili2 + 
    rok:obdobi:kraj, family = ""quasibinomial"")
[... see http://stats.stackexchange.com/q/48739/5509 for complete summary output ]

&gt; cv.glm(na.omit(data.frame(orel, resid_usili2)), m5, K = 10)
$call
cv.glm(data = na.omit(data.frame(orel, resid_usili2)), glmfit = m5, 
    K = 10)

$K
[1] 10

$delta
[1] 0.2415355 0.2151626

$seed
  [1]         403         271  1234892862 -1124595763  -489713400  1566924080   147612843
  [8]  1879282918  -694084381  1171051622  2063023839 -1307030905  -477709428  1248673977
 [15]  -746898494   420363755  -890078828   460552896  -758793089  -913500073  -882355605
[....]
Warning message:
glm.fit: algorithm did not converge
</code></pre>

<p>I guess the delta is the mean fitting error, but how to interpret it? Is it a good or bad fit? BTW, the algorithm did not converge, maybe due to the enormous coefficients (?)</p>

<p>I tried a simplified model:</p>

<pre><code>&gt; summary(m)

Call:
glm(formula = cbind(ml, ad) ~ rok + obdobi + kraj, family = ""quasibinomial"")

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7335  -1.2324  -0.1666   1.0866   3.1788  

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -107.60761   48.06535  -2.239 0.025335 *  
rok            0.05381    0.02393   2.249 0.024683 *  
obdobinehn    -0.26962    0.10372  -2.599 0.009441 ** 
krajJHC        0.68869    0.27617   2.494 0.012761 *  
krajJHM       -0.26607    0.28647  -0.929 0.353169    
krajLBK       -1.11305    0.55165  -2.018 0.043828 *  
krajMSK       -0.61390    0.37252  -1.648 0.099593 .  
krajOLK       -0.49704    0.32935  -1.509 0.131501    
krajPAK       -1.18444    0.35090  -3.375 0.000758 ***
krajPLK       -1.28668    0.44238  -2.909 0.003691 ** 
krajSTC        0.01872    0.27806   0.067 0.946322    
krajULKV      -0.41950    0.61647  -0.680 0.496315    
krajVYS       -1.17290    0.39733  -2.952 0.003213 ** 
krajZLK       -0.38170    0.36487  -1.046 0.295698    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for quasibinomial family taken to be 1.304775)

    Null deviance: 2396.8  on 1343  degrees of freedom
Residual deviance: 2198.6  on 1330  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 4
</code></pre>

<p>and it's crossvalidation:</p>

<pre><code>&gt; cv.glm(orel, m, K = 10)
$call
cv.glm(data = orel, glmfit = m, K = 10)

$K
[1] 10

$delta
[1] 0.2156313 0.2154078

$seed
  [1]         403         526   300751243  -244464717  1066448079  1971573706 -1154513152
  [8]   634841816 -1521293072 -1040655077   505710009  -323431793 -1218609191  1060964279
 [15]  1349082996   -32847357 -1387496845   821178952  -971482876  1295018851  1380491861
</code></pre>

<p>Now it converged. But the delta seems more or less the same, despite of the fact that this model looks much more sane! I'm confused by the crossvalidation now... please give me a hint on how interpret it.</p>
"
"0.10232890201933","0.102597835208515"," 63494","<p>In <code>R</code> I have a categorical variable that I performed logistic regression on and got the following result:</p>

<pre><code>glm(formula = mortality ~ SMOKE, family = binomial, data = c.data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.2155  -0.2155  -0.2155  -0.1860   2.8515  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -4.0483     0.3189 -12.694   &lt;2e-16 ***
SMOKEN        0.2968     0.3559   0.834    0.404    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 492.45  on 2369  degrees of freedom
Residual deviance: 491.72  on 2368  degrees of freedom
AIC: 495.72

Number of Fisher Scoring iterations: 6
</code></pre>

<p>Is the value for the intercept the same as <code>SMOKEY</code> (has a history of smoking)?</p>
"
"0.20465780403866","0.205195670417031"," 63927","<p>I am struggling to fit a simple logistic regression for one dependent value (group) by one independent qualitative variable (dilat) measured twice independently (rater).</p>

<p>I try many solutions and think according <a href=""http://www.ats.ucla.edu/stat/mult_pkg/whatstat/"" rel=""nofollow"">http://www.ats.ucla.edu/stat/mult_pkg/whatstat/</a> that the solution is a Mixed Effects Logistic Regression.</p>



<pre class=""lang-r prettyprint-override""><code>glmer_dilat&lt;-glmer(group ~ dilat + (1 | rater), data = ex, family = binomial)
summary(glmer_dilat)
</code></pre>



<pre class=""lang-r prettyprint-override""><code>Generalized linear mixed model fit by the Laplace approximation 
Formula: group ~ dilat + (1 | rater) 
   Data: ex 
   AIC   BIC logLik deviance
 105.5 112.5 -49.74    99.48
Random effects:
 Groups Name        Variance Std.Dev.
 rater  (Intercept)  0        0      
Number of obs: 76, groups: rater, 2

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.8473     0.4880   1.736   0.0825 .
dilat        -1.2827     0.5594  -2.293   0.0219 *
</code></pre>

<p>But the result is the same without !</p>

<pre class=""lang-r prettyprint-override""><code>summary(glm(group ~ dilat, data =ex, family = binomial))

glm(formula = group ~ dilat, family = binomial, data = ex)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.552  -0.999  -0.999   1.367   1.367  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.8473     0.4879   1.736   0.0825 .
dilat        -1.2826     0.5594  -2.293   0.0219 *
</code></pre>

<p>What is the solution?</p>

<p>please find my data set here after applying a dput command to it.</p>

<pre class=""lang-r prettyprint-override""><code>structure(list(id = structure(c(38L, 11L, 6L, 28L, 3L, 30L, 39L, 4L, 8L, 12L, 32L, 29L, 34L, 35L, 33L, 16L, 27L, 5L, 36L, 10L, 9L, 14L, 1L, 13L, 31L, 2L, 17L, 7L, 19L, 20L, 18L, 21L, 23L, 15L, 24L, 25L, 37L, 26L, 38L, 11L, 6L, 28L, 3L, 30L, 39L, 4L, 8L, 12L, 32L, 29L, 34L, 35L, 33L, 16L, 27L, 5L, 36L, 10L, 9L, 14L, 1L, 13L, 31L, 2L, 17L, 7L, 19L, 20L, 18L, 21L, 22L, 23L, 15L, 24L, 37L, 26L), .Label = c(""1038835"", ""2025267"", ""2053954"", ""3031612"", ""40004760"", ""40014515"", ""40040532"", ""40092413"", ""40101857"", ""40105328"", ""4016213"", ""40187296"", ""40203950"", ""40260642"", ""40269263"", ""40300349"", ""40308059"", ""40327146"", ""40333651"", ""40364468"", ""40435267"", ""40440293"", ""40443920"", ""40485124"", ""40609779"", ""40628741"", ""40662695"", ""5025220"", ""E9701737"", ""M/377313"", ""qsc22913"", ""QSC29371"", ""QSC43884"", ""QSC62220"", ""QSC75555"", ""QSC92652"", ""QSD01289"", ""QSD02237"", ""U/FY0296"" ), class = ""factor""), group = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), rater = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), dilat = c(1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L), midbrain_atroph = c(1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), quadrigemi_atroph = c(1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), hum_sig = c(1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), flower_sig = c(0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), fp_atroph = c(0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), scp_atroph = c(0L, 1L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L)), .Names = c(""id"", ""group"", ""rater"", ""dilat"", ""midbrain_atroph"", ""quadrigemi_atroph"", ""hum_sig"", ""flower_sig"", ""fp_atroph"", ""scp_atroph""), class = ""data.frame"", row.names = c(NA, -76L))
</code></pre>
"
"0.191439846060547","0.191942973987479"," 64788","<p>I performed multivariate logistic regression with the dependent variable <code>Y</code> being death at a nursing home within a certain period of entry and got the following results (note if the variables starts in <code>A</code> it is a continuous value while those starting in <code>B</code> are categorical):</p>

<pre><code>Call:
glm(Y ~ A1 + B2 + B3 + B4 + B5 + A6 + A7 + A8 + A9, data=mydata, family=binomial)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.0728  -0.2167  -0.1588  -0.1193   3.7788  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  20.048631  6.036637   3.321 0.000896 ***
A1           0.051167   0.016942   3.020 0.002527 ** 
B2          -0.664940   0.304299  -2.185 0.028878 *  
B3          -2.825281   0.633072  -4.463 8.09e-06 ***
B4          -2.547931   0.957784  -2.660 0.007809 ** 
B5          -2.862460   1.385118  -2.067 0.038774 *  
A6          -0.129808   0.041286  -3.144 0.001666 ** 
A7           0.020016   0.009456   2.117 0.034276 *  
A8          -0.707924   0.253396  -2.794 0.005210 ** 
A9           0.003453   0.001549   2.229 0.025837 *  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 485.10  on 2206  degrees of freedom
Residual deviance: 417.28  on 2197  degrees of freedom
AIC: 437.28

Number of Fisher Scoring iterations: 7

 (Intercept)           A1           B2           B3           B4           B5           A6           A7           A8           A9 
5.093426e+08 1.052499e+00 5.143045e-01 5.929197e-02 7.824340e-02 5.712806e-02 8.782641e-01 1.020218e+00 4.926657e-01 1.003459e+00 

                   2.5 %       97.5 %
(Intercept) 3.703525e+03 7.004944e+13
A1          1.018123e+00 1.088035e+00
B2          2.832698e-01 9.337710e-01
B3          1.714448e-02 2.050537e-01
B4          1.197238e-02 5.113460e-01
B5          3.782990e-03 8.627079e-01
A6          8.099945e-01 9.522876e-01
A7          1.001484e+00 1.039302e+00
A8          2.998207e-01 8.095488e-01
A9          1.000416e+00 1.006510e+00
</code></pre>

<p>As you can see, all of the variables are ""significant"" in that their p values are below the usual threshold of 0.05. However looking at the coefficients, I'm not quite sure what to make of these results. It seems that although these variables contribute to the model, looking at the odds ratios, they don't seem to really seem to have much predictive power. Of note, when I calculated the AUC, I got approximately 0.8. </p>

<p>Can I say that this model is better at predicting against mortality (e.g. predicting that seniors will live past the prescribed period) compared to predicting for mortality?</p>
"
"0.191439846060547","0.191942973987479"," 73567","<p>I have a logistic regression model with several variables and one of those variables (called x3 in my example below) is not significant. However, x3 should remain in the model because it is scientifically important.</p>

<p>Now, x3 is continuous and I want to create a plot of the predicted probability vs x3. Even though x3 is not statistically significant, it has an effect on my outcome and therefore it has an effect on the predicted probability. This means that I can see from the graph, that the probability changes with increasing x3. However, how should I interpret the graph and the change in the predicted probability, given that x3 is indeed not statistically significant?</p>

<p>Below is a simulated data in R set to illustrate my question. The graph also contains a 95% confidence interval for the predicted probability (dashed lines):</p>

<pre><code>&gt; set.seed(314)
&gt; n &lt;- 300
&gt; x1 &lt;- rbinom(n,1,0.5)
&gt; x2 &lt;- rbinom(n,1,0.5)
&gt; x3 &lt;- rexp(n)
&gt; logit &lt;- 0.5+0.9*x1-0.5*x2
&gt; prob &lt;- exp(logit)/(1+exp(logit))
&gt; y &lt;- rbinom(n,1,prob)
&gt; 
&gt; model &lt;- glm(y~x1+x2+x3, family=""binomial"")
&gt; summary(model)

Call:
glm(formula = y ~ x1 + x2 + x3, family = ""binomial"")

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.0394  -1.1254   0.5604   0.8554   1.4457  

Coefficients:
            Estimate Std. Error z value Pr(    &gt;|z|)    
(Intercept)   1.1402     0.2638   4.323 1.54e-05 ***
x1            0.8256     0.2653   3.112  0.00186 ** 
x2           -1.1338     0.2658  -4.266 1.99e-05 ***
x3           -0.1478     0.1249  -1.183  0.23681    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 373.05  on 299  degrees of freedom
Residual deviance: 341.21  on 296  degrees of freedom
AIC: 349.21

Number of Fisher Scoring iterations: 3

&gt; 
&gt; dat &lt;- data.frame(x1=1, x2=1, x3=seq(0,5,0.1))
&gt; preds &lt;- predict(model, dat,type = ""link"", se.fit = TRUE )
&gt; critval &lt;- 1.96
&gt; upr &lt;- preds$fit + (critval * preds$se.fit)
&gt; lwr &lt;- preds$fit - (critval * preds$se.fit)
&gt; fit &lt;- preds$fit
    &gt; 
    &gt; fit2 &lt;- mod$family$linkinv(fit)
    &gt; upr2 &lt;- mod$family$linkinv(upr)
    &gt; lwr2 &lt;- mod$family$linkinv(lwr)
    &gt; 
    &gt; plot(dat$x3, fit2, lwd=2, type=""l"", main=""Predicted Probability"", ylab=""Probability"", xlab=""x3"", ylim=c(0,1.00))
&gt; lines(dat$x3, upr2, lty=2)
    &gt; lines(dat$x3, lwr2, lty=2)
</code></pre>

<p><img src=""http://i.stack.imgur.com/ljW7W.png"" alt=""enter image description here""></p>

<p>Thanks!</p>

<p>Emilia</p>
"
"0.125326797943307","0.125656172487509"," 74549","<p>This is from the book <em>The statistical sleuth--A course in methods of Data analysis</em> Chapter 20, Exercise 12(c)-(e). I am using logistic regression to predict carrier with possible predictors <code>CK</code> and <code>H</code>. Here is my solution:</p>

<pre><code>Carrier &lt;- c(0,0,0,0,0,1,1,1,1,1)  
CK      &lt;- c(52,20,28,30,40,167,104,30,65,440)  
H       &lt;- c(83.5,77,86.5,104,83,89,81,108,87,107)  
logCK   &lt;- log(CK)  
fit4    &lt;- glm(Carrier~logCK+H, family=""binomial"", control=list(maxit=100))  
Warning message:  
glm.fit: fitted probabilities numerically 0 or 1 occurred   
summary(fit4)
## 
## Call:
## glm(formula = Carrier ~ logCK + H, family = ""binomial"", control = list(maxit = 100))
## 
## Deviance Residuals: 
##        Min          1Q      Median          3Q         Max  
## -1.480e-05  -2.110e-08   0.000e+00   2.110e-08   1.376e-05  
##
## Coefficients:  
##              Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   -2292.8  4130902.8  -0.001        1  
## logCK           315.6   589675.2   0.001        1  
## H                11.5    21279.6   0.001        1
</code></pre>

<p>This results appear to be weird, because it seems that all coefficients are not significant.  Also the next question is to do a drop-in-deviance test for this full model and the reduced model that neither of <code>logCK</code> and <code>H</code> is useful predictor. I get:  </p>

<pre><code>fit5 &lt;- glm(Carrier~1, family=""binomial"")  
1-pchisq(deviance(fit5)-deviance(fit4), df.residual(fit5)-df.residual(fit4))  
## [1] 0.0009765625
</code></pre>

<p>So the p-value indicates that at least one of <code>logCK</code> and <code>H</code> is useful. Then I'm stuck at the next question, it asks me to calculate odds ratio for a woman with (CK, H)=(300,100) over one with (CK, H)=(80, 85).  </p>

<p>But how can I get a meaningful result with all coefficients in this model ranging so wildly? Is there anything wrong with the way I did this logistic regression? Are there any remedial measures?  </p>
"
"0.20465780403866","0.205195670417031"," 89692","<p>My data has 3 major inputs: <code>BLDDAY</code> (a factor), <code>BLDMNT</code> (a factor), and <code>D_BLD_SER</code> (days as an integer variable).  The output is whether input variable has any impact on failure.  My model is: <code>model = glm(FAILED~BLDDAY+BLDMNT+D_BLD_SER, family=""binomial"", data=data_list)</code>.  (I used <a href=""http://www.ats.ucla.edu/stat/r/dae/logit.htm"" rel=""nofollow"">UCLA's statistics help site's guide to logistic regression in R</a> to build this model.)  </p>

<p>Output: </p>

<pre><code>Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.3282  -0.9123  -0.8128   1.4056   2.1053  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)     -0.7672583  0.1317132  -5.825 5.70e-09 ***
BLDDAYMonday    -0.1545646  0.0839380  -1.841  0.06556 .  
BLDDAYSaturday  -0.1257976  0.2028259  -0.620  0.53511    
BLDDAYSunday    -0.1183008  0.1868713  -0.633  0.52669    
BLDDAYThursday  -0.2007452  0.0772653  -2.598  0.00937 ** 
BLDDAYTuesday    0.0480453  0.0758603   0.633  0.52651    
BLDDAYWednesday -0.0358585  0.0760027  -0.472  0.63707    
BLDMNTAug        0.3009445  0.1405545   2.141  0.03226 *  
BLDMNTDec        0.5562170  0.1338467   4.156 3.24e-05 ***
BLDMNTFeb        0.3334978  0.2133475   1.563  0.11801    
BLDMNTJan        0.4076504  0.2277978   1.790  0.07353 .  
BLDMNTJul        0.1306585  0.1415302   0.923  0.35591    
BLDMNTJun       -0.0357361  0.1428105  -0.250  0.80241    
BLDMNTMar        0.4570491  0.1949815   2.344  0.01907 *  
BLDMNTMay       -0.2292620  0.1614577  -1.420  0.15562    
BLDMNTNov        0.3060012  0.1334034   2.294  0.02180 *  
BLDMNTOct        0.2390501  0.1341877   1.781  0.07484 .  
BLDMNTSep        0.2481405  0.1384901   1.792  0.07317 .  
D_BLD_SER       -0.0020960  0.0003367  -6.225 4.82e-10 ***

(Dispersion parameter for binomial family taken to be 1)
    Null deviance: 10288  on 8182  degrees of freedom
Residual deviance: 10154  on 8164  degrees of freedom
AIC: 10192
Number of Fisher Scoring iterations: 4
</code></pre>

<p>The ANOVA table is the following:</p>

<pre><code>anova(model, test=""Chisq"")
Analysis of Deviance Table
Model: binomial, link: logit
Response: FAILED
Terms added sequentially (first to last)

          Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                       8182      10288              
BLDDAY     6   20.392      8176      10268  0.002357 ** 
BLDMNT    11   70.662      8165      10197 9.142e-11 ***
D_BLD_SER  1   43.797      8164      10154 3.642e-11 ***
</code></pre>

<p>My questions are:</p>

<ol>
<li><p>Although the p-values for all three components are less than 0.05, which can be considered as significant, the deviance reduced due to each component is less than 1% of the total deviance. <strong>Normally the interpretation of output like this is input parameter affects output and it's better to use this parameter then using noting.</strong> But does it really make sense of taking this parameter as significant input?</p></li>
<li><p>The p-values for <code>BLDDAY</code> and <code>BLDMNT</code> given by <code>anova()</code> is the overall p-value,  which is significant, but <code>summary()</code> gives detailed impact of each factor level. If I consider the p-values for each factor overall <code>BLDDAY</code> is significant but individually only <code>BLDDAYThursday</code> is significant. I am bit confused not as whether to consider <code>BLDDAY</code> as significant input, or Thursday only, or Thursday &amp; Friday both.</p></li>
</ol>
"
"0.177238857380217","0.177704663327728"," 95891","<p>I'm running a logistic regression model where anecdotally I expected age to be a very large factor. If you see from the charts I made in Excel before running the model through R, this is how the support lines up by age:</p>

<p><img src=""http://i.stack.imgur.com/oEVZQ.jpg"" alt=""enter image description here""></p>

<p>Looks pretty significant.</p>

<p>Though when I run the model, as you can see below, age is the <em>only</em> thing that's not significant -- which was very surprising:</p>

<pre><code>&gt; attach(mydata) 
&gt; 
&gt; # Define variables 
&gt; 
&gt; Y &lt;- cbind(support)
&gt; X &lt;- cbind(sex, region, age, supportscore1, supportscore2, county)
&gt;
&gt; # Logit model coefficients 
&gt; 
&gt; logit &lt;- glm(Y ~ X, family=binomial (link = ""logit""), na.action = na.exclude) 
&gt; 
&gt; summary(logit) 

Call:
glm(formula = Y ~ X, family = binomial(link = ""logit""), na.action = na.exclude)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.1019  -0.7609   0.5231   0.7101   2.3965  

Coefficients:
                       Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)            4.013446   0.440962   9.102  &lt; 2e-16 ***
Xsex                  -0.229256   0.104859  -2.186 0.028792 *  
Xregion               -1.103308   0.091497 -12.058  &lt; 2e-16 ***
Xage                   0.004569   0.003209   1.424 0.154512    
Xsupportscore1        -0.019262   0.005732  -3.360 0.000778 ***
Xsupportscore2         0.019810   0.005264   3.764 0.000168 ***
Xcounty               -0.047581   0.011161  -4.263 2.02e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2871.5  on 2072  degrees of freedom
Residual deviance: 2245.5  on 2066  degrees of freedom
  (66 observations deleted due to missingness)
AIC: 2259.5

Number of Fisher Scoring iterations: 4
</code></pre>

<p>My only guess on this is that the previous support scores (both 0-100 numerical values) I'm using may have already taken age into account, and the model doesn't want to count it twice. Though, to compare, region and county are just two different ways of cutting up the geography -- and those both seem significant.</p>

<p>Can somebody let me know what you would think if your model told you that age wasn't significant when in clearly is? Trying to figure out if there's a way of thinking about it that I'm missing or if something in my code is wrong.</p>

<p>Thanks!</p>

<p>--
<strong>EDIT</strong></p>

<p>Pairs plot added to show correlation (despite some factors being categorical):</p>

<pre><code>pairs(~sex + region +  age + supportscore1 + supportscore2 + county, data=mydata)
</code></pre>

<p><img src=""http://i.stack.imgur.com/N2IG4.jpg"" alt=""enter image description here""></p>
"
"0.147699047816848","0.177704663327728"," 96236","<p>I am following an example <a href=""http://www.ats.ucla.edu/stat/r/dae/logit.htm"" rel=""nofollow"">here</a> on using Logistic Regression in R. However, I need some help interpreting the results. They do go over some of the interpretations in the above link, but I need more help with understanding a goodness of fit for Logistic Regression and the output that I am given.</p>

<p>For convenience, here is the summary given in the example:</p>

<pre><code>## Call:
## glm(formula = admit ~ gre + gpa + rank, family = ""binomial"", 
##     data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.627  -0.866  -0.639   1.149   2.079  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -3.98998    1.13995   -3.50  0.00047 ***
## gre          0.00226    0.00109    2.07  0.03847 *  
## gpa          0.80404    0.33182    2.42  0.01539 *  
## rank2       -0.67544    0.31649   -2.13  0.03283 *  
## rank3       -1.34020    0.34531   -3.88  0.00010 ***
## rank4       -1.55146    0.41783   -3.71  0.00020 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 499.98  on 399  degrees of freedom
## Residual deviance: 458.52  on 394  degrees of freedom
## AIC: 470.5
## 
## Number of Fisher Scoring iterations: 4
</code></pre>

<ol>
<li>How well did Logistic Regression fit here?</li>
<li>What exactly are the Deviance Residuals? I believe they are the average residuals per quartile. How do I determine if they are bad/good/statistically significant?</li>
<li>What exactly is the <code>z-value</code> here? Is it the normalized standard deviation from the mean of the Estimate assuming a mean of 0? </li>
<li>What exactly are Signif. codes?</li>
</ol>

<p>Any help is greatly appreciated! You do not have to answer them all!</p>
"
"0.161796200422643","0.162221421130763","102695","<p>I'm using R to run some logistic regression. My variables were continuous, but I used cut to bucket the data. Some particular buckets for these variables always result in dependent variable being equal to 1. As expcted, the coefficient estimate for this bucket is very high, but the p-value is also high. There are about ~90 observations in either these buckets, and around 800 total observations, so I don't think it's a problem of sample size. Also, this variable should not be related to other variables, which would naturally reduce their p-values.</p>

<p>Are there any other plausible explanations for the high p-value?</p>

<p>Example:</p>

<pre><code>myData &lt;- read.csv(""application.csv"", header = TRUE)
myData$FICO &lt;- cut(myData$FICO, c(0, 660, 680, 700, 720, 740, 780, Inf), right = FALSE)
myData$CLTV &lt;- cut(myData$CLTV, c(0, 70, 80, 90, 95, 100, 125, Inf), right = FALSE)
fit &lt;- glm(Denied ~ CLTV + FICO, data = myData, family=binomial())
</code></pre>

<p>Results are something like this:</p>

<pre><code>Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.53831  -0.77944  -0.62487   0.00027   2.09771  

Coefficients:
                Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)     -1.33630    0.23250  -5.747 9.06e-09 ***
CLTV(70,80]     -0.54961    0.34864  -1.576 0.114930    
CLTV(80,90]     -0.51413    0.31230  -1.646 0.099715 .  
CLTV(90,95]     -0.74648    0.37221  -2.006 0.044904 *  
CLTV(95,100]     0.38370    0.37709   1.018 0.308906    
CLTV(100,125]   -0.01554    0.25187  -0.062 0.950792    
CLTV(125,Inf]   18.49557  443.55550   0.042 0.966739    
FICO[0,660)     19.64884 3956.18034   0.005 0.996037    
FICO[660,680)    1.77008    0.47653   3.715 0.000204 ***
FICO[680,700)    0.98575    0.30859   3.194 0.001402 ** 
FICO[700,720)    1.31767    0.27166   4.850 1.23e-06 ***
FICO[720,740)    0.62720    0.29819   2.103 0.035434 *  
FICO[740,780)    0.31605    0.23369   1.352 0.176236    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1037.43  on 810  degrees of freedom
Residual deviance:  803.88  on 798  degrees of freedom
AIC: 829.88

Number of Fisher Scoring iterations: 16
</code></pre>

<p>FICO in the range [0, 660) and CLTV in the range (125, Inf] indeed always results in Denial = 1, so their coefficients are very large, but why are they also ""insignificant""?</p>
"
"0.323959910788652","0.34027852368936","112241","<p><strong>Summary:</strong> Is there any statistical theory to support the use of the $t$-distribution (with degrees of freedom based on the residual deviance) for tests of logistic regression coefficients, rather than the standard normal distribution?</p>

<hr>

<p>Some time ago I discovered that when fitting a logistic regression model in SAS PROC GLIMMIX, under the default settings, the logistic regression coefficients are tested using a $t$ distribution rather than the standard normal distribution.$^1$ That is, GLIMMIX reports a column with the ratio $\hat{\beta}_1/\sqrt{\text{var}(\hat{\beta}_1)}$ (which I will call $z$ in the rest of this question), but also reports a ""degrees of freedom"" column, as well as a $p$-value based on assuming a $t$ distribution for $z$ with degrees of freedom based on the residual deviance -- that is, degrees of freedom = total number of observations minus number of parameters. At the bottom of this question I provide some code and output in R and SAS for demonstration and comparison.$^2$</p>

<p>This confused me, since I thought that for generalized linear models such as logistic regression, there was no statistical theory to support the use of the $t$-distribution in this case. Instead I thought what we knew about this case was that</p>

<ul>
<li>$z$ is ""approximately"" normally distributed;</li>
<li>this approximation might be poor for small sample sizes;</li>
<li>nevertheless it <em>cannot</em> be assumed that $z$ has a $t$ distribution like we can assume in the case of normal regression.</li>
</ul>

<p>Now, on an intuitive level, it does seem reasonable to me that if $z$ is approximately normally distributed, it might in fact have some distribution that is basically ""$t$-like"", even if it is not exactly $t$. So the use of the $t$ distribution here does not seem crazy. But what I want to know is the following:</p>

<ol>
<li>Is there in fact statistical theory showing that $z$ really does follow a $t$ distribution in the case of logistic regression and/or other generalized linear models?</li>
<li>If there is no such theory, are there at least papers out there showing that assuming a $t$ distribution in this way works as well as, or maybe even better than, assuming a normal distribution?</li>
</ol>

<p>More generally, is there any actual support for what GLIMMIX is doing here other than the intuition that it is probably basically sensible?</p>

<p>R code:</p>

<pre><code>summary(glm(y ~ x, data=dat, family=binomial))
</code></pre>

<p>R output:</p>

<pre><code>Call:
glm(formula = y ~ x, family = binomial, data = dat)

Deviance Residuals: 
   Min      1Q  Median      3Q     Max  
-1.352  -1.243   1.025   1.068   1.156  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  0.22800    0.06725   3.390 0.000698 ***
x           -0.17966    0.10841  -1.657 0.097462 .  
---
  Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1235.6  on 899  degrees of freedom
Residual deviance: 1232.9  on 898  degrees of freedom
AIC: 1236.9

Number of Fisher Scoring iterations: 4
</code></pre>

<p>SAS code:</p>

<pre><code>proc glimmix data=logitDat;
    model y(event='1') = x / dist=binomial solution;
run;
</code></pre>

<p>SAS output (edited/abbreviated):</p>

<pre><code>The GLIMMIX Procedure

               Fit Statistics

-2 Log Likelihood            1232.87
AIC  (smaller is better)     1236.87
AICC (smaller is better)     1236.88
BIC  (smaller is better)     1246.47
CAIC (smaller is better)     1248.47
HQIC (smaller is better)     1240.54
Pearson Chi-Square            900.08
Pearson Chi-Square / DF         1.00


                       Parameter Estimates

                         Standard
Effect       Estimate       Error       DF    t Value    Pr &gt; |t|

Intercept      0.2280     0.06725      898       3.39      0.0007
x             -0.1797      0.1084      898      -1.66      0.0978
</code></pre>

<p>$^1$Actually I first noticed this about <em>mixed-effects</em> logistic regression models in PROC GLIMMIX, and later discovered that GLIMMIX also does this with ""vanilla"" logistic regression.</p>

<p>$^2$I do understand that in the example shown below, with 900 observations, the distinction here probably makes no practical difference. That is not really my point. This is just data that I quickly made up and chose 900 because it is a handsome number. However I do wonder a little about the practical differences with small sample sizes, e.g. $n$ &lt; 30.</p>
"
"0.239982547358447","0.240613251592894","115188","<p>I am trying to look at whether 2 variables (one dichotomous categorical and one continuous) predict the occurrence of a dichotomous categorical dependent variable.</p>

<pre><code>dependent variable is LENIpos - 0 = no event, 1 = event
predictor variables are Hip.Prox.Femur - 0 = no hip fracture, 1 = hip fracture
                and     age (continuous)
</code></pre>

<p>Both predictor variables have significant p values in separate chi square test and Mann Whitney U test respectively.</p>

<p>When I run a logistic regression <code>glm(LENIpos ~ age + Hip.Prox.Femur, family = ""binomial)</code>, the variables come out as not significant. (1)</p>

<p>However, when I run the logistic regression with interactions <code>glm(LENIpos ~ age * Hip.Prox.Femur...)</code> (2), they are no both significant.  How is this to be interpreted?</p>

<p>Example R outputs:</p>

<p>(1)</p>

<pre><code>Call: glm(formula = LENIpos ~ age + Hip.Prox.Fem, family = ""binomial"", 
    data = dvt)

Deviance Residuals: 
     Min       1Q   Median       3Q      Max  
 -0.9346  -0.7826  -0.4952  -0.3374   2.1897  

Coefficients:
                         Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept)              -3.46888    1.00693  -3.445 0.000571 ***
age                       0.02122    0.01519   1.397 0.162535  
Hip.Prox.Femhip fracture  0.72410    0.57790   1.253 0.210212    

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 145.23  on 151  degrees of freedom
Residual deviance: 135.48  on 149  degrees of freedom
AIC: 141.48

Number of Fisher Scoring iterations: 5
</code></pre>

<p>(2)</p>

<pre><code>glm(formula = LENIpos ~ age * Hip.Prox.Fem, family = ""binomial"", 
    data = dvt)

Deviance Residuals: 
        Min       1Q   Median       3Q      Max  
    -1.0364  -0.7815  -0.5373  -0.1761   2.3443  

Coefficients:
                             Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                  -5.89984    1.98289  -2.975  0.00293 **
age                           0.05851    0.02818   2.076  0.03788 * 
Hip.Prox.Femhip fracture      5.04990    2.46269   2.051  0.04031 * 
age:Hip.Prox.Femhip fracture -0.06058    0.03339  -1.814  0.06965 . 


(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 145.23  on 151  degrees of freedom
Residual deviance: 131.82  on 148  degrees of freedom
AIC: 139.82

Number of Fisher Scoring iterations: 6
</code></pre>
"
"0.218165952144043","0.240613251592894","115356","<p>I'm a beginner in statistics and I have to run multilevel logistic regressions. I am confused with the results as they differ from logistic regression with just one level. </p>

<p>I don't know how to interpret the variance and correlation of the random variables. And I wonder how to compute the ICC.</p>

<p>For example : I have a dependent variable about the protection friendship ties give to individuals (1 is for individuals who can rely a lot on their friends, 0 is for the others). There are 50 geographic clusters of respondant and one random variable which is a factor about the social situation of the neighborhood. Upper/middle class is the reference, the other modalities are working class and underprivileged neighborhoods. </p>

<p>I get these results :</p>

<pre><code>&gt; summary(RLM3)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: Arp ~ Densite2 + Sexe + Age + Etudes + pcs1 + Enfants + Origine3 +      Sante + Religion + LPO + Sexe * Enfants + Rev + (1 + Strate |  
    Quartier)
   Data: LPE
Weights: PONDERATION
Control: glmerControl(optimizer = ""bobyqa"")

     AIC      BIC   logLik deviance df.resid 
  3389.9   3538.3  -1669.9   3339.9     2778 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.2216 -0.7573 -0.3601  0.8794  2.7833 

Random effects:
 Groups   Name           Variance Std.Dev. Corr       
 Neighb. (Intercept)     0.2021   0.4495              
          Working Cl.    0.2021   0.4495   -1.00      
          Underpriv.     0.2021   0.4495   -1.00  1.00
Number of obs: 2803, groups:  Neigh., 50

Fixed effects:
</code></pre>

<p>The differences with the ""call"" part is due to the fact I translated some words.</p>

<p>I think I understand the relation between the random intercept and the random slope for linear regressions but it is more difficult for logistics ones. I guess that when the correlation is positive, I can conclude that the type of neighborhood (social context) has a positive impact on the protectiveness of friendship ties, and conversely. But how do I quantify that ?</p>

<p>Moreover, I find it odd to get correlation of 1 or -1 and nothing more intermediate.</p>

<p>As for the ICC I am puzzled because I have seen a post about lmer regression that indicates that intraclass correlation can be computed by dividing the variance of the random intercept by the variance of the random intercept, plus the variance the random variables, plus the residuals. </p>

<p>But there are no residuals in the results of a glmer. I have read in a book that ICC must be computed by dividing the random intercept variance by the random intercept variance plus 2.36 (piÂ²/3). But in another book, 2.36 was replaced by the inter-group variance (the first level variance I guess). 
What is the good solution ?</p>

<p>I hope these questions are not too confused.
Thank you for your attention !</p>
"
"0.129436960338115","0.12977713690461","116347","<p>I am trying to generate a data frame of fake data for exploratory purposes. Specifically, I am trying to produce data with a binary dependent variable (say, failure/success), and a categorical independent variable called 'picture' with 5 levels (pict1, pict2, etc.). I am following the answer provided <a href=""http://stats.stackexchange.com/questions/49916/simulating-data-for-logistic-regression-with-a-categorical-variable"">here</a>, which allows me to successfully generate the data. However, I need each level of 'picture' to occur the same number of times (i.e. 11 repetitions of each level = 55 total observations per subject). </p>

<p>Here is a reproducible example of what has worked so far (code from user: ocram):</p>

<pre><code>library(dummies)

#------ parameters ------
n &lt;- 1000 
beta0 &lt;- 0.07
betaB &lt;- 0.1
betaC &lt;- -0.15
betaD &lt;- -0.03
betaE &lt;- 0.9
#------------------------

#------ initialisation ------
beta0Hat &lt;- rep(NA, 1000)
betaBHat &lt;- rep(NA, 1000)
betaCHat &lt;- rep(NA, 1000)
betaDHat &lt;- rep(NA, 1000)
betaEHat &lt;- rep(NA, 1000)
#----------------------------

#------ simulations ------
for(i in 1:1000)
{
  #data generation
  x &lt;- sample(x=c(""pict1"",""pict2"", ""pict3"", ""pict4"", ""pict5""), 
              size=n, replace=TRUE, prob=rep(1/5, 5))  #(a)
  linpred &lt;- cbind(1, dummy(x)[, -1]) %*% c(beta0, betaB, betaC, betaD, betaE)  #(b)
  pi &lt;- exp(linpred) / (1 + exp(linpred))  #(c)
  y &lt;- rbinom(n=n, size=1, prob=pi)  #(d)
  data &lt;- data.frame(picture=x, choice=y)

  #fit the logistic model
  mod &lt;- glm(choice ~ picture, family=""binomial"", data=data)

  #save the estimates
  beta0Hat[i] &lt;- mod$coef[1]
      betaBHat[i] &lt;- mod$coef[2]
  betaCHat[i] &lt;- mod$coef[3]
      betaDHat[i] &lt;- mod$coef[4]
  betaEHat[i] &lt;- mod$coef[5]
}
</code></pre>

<p>However, as you can see from the output, each level of the factor 'picture' does not occur the same number of times (i.e. 200 times each). </p>

<pre><code>&gt; summary(data)
picture     choice     
pict1:200   Min.   :0.000  
pict2:207   1st Qu.:0.000  
pict3:217   Median :1.000  
pict4:163   Mean   :0.559  
pict5:213   3rd Qu.:1.000  
            Max.   :1.000 
</code></pre>

<p>Moreover, it is not entirely clear to me how to manipulate the initial beta values as to determine the probability of success/failure for each level of 'picture'. I cannot comment the original question because I do not yet have the necessary reputation points. </p>
"
"0.153493353028995","0.153896752812773","117450","<p>I have a confusing situation where I have strongly conflicting results from two ways of analyzing my simple data. I measure two binary variables from each participant, AestheticOnly and ChoiceVA. I want to know if AestheticOnly depends on ChoiceVA and whether this relation is different in two different experiments. Here is my participant count data:</p>

<pre><code>Experiment 1
                 AestheticOnly
                 0   1  All
ChoiceVA A      35   6   41
         V      20  13   33
         All    55  19   74

Experiment 2
                 AestheticOnly
                 0   1  All
ChoiceVA A      12  10   22
         V      31  11   42
         All    43  21   64
</code></pre>

<p>I run a logistic regression where AestheticOnly is modelled by ChoiceVA, Experiment, and the interaction:</p>

<pre><code>&gt; mod &lt;- glm( AestheticOnly ~ ChoiceVA*Experiment, data = d, family=binomial)
&gt; summary(mod)

Call:
glm(formula = AestheticOnly ~ ChoiceVA * Experiment, family = binomial, 
    data = d)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.1010  -0.7793  -0.5625   1.2557   1.9605  

Coefficients:
                     Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)           -3.3449     0.9820  -3.406 0.000659 ***
ChoiceVAV              3.5194     1.2630   2.787 0.005327 ** 
Experiment             1.5813     0.6153   2.570 0.010170 *  
ChoiceVAV:Experiment  -2.1866     0.7929  -2.758 0.005820 ** 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 166.16  on 137  degrees of freedom
Residual deviance: 157.01  on 134  degrees of freedom
AIC: 165.01

Number of Fisher Scoring iterations: 4
</code></pre>

<p>Apparently all factors are significant. But, this just doesn't make sense to me. For example, looking at the main effect of experiment should be equivalent to performing a Fisher's Exact test comparing 55 and 19 with 43 and 21 (bottom lines of each table). This is obviously not significant (p=.452). So why does the regression model give such a different result? Any help much appreciated.</p>
"
"0.220751836546614","0.221332000061022","117631","<p>I measure two binary responses from each participant (ChoiceVA = V or A, AestheticOnly = 0 or 1). There are two experiments (between-participant). I want to test the following hypotheses:</p>

<p>AestheticOnly depends on Experiment (main effect)
AestheticOnly depends on ChoiceVA (main effect)
The way AestheticOnly depends on Experiment depends on ChoiceVA (interaction)</p>

<p>Here is my data. The first number in each cell is the proportion of participants scoring 1 for AestheticOnly, and the second number is the n for participants in that cell.</p>

<pre><code>                         ChoiceVA               
                        A       V     All

Experiment  1      0.1463  0.3939  0.2568
                       41      33      74

            2      0.4545  0.2619  0.3281
                       22      42      64

            All    0.2540  0.3200  0.2899
                       63      75     138
</code></pre>

<p>Just from looking at the data it is pretty obvious that neither main effect is significant (e.g. for ChoiceVA, bottom row, .25 of 63 participants is not significantly different from .32 of 75 participants). In my naivity I thought perhaps I could test these hypotheses with a straightforward binary logistic regression:</p>

<pre><code>&gt; mod &lt;- glm( AestheticOnly ~ Experiment+ChoiceVA+Experiment*ChoiceVA, data = d, family=binomial )
&gt; summary(mod)

Call:
glm(formula = AestheticOnly ~ Experiment + ChoiceVA + Experiment *
    ChoiceVA, family = binomial, data = d)

Deviance Residuals:
    Min       1Q   Median       3Q      Max 
-1.1010  -0.7793  -0.5625   1.2557   1.9605 

Coefficients:
                      Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept)            -1.7636     0.4419  -3.991 6.57e-05 ***
Experiment2             1.5813     0.6153   2.570  0.01017 * 
ChoiceVAV               1.3328     0.5676   2.348  0.01887 * 
Experiment2:ChoiceVAV  -2.1866     0.7929  -2.758  0.00582 **
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 166.16  on 137  degrees of freedom
Residual deviance: 157.01  on 134  degrees of freedom
AIC: 165.01

Number of Fisher Scoring iterations: 4
</code></pre>

<p>Clearly, the main effects are not being tested here in the way I hoped. I believe that this model, in testing main effects, rather than testing e.g. ChoiceVA=A against ChoiceVA=V across both levels of Experiment, is confining itself to that comparison only when Experiment=1. Can a model be constructed that instead tests the main effects in the way I would like?</p>

<p>This is related to a previous question (<a href=""http://stats.stackexchange.com/questions/117450/logistic-regression-gives-very-different-result-to-fishers-exact-test-why"">Logistic regression gives very different result to Fisher&#39;s exact test - why?</a>), but when I asked it I understand this even worse than I do now and consequently the question was so unclear that I need to start again.</p>
"
"0.229765796229396","0.251312344975017","122212","<p>I have been developing a logistic regression model based on retrospective data from a national trauma database of head injury in the UK. The key outcome is 30 day mortality (denoted as ""Survive"" measure). Other measures with published evidence of significant effect on outcome in previous studies include:</p>

<pre><code>Year - Year of procedure = 1994-2013
Age - Age of patient = 16.0-101.5
ISS - Injury Severity Score = 0-75
Sex - Gender of patient = Male or Female
inctoCran - Time from head injury to craniotomy in minutes = 0-2880 (After 2880 minutes is defined as a separate diagnosis)
</code></pre>

<p>Using these models, given the dichotomous dependent variable, I have built a logistic regression using lrm.</p>

<p>The method of model variable selection was based on existing clinical literature modelling the same diagnosis. All have been modelled with a linear fit with the exception of ISS which has been modelled traditionally through fractional polynomials. No publication has identified known significant interactions between the above variables.</p>

<p>Following advice from Frank Harrell, I have proceeded with the use of regression splines to model ISS (there are advantages to this approach highlighted in the comments below). The model was thus pre-specified as follows:</p>

<pre><code>rcs.ASDH&lt;-lrm(formula = Survive ~ Age + GCS + rcs(ISS) +
    Year + inctoCran + oth, data = ASDH_Paper1.1, x=TRUE, y=TRUE)
</code></pre>

<p>Results of the model were:</p>

<pre><code>&gt; rcs.ASDH

Logistic Regression Model

lrm(formula = Survive ~ Age + GCS + rcs(ISS) + Year + inctoCran + 
    oth, data = ASDH_Paper1.1, x = TRUE, y = TRUE)

                      Model Likelihood     Discrimination    Rank Discrim.    
                         Ratio Test            Indexes          Indexes       
Obs          2135    LR chi2     342.48    R2       0.211    C       0.743    
 0            629    d.f.             8    g        1.195    Dxy     0.486    
 1           1506    Pr(&gt; chi2) &lt;0.0001    gr       3.303    gamma   0.487    
max |deriv| 5e-05                          gp       0.202    tau-a   0.202    
                                           Brier    0.176                     

          Coef     S.E.    Wald Z Pr(&gt;|Z|)
Intercept -62.1040 18.8611 -3.29  0.0010  
Age        -0.0266  0.0030 -8.83  &lt;0.0001 
GCS         0.1423  0.0135 10.56  &lt;0.0001 
ISS        -0.2125  0.0393 -5.40  &lt;0.0001 
ISS'        0.3706  0.1948  1.90  0.0572  
ISS''      -0.9544  0.7409 -1.29  0.1976  
Year        0.0339  0.0094  3.60  0.0003  
inctoCran   0.0003  0.0001  2.78  0.0054  
oth=1       0.3577  0.2009  1.78  0.0750  
</code></pre>

<p>I then used the calibrate function in the rms package in order to assess accuracy of the predictions from the model. The following results were obtained:</p>

<pre><code>plot(calibrate(rcs.ASDH, B=1000), main=""rcs.ASDH"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/HYTsp.png"" alt=""Bootstrap calibration curves penalized for overfitting""></p>

<p>Following completion of the model design, I created the following graph to demonstrate the effect of the Year of incident on survival, basing values of the median in continuous variables and the mode in categorical variables:</p>

<pre><code>ASDH &lt;- Predict(rcs.ASDH, Year=seq(1994,2013,by=1),Age=48.7,ISS=25,inctoCran=356,Other=0,GCS=8,Sex=""Male"",neuroYN=1,neuroFirst=1)
Probabilities &lt;- data.frame(cbind(ASDH$yhat,exp(ASDH$yhat)/(1+exp(ASDH$yhat)),exp(ASDH$lower)/(1+exp(ASDH$lower)),exp(ASDH$upper)/(1+exp(ASDH$upper))))
names(Probabilities) &lt;- c(""yhat"",""p.yhat"",""p.lower"",""p.upper"")
ASDH&lt;-merge(ASDH,Probabilities,by=""yhat"")
plot(ASDH$Year,ASDH$p.yhat,xlab=""Year"",ylab=""Probability of Survival"",main=""30 Day Outcome Following Craniotomy for Acute SDH by Year"", ylim=range(c(ASDH$p.lower,ASDH$p.upper)),pch=19)
arrows(ASDH$Year,ASDH$p.lower,ASDH$Year,ASDH$p.upper,length=0.05,angle=90,code=3)
</code></pre>

<p>The code above resulted in the following output:</p>

<p><img src=""http://i.stack.imgur.com/KGYcz.png"" alt=""Year trend with lower and upper""></p>

<p><strong><em>My remaining questions are the following:</em></strong></p>

<p><strong>1. Spline Interpretation</strong> - How can I calculate the p-value for the splines combined for the overall variable?</p>
"
"0.192953228077979","0.19346033336267","123210","<p>I am doing a logistic regression in R, where I am modeling how potholes and weather correlate to accidents. When I run a logistic regression, I get the message ""Algorithm does not converge""</p>

<p>The problem I think I have is that I have 24,000 accidents with only 350 potholes related to these accidents. Is this to small of a sample size?</p>

<p>The other possible issue I thought of, is that when I look at sample logistic regressions, the outcome is either zero or one, but the only outcome I have is the outcome of one, or accident in my case. I do not have any non accident data in my set, could this be what is causing the problem? </p>

<p>I will attach my current code and its output.</p>

<pre><code>require(ggplot2)
require(sandwich)
require(msm)
mydata &lt;- read.csv(""C:\\Users\\myname\\downloads\\logreg1.csv"")
## view the first few rows of the data
head(mydata)
summary(mydata)
mylogit &lt;- glm(Accident ~  Rain + Snow, data = mydata, family = ""binomial"")

&gt; head(mydata)
      Date Pothole Rain Snow Accident
1 1/1/2012       0    0    0        1
2 1/1/2012       0    0    0        1
3 1/1/2012       0    0    0        1
4 1/1/2012       0    0    0        1
5 1/1/2012       0    0    0        1
6 1/1/2012       0    0    0        1
&gt; summary(mydata)
         Date          Pothole            Rain              Snow            Accident
 1/8/2014  :   87   Min.   :0.0000   Min.   :0.00000   Min.   : 0.0000   Min.   :1  
 1/30/2013 :   82   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.: 0.0000   1st Qu.:1  
 3/21/2013 :   77   Median :0.0000   Median :0.00000   Median : 0.0000   Median :1  
 12/21/2012:   76   Mean   :0.0173   Mean   :0.08077   Mean   : 0.1129   Mean   :1  
 3/10/2013 :   66   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.: 0.0000   3rd Qu.:1  
 12/13/2013:   59   Max.   :8.0000   Max.   :3.32000   Max.   :11.1000   Max.   :1  
 (Other)   :23606                                                                   
&gt; mylogit &lt;- glm(Accident ~  Rain + Snow, data = mydata, family = ""binomial"")
Warning message:
glm.fit: algorithm did not converge
</code></pre>
"
"0.191439846060547","0.191942973987479","124616","<p>I am testing the logistic regression classifier in R. I created some test data like this:</p>

<pre><code>x=runif(10000)
y=runif(10000)
df=data.frame(x,y,as.factor(x-y&gt;0))
</code></pre>

<p>basically I am sampling the 2D unit square [0,1] and classifying a point belonging to class A or B depending on which side of y=x it lies.</p>

<p>I generated a scatter plot of the data like below:</p>

<pre><code>names(df) = c(""feature1"", ""feature2"", ""class"")
levels=levels(df[[3]])
obs1=as.matrix(subset(df,class==levels[[1]])[,1:2])
obs2=as.matrix(subset(df,class==levels[[2]])[,1:2])
# make scatter plot
dev.new()
plot(obs1[,1],obs1[,2],xlab=""x"",ylab=""y"",main=""scatter plot"",pch=0,col=colors[[1]])
points(obs2[,1],obs2[,2],xlab=""x"",ylab=""y"",main=""scatter plot"",pch=1,col=colors[[2]])
</code></pre>

<p>it gives me below graph:</p>

<p><img src=""http://i.stack.imgur.com/5zN4y.png"" alt=""scatter plot""></p>

<p>Now I tried running LR (logistic regression) on this data using code below:</p>

<pre><code>model=glm(class~.,family=""binomial"",data=df)
summary(model) # prints summary
</code></pre>

<p>here are the results:</p>

<pre><code>Call:
glm(formula = class ~ ., family = ""binomial"", data = df)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-0.11832   0.00000   0.00000   0.00000   0.08847  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)  5.765e-01  1.923e+01   0.030    0.976
feature1     9.761e+04  8.981e+04   1.087    0.277
feature2    -9.761e+04  8.981e+04  -1.087    0.277

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1.3863e+04  on 9999  degrees of freedom
Residual deviance: 2.9418e-02  on 9997  degrees of freedom
AIC: 6.0294

Number of Fisher Scoring iterations: 25
</code></pre>

<p>I also get these warning messages:</p>

<pre><code>Warning messages:
1: glm.fit: algorithm did not converge 
2: glm.fit: fitted probabilities numerically 0 or 1 occurred 
</code></pre>

<p>If I try plotting the ROC curve using a varying threshold, I get following graph (AUC=1 which is good):
<img src=""http://i.stack.imgur.com/xbyPX.png"" alt=""enter image description here""></p>

<p><strong>Could someone please explain why the algorithm does not converge and coefficient estimates are not statistically significant (high std. error in coeff estimates)?</strong></p>

<p>I also compared to LDA:</p>

<pre><code>lda_classifier=lda(class~., data=df)
</code></pre>

<p>gives:</p>

<pre><code>Call:
lda(class ~ ., data = df)

Prior probabilities of groups:
 FALSE   TRUE 
0.5007 0.4993 

Group means:
       feature1  feature2
FALSE 0.3346288 0.6676169
TRUE  0.6710111 0.3380432

Coefficients of linear discriminants:
               LD1
**feature1  4.280490
feature2 -4.196388**
</code></pre>
"
"0.217072381587726","0.217642875033004","125130","<p>I realize that a similar question to this has been asked, but it was not ultimately resolved. I have tried the suggestions posted to that question <a href=""https://stackoverflow.com/questions/23347467/is-there-any-way-to-fit-a-glm-so-that-all-levels-are-included-i-e-no-refer"">here</a>, but have had no success. I am using the following code:       </p>

<pre><code>allinfa4.exp = glm(survive ~ year + julianvisit + class + sitedist + roaddist
+ ngwdist, family = binomial(logexp(alldata$expos)), data=alldata)
summary(allinfa4.exp)

 Call:
glm(formula = survive ~ year + julianvisit + class + sitedist + 
roaddist + ngwdist, family = binomial(logexp(alldata$expos)), 
data = alldata)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-2.6435   0.3477   0.4164   0.4960   0.9488  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  4.458e+00  7.117e-01   6.265 3.74e-10 ***
year2013     3.680e-01  1.862e-01   1.976  0.04819 *  
year2014     2.136e-02  1.802e-01   0.119  0.90564    
julianvisit -5.714e-03  3.890e-03  -1.469  0.14192    
classb       2.863e-02  2.194e-01   0.131  0.89615    
classc      -2.394e-01  2.277e-01  -1.051  0.29304    
classd      -1.868e-01  2.479e-01  -0.754  0.45109    
classe      -4.500e-01  2.076e-01  -2.167  0.03021 *  
classf      -5.728e-01  2.005e-01  -2.858  0.00427 ** 
classg      -8.495e-01  3.554e-01  -2.390  0.01684 *  
classh      -1.858e-01  2.224e-01  -0.835  0.40351    
classi      -3.196e-01  4.417e-01  -0.724  0.46932    
sitedist    -2.607e-04  5.043e-04  -0.517  0.60520    
roaddist     6.768e-05  4.311e-04   0.157  0.87525    
ngwdist     -5.751e-05  9.456e-05  -0.608  0.54306
</code></pre>

<p>The main thing to note here is that I have two categorical variables, <code>year</code> and <code>class</code>, and R has combined the first level of each (2012 and class a) into a reference level intercept term. Not only do I need to know the intercept term for these levels individually, but I also need to know the base intercept terms itself (beta0), just as SAS produces. </p>

<p>I have tried changing the contrasts and deviation coding to accomplish this, but although doing so allows me to extract different levels, it changes the way they are calculated and still does not produce beta0. I've also tried adding +0 and -1, but this also does not provide what I need. Is what I'm trying to do simply impossible in R? It may seem like a strange request, but beta0 is necessary to convert the results of logistic exposure (special kind of logistic regression for nest-survival data) to daily survival rates. Any help would be hugely appreciated. Thanks!</p>

<p>Here is an example of SAS output I want to emulate (taken from a similar analysis done by my lab mate) :</p>

<pre><code>Parameter Estimates
Parameter   Estimate    Standard Error  DF  t Value Pr &gt; |t|              
beta0       7.8404      2.8479          19  2.75    0.0127  
NT         -3.8786      1.8831          19  -2.06   0.0534  
bgdensity  -0.1127      0.1614          19  -0.70   0.4935  
nwh         1.3466      1.4625          19  0.92    0.3687      
NRD        -2.6981      1.9496          19  -1.38   0.1824      
NAGW       -0.4898      2.2518          19  -0.22   0.8301      
</code></pre>
"
"0.125326797943307","0.125656172487509","125603","<p>I am new to the world of <strong>Regression</strong> in statistics and I have been doing a research in which I am building an ordinal logistic regression model (ORM). In order to fit my ORM model, I am using the 'orm' function of 'rms' package from R (<a href=""http://cran.r-project.org/web/packages/rms/rms.pdf"" rel=""nofollow"">http://cran.r-project.org/web/packages/rms/rms.pdf</a>).</p>

<p>Now I am trying to assess the goodness of fit of my model. By reading the R documentation, I can see the following statement in the 'stat' property of the 'orm' object (pg.98):</p>

<p>""(...)Nagelkerke R2 index, the g-index, gr (the g-index on the odds ratio scale),
and <strong>pdm (the mean absolute difference between 0.5 and the predicted probability
that $Y\geq q$  the marginal median)</strong>(...).""</p>

<p>I don't have enough background to understand the short description of the pdm measure. But when I try to do more research on this measure, I am not able to find related material (e.g. I've been finding ""prescription drug misuse""). In summary, my question is:</p>

<p>Would you know if the 'pdm' measure has some synonym which is more widely used? Or can you provide some references where I can study the pdm metric?</p>
"
"0.396318133356556","0.397359707119513","127479","<p>I'm using a mixed effects model with logistic link function (using lme4 version 1.1-7 in R).  However, I noticed that the estimates of significance for fixed effects change depending on the order of the rows in the dataset.  </p>

<p>That is, if I run a model on a dataset, I get certain estimate for my fixed effect and it has a certain p-value.  I run the model again, and I get the same estimate and p-value.  Now, I shuffle the order of rows (the data is not mixed, just the rows are in a different order).  Running the model a third time, the p-value is very different.</p>

<p>For the data I have, the estimated p-value for the fixed effect can be between p=0.001 and p=0.08.  Obviously, these are crucial differences given conventional significance levels. </p>

<p>I understand that the estimates are just estimated, and there will be differences between values for a number of reasons.  However, the magnitude of the differences for my data seem large to me, and I wouldn't expect the order of my dataframe to have this effect (we discovered this problem by chance when a colleague ran the same model but got different results.  It turned out they had ordered their data frame.).  </p>

<p>Here is the output of my script:
(X and Y are binary variables which are contrast-coded and centred, Group and SubGroup are categorical variables)</p>

<pre><code>&gt; # Fit model
&gt; m1 = glmer(X ~Y+(1+Y|Group)+(1+Y|SubGroup),family=binomial(link='logit'),data=d)
&gt; # Shuffle order of rows
&gt; d = d[sample(1:nrow(d)),]
&gt; # Fit model again
&gt; m2 = glmer(X ~Y+(1+Y|Group)+(1+Y|SubGroup),family=binomial(link='logit'),data=d)
&gt; summary(m1)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) 
      ['glmerMod']
 Family: binomial  ( logit )
Formula: X ~ Y + (1 + Y | Group) + (1 + Y | SubGroup)
   Data: d

      AIC       BIC    logLik  deviance  df.resid 
 200692.0  200773.2 -100338.0  200676.0    189910 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.1368 -0.5852 -0.4873 -0.1599  6.2540 

Random effects:
 Groups       Name        Variance Std.Dev. Corr 
 SubGroup     (Intercept) 0.2939   0.5421        
              Y1          0.1847   0.4298   -0.79
 Group        (Intercept) 0.2829   0.5319        
              Y1          0.4640   0.6812   -0.07
Number of obs: 189918, groups:  SubGroup, 15; Group, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.0886     0.1325  -8.214   &lt;2e-16 ***
Y1            0.3772     0.2123   1.777   0.0756 .  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
     (Intr)
Y1 0.112 
&gt;
&gt; # -----------------
&gt; summary(m2)
Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) 
      ['glmerMod']
 Family: binomial  ( logit )
Formula: X ~ Y + (1 + Y | Group) + (1 + Y | SubGroup)
   Data: d

      AIC       BIC    logLik  deviance  df.resid 
 200692.0  200773.2 -100338.0  200676.0    189910 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-1.1368 -0.5852 -0.4873 -0.1599  6.2540 

Random effects:
 Groups       Name        Variance Std.Dev. Corr 
 SubGroup     (Intercept) 0.2939   0.5422        
              Y1          0.1846   0.4296   -0.79
 Group        (Intercept) 0.2829   0.5318        
              Y1          0.4641   0.6813   -0.07
Number of obs: 189918, groups:  SubGroup, 15; Group, 12

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  -1.0886     0.1166  -9.334  &lt; 2e-16 ***
Y1            0.3773     0.1130   3.339 0.000841 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
     (Intr)
Y1 0.074 
</code></pre>

<p>I'm afraid that I can't attach the data due to privacy reasons. </p>

<p>Both models converge.  The difference appears to be in the standard errors, while the differences in coefficient estimates are smaller.  The model fit (AIC etc.) are the same, so maybe there are multiple optimal convergences, and the order of the data pushes the optimiser into different ones.  However, I get slightly different estimates every time I shuffle the data frame (not just two or three unique estimates).  In one case (not shown above), the model did not converge simply because of a shuffling of the rows.</p>

<p>I suspect that the problem lies with the structure of my particular data.  It's reasonably large (nearly 200,000 cases), and has nested random effects.  I have tried centering the data, using contrast coding and feeding starting values to lmer based on a previous fit.  This seems to help somewhat, but I still get reasonably large differences in p-values.  I also tried using different ways of calculating p-values, but I got the same problem.</p>

<p>Below, I've tried to replicate this problem with synthesised data.  The differences here aren't as big as with my real data, but it gives an idea of the problem.</p>

<pre><code>library(lme4)
set.seed(999)

# make a somewhat complex data frame
x = c(rnorm(10000),rnorm(10000,0.1))
x = sample(x)
y = jitter(x,amount=10)
a = rep(1:20,length.out=length(x))
y[a==1] = jitter(y[a==1],amount=3)
y[a==2] = jitter(x[a==2],amount=1)
y[a&gt;3 &amp; a&lt;6] = rnorm(sum(a&gt;3 &amp; a&lt;6))
# convert to binary variables
y = y &gt;0
x = x &gt;0
# make a data frame
d = data.frame(x1=x,y1=y,a1=a)

# run model 
m1 = glmer(x1~y1+(1+y1|a1),data=d,family=binomial(link='logit'))

# shuffle order of rows
d = d[sample(nrow(d)),]

# run model again
m2 = glmer(x1~y1+(1+y1|a1),data=d,family=binomial(link='logit'))

# show output
summary(m1)
summary(m2)
</code></pre>

<p>One solution to this is to run the model multiple times with different row orders, and report the range of p-values.  However, this seems inelegant and potentially quite confusing.</p>

<p>The problem does not affect model comparison estimates (using anova), since these are based on differences in model fit.  The fixed effect coefficient estimates are also reasonably robust.  Therefore, I could just report the effect size, confidence intervals and the p-value from a model comparison with a null model, rather than the p-values from within the main model.</p>

<p>Anyway, has anyone else had this problem?  Any advice on how to proceed?</p>
"
"0.10232890201933","0.102597835208515","138176","<p>I used a logistic regression on a variable indicating whether a person of an address-dataset took part in a survey (1), or not (0). I extracted the probabilities of each person to participate and calculated the inverse-probability (hence the name of the weighting method - inverse propensity score weighting). </p>

<p>What irritates me, is, that my smallest survey-weight is 1.901. I expected the smallest survey weight to at least be below ""1"". </p>

<p>I hope somebody can help me and either find out where i made a mistake, or assure me, that iÂ´m on the right track. Any help is greatly appreciated! Thank you!</p>

<hr>

<hr>

<pre><code>#Calculate logistic regression 
glm2&lt;-glm(indicator ~ var1 + varx,family=binomial,data=sampleframe)

#extract inverse probability of every case  
sampleframe$weight&lt;-glm2$fitted^-1

#combine the survey-weight to the survey-data 
surveydata&lt;-left_join(surveydata,sampleframe, by=""ID"")

#diagnostics:
#summary of the weights for the complete sampleframe    
Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
1.901   2.810   3.247   3.616   3.836  12.070

#summary of the survey-weights of the participants   
Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
1.925   2.686   3.078   3.308   3.502  12.070 

#comparison of mean-weight for participants (1) / non-participants (0)   
indicator weight.mean 
0    3.755967 
1    3.295854
</code></pre>
"
"0.251398481914768","0.271448357015318","139528","<p>When modelling continuous proportions (e.g. proportional vegetation cover at survey quadrats, or proportion of time engaged in an activity), logistic regression is considered inappropriate (e.g. <a href=""http://www.esajournals.org/doi/full/10.1890/10-0340.1"" rel=""nofollow"">Warton &amp; Hui (2011) The arcsine is asinine: the analysis of proportions in ecology</a>). Rather, OLS regression after logit-transforming the proportions, or perhaps beta regression, are more appropriate.</p>

<p>Under what conditions do the coefficient estimates of logit-linear regression and logistic regression differ when using R's <code>lm</code> and <code>glm</code>?</p>

<p>Take the following simulated dataset, where we can assume that <code>p</code> are our raw data (i.e. continuous proportions, rather than representing ${n_{successes}\over n_{trials}}$):</p>

<pre><code>set.seed(1)
x &lt;- rnorm(1000)
a &lt;- runif(1)
b &lt;- runif(1)
logit.p &lt;- a + b*x + rnorm(1000, 0, 0.2)
p &lt;- plogis(logit.p)

plot(p ~ x, ylim=c(0, 1))
</code></pre>

<p><img src=""http://i.stack.imgur.com/AzWOX.png"" alt=""enter image description here""></p>

<p>Fitting a logit-linear model, we obtain:</p>

<pre><code>summary(lm(logit.p ~ x))
## 
## Call:
## lm(formula = logit.p ~ x)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.64702 -0.13747 -0.00345  0.15077  0.73148 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.868148   0.006579   131.9   &lt;2e-16 ***
## x           0.967129   0.006360   152.1   &lt;2e-16 ***
## ---
## Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
## 
## Residual standard error: 0.208 on 998 degrees of freedom
## Multiple R-squared:  0.9586, Adjusted R-squared:  0.9586 
## F-statistic: 2.312e+04 on 1 and 998 DF,  p-value: &lt; 2.2e-16
</code></pre>

<p>Logistic regression yields:</p>

<pre><code>summary(glm(p ~ x, family=binomial))
## 
## Call:
## glm(formula = p ~ x, family = binomial)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -0.32099  -0.05475   0.00066   0.05948   0.36307  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.86242    0.07684   11.22   &lt;2e-16 ***
## x            0.96128    0.08395   11.45   &lt;2e-16 ***
## ---
## Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 176.1082  on 999  degrees of freedom
## Residual deviance:   7.9899  on 998  degrees of freedom
## AIC: 701.71
## 
## Number of Fisher Scoring iterations: 5
## 
## Warning message:
## In eval(expr, envir, enclos) : non-integer #successes in a binomial glm!
</code></pre>

<p>Will the logistic regression coefficient estimates always be unbiased with respect to the logit-linear model's estimates?</p>
"
"0.0723574605292422","0.0725476250110012","140509","<p>I used logistic regression and found that my model fits well: </p>

<pre><code>Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.6434  -1.4623   0.8704   0.9013   1.0066  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   0.41595    0.02115   19.67   &lt;2e-16 ***
init_att_cnt  0.02115    0.00146   14.48   &lt;2e-16 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
(Dispersion parameter for binomial family taken to be 1)

Null deviance: 154956  on 122239  degrees of freedom
Residual deviance: 154746  on 122238  degrees of freedom
AIC: 154750
</code></pre>

<p>The chi-squared test is hightly statisticaly significant: <code>p = 9.642755e-48</code>. I decided to check the Nagelkerke $R^2$ statistic, </p>

<pre><code>R2 &lt;- R2/(1-exp((-mylogit$null.deviance)/n))
</code></pre>

<p>but it was $R^2 = 0.001350927$. This is unbelievable, why is $R^2$ so small, if my model fits well?</p>
"
"0.191439846060547","0.191942973987479","141603","<p>So I'm playing around with logistic regression in R, using the mtcars dataset, and I decide to create a logistic regression model on the 'am' parameter (that is manual or automatic transmission for those of you familiar with the mtcars-dataset).</p>

<pre><code>Call:
glm(formula = am ~ mpg + qsec + wt, family = binomial, data = mtcars)

Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-4.484e-05  -2.100e-08  -2.100e-08   2.100e-08   5.163e-05  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)    924.89  883764.07   0.001    0.999
mpg             20.65   18004.32   0.001    0.999
qsec           -55.75   32172.52  -0.002    0.999
wt            -111.33  103183.48  -0.001    0.999

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 4.3230e+01  on 31  degrees of freedom
Residual deviance: 6.2903e-09  on 28  degrees of freedom
AIC: 8

Number of Fisher Scoring iterations: 25
</code></pre>

<p>Now, at first sight this looks like a terrible regression, right? The standard errors are HUGE, the z-values are all close to zero and the corresponding probabilities are all close to one. HOWEVER, the residual deviance is extremely small! </p>

<p>I decide to check how well the model does as a classification model by running:</p>

<pre><code>pred &lt;- predict(logit_fit, data.frame(qsec = mtcars$qsec, wt = mtcars$wt, mpg = mtcars$mpg), type = ""response"") # Make a prediction of the probabilities on our data
mtcars$pred_r &lt;- round(pred, 0) # Round probabilities to closest 0 or 1
table(mtcars$am, mtcars$pred_r) # Check if results of classification is any good.
</code></pre>

<p>Indeed, the model perfectly predicts the data:</p>

<pre><code>     0  1
  0 19  0
  1  0 13
</code></pre>

<p>Have I completely misunderstood how to interpret model data? Am I overfitting massively or what's going on here? What's going on?</p>
"
"0.261556623630041","0.280975743474508","154782","<p>I'm attempting logistic regression in R for a survey for 613 students. I'm looking to see if there is an association between my <strong>Dependent Variable</strong> (called 'BinaryShelter', coded as 0 or 1, signifying whether students took shelter during a tornado warning) and my <strong>5 independent/predictor variables</strong>. My categorical IV's have anywhere from 3 to 11 distinct levels/categories within them. The other two IV's are binary coded as 0 or 1. The first 10 surveys and R output are given below: </p>

<pre><code>    Survey  KSCat   WSCat   PlanHome    PlanWork    KLNKVulCat  BinaryShelter
    1       J       B       1           1           A           1
    2       A       B       1           0           NA          1
    3       B       B       1           1           C           1
    4       B       D       1           1           A           0
    5       B       D       1           1           A           1
    6       G       E       1           1           A           0
    7       A       A       1           1           B           1
    8       C       F       NA          1           C           0
    9       B       B       1           1           A           1
    10      C       B       0           0           NA          1



Call:
glm(formula = BinaryShelter ~ KSCat + WSCat + PlanHome + PlanWork + 
KLNKVulCat, family = binomial(""logit""), data = mydata)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-2.0583  -1.3564   0.7654   0.8475   1.6161  

Coefficients:
              Estimate   St. Error  z val   Pr(&gt;|z|)  
(Intercept)    0.98471    0.43416   2.268   0.0233 *
KSCatB        -0.63288    0.34599  -1.829   0.0674 .
KSCatC        -0.14549    0.27880  -0.522   0.6018  
KSCatD         0.59855    1.12845   0.530   0.5958  
KSCatE        15.02995 1028.08167   0.015   0.9883  
KSCatF         0.61015    0.68399   0.892   0.3724  
KSCatG        -1.60723    1.54174  -1.042   0.2972  
KSCatH        -1.57777    1.26621  -1.246   0.2127  
KSCatI        -2.06763    1.18469  -1.745   0.0809 .
KSCatJ        -0.23560    0.65723  -0.358   0.7200  
WSCatB        -0.30231    0.28752  -1.051   0.2931  
WSCatC        -0.49467    1.26400  -0.391   0.6955  
WSCatD         0.52501    0.71082   0.739   0.4601  
WSCatE        -0.32153    0.63091  -0.510   0.6103  
WSCatF        -0.51699    0.74680  -0.692   0.4888  
WSCatG        -0.64820    0.39537  -1.639   0.1011  
WSCatH        -0.05866    0.89820  -0.065   0.9479  
WSCatI       -17.07156 1455.39758  -0.012   0.9906  
WSCatJ       -16.31078  662.38939  -0.025   0.9804  
PlanHome       0.27095    0.28121   0.964   0.3353  
PlanWork       0.24983    0.24190   1.033   0.3017  
KLNKVulCatB    0.17280    0.42353   0.408   0.6833  
KLNKVulCatC   -0.12551    0.24777  -0.507   0.6125  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 534.16  on 432  degrees of freedom
Residual deviance: 502.31  on 410  degrees of freedom
  (180 observations deleted due to missingness)
AIC: 548.31

Number of Fisher Scoring iterations: 14

&gt; Anova(ShelterYorN, Test = ""LR"")
Analysis of Deviance Table (Type II tests)

Response: BinaryShelter
          LR Chisq Df Pr(&gt;Chisq)
KSCat       13.3351  9     0.1480
WSCat       14.3789  9     0.1095
PlanHome     0.9160  1     0.3385
PlanWork     1.0583  1     0.3036
KLNKVulCat   0.7145  2     0.6996
</code></pre>

<p>My questions are:</p>

<p><strong>1)</strong> Does a very large St. Deviation (like the one for KSCatE) indicate that I should not use that level of that categorical IV if I want the model to fit the data better? The ones that had such large St. Deviations were from small groups. Should I not include data from very small groups? For instance if only 2 or 3 people picked category 'E' for KSCat, should I exclude that data?</p>

<p><strong>2)</strong> When using factors for my categorical data, or when adding in more than one IV, sometimes my beta coefficients flip signs. Does this mean I should test for interaction and then try to conduct some form of a PCA or jump straight to doing a PCA?</p>

<p>These next questions may be better asked on stack overflow, but I figured I'd give it a shot here:</p>

<p><strong>3)</strong> I do not want a particular level of the categorical variables to be the reference level. I know that R automatically picks the reference level (A if letters, and the first one if numbers). As in the answer to this question (<a href=""http://stats.stackexchange.com/questions/60817/significance-of-categorical-predictor-in-logistic-regression"">Significance of categorical predictor in logistic regression</a>), I tried fitting the model without an intercept by adding - 1 to the formula to see all coefficients directly. But when I do this, the results only show the 'A' level of the first variable and none of the others. For example, I can see results for 'KSCatA' but not 'WSCatA' or 'KLNKVulCatA'. </p>

<p><strong>4)</strong> How does R handle missing observations for logistic regression? For example survey #10 was missing the 'KLNKVulCat' Variable, but not any of the other IV's. Would R or any other statistical languages not use any of the information for this particular person, or just that particular variable?</p>

<p>Any help is greatly appreciated, thank you.</p>
"
"0.177238857380217","0.177704663327728","164541","<p>I am attempting to do a logistic regression bootstrap with R. The problem is I get high SE's. I'm not sure what to do about this or what it means. Does it mean that bootstrap does not work well for my particular data? Here is my code:</p>

<pre><code>get.coeffic = function(data, indices){
  data    = data[indices,]
  mylogit = glm(F~B+D, data=data, family=""binomial"")
  return(mylogit$coefficients)
}

Call:
boot(data = Pres, statistic = logit.bootstrap, R = 1000)

Bootstrap Statistics :
       original      bias    std. error
t1* -10.8609610 -23.0604501  338.048398
t2*   0.2078474   0.4351766    6.387781
</code></pre>

<p>I also want to know that after bootstrapping, how would this help with my final regression model? That is, how do I find what regression coefficient do I use in my final model?</p>

<pre><code>&gt; fit &lt;- glm(F ~ B + D , data = President, family = ""binomial"")
&gt; summary(fit)
Call:
glm(formula = F ~ B + D, family = ""binomial"", data = President)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.7699  -0.5073   0.1791   0.8147   1.2836  

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept) -14.57829    8.98809  -1.622   0.1048  
B             0.15034    0.14433   1.042   0.2976  
D             0.13385    0.08052   1.662   0.0965 .
- --
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1 

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 23.508  on 16  degrees of freedom
Residual deviance: 14.893  on 14  degrees of freedom
AIC: 20.893

Number of Fisher Scoring iterations: 5
</code></pre>
"
"0.144714921058484","0.145095250022002","169291","<p>I have a logistic regression model below, predicting a dichotomous variable <em>type</em> from a single continuous predictor <em>fatigue</em>. Using the coefficients below I can obtain the increase in the odds of a positive <em>type</em> from a 1 unit increase in fatigue.</p>

<p>Also I believe by forming the model expression</p>

<pre><code>logit(type) = 0.3134 - 91.1171 * fatigue 
</code></pre>

<p>I can obtain the odds of a positive <em>type</em> for a given value of <em>fatigue</em> by plugging it in, say for a value <em>fatigue</em> = 1.</p>

<p><strong>However</strong>, what I want to do is to obtain the odds of a positive <em>type</em> for a range of <em>fatigue</em> values, i.e. <strong>&lt;= 0</strong>. Is this possible?</p>

<pre><code>## Call:
## glm(formula = type ~ fatigue, family = binomial(), data = myData)

## Deviance Residuals:
## Min 1Q Median 3Q Max
## -1.6703 -1.3104 0.8369 1.0049 1.4695
##
## Coefficients:
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 0.3134 0.1496 2.095 0.0362 *
## fatigue -91.1171 36.3785 -2.505 0.0123 *
## ---
## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 282.84 on 210 degrees of freedom
## Residual deviance: 276.03 on 209 degrees of freedom
## AIC: 280.03
##
## Number of Fisher Scoring iterations: 4
</code></pre>
"
"0.125326797943307","0.125656172487509","171879","<p>I have the R output for the logistic regression model. It seems that only the intercept and psa are statistically significant. Does that mean I should remove sorbets_psa and cinko from my model and create a new model as new.model = glm(status ~ psa,family = binomial(link =""probit""))</p>

<pre><code>Call:
glm(formula = status ~ psa + serbest_psa + cinko, family = binomial(link =""probit""), data = data)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-2.3285  -0.6773  -0.6261  -0.5604   1.9500  

Coefficients:
      Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept) -0.9697009  0.2409856  -4.024 5.72e-05 ***
psa          0.0444376  0.0094368   4.709 2.49e-06 ***
serbest_psa -0.0440718  0.0250486  -1.759   0.0785 .  
cinko       -0.0006923  0.0016984  -0.408   0.6835    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 534.27  on 477  degrees of freedom
Residual deviance: 477.07  on 474  degrees of freedom
AIC: 485.07

Number of Fisher Scoring iterations: 6
</code></pre>
"
"0.229765796229396","0.230369649560433","172943","<p>I'm trying to understand the output of <code>glm</code> when a categorical variable has more than 2 categories.</p>

<p>I'm analysing if age affects death. Age is a categorical variable with 4 categories</p>

<p>I use the following code in R:</p>

<pre><code>mydata &lt;- read.delim(""Data.txt"", header = TRUE)
mydata$Agecod &lt;- factor(mydata$Agecod)
mylogit &lt;- glm(Death ~ Agecod, data = mydata, family = ""binomial"")
summary(mylogit)
</code></pre>

<p>Obtaining the following output: </p>

<pre><code>Call:
glm(formula = Death ~ Agecod, family = ""binomial"", data = mydata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.4006  -0.8047  -0.8047   1.2435   2.0963  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   0.5108     0.7303   0.699   0.4843  
Agecod2      -0.6650     0.7715  -0.862   0.3887  
Agecod3      -1.4722     0.7658  -1.922   0.0546 .
Agecod4      -2.5903     1.0468  -2.474   0.0133 *

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 237.32  on 184  degrees of freedom
Residual deviance: 223.73  on 181  degrees of freedom
  (1 observation deleted due to missingness)
AIC: 231.73

Number of Fisher Scoring iterations: 4
</code></pre>

<p>Since I have p-values for <code>Agecod2</code>, <code>Agecod3</code> and <code>Agecod4</code> and only <code>Agecod4</code> has a significant p-value my questions are:</p>

<ol>
<li>Is really <code>Age</code> associated with death?</li>
<li>Is only the 4th age category associated with death?</li>
<li>What happens with the first category since I don't have its p-value?</li>
</ol>

<p>Update:</p>

<p>Since Antoni Parellada says â€œIt seems as though you have proven that old age is a good predictor of deathâ€ and Gung points â€œYou cannot tell from your output if Age is associated with deathâ€ Iâ€™m still confused.</p>

<p>I understand that â€œInterceptâ€ is representing Agecod1 and is the â€œreference levelâ€. According to Gung â€œThe Estimates for the rest are the differences between the indicated level and the reference level. The associated p-values are for the tests of the indicated level vs. the reference level in isolation.â€ </p>

<p>My question now is: </p>

<p>Since Agecod4 p-value (0.0133) is significantly different from Agecod1 (reference lelvel) it doesnâ€™t mean that age is associated with death?</p>

<p>I have also tried to perform a nested test with the following command:</p>

<pre><code>anova(mylogit, test=""LRT"")
</code></pre>

<p>Obtaining:</p>

<pre><code>       Df Deviance Resid. Df Resid. Dev Pr(&gt;Chi)   
NULL                     184     237.32            
Agecod  3   13.583       181     223.73 0.003531 *
</code></pre>

<p>Does it mean that Age is definitively associated with death?</p>

<p>Update2:</p>

<p>I have solved my problem using binary logistic regression in SPSS. The output is the same than â€œmylogitâ€ but with SPSS I obtain a global p-value for the overall variable Agecod which is 0.008.</p>

<p>I donâ€™t know if is possible to obtain this â€œglobal p-valueâ€ with R, but since I know that I can use SPSS is not a big problem for me.</p>
"
"0.228814380978138","0.229415733870562","175767","<p>Logistic regression models the relationship between a set of independent variables and the probability that a case is a member of one of the categories of the dependent variable. If the probability is greater than 0.5, the case is classified in the modeled category.  If the probability is less than 0.50, the case is classified in the other category. The problem is that when I run the model with my dataset, the probabilities are far from 0.5, in fact it never gets to that value.</p>

<p>Here is part of My dataset:</p>

<pre><code>  sum_profit   direction   profit_cl1
   10           up          0.00
   0            Not_up     -0.03
  -5            Not_up      0.04
  -5            Not_up     -0.04
</code></pre>

<p>I want to find a relationship between the price of oil and the stock price of a Colombian oil company. So the variable 'sum_profit' is the sum of the change in the stock price in the next ten minutes. The variable 'profit_cl1' shows me the net change in the oil price in the last 10 minutes. </p>

<p>So what I want to know is that if the oil price changes in the last 10 minutes how would I expect the stock price direction to be in the following 10 minutes (Up or Down).</p>

<p>The problem is that my probabilities once I run the logistic regression are far from 0.5 even though the model is significant </p>

<pre><code>    glm.fit=glm(formula = direction ~ profit_cl1, family = binomial, data = datos)

    Deviance Residuals: 
      Min       1Q   Median       3Q      Max  
    -0.6786  -0.6786  -0.6131  -0.6131   1.8783  

    Coefficients:
                    Estimate Std. Error z value Pr(&gt;|z|)    
    (Intercept)     -1.57612    0.01618 -97.394   &lt;2e-16 ***
    profit_cl1       0.22485    0.02288   9.829   &lt;2e-16 ***
    ---
    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    (Dispersion parameter for binomial family taken to be 1)

     Null deviance: 48530  on 50309  degrees of freedom
    Residual deviance: 48434  on 50308  degrees of freedom
    AIC: 48438

    Number of Fisher Scoring iterations: 4 
</code></pre>

<p>The code to get the probabilities:</p>

<pre><code>   log.probs=predict(glm.fit, type=""response"")
   mean(log.probs)=0.1873 
</code></pre>

<p>the 0.1873 is very far from 0.5.</p>

<p>Sorry but I did not know where else to look for help! I appreciate any suggestion!</p>
"
"0.144714921058484","0.145095250022002","177650","<p>I have a binary response variable and a categorical predictor variable. If I test for associations between the 2 variables using chi-square test , it turns out to be significant. However, if I do a logistic regression with the same set of variables, the predictor is not significant. Why does this happen?</p>

<pre><code>  table(Data1$pred,Data1$target)

                            0    1
  Level1                    1    0
  Level2                    4    0
  Level3                   98    1
  Level4                 2056   22
  Level5                    1    0
  Level6                    2    0
  Level7                  311    0
  Level8                    6    1
  Level9                  131    7
  Level10                  49    2

  chisq.test(table(Data1$pred,Data1$target))

  Pearson's Chi-squared test

  data:  tabletable(Data1$pred,Data1$target)
  X-squared = 34.2614, df = 9, p-value = 8.037e-05
</code></pre>

<p>Logistic Regression on the same</p>

<pre><code>  logit.glm &lt;- glm(as.factor(target) ~ pred,                  
               data=Data1, family=binomial(link=""logit"")
  summary(logit.glm)
  Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.5553  -0.1459  -0.1459  -0.1459   3.0315  

  Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)
  (Intercept)   -2.057e+01  1.773e+04  -0.001    0.999
  Data1Level2   -6.313e-06  1.982e+04   0.000    1.000
  Data1Level3    1.598e+01  1.773e+04   0.001    0.999
  Data1Level4    1.603e+01  1.773e+04   0.001    0.999
  Data1Level5   -6.312e-06  2.507e+04   0.000    1.000
  Data1Level6   -6.312e-06  2.172e+04   0.000    1.000
  Data1Level7   -6.312e-06  1.776e+04   0.000    1.000
  Data1Level8    1.877e+01  1.773e+04   0.001    0.999
  Data1Level9    1.764e+01  1.773e+04   0.001    0.999
  Data1Level10   1.737e+01  1.773e+04   0.001    0.999

  (Dispersion parameter for binomial family taken to be 1)

   Null deviance: 356.09  on 2691  degrees of freedom
   Residual deviance: 333.06  on 2682  degrees of freedom
   AIC: 353.06

   Number of Fisher Scoring iterations: 19
</code></pre>
"
"0.280239239603615","0.280975743474508","183320","<p>I have the following dataframe on which I did logistic regression with response as outcome. There are some good predictors in these variables so I expected significant variables.</p>

<pre><code>structure(list(response = c(0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 
    0L, 0L, 1L, 0L, 1L, 0L), HIST1H3F_rna = c(1.09861228866811, 0.693147180559945, 
    2.07944154167984, 1.09861228866811, 1.79175946922805, 0, 0, 0, 
    2.39789527279837, 1.38629436111989, 1.6094379124341, 1.6094379124341, 
    0.693147180559945, 1.79175946922805, 0), NCF1_rna = c(2.77258872223978, 
    3.09104245335832, 2.63905732961526, 2.19722457733622, 2.30258509299405, 
    2.56494935746154, 3.09104245335832, 3.98898404656427, 2.56494935746154, 
    4.06044301054642, 3.87120101090789, 2.07944154167984, 3.49650756146648, 
    3.17805383034795, 3.95124371858143), WDR66_rna = c(5.06890420222023, 
    4.49980967033027, 5.11799381241676, 3.40119738166216, 3.25809653802148, 
    4.02535169073515, 5.8348107370626, 5.89440283426485, 3.87120101090789, 
    5.67675380226828, 5.35185813347607, 4.15888308335967, 6.23441072571837, 
    5.91889385427315, 3.68887945411394), PTH2R_rna = c(0.693147180559945, 
    5.08759633523238, 0.693147180559945, 1.09861228866811, 0, 6.01126717440416, 
    6.56526497003536, 5.18178355029209, 0, 4.36944785246702, 2.19722457733622, 
    1.09861228866811, 3.49650756146648, 1.38629436111989, 5.93753620508243
    ), HAVCR2_rna = c(4.48863636973214, 3.40119738166216, 3.09104245335832, 
    2.94443897916644, 3.2188758248682, 3.76120011569356, 3.95124371858143, 
    2.83321334405622, 2.07944154167984, 4.36944785246702, 3.58351893845611, 
    1.94591014905531, 4.23410650459726, 3.43398720448515, 2.56494935746154
    ), CD200R1_rna = c(2.484906649788, 2.94443897916644, 0.693147180559945, 
    1.94591014905531, 0.693147180559945, 2.89037175789616, 2.56494935746154, 
    1.6094379124341, 1.6094379124341, 1.94591014905531, 2.19722457733622, 
    0.693147180559945, 4.26267987704132, 1.6094379124341, 0.693147180559945
    )), .Names = c(""response"", ""HIST1H3F_rna"", ""NCF1_rna"", ""WDR66_rna"", 
    ""PTH2R_rna"", ""HAVCR2_rna"", ""CD200R1_rna""), row.names = c(NA, 
    -15L), class = ""data.frame"")
</code></pre>

<p>However, running the following lines and getting a summary of the model I find that all variables have a p-value of 1 and the standard errors seem so high. What's going on here?</p>

<pre><code>fullmod &lt;- glm(response ~ ., data=final_model,family='binomial')
summary(fullmod)
Call:
glm(formula = response ~ ., family = ""binomial"", data = final_model)

Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-6.515e-06  -2.404e-06  -2.110e-08   2.110e-08   7.470e-06  

Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)   1.460e+02  5.598e+05       0        1
HIST1H3F_rna  2.135e+01  5.145e+05       0        1
NCF1_rna     -4.133e+01  3.388e+05       0        1
WDR66_rna     1.296e+01  6.739e+05       0        1
PTH2R_rna     1.975e+00  3.775e+05       0        1
HAVCR2_rna   -2.477e+01  1.191e+06       0        1
CD200R1_rna  -1.420e+01  1.315e+06       0        1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2.0190e+01  on 14  degrees of freedom
Residual deviance: 2.2042e-10  on  8  degrees of freedom
AIC: 14

Number of Fisher Scoring iterations: 25
</code></pre>

<hr>

<p>In response to your comments I'll show the feature selection step (and the complete dataframe I'm working with below that).  </p>

<pre><code># forward  feature selection 
library('boot')
z = c()
nullmod &lt;- glm(response ~ 1, data=final_model, family='binomial') ## â€˜emptyâ€™ 
fullmod &lt;- glm(response ~ ., data=final_model, family='binomial') ## Full model
first = T
for(x in 1:ncol(final_model)){
  stepmod &lt;- step(nullmod, scope=list(lower=formula(nullmod), upper=formula(fullmod)),
                  direction=""forward"", data=final_model, steps=x, trace=F)
  cv.err  &lt;- cv.glm(data=final_model, glmfit=stepmod, K=nrow(final_model))$delta[1]
  if (first == T){
    first=F
    final_features &lt;- stepmod
  }else{
    if (cv.err &lt; min(z)){ final_features &lt;- stepmod }
  }
  z[x] &lt;- cv.err
  print(paste(x,cv.err))
  print(colnames(final_features$model))
}

plot(z, main='Forward Feature Selection GLM Final Model', 
     xlab='Number of Steps', ylab='LOOCV-error', col='red', type='l')
points(z)
colnames(final_features$model)
summary(final_features)

structure(list(response = c(0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 
0L, 1L, 0L, 1L, 1L, 1L), HIST1H3F_rna = c(1.09861228866811, 2.07944154167984, 
1.09861228866811, 1.79175946922805, 0, 0, 0, 2.39789527279837, 
1.38629436111989, 1.6094379124341, 1.6094379124341, 0.693147180559945, 
2.19722457733622, 2.39789527279837, 2.89037175789616), NCF1_rna = c(2.77258872223978, 
2.63905732961526, 2.19722457733622, 2.30258509299405, 2.56494935746154, 
3.09104245335832, 3.98898404656427, 2.56494935746154, 4.06044301054642, 
3.87120101090789, 2.07944154167984, 3.49650756146648, 2.07944154167984, 
2.07944154167984, 1.09861228866811), WDR66_rna = c(5.06890420222023, 
5.11799381241676, 3.40119738166216, 3.25809653802148, 4.02535169073515, 
5.8348107370626, 5.89440283426485, 3.87120101090789, 5.67675380226828, 
5.35185813347607, 4.15888308335967, 6.23441072571837, 4.0943445622221, 
4.21950770517611, 3.95124371858143), PTH2R_rna = c(0.693147180559945, 
0.693147180559945, 1.09861228866811, 0, 6.01126717440416, 6.56526497003536, 
5.18178355029209, 0, 4.36944785246702, 2.19722457733622, 1.09861228866811, 
3.49650756146648, 0, 0.693147180559945, 1.38629436111989), 
HAVCR2_rna = c(4.48863636973214, 
3.09104245335832, 2.94443897916644, 3.2188758248682, 3.76120011569356, 
3.95124371858143, 2.83321334405622, 2.07944154167984, 4.36944785246702, 
3.58351893845611, 1.94591014905531, 4.23410650459726, 1.38629436111989, 
1.09861228866811, 1.38629436111989), CD200R1_rna = c(2.484906649788, 
0.693147180559945, 1.94591014905531, 0.693147180559945, 2.89037175789616, 
2.56494935746154, 1.6094379124341, 1.6094379124341, 1.94591014905531, 
2.19722457733622, 0.693147180559945, 4.26267987704132, 1.94591014905531, 
0, 0.693147180559945), GDF7 = c(0.2232, -0.7281, 0.0655, -0.7919, 
0.175, 0.0891, 0.4396, -0.2774, -0.4079, 0.4069, 0.3057, 0.7371, 
-0.4978, -0.5096, -0.0827), HS1BP3 = c(0.2232, -0.7281, 0.0655, 
-0.7919, 0.175, 0.0891, 0.4396, -0.2774, -0.4079, 0.4069, 0.3057, 
0.7371, -0.4978, -0.5096, -0.0827), NKAIN3 = c(0.4072, 0.3216, 
-0.5466, -0.1588, 0.4515, 0.2849, 0.1675, 0.0847, 0.6601, 0.6331, 
-0.135, 1.3532, -0.503, -0.1241, 0.2061), UG0898H09 = c(0.4072, 
0.3216, -0.5466, -0.1588, 0.4515, 0.2849, 0.1675, 0.0847, 0.6601, 
0.6331, -0.135, 1.3532, -0.503, -0.1241, 0.2061), C15orf41 = c(0.122, 
-0.7519, -1.1267, -0.7882, -0.1117, -0.5105, -0.3905, -0.6834, 
-0.5944, 0.0714, -0.8134, -0.0115, -1.1112, -1.1488, -0.4878), 
    FAM98B = c(-0.1871, -0.7519, -1.1267, -0.7882, -0.1117, -0.5105, 
    -0.3905, -0.6834, -0.5944, 0.0714, -0.8134, -0.0115, -1.1112, 
    -1.1488, -0.4878), SPRED1 = c(-0.1871, -0.7519, -1.1267, 
    -0.7882, -0.1117, -0.5105, -0.3905, -0.6834, -0.5944, 0.0714, 
    -0.8134, -0.0115, -1.1112, -1.1488, -0.4878), MPDZ_ex = c(1, 
    0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0), TPR_ex = c(0, 
    0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), BUB1B_ex = c(0, 
    0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0), APC_ex = c(0, 
    0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0), ATM_ex = c(0, 
    0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0), DYNC1LI1_ex = c(0, 
    0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0), TTK_ex = c(0, 
    0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0), PSMG2_ex = c(1, 
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), NegRegMitosis = c(1, 
    0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0), brca1ness = c(0.037719, 
    0.900878, 0.013261, 0.900878, 0.659963, 0.005629, 9.8e-05, 
    0.996336, 0.910072, 0.850776, 0.000613, 0.104428, 0.978114, 
    0.938767, 0.041696), Methylation = c(0L, 0L, 0L, 1L, 1L, 
    1L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L), LinoleicAcid_Metab = structure(c(2L, 
    2L, 2L, 2L, 1L, 3L, 2L, 2L, 1L, 5L, 2L, 5L, 1L, 2L, 2L), .Label = c(""CYP2E1_high"", 
    ""CYP2E1_med"", ""high"", ""low"", ""PLA2G2A_high""), class = ""factor""), 
    Neuro_lr = structure(c(2L, 2L, 1L, 1L, 3L, 3L, 3L, 1L, 3L, 
    1L, 1L, 3L, 3L, 1L, 1L), .Label = c(""1"", ""2"", ""3"", ""4""), class = ""factor""), 
    NOX_signalling = structure(c(2L, 2L, 2L, 2L, 1L, 2L, 1L, 
    2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L), .Label = c(""high"", ""low""
    ), class = ""factor"")), .Names = c(""response"", ""HIST1H3F_rna"", 
""NCF1_rna"", ""WDR66_rna"", ""PTH2R_rna"", ""HAVCR2_rna"", ""CD200R1_rna"", 
""GDF7"", ""HS1BP3"", ""NKAIN3"", ""UG0898H09"", ""C15orf41"", ""FAM98B"", 
""SPRED1"", ""MPDZ_ex"", ""TPR_ex"", ""BUB1B_ex"", ""APC_ex"", ""ATM_ex"", 
""DYNC1LI1_ex"", ""TTK_ex"", ""PSMG2_ex"", ""NegRegMitosis"", ""brca1ness"", 
""Methylation"", ""LinoleicAcid_Metab"", ""Neuro_lr"", ""NOX_signalling""
), row.names = c(NA, -15L), class = ""data.frame"")
</code></pre>

<p>Summary now gives the following:</p>

<pre><code>Call:
glm(formula = response ~ NegRegMitosis, family = ""binomial"", 
    data = final_model)

Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-3.971e-06  -3.971e-06   3.971e-06   3.971e-06   3.971e-06  

Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)       25.57   76367.61       0        1
NegRegMitosis    -51.13  111790.71       0        1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 2.0728e+01  on 14  degrees of freedom
Residual deviance: 2.3655e-10  on 13  degrees of freedom
AIC: 4

Number of Fisher Scoring iterations: 24
</code></pre>

<p>Again even in a single predictor model, my p-value is 1. The predictor in this case is equal to the response, so it should predict perfectly. Then why is my pvalue 1?</p>
"
"0.229765796229396","0.251312344975017","183699","<p>I encountered a strange phenomenon when calculating pseudo R2 for logistic models when using aggregated files: the results are simply too good to be true. An example (but as far as I can see, every aggregated file offers similar problems):</p>

<pre><code> library(pscl)
 cuse &lt;- read.table(""http://data.princeton.edu/wws509/datasets/cuse.dat"",
               header=TRUE)

 head(cuse)
 cuse.fit &lt;- glm( cbind(using, notUsing) ~ age + education + wantsMore, 
             family = binomial, data=cuse)

 summary(cuse.fit)
 pR2(cuse.fit)     
</code></pre>

<p>The results are:</p>

<pre><code>&gt; summary(cuse.fit)

Call:
glm(formula = cbind(using, notUsing) ~ age + education + wantsMore, 
family = binomial, data = cuse)

Deviance Residuals: 
Min       1Q   Median       3Q      Max  
-2.5148  -0.9376   0.2408   0.9822   1.7333  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -0.8082     0.1590  -5.083 3.71e-07 ***
age25-29       0.3894     0.1759   2.214  0.02681 *  
age30-39       0.9086     0.1646   5.519 3.40e-08 ***
age40-49       1.1892     0.2144   5.546 2.92e-08 ***
educationlow  -0.3250     0.1240  -2.620  0.00879 ** 
wantsMoreyes  -0.8330     0.1175  -7.091 1.33e-12 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 165.772  on 15  degrees of freedom
Residual deviance:  29.917  on 10  degrees of freedom
AIC: 113.43

Number of Fisher Scoring iterations: 4

&gt; pR2(cuse.fit)
         llh      llhNull           G2     McFadden         r2ML 
 -50.7125647 -118.6401419  135.8551544    0.5725514    0.9997947 
       r2CU 
  0.9997950 
</code></pre>

<p>The last three outcomes from pscl function pR2 present McFadden's pseudo r-squared,  Maximum likelihood pseudo r-squared (Cox &amp; Snell) and Cragg and Uhler's or Nagelkerke's pseudo r-squared. The calculation seems to be flawless, but the outcomes close to 1 seem to good to be true.</p>

<p>Using weight instead of cbind:</p>

<pre><code>cuse2 = rbind(cuse,cuse)
cuse2$using.contraceptive=1
    cuse2$using.contraceptive[1:nrow(cuse)]=0
cuse2$freq = cuse2$notUsing
cuse2$freq[1:nrow(cuse)] = cuse2$using[1:nrow(cuse)]
cuse.fit2 = glm(using.contraceptive ~ age + education + wantsMore,
            weight=freq, family = binomial, data = cuse2)
summary(cuse.fit2)
round(pR2(cuse.fit2),5)
</code></pre>

<p>produces different logistic regression coefficients, and slightly different pseudo R2's for r2ml and r2CU and a large difference for McFadden R2:</p>

<pre><code>&gt; round(pR2(cuse.fit2),5)
         llh     llhNull          G2    McFadden        r2ML 
  -933.91920 -1001.84677   135.85515     0.06780     0.98567 
        r2CU 
     0.98567 
</code></pre>

<p>Full expansion results in very different estimates from pR2:</p>

<pre><code> cuse3 = rbind(cuse[rep(1:nrow(cuse), cuse[[""notUsing""]]), ],
          cuse[rep(1:nrow(cuse), cuse[[""using""]]), ])
 cuse3$using.contraceptive=1
     cuse3$using.contraceptive[1:sum(cuse$notUsing)]=0
 summary(cuse3)
 cuse.fit3 = glm(using.contraceptive ~ age + education + wantsMore,
            family = binomial, data = cuse3)
 summary(cuse.fit3)
 round(pR2(cuse.fit3),5)

 &gt; round(pR2(cuse.fit3),5)
         llh     llhNull          G2    McFadden        r2ML 
  -933.91920 -1001.84677   135.85515     0.06780     0.08106 
        r2CU 
     0.11376 
</code></pre>

<p>This indicates a logistic model which explains very little, which is a little bit more believable than the near perfect results from the aggregated files. Is there a more correct, and preferably more consistent, way to calculate the pseudo R2's? </p>
"
"0.0723574605292422","0.0725476250110012","185166","<p>I thought I've understood the output of the logistic regression in R (also I learned a lot through stackexchange), but somehow my vizualization tells me something different.
The output of the glm in R is: </p>

<pre><code>Call:
glm(formula = Zustand ~ Temp + Tag + Gehege + Temp:Gehege + Tag:Gehege + 
    Individuum + Gehege:Individuum + Temp:Individuum + Tag:Individuum, 
    family = binomial)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.9257  -0.5462  -0.4408  -0.3106   2.8510  

Coefficients:
                               Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                   -3.124244   1.302784  -2.398 0.016479 *  
Temp                           0.083585   0.068098   1.227 0.219664    
Tag                           -0.005485   0.013584  -0.404 0.686364    
Gehegeneues                    3.646637   1.249182   2.919 0.003509 ** 
IndividuumJoachim             -0.769787   0.927953  -0.830 0.406791    
IndividuumMary                -0.420745   0.797966  -0.527 0.598005    
Temp:Gehegeneues              -0.169516   0.062047  -2.732 0.006294 ** 
Tag:Gehegeneues               -0.057955   0.017154  -3.379 0.000729 ***
Gehegeneues:IndividuumJoachim  0.728588   0.329791   2.209 0.027158 *  
Gehegeneues:IndividuumMary     0.951688   0.396865   2.398 0.016484 *  
Temp:IndividuumJoachim         0.015466   0.049143   0.315 0.752979    
Temp:IndividuumMary           -0.012944   0.044467  -0.291 0.770985    
Tag:IndividuumJoachim         -0.035718   0.019177  -1.863 0.062532 .  
Tag:IndividuumMary             0.016538   0.019597   0.844 0.398724  
</code></pre>

<p>But my vizualization with the visreg-package...</p>

<pre><code>visreg(Ergebnis3, ""Gehege"", by = ""Individuum"", type = ""contrast"", scale = 'response', rug = F, ylim = c(0.0,0.6), main = ""Preening / Moulting"", xlab = ""Enclosure"", ylab = ""Likelihood"")
</code></pre>

<p>...looks like this:</p>

<p><a href=""http://i.stack.imgur.com/YxQc4.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/YxQc4.jpg"" alt=""enter image description here""></a></p>

<p>""Individuum = Georg"" and ""Gehege = altes"" is my reference level and I thought the coefficient of ""Gehege = neues"" (3.64) means that the probability of ""Zustand"" in ""Gehege = neues"" is 3.64 times higher than in ""Gehege = altes"" or not? But in the graphic it's lower. Also for changing continuous variables ""Temp"" and ""Tag"" (here it's shown i.e. for 19.5 Â°C) ""Gehege = neues"" keeps to be lower for most of the times. The odds Ratio for ""Gehege = neues"" are also about 38, this high number is a bit weird... </p>

<p>I hope this is enough information to help, I have a real complex question I want to answer.</p>
"
"0.250653595886614","0.251312344975017","186845","<p>I created some data using the following code:</p>

<pre><code>set.seed(1221)
x &lt;- runif(500)
y &lt;- runif(500,0,2)
z &lt;- rep(0,500)
z[-0.8*x + y - 0.75 &gt; 0] &lt;- 1
plot(x,y,col=as.factor(z))
</code></pre>

<p>This produces the following plot</p>

<p><a href=""http://i.stack.imgur.com/ycWdr.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ycWdr.png"" alt=""enter image description here""></a></p>

<p>The data is linearly separable. Then, I applied the glm function to create a logistic regression model.</p>

<pre><code>df &lt;- data.frame(class = z, x = x, y = y)
model &lt;- glm(z ~ x + y, family = binomial, data = df)
</code></pre>

<p>This produces the following output:</p>

<pre><code>summary(model)
Call:
glm(formula = z ~ x + y, family = binomial, data = df)

Deviance Residuals: 
       Min          1Q      Median          3Q         Max  
-8.127e-04  -2.000e-08  -2.000e-08   2.000e-08   7.699e-04  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)    -1062      52666   -0.02    0.984
x              -1163      57197   -0.02    0.984
y               1433      70408    0.02    0.984

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 6.8274e+02  on 499  degrees of freedom
Residual deviance: 1.3345e-06  on 497  degrees of freedom
AIC: 6

Number of Fisher Scoring iterations: 25
</code></pre>

<p>The result surprised me, first because the parameter estimates are huge, and second because I was expecting such estimates to be close to the original decision boundary function, i.e. <code>-0.8x + y - 0.75 = 0</code>.</p>

<p>I then used the <a href=""http://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html"" rel=""nofollow"">glmnet</a> package to see if I could solve this issue. This package creates a penalised logistic regression model in order to deal with the large values in the parameter estimates. The code I used is the following:</p>

<pre><code>library(glmnet)
cvfit &lt;- cv.glmnet(as.matrix(df[,-1]), as.factor(df$class), family =   ""binomial"", type.measure = ""class"")
plot(cvfit)
</code></pre>

<p><a href=""http://i.stack.imgur.com/vH4AV.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/vH4AV.png"" alt=""enter image description here""></a></p>

<p>And the coefficients for the optimal penalty strength are:</p>

<pre><code>coef(cvfit, s = ""lambda.min"")
3 x 1 sparse Matrix of class ""dgCMatrix""
                    1
(Intercept) -84.01446
x           -91.40983
y           113.18736
</code></pre>

<p>Such coefficients are smaller than the ones obtained with the <code>glm</code> function. Still they are not the same as the decision boundary function. </p>

<p>Does anybody know why this is happening? Any help is greatly appreciated.</p>
"
"0.20465780403866","0.205195670417031","189188","<p>If I create a linear model in R, I get a p-value for the whole model. When I create a logistic regression model, I don't. Why is this?</p>

<p><strong>Linear Regression</strong></p>

<pre><code>x&lt;-rnorm(100)
y&lt;-x+rnorm(100)
summary(lm(y~x))

 Call: lm(formula = y ~ x)

 Residuals:
      Min       1Q   Median       3Q      Max 
 -2.46237 -0.52810 -0.04574  0.48878  2.81002 

 Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)     (Intercept) -0.02318    0.09394  -0.247    0.806     x            1.10130    0.09421  11.690   &lt;2e-16***
 --- Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

 Residual standard error: 0.9374 on 98 degrees of freedom Multiple
 R-squared:  0.5824,    Adjusted R-squared:  0.5781  F-statistic: 136.7 on
 1 and 98 DF,  p-value: &lt; 2.2e-16
</code></pre>

<p><strong>Logistic Regression</strong></p>

<pre><code>x&lt;-rnorm(100)
y&lt;-factor(c(rep(""ONE"",50),rep(""TWO"",50)))
summary(glm(y~x,family = ""binomial""))

 Call: glm(formula = y ~ x, family = ""binomial"")

 Deviance Residuals: 
      Min        1Q    Median        3Q       Max  
 -1.20658  -1.18093  -0.00499   1.17444   1.21414  

 Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|) (Intercept)  3.857e-05  .000e-01   0.000    1.000 x           -3.924e-02  2.055e-01  -0.191    0.849

 (Dispersion parameter for binomial family taken to be 1)

    Null deviance: 138.63  on 99  degrees of freedom Residual deviance: 138.59  on 98  degrees of freedom AIC: 142.59

 Number of Fisher Scoring iterations: 3
</code></pre>
"
"0.192953228077979","0.217642875033004","191063","<p>need help.
I use <code>rms</code> and can't understand different between <code>orm</code> and <code>lrm</code> when i used <code>contrasts</code>. For example:</p>

<pre><code>x &lt;- factor(rbinom(100,2,0.6), labels = c(""a"",""b"",""c""), ordered = TRUE)
y &lt;- factor(rbinom(100,1,0.5), labels=c(""no"",""yes""))
l&lt;-lrm(x~y);l
Logistic Regression Model

lrm(formula = x ~ y)
                     Model Likelihood     Discrimination    Rank Discrim.    
                        Ratio Test            Indexes          Indexes       
Obs           100    LR chi2      0.51    R2       0.006    C       0.529    
 a             24    d.f.            1    g        0.133    Dxy     0.059    
 b             40    Pr(&gt; chi2) 0.4764    gr       1.143    gamma   0.117    
 c             36                         gp       0.024    tau-a   0.039    
max |deriv| 1e-10                         Brier    0.181                     

      Coef    S.E.   Wald Z Pr(&gt;|Z|)
y&gt;=b   1.0188 0.2988  3.41  0.0007  
y&gt;=c  -0.7162 0.2884 -2.48  0.0130  
y=yes  0.2642 0.3715  0.71  0.4769

o&lt;-orm(x~y);l;o
Logistic (Proportional Odds) Ordinal Regression Model

orm(formula = x ~ y)
                     Model Likelihood          Discrimination          Rank Discrim.    
                        Ratio Test                 Indexes                Indexes       
Obs           100    LR chi2      0.51    R2                  0.006    rho     0.071    
 a             24    d.f.            1    g                   0.133                     
 b             40    Pr(&gt; chi2) 0.4764    gr                  1.143                     
 c             36    Score chi2   0.51    |Pr(Y&gt;=median)-0.5| 0.259                     
Unique Y        3    Pr(&gt; chi2) 0.4766                                                  
Median Y        2                                                                       
max |deriv| 7e-05                                                                       

      Coef    S.E.   Wald Z Pr(&gt;|Z|)
y&gt;=b   1.0188 0.2988  3.41  0.0007  
y&gt;=c  -0.7162 0.2884 -2.48  0.0130  
y=yes  0.2642 0.3715  0.71  0.4769  
</code></pre>

<p>We can see, that results <code>orm</code> and <code>lrm</code> are equal. When we use <code>contrasts</code> results are different:</p>

<pre><code>contrast(l,list(y=""no""),list(y=""yes""))
     Contrast      S.E.      Lower     Upper     Z Pr(&gt;|z|)
11 -0.2642454 0.3714673 -0.9923081 0.4638172 -0.71   0.4769
Confidence intervals are 0.95 individual intervals
</code></pre>

<p>and </p>

<pre><code>contrast(o,list(y=""no""),list(y=""yes""))

Contrast      S.E.      Lower   Upper    Z Pr(&gt;|z|)
11 0.7545878 0.3714672 0.02652544 1.48265 2.03   0.0422

Confidence intervals are 0.95 individual intervals
</code></pre>

<p>Why <code>orm</code> contrast aren't equal beta regression coefficient as <code>lrm</code> contrast? p.s. sorry for bad English</p>
"
"0.486339412367715","0.467300174453611","191810","<h2>Study design</h2>

<p>504 individuals were all sampled 2 times. Once before and once after a celebration.</p>

<p>The goal is to investigate if this event (Celebration) as well as working with animals (sheepdog) have an influence on the probability that an individual gets infected by a parasite. (out of 1008 observations only 22 are found to be infected)</p>

<p><strong>Variables</strong></p>

<ul>
<li>dependent variable = ""T_hydat"" (infected or not) </li>
</ul>

<p>(most predictiv variables are categorical) </p>

<ul>
<li>""Celebration"" (yes/no)</li>
<li>""sex"" (m/f)</li>
<li>""RelAge"" (5 levels)</li>
<li>""SheepDog"" (yes/no)</li>
<li>""Area"" (geographical area = 4 levels)</li>
<li>""InfectionPeriodT_hydat"" (continuous --> Nr Days after deworming"")</li>
<li>""Urbanisation (3 levels)</li>
</ul>

<h2>Question 1:</h2>

<p>1) Should I include Individual-ID (""ID"") as a random Effekt as I sampled each Ind. 2 times? (Pseudoreplication?) </p>

<pre><code>mod_fail &lt;- glmer( T_hydat ~ Celebration + Sex + RelAge + SheepDog + InfectionPeriodT_hydat + Urbanisation + (1|ID), family = binomial)

Warnmeldungen:
1: In (function (fn, par, lower = rep.int(-Inf, n), upper = rep.int(Inf,  :
  failure to converge in 10000 evaluations
2: In checkConv(attr(opt, ""derivs""), opt$par, ctrl = control$checkConv,  :
  Model failed to converge with max|grad| = 1.10808 (tol = 0.001, component 10)
3: In checkConv(attr(opt, ""derivs""), opt$par, ctrl = control$checkConv,  :
  Model is nearly unidentifiable: large eigenvalue ratio
 - Rescale variables?
</code></pre>

<p>--> unfortunately this model fails to converge (is it a problem that ID = 504 levels with only 2 observations per level?) 
Convergence is achieved with glmmPQL() but after droping some unsignficant preditiv variables the model fails to converge again ? What is the Problem here? Could geeglm() be a solution?</p>

<p>In an other attempt I run the model only with ""Area"" (4 levels) as random effect (my expectation is that Ind. in the same geogr. Area are suffering from the same parasite pressure etc.) and received the follwoing p-Values. </p>

<h2>My model in R:</h2>

<pre><code>mod_converges &lt;- glmer( T_hydat ~ Celebration + Sex + RelAge + SheepDog + InfectionPeriodT_hydat + Urbanisation + (1|Area), family = binomial)
</code></pre>

<h2>mod_converges output:</h2>

<p>summary(mod_converges)</p>

<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: T_hydat ~ Celebration + sex + SheepDog + RelAge + Urbanisation +  
    InfectionPeriodT_hydat + (1 | Area)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
   203.0    262.0    -89.5    179.0      996 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.461 -0.146 -0.088 -0.060 31.174 

Random effects:
 Groups Name        Variance Std.Dev.
 Area   (Intercept) 0.314    0.561   
Number of obs: 1008, groups:  Area, 4

Fixed effects:
                       Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)            -6.81086    1.96027   -3.47  0.00051 ***
Celebration1            1.36304    0.57049    2.39  0.01688 *  
sexm                   -0.18064    0.49073   -0.37  0.71279    
SheepDog1               2.02983    0.51232    3.96  7.4e-05 ***
RelAge2                 0.34815    1.18557    0.29  0.76902    
RelAge3                 0.86344    1.05729    0.82  0.41412    
RelAge4                -0.54501    1.43815   -0.38  0.70471    
RelAge5                 0.85741    1.25895    0.68  0.49584    
UrbanisationU           0.17939    0.78669    0.23  0.81962    
UrbanisationV           0.01237    0.59374    0.02  0.98338    
InfectionPeriodT_hydat  0.00324    0.01159    0.28  0.77985    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1
</code></pre>

<h2>glmmPQL-Model output below (added after the first reply by usÎµr11852)</h2>

<p>This model converges with ""Sample_ID"" as a random effect, however, as statet by 
<strong>usÎµr11852</strong> the varaince of the random effect is quiet high  4.095497^2 = 16.8. And the std.error of Area5 is far to high (complete separation).
Can I just remove Datapoints from Area5 to overcome this Problem? </p>

<pre><code>#     T_hydat
#  Area   0   1
#     1 226   4
#     2 203   3
#     4 389  15
#     5 168   0  ## here is the problematic cell

Linear mixed-effects model fit by maximum likelihood
 Data: dat 
  AIC BIC logLik
   NA  NA     NA

Random effects:
 Formula: ~1 | Sample_ID
        (Intercept)  Residual
StdDev:    4.095497 0.1588054

Variance function:
 Structure: fixed weights
 Formula: ~invwt 
Fixed effects: T_hydat ~ Celebration + sex + SheepDog + YoungOld + Urbanisation +      InfectionPeriodT_hydat + Area 
                            Value Std.Error  DF    t-value p-value
(Intercept)            -20.271630     1.888 502 -10.735869  0.0000
Celebration1             5.245428     0.285 502  18.381586  0.0000
sexm                    -0.102451     0.877 495  -0.116865  0.9070
SheepDog1                3.356856     0.879 495   3.817931  0.0002
YoungOldyoung            0.694322     1.050 495   0.661017  0.5089
UrbanisationU            0.660842     1.374 495   0.480990  0.6307
UrbanisationV            0.494653     1.050 495   0.470915  0.6379
InfectionPeriodT_hydat   0.059830     0.007 502   8.587736  0.0000
Area2                   -1.187005     1.273 495  -0.932576  0.3515
Area4                   -0.700612     0.973 495  -0.720133  0.4718
Area5                  -23.436977 28791.059 495  -0.000814  0.9994
 Correlation: 
                       (Intr) Clbrt1 sexm   ShpDg1 YngOld UrbnsU UrbnsV InfPT_ Area2  Area4 
Celebration1           -0.467                                                               
sexm                   -0.355  0.018                                                        
SheepDog1              -0.427  0.079  0.066                                                 
YoungOldyoung          -0.483  0.017  0.134  0.045                                          
UrbanisationU          -0.273  0.005 -0.058  0.317 -0.035                                   
UrbanisationV          -0.393  0.001 -0.138  0.417 -0.087  0.586                            
InfectionPeriodT_hydat -0.517  0.804  0.022  0.088  0.016  0.007  0.003                     
Area2                  -0.044 -0.035 -0.044 -0.268 -0.070 -0.315 -0.232 -0.042              
Area4                  -0.213 -0.116 -0.049 -0.186 -0.023 -0.119  0.031 -0.148  0.561       
Area5                   0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max 
-14.208465914  -0.093224405  -0.022551663  -0.004948562  14.733133744 

Number of Observations: 1008
Number of Groups: 504 
</code></pre>

<p><strong>Output from logistf (Firth's penalized-likelihood logistic regression)</strong></p>

<pre><code>logistf(formula = T_hydat ~ Celebration + sex + SheepDog + YoungOld + 
    Urbanisation + InfectionPeriodT_hydat + Area, data = dat, 
    family = binomial)

Model fitted by Penalized ML
Confidence intervals and p-values by Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood Profile Likelihood 

                               coef   se(coef)  lower 0.95  upper 0.95       Chisq
(Intercept)            -5.252164846 1.52982941 -8.75175093 -2.24379091 12.84909207
Celebration1            1.136833737 0.49697927  0.14999782  2.27716500  5.17197661
sexm                   -0.200450540 0.44458464 -1.09803320  0.77892986  0.17662930
SheepDog1               2.059166246 0.47197694  1.10933774  3.12225212 18.92002321
YoungOldyoung           0.412641416 0.56705186 -0.66182554  1.77541644  0.50507269
UrbanisationU           0.565030324 0.70697218 -0.98974390  1.97489240  0.56236485
UrbanisationV           0.265401035 0.50810444 -0.75429596  1.33772658  0.25619218
InfectionPeriodT_hydat -0.003590666 0.01071497 -0.02530179  0.02075254  0.09198425
Area2                  -0.634761551 0.74958750 -2.27274031  0.90086554  0.66405078
Area4                   0.359032194 0.57158464 -0.76903324  1.63297249  0.37094569
Area5                  -2.456953373 1.44578029 -7.36654837 -0.13140806  4.37267766
                                  p
(Intercept)            3.376430e-04
Celebration1           2.295408e-02
sexm                   6.742861e-01
SheepDog1              1.363144e-05
YoungOldyoung          4.772797e-01
UrbanisationU          4.533090e-01
UrbanisationV          6.127483e-01
InfectionPeriodT_hydat 7.616696e-01
Area2                  4.151335e-01
Area4                  5.424892e-01
Area5                  3.651956e-02

Likelihood ratio test=36.56853 on 10 df, p=6.718946e-05, n=1008
Wald test = 32.34071 on 10 df, p = 0.0003512978
</code></pre>

<p>** glmer Model (Edited 28th Jan 2016)**</p>

<p>Output from glmer2var: Mixed effect model with the 2 most ""important"" variables (""Celebration"" = the factor I am interested in and ""SheepDog"" which was found to have a significant influence on infection when data before and after the celebration were analysed separately.) The few number of positives make it impossible to fit a model with more than two explanatory variables (see commet EdM). </p>

<p>There seems to be a strong effect of ""Celebration"" that probably cancels out the effect of ""SheepDog"" found in previous analysis.</p>

<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: T_hydat ~ Celebration + SheepDog + (1 | Sample_ID)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
   113.0    132.6    -52.5    105.0     1004 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-4.5709 -0.0022 -0.0001  0.0000 10.3491 

Random effects:
 Groups    Name        Variance Std.Dev.
 Sample_ID (Intercept) 377.1    19.42   
Number of obs: 1008, groups:  Sample_ID, 504

Fixed effects:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -19.896      4.525  -4.397  1.1e-05 ***
Celebration1    7.626      2.932   2.601  0.00929 ** 
SheepDog1       1.885      2.099   0.898  0.36919    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
            (Intr) Clbrt1
Celebratin1 -0.908       
SheepDog1   -0.297 -0.023
</code></pre>

<h2>Question 2:</h2>

<p>2) Can I use drop1() to get the final model and use the p-Values from summary(mod_converges) for interpretation? Does my output tell me if it makes sense to include the random effect (""Area"") ?</p>

<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
 Family: binomial  ( logit )
Formula: T_hydat ~ Celebration + SheepDog + (1 | Area)
   Data: dat

     AIC      BIC   logLik deviance df.resid 
   190.8    210.4    -91.4    182.8     1004 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-0.369 -0.135 -0.096 -0.071 17.438 

Random effects:
 Groups Name        Variance Std.Dev.
 Area   (Intercept) 0.359    0.599   
Number of obs: 1008, groups:  Area, 4

Fixed effects:
             Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)    -5.912      0.698   -8.47  &lt; 2e-16 ***
Celebration1    1.287      0.512    2.51    0.012 *  
SheepDog1       2.014      0.484    4.16  3.2e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Correlation of Fixed Effects:
            (Intr) Clbrt1
Celebratin1 -0.580       
SheepDog1   -0.504  0.027
</code></pre>

<p>I know there are quite a few questions but I would really appreciate some advice from experienced people. Thanks!</p>
"
"0.228814380978138","0.229415733870562","191891","<p>I'm hoping someone can help clarify a few things for me.</p>

<p>I ran some relatively simple logistic regressions in r and am having trouble with interpretation.  I'm interested in the effects of elevation and a species diversity index on the presence/absence of a disease in individual animals.</p>

<p>I ran a simple model of: <code>Result~Elevation+Diversity</code> which gave this result</p>

<pre><code>Call:
glm(formula = Test_Result ~ Elevation + Simpsons_Diversity, family = binomial, 
    data = XXXXXX)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.8141  -0.6984  -0.5317  -0.4143   2.3337  

Coefficients:
                     Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -2.118e+00  1.594e-01 -13.289  &lt; 2e-16 
Elevation           1.316e-04  2.247e-05   5.855 4.76e-09 
Simpsons_Diversity -9.907e-01  2.725e-01  -3.635 0.000278 

    Null deviance: 3015.2  on 3299  degrees of freedom
Residual deviance: 2923.6  on 3297  degrees of freedom
AIC: 2929.6
</code></pre>

<p>I have a strong suspicion that diversity decreases with increasing elevation which I have confirmed although the relationship isn't quite as strong as I thought. When I run a model with an interaction term <code>elevation*diversity</code> I get:</p>

<pre><code>Call:
glm(formula = Test_Result ~ Elevation_1000 + Simpsons_Diversity_100 + 
    Elevation_1000 * Simpsons_Diversity_100, family = binomial, 
    data = XXXXXXX)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7908  -0.6959  -0.5437  -0.3963   2.4215  

Coefficients:
                                       Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                           -2.014422   0.179507 -11.222  &lt; 2e-16 
Elevation_1000                         0.112466   0.027433   4.100 4.14e-05 
Simpsons_Diversity_100                -0.015851   0.005780  -2.743   0.0061  
Elevation_1000:Simpsons_Diversity_100  0.001408   0.001200   1.173   0.2406   

    Null deviance: 3015.2  on 3299  degrees of freedom
Residual deviance: 2922.2  on 3296  degrees of freedom
AIC: 2930.2

Number of Fisher Scoring iterations: 5
</code></pre>

<p>Showing that adding the interaction term doesn't really help the fit of the model (AIC = 2930) and the interaction term itself is not significant (p-value=0.24).</p>

<p>Am I on the right track so far?</p>

<p>If I am, I understand how to convert coefficients to odds ratios and interpret those.  My main question is can I plot the predicted probabilities for a combination of elevation and diversity where each variable is allowed to vary? Or is this essentially plotting the interaction?  </p>

<p>I was able to create a dataframe where I varied elevation and diversity and I used my simple non-interaction model to obtain predicted probabilities using the PREDICT fuction) for those combinations, but I want to make sure that I am doing things correctly.  I've attached the plot of predicted probs for different levels of diversity. </p>

<p><a href=""http://i.stack.imgur.com/NINBE.gif"" rel=""nofollow""><img src=""http://i.stack.imgur.com/NINBE.gif"" alt=""Elevation vs. Predicted Probabilities for various levels of diversity)""></a></p>
"
"0.177238857380217","0.177704663327728","200031","<p>I have very easy question that I'm hoping someone can assist me with:</p>

<p>I ran an example logistic regression using this R code:</p>

<pre><code>     hours &lt;- c(0.5, 0.75, 1, 1.25, 1.5, 1.75, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4, 4.25, 4.5, 4.75, 5, 5.5)
        pass &lt;- c(0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1)
        data &lt;- data.frame(hours, pass)
        mylogit &lt;- glm(pass ~ hours, data = data, family = ""binomial"") #Activates the logistic regression model
        summary(mylogit) #Summary of the model

    Call:
    glm(formula = pass ~ hours, family = ""binomial"", data = data)

    Deviance Residuals: 
         Min        1Q    Median        3Q       Max  
    -1.70557  -0.57357  -0.04654   0.45470   1.82008  

    Coefficients:
                Estimate Std. Error z value Pr(&gt;|z|)  
    (Intercept)  -4.0777     1.7610  -2.316   0.0206 *
    hours         1.5046     0.6287   2.393   0.0167 *
    ---
    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

    (Dispersion parameter for binomial family taken to be 1)

        Null deviance: 27.726  on 19  degrees of freedom
    Residual deviance: 16.060  on 18  degrees of freedom
    AIC: 20.06

    Number of Fisher Scoring iterations: 5

    round(exp(cbind(OR = coef(mylogit), confint(mylogit))),3)

               OR 2.5 % 97.5 %
   (Intercept) 0.017 0.000  0.281
    hours       4.503 1.698 23.223
</code></pre>

<p>I know that by taking the exponent of the log-odds/coefficients for hours the odds of passing increase by a factor of 4.503 for a one-unit change in hours.  However, given that the explanatory variable (hours) is continuous, what is considered a 'one-unit change' i.e. going from 1 to 2 hours as one unit? or from 1.75 to 1.76 hours as one unit?  Also, is this interpretation of one-unit the same for regular OLS regression as well? I'm seeking to better understand the rules R applies to creating its regression coefficients.  </p>
"
"0.125326797943307","0.125656172487509","201462","<p>I'm fitting a logistic regression model with <code>patient_group</code> (0,1) as response variable and the explanatory variable being an interaction between two SNPs. When running summary for the model, the alert 'Coefficients: (1 not defined because of singularities)' is shown, and I guess it is due to the fact that the combination AACT has 0 observations. </p>

<p>My question is whether the statistics are still valid, or is there a better way to analyse this kind of data? (The SNPs are located close to each other and are most likely strongly linked.)</p>

<pre><code>&gt; table(data$SNP1, data$SNP2)    
     CC CT
  TT 27  9
  AT 83 14
  AA 47  0
&gt; model &lt;- glm(patient_group ~ SNP1 * SNP2, data=data, family=""binomial"")
&gt; summary(model)
Call:
glm(formula = patient_group ~ SNP1 * SNP2, family = ""binomial"", 
data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.2735  -0.9072  -0.7679   1.4742   1.8365  

Coefficients: (1 not defined because of singularities)
              Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept)    -1.4816     0.4954  -2.991  0.00279 **
SNP1AT          0.8065     0.5471   1.474  0.14048   
SNP1AA          0.4112     0.5978   0.688  0.49158   
SNP2CT          1.7047     0.8339   2.044  0.04093 * 
SNP1AT:SNP2CT  -2.3289     1.0833  -2.150  0.03157 * 
SNP1AA:SNP2CT       NA         NA      NA       NA   

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 218.19  on 179  degrees of freedom
Residual deviance: 212.31  on 175  degrees of freedom
(26 observations deleted due to missingness)
AIC: 222.31

Number of Fisher Scoring iterations: 4
</code></pre>
"
"0.0723574605292422","0.0725476250110012","204192","<p>I have a categorical response which i want to predict, so i am in the process of developing a logistic model.  I am using k-fold cross-validation for model selection. The first model, which was just an intercept model is throwing negative fitted values.</p>

<p>So i tried adding just 2 predictors to understand what was causing this, but the model with the 2 predictors is also predicting negative probabilities.</p>

<p>Below is the code that i used:</p>

<pre><code>    logistic_null1 &lt;- glm(SeriousDlqin2yrs ~ 1, family=binomial(), data=trainingdata)

logistic_null1 &lt;- glm(SeriousDlqin2yrs ~ age + income, family=binomial(), data=trainingdata)
</code></pre>

<p>I checked if may be the response Y is not a factors but doesn't seem to be the case either</p>

<pre><code>&gt; class(trainingdata$SeriousDlqin2yrs)
[1] ""factor""
&gt; check3 &lt;- as.data.frame(predict(logistic_null1, testdata))
&gt; summary(check3)
 predict(logistic_null1, testdata)
 Min.   :-4.609                   
 1st Qu.:-3.047                   
 Median :-2.700                   
 Mean   :-2.703                   
 3rd Qu.:-2.346                   
 Max.   :-1.601 
</code></pre>

<p>What could cause this</p>
"
"0.161796200422643","0.162221421130763","206702","<p>I have some data to fit a logistic regression, although the data seems quite good, the resulted fit does not look as expected.</p>

<blockquote>
<pre><code>  paramValue      normality
1  3.69             0
2  1.16             0
3  6.12             1
4  2.78             1
5  1.45             1
6  3.56             0
</code></pre>
</blockquote>

<pre><code>mylogit &lt;- glm(normality ~paramValue,  family = binomial(link=""logit""))
summary(mylogit)
</code></pre>

<blockquote>
<pre><code>Call:
glm(formula = normality ~ paramValue, family = binomial(link = ""logit""))

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.44994  -0.73312   0.08151   0.63377   1.41140  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  -1.9945     0.9531  -2.093   0.0364 *
paramValue    1.2582     0.5655   2.225   0.0261 *
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 29.065  on 20  degrees of freedom
Residual deviance: 19.746  on 19  degrees of freedom
AIC: 23.746

Number of Fisher Scoring iterations: 5
</code></pre>
</blockquote>

<pre><code>    plot(paramValue,normality)

    x &lt;- seq(-1, 6, 0.1)

curve(predict(mylogit,data.frame(paramValue=x),type=""response""),add=TRUE, col=""red"")
</code></pre>

<p><a href=""http://i.stack.imgur.com/1f0DY.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/1f0DY.png"" alt=""enter image description here""></a></p>

<p>Did I do something wrong? Is there any way to force the regression to cross the origin?</p>
"
"0.218165952144043","0.240613251592894","212611","<p>I have ran these two Logistic Regression models (below) on some small data and I am able to interpret the output - significance and direction - of the regressors, but I do not know for sure how to interpret all the data which is supposed to tell me everything related to <strong>effect (size) etc</strong>. I did select my predictors properly by adding one each time and checking whether the model was still significant (which yielded the same result as an automatic stepAIC from the MASS package) and I also did some diagnostic checks (outliertest, VIF-score).</p>

<p>What (I think) I got from the models is:</p>

<ul>
<li><strong>R2</strong>: model1 only explains 4.8% of all variation and model2 6.6%, so no predictive power?</li>
<li><strong>C</strong>: model1 does not have acceptable discrimination, neither does model2 (&lt;0.7)</li>
</ul>

<p>Is there other <strong>important information that I am ignorant of</strong>? It seems that these models do <strong>not have much 'power'</strong> (according to <strong>R2</strong> and <strong>C</strong>), but how are they then <strong>still significant</strong> (there is also very significant behaviour (***) for regressors)?</p>

<p>*PS: Sorry if am missing obvious things - I do not have that strong of a statistical background. I am also finding it a hard time searching for all the parameters and metrics since they are often denoted by a one letter name (e.g. C, g) - which is not easy to search for if you do not know what you are looking for... So that's why I came to CrossValidated!</p>

<p>I have found <a href=""http://stats.stackexchange.com/questions/104485/logistic-regression-evaluation-metrics"">this question</a>, but it does not really have an answer since it's maybe way too vague? If someone else has a reading suggestion for my problem, that's also welcomed!*</p>

<h2>First model: Agentivity ~ Period + Genre</h2>

<pre><code>(from lrm)      
                     Model Likelihood      Discrimination    Rank Discrim.    
                       Ratio Test            Indexes           Indexes       
Obs          700    LR chi2      25.55    R2       0.048    C       0.602    
 strong      403    d.f.             4    g        0.440    Dxy     0.204    
 weak        297    Pr(&gt; chi2) &lt;0.0001    gr       1.553    gamma   0.240    
max |deriv| 3e-14                         gp       0.105    tau-a   0.100    
                                          Brier    0.236                     

(from glm)
Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.3171  -0.9825  -0.8094   1.1882   1.6090  

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 954.29  on 699  degrees of freedom
Residual deviance: 928.74  on 695  degrees of freedom
AIC: 938.74

Number of Fisher Scoring iterations: 4
</code></pre>

<h2>Second model: Type ~ Period</h2>

<pre><code>(from lrm)
                      Model Likelihood      Discrimination    Rank Discrim.    
                         Ratio Test           Indexes           Indexes       
Obs           872    LR chi2      36.70    R2       0.066    C       0.637    
 mediopassive 701    d.f.             2    g        0.552    Dxy     0.275    
 passive      171    Pr(&gt; chi2) &lt;0.0001    gr       1.736    gamma   0.401    
max |deriv| 9e-10                          gp       0.087    tau-a   0.087    
                                           Brier    0.151                     

(for glm)
Deviance Residuals: 
 Min       1Q   Median       3Q      Max  
-0.8645  -0.6109  -0.4960  -0.4960   2.0767  

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 863.19  on 871  degrees of freedom
Residual deviance: 826.49  on 869  degrees of freedom
AIC: 832.49

Number of Fisher Scoring iterations: 4
</code></pre>
"
"0.217072381587726","0.19346033336267","212903","<p>I have the data <a href=""https://docs.google.com/spreadsheets/d/1lEzUt0QdFCp1ho-iWd4HzEIZoo8IyAM8YP2gu-K7BQo/edit?usp=sharing"" rel=""nofollow"">here</a>.But When I tried to build the logistic regression model using glm function its shows NA in TotalVisits. I have found similar question on stack overflow but that is answered for linear model.  </p>

<pre><code> str(quality)
'data.frame':   131 obs. of  14 variables:
 $ MemberID            : int  1 2 3 4 5 6 7 8 9 10 ...
 $ InpatientDays       : int  0 1 0 0 8 2 16 2 2 4 ...
 $ ERVisits            : int  0 1 0 1 2 0 1 0 1 2 ...
 $ OfficeVisits        : int  18 6 5 19 19 9 8 8 4 0 ...
 $ Narcotics           : int  1 1 3 0 3 2 1 0 3 2 ...
 $ DaysSinceLastERVisit: num  731 411 731 158 449 ...
 $ Pain                : int  10 0 10 34 10 6 4 5 5 2 ...
 $ TotalVisits         : int  18 8 5 20 29 11 25 10 7 6 ...
 $ ProviderCount       : int  21 27 16 14 24 40 19 11 28 21 ...
 $ MedicalClaims       : int  93 19 27 59 51 53 40 28 20 17 ...
 $ ClaimLines          : int  222 115 148 242 204 156 261 87 98 66 ...
 $ StartedOnCombination: logi  FALSE FALSE FALSE FALSE FALSE FALSE ...
 $ AcuteDrugGapSmall   : int  0 1 5 0 0 4 0 0 0 0 ...
 $ PoorCare            : int  0 0 0 0 0 1 0 0 1 0 ...



table(is.na(quality))
FALSE 
1834
</code></pre>

<p>My data does not contain any NA values.</p>

<pre><code>set.seed(100)
split &lt;- sample.split(quality$PoorCare, SplitRatio = .5)
train &lt;-subset(quality, split ==TRUE)
test &lt;- subset(quality, split ==FALSE)
</code></pre>

<p>Building the model using all variable </p>

<pre><code>log.Quality &lt;- glm(PoorCare ~ ., data = train, family = 'binomial')

summary(log.Quality)      
Call:
glm(formula = PoorCare ~ ., family = ""binomial"", data = train)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.5679  -0.6384  -0.3604  -0.1154   2.1298  

Coefficients: (1 not defined because of singularities)
                          Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)              -3.583178   1.807020  -1.983   0.0474 *
MemberID                 -0.008742   0.010988  -0.796   0.4263  
InpatientDays            -0.106578   0.095632  -1.114   0.2651  
ERVisits                  0.275225   0.310364   0.887   0.3752  
OfficeVisits              0.126433   0.066140   1.912   0.0559 .
Narcotics                 0.190862   0.106890   1.786   0.0742 .
DaysSinceLastERVisit     -0.001221   0.002026  -0.603   0.5467  
Pain                     -0.020104   0.023057  -0.872   0.3832  
TotalVisits                     NA         NA      NA       NA  
ProviderCount             0.046297   0.040637   1.139   0.2546  
MedicalClaims             0.025123   0.030564   0.822   0.4111  
ClaimLines               -0.010384   0.012746  -0.815   0.4152  
StartedOnCombinationTRUE  2.205058   1.724923   1.278   0.2011  
AcuteDrugGapSmall         0.217813   0.139890   1.557   0.1195  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 72.549  on 64  degrees of freedom
Residual deviance: 49.213  on 52  degrees of freedom
AIC: 75.213

Number of Fisher Scoring iterations: 6
</code></pre>

<p>Can anyone provide me a good explanation why this is happening ? </p>
"
"0.280239239603615","0.262244027242874","213982","<p>I am trying to use ""propodds""  in the VGAM function in R, but am not sure if I am doing it right and don't really understand how to analyze the output I got so far to check to see if I am using it right. Any help on how to correctly use ""propodds"" or analyze the output would be appreciated. This is what I have so far:</p>

<pre><code>    &gt; fittest &lt;-vglm(rp ~ is.native + is.male + age2 + is.debt + oh + ms + cjs, propodds, data = dummydata2)
&gt; fittest
Call:
vglm(formula = rp ~ is.native + is.male + age2 + is.debt + oh + 
    ms + cjs, family = propodds, data = dummydata2)

    Coefficients:
(Intercept):1 (Intercept):2 (Intercept):3 (Intercept):4 (Intercept):5     is.native 
  2.827674173  -0.463602645  -0.474290665  -0.614877500  -2.514394420  -0.063546621 
      is.male          age2       is.debt            oh            ms           cjs 
  0.114052675   0.067835161  -0.058563607  -0.089420626   0.109135966   0.003937505 

Degrees of Freedom: 52000 Total; 51988 Residual
Residual deviance: 24702.04 
Log-likelihood: -12351.02 
&gt; summary(fittest)

Call:
vglm(formula = rp ~ is.native + is.male + age2 + is.debt + oh + 
    ms + cjs, family = propodds, data = dummydata2)

Pearson residuals:
                    Min      1Q  Median      3Q     Max
logit(P[Y&gt;=2])  -5.1080  0.1300  0.2803  0.3016  0.3335
logit(P[Y&gt;=3])  -0.6976 -0.5876 -0.5490  0.5937 14.7717
logit(P[Y&gt;=4]) -13.1157 -0.5173 -0.4831  0.6080  3.0626
logit(P[Y&gt;=5])  -4.0174 -0.4072 -0.3746  1.0167  1.2176
logit(P[Y&gt;=6])  -0.6164 -0.5749 -0.1610 -0.1541  3.6060

Coefficients:
               Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept):1  2.827674   0.079827  35.423  &lt; 2e-16 ***
(Intercept):2 -0.463603   0.068894  -6.729 1.71e-11 ***
(Intercept):3 -0.474291   0.068901  -6.884 5.83e-12 ***
(Intercept):4 -0.614878   0.069009  -8.910  &lt; 2e-16 ***
(Intercept):5 -2.514394   0.074892 -33.573  &lt; 2e-16 ***
is.native     -0.063547   0.062409  -1.018  0.30857    
is.male        0.114053   0.039694   2.873  0.00406 ** 
age2           0.067835   0.024789   2.737  0.00621 ** 
is.debt       -0.058564   0.052983  -1.105  0.26902    
oh            -0.089421   0.057526  -1.554  0.12008    
ms             0.109136   0.041587   2.624  0.00868 ** 
cjs            0.003938   0.043653   0.090  0.92813    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

Number of linear predictors:  5 

Names of linear predictors: 
logit(P[Y&gt;=2]), logit(P[Y&gt;=3]), logit(P[Y&gt;=4]), logit(P[Y&gt;=5]), logit(P[Y&gt;=6])

Dispersion Parameter for cumulative family:   1

Residual deviance: 24702.04 on 51988 degrees of freedom

Log-likelihood: -12351.02 on 51988 degrees of freedom

Number of iterations: 4 

Exponentiated coefficients:
is.native   is.male      age2   is.debt        oh        ms       cjs 
0.9384304 1.1208112 1.0701889 0.9431182 0.9144608 1.1153140 1.0039453 
</code></pre>

<p>A little background on my data that may help: I am trying to determine if risk preferences (variable ""rp"" in the code) is determined by immigration status (variable ""is.native"" in the code, which is a dummy variable where 0 = native and 1 = immigrant). I have a few factors that I want to control for since they may affect risk preferences [age2, is.debt, oh(owns home), ms (marital status), and cjs (current job status)]. Based on similar research the best way to analyze this is the cumulative logistic regression and they seemed to look at the proportional odds. The data came from the 2014 Health and Retirement Study which is representative of the US population over age 50. There are about 20,000 participants. </p>

<p>I'm not sure if my model is formatted correctly. ""rp"" has 6 categories - a control group, low risk tolerance (rt), some rt, high rt, substantial rt and ""ignore"" which is answers of ""don't know"" or ""NA"".  All other variables are dummy variables with only options for ""0"" or ""1"" besides ""age2"" which has 6 categories (under 50, 50-60, 60-70, 70-80, 80-90, 90+). Are these dummy variables appropriate to use or should I just use the actual answers provided by the participants?</p>

<p>I know the significant codes in the ""summary"" section tell me gender, age, and marital status are significant at the 1% significance level, but I don't understand any of the other results. Such as, what does it mean that all the intercepts are significant? Is the model as a whole significant? What is the dispersion parameter? What are the exponentiated coefficients? </p>
"
"0.125326797943307","0.125656172487509","214892","<p>I'm trying to construct a univariate prediction model using logistic regression in order to predict credit default likelihood from overdue level in telecommunication companies:</p>

<p><a href=""https://drive.google.com/open?id=0BzdYGYN6vfqBeDdKRDFpelFKbTg"" rel=""nofollow"">https://drive.google.com/open?id=0BzdYGYN6vfqBeDdKRDFpelFKbTg</a></p>

<p>For this, I used the function glm and found two problematic ranks:
        RANK_OVERDUE between S/. 3,000 and S/. 5,000 &amp; RANK_OVERDUE More than S/. 5,000.</p>

<p>which have p-values of 0.946 and 0.473:</p>

<pre><code>Call:
glm(formula = impago ~ MONTO_VENCIDO_DOC_IMPAGOS, family = binomial, 
    data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.1355  -0.0569  -0.0569  -0.0569   3.5855  

Coefficients:
                                                  Estimate
(Intercept)                                       -6.42627
RANK_OVERDUE&lt;S/. 0 - S/. 500]         0.69763
RANK_OVERDUE&lt;S/. 1,500 - S/. 3,000]   1.73952
RANK_OVERDUE&lt;S/. 3,000 - S/. 5,000] -10.13980
RANK_OVERDUE&lt;S/. 500 - 1,500]         1.13854
RANK_OVERDUEMÃ¡s de S/. 5,000          0.71916
</code></pre>

<p></p>

<pre><code>                                                 Pr(&gt;|z|)    
(Intercept)                                       &lt; 2e-16 ***
RANK_OVERDUE&lt;S/. 0 - S/. 500]       1.78e-15 ***
RANK_OVERDUE&lt;S/. 1,500 - S/. 3,000] 2.51e-05 ***
RANK_OVERDUE&lt;S/. 3,000 - S/. 5,000]    0.946    
RANK_OVERDUE&lt;S/. 500 - 1,500]       1.23e-06 ***
RANK_OVERDUEMÃ¡s de S/. 5,000           0.473    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 9683.9  on 345828  degrees of freedom
Residual deviance: 9603.5  on 345823  degrees of freedom
AIC: 9615.5

Number of Fisher Scoring iterations: 15
</code></pre>

<p>I would need to know what options I have on order to deal with this situation. Should these ranks be included in the model? I tried to join them into one (overdue over S/. 3,000) but when applying again the model, it continued to be not significant (I obtained a p-value of 0.919).</p>
"
"0.289931889054769","0.307793505625546","216122","<p>As far as I know, the difference between logistic model and fractional response model (frm) is that the dependent variable (Y) in which frm is [0,1], but logistic is {0, 1}. Further, frm uses the quasi-likelihood estimator to determine its parameters. </p>

<p>Normally, we can use <code>glm</code> to obtain the logistic models by <code>glm(y ~ x1+x2, data = dat, family = binomial(logit))</code>. </p>

<p>For frm, we change <code>family = binomial(logit)</code> to <code>family = quasibinomial(logit)</code>.  </p>

<p>I noticed we can also use <code>family = binomial(logit)</code> to obtain frm's parameter since it gives the same estimated values. See the following example</p>

<pre><code>library(foreign)
mydata &lt;- read.dta(""k401.dta"")


glm.bin &lt;- glm(prate ~ mrate + age + sole + totemp, data = mydata
,family = binomial('logit'))
summary(glm.bin)
</code></pre>

<p>return,</p>

<pre><code>Call:
glm(formula = prate ~ mrate + age + sole + totemp, family = binomial(""logit""), 
    data = mydata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.1214  -0.1979   0.2059   0.4486   0.9146  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)  1.074e+00  8.869e-02  12.110  &lt; 2e-16 ***
mrate        5.734e-01  9.011e-02   6.364 1.97e-10 ***
age          3.089e-02  5.832e-03   5.297 1.17e-07 ***
sole         3.636e-01  9.491e-02   3.831 0.000128 ***
totemp      -5.780e-06  2.207e-06  -2.619 0.008814 ** 
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1166.6  on 4733  degrees of freedom
Residual deviance: 1023.7  on 4729  degrees of freedom
AIC: 1997.6

Number of Fisher Scoring iterations: 6
</code></pre>

<p>And for <code>family = quasibinomial('logit')</code>,</p>

<pre><code>glm.quasi &lt;- glm(prate ~ mrate + age + sole + totemp, data = mydata
,family = quasibinomial('logit'))
summary(glm.quasi)
</code></pre>

<p>return,</p>

<pre><code>Call:
glm(formula = prate ~ mrate + age + sole + totemp, family = quasibinomial(""logit""), 
    data = mydata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.1214  -0.1979   0.2059   0.4486   0.9146  

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.074e+00  4.788e-02  22.435  &lt; 2e-16 ***
mrate        5.734e-01  4.864e-02  11.789  &lt; 2e-16 ***
age          3.089e-02  3.148e-03   9.814  &lt; 2e-16 ***
sole         3.636e-01  5.123e-02   7.097 1.46e-12 ***
totemp      -5.780e-06  1.191e-06  -4.852 1.26e-06 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for quasibinomial family taken to be 0.2913876)

    Null deviance: 1166.6  on 4733  degrees of freedom
Residual deviance: 1023.7  on 4729  degrees of freedom
AIC: NA

Number of Fisher Scoring iterations: 6
</code></pre>

<p>The estimated Beta from both <code>family</code> are the same, but the difference is the SE values.  However, to obtain the correct SE, we have to use <code>library(sandwich)</code> as in this <a href=""http://stackoverflow.com/questions/37584715/fractional-response-regression-in-r"">post</a>.</p>

<p>Now, my questions:</p>

<ol>
<li>What is the difference between these two codes?</li>
<li>Is frm about to obtain robust SE?</li>
</ol>

<p>If my understanding is not correct, please give some suggestions.</p>
"
"0.228814380978138","0.229415733870562","218738","<p>I want to build a linear regression model where I predict a mean of a group of participants (how they rate something on average). Predictors should be </p>

<ol>
<li>age (continuous)</li>
<li>origin (deviation coded, each level compared to grand mean, levels=1,2,3,4)</li>
<li>education (Helmert coded, each level compared to subsequent ones, haven't decided on number of levels yet)</li>
<li>gender/sex (dummy coded, 0/1)</li>
</ol>

<p>Following questions:</p>

<p><strong>1.</strong> In R, I use the following code for the coding, for example for 4) sex:</p>

<pre><code>    data$sex &lt;- factor(data$sex, labels=c(""1"",""2"")) 
    contr.treatment(2) 
    contrasts(data$sex) = contr.treatment(2)  
</code></pre>

<p>That gives me the right (dummy) coding, for the other 2 and 3 a little differently. Can I use run this kind of code for each predictor (except age) and then throw all predictors into a model like this:</p>

<pre><code>    model &lt;- lm(Mean ~ age +  sex + educ..., data)
</code></pre>

<p>It seems wrong because: what is the common intercept going to be with these different coding systems? It's different for each coding system.
But then, how am I going to enter these different predictors into a model?</p>

<p><strong>2.</strong> Can I leave age in there as it is, unchanged, continuous?</p>

<p><strong>3. Quite a different question:</strong> This is my <em>participant analysis</em>. For the <em>item analysis</em>, I used a logistic regression based on medians instead of means. That's because I did four rating surveys with Likert scales. 4 surveys - 4 participant groups - each group rated the items on <strong>one</strong> property only, such that each item was rated on 4 properties by different people.</p>

<p>Given this, is it okay if I use linear models and means in this analysis now? And can I even build my model as I suggested above?</p>

<p><strong>Many thanks</strong> for any input! I've been trying some things, but confusion isn't fading yet...</p>
"
"0.191439846060547","0.191942973987479","219828","<p>I am doing logistic regression in R on a binary dependent variable with only one independent variable. I found the odd ratio as 0.99 for an outcomes. This can be shown in following. Odds ratio is defined as, $ratio_{odds}(H) = \frac{P(X=H)}{1-P(X=H)}$. As given earlier $ratio_{odds} (H) = 0.99$ which implies that $P(X=H) = 0.497$ which is close to 50% probability. This implies that the probability for having a H cases or non H cases 50% under the given condition of independent variable. This does not seem realistic from the data as only ~20% are found as H cases. Please give clarifications and proper explanations of this kind of cases in logistic regression.</p>

<p>I am hereby adding the results of my model output:</p>

<pre><code>M1 &lt;- glm(H~X, data=data, family=binomial())
summary(M1)

Call:
glm(formula = H ~ X, family = binomial(), data = data)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.8563   0.6310   0.6790   0.7039   0.7608  

Coefficients:
                Estimate      Std. Error      z value     Pr(&gt;|z|)    
(Intercept)    1.6416666      0.2290133      7.168      7.59e-13 ***
   X          -0.0014039      0.0009466     -1.483      0.138    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1101.1  on 1070  degrees of freedom
Residual deviance: 1098.9  on 1069  degrees of freedom
  (667 observations deleted due to missingness)
AIC: 1102.9

Number of Fisher Scoring iterations: 4


exp(cbind(OR=coef(M1), confint(M1)))
Waiting for profiling to be done...
                                      OR           2.5 %       97.5 %
(Intercept)                    5.1637680       3.3204509     8.155564
     X                         0.9985971       0.9967357     1.000445
</code></pre>

<p>I have 1738 total dataset, of which H is a dependent binomial variable. There are 19.95% fall in (H=0) category and remaining are in (H=1) category. Further this binomial dependent variable compare with the covariate X whose minimum value is 82.23, mean value is 223.8 and maximum value is 391.6. The 667 missing values correspond to the covariate X i.e 667 data for X is missing in the dataset out of 1738 data.</p>
"
"0.245689666817022","0.281526137231115","221510","<p>I'm new to logistic regression analysis, and was unable to find an answer elsewhere in Cross Validated or Stack Overflow. </p>

<p>Consider a standard logistic regression analysis of a binary outcome (admission to college) based on continuous covariates gre score and high school gpa, and ordinal categorical rank prestige of the undergraduate institution (data from the nice UCLA stats dept. logistic regression in R tutorial: <a href=""http://www.ats.ucla.edu/stat/r/dae/logit.htm"" rel=""nofollow"">http://www.ats.ucla.edu/stat/r/dae/logit.htm</a>)</p>

<pre><code>&gt; admissions.data &lt;- read.csv(""http://www.ats.ucla.edu/stat/data/binary.csv"")
&gt; admissions.data$rank &lt;- as.factor(admissions.data$rank)
&gt; summary(admissions.data)
     admit             gre             gpa        rank
 Min.   :0.0000   Min.   :220.0   Min.   :2.260   1: 61
 1st Qu.:0.0000   1st Qu.:520.0   1st Qu.:3.130   2:151
 Median :0.0000   Median :580.0   Median :3.395   3:121
 Mean   :0.3175   Mean   :587.7   Mean   :3.390   4: 67
 3rd Qu.:1.0000   3rd Qu.:660.0   3rd Qu.:3.670
 Max.   :1.0000   Max.   :800.0   Max.   :4.000

&gt; fit1 &lt;- glm(admit ~ gre + gpa + rank, data = admissions.data, family=""binomial"")
&gt; summary(fit1)

Call:
glm(formula = admit ~ gre + gpa + rank, family = ""binomial"",
    data = admissions.data)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-1.6268  -0.8662  -0.6388   1.1490   2.0790

Coefficients:
             Estimate Std. Error z value Pr(&gt;|z|)
(Intercept) -3.989979   1.139951  -3.500 0.000465 ***
gre          0.002264   0.001094   2.070 0.038465 *
gpa          0.804038   0.331819   2.423 0.015388 *
rank2       -0.675443   0.316490  -2.134 0.032829 *
rank3       -1.340204   0.345306  -3.881 0.000104 ***
rank4       -1.551464   0.417832  -3.713 0.000205 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 499.98  on 399  degrees of freedom
Residual deviance: 458.52  on 394  degrees of freedom
AIC: 470.52

Number of Fisher Scoring iterations: 4

# Odds Ratios
&gt; exp(coef(fit1))
(Intercept)         gre         gpa       rank2       rank3       rank4
  0.0185001   1.0022670   2.2345448   0.5089310   0.2617923   0.2119375

# 95% confidence intervals
&gt; exp(confint(fit1))
Waiting for profiling to be done...
                  2.5 %    97.5 %
(Intercept) 0.001889165 0.1665354
gre         1.000137602 1.0044457
gpa         1.173858216 4.3238349
rank2       0.272289674 0.9448343
rank3       0.131641717 0.5115181
rank4       0.090715546 0.4706961
</code></pre>

<p>My questions are:</p>

<p>1) In R, is there a straight-forward way to determine ORs with 95% CIs for specific values of the covariates? E.g., based on this model, what are the odds of college acceptance for students applying to a rank 2 schools with a gpa of 3 and a gre score of 750, compared with a student applying to a rank 3 school with the same gpa and gre score? I could calculate ORs by hand given the model coefficient estimates and these specific covariate values, but am unsure how to correctly propagate SEs to calculate 95% CIs.</p>

<p>2) Would this particular example be considered a case-control study design, and therefore odds ratios could be estimated, but not predictions? (See: <a href=""http://stats.stackexchange.com/questions/69561/case-control-study-and-logistic-regression"">Case-control study and Logistic regression</a>)</p>
"
"0.217072381587726","0.217642875033004","225697","<p>Let me give a simple example,</p>

<pre><code>set.seed(100)
disease = sample(c(0,1),100,replace = TRUE)
snp1 = sample(c(""AA"",""AB"",""BB""),100,replace = TRUE)
snp2 = sample(c(""XX"",""XY"",""YY""),100,replace = TRUE)

summary(glm(disease~snp1*snp2, family = binomial))
</code></pre>

<p>output1</p>

<pre><code>Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.55176  -0.94003  -0.00649   0.90052   1.53535  

Coefficients:
                Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)   -8.109e-01  6.009e-01  -1.349   0.1772  
snp1AB         5.232e-01  9.718e-01   0.538   0.5903  
snp1BB         1.504e+00  8.580e-01   1.753   0.0796 .
snp2XY         4.074e-16  8.498e-01   0.000   1.0000  
snp2YY         1.504e+00  9.280e-01   1.621   0.1051  
snp1AB:snp2XY  1.135e+00  1.335e+00   0.850   0.3952  
snp1BB:snp2XY  1.542e-01  1.254e+00   0.123   0.9022  
snp1AB:snp2YY -1.216e+00  1.333e+00  -0.912   0.3616  
snp1BB:snp2YY -2.785e+00  1.244e+00  -2.239   0.0252 *
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 138.63  on 99  degrees of freedom
Residual deviance: 127.71  on 91  degrees of freedom
AIC: 145.71
</code></pre>

<p>Output2</p>

<pre><code>snp12 = interaction(snp1,snp2)
summary(glm(disease~snp12, family = binomial))


Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.55176  -0.94003  -0.00649   0.90052   1.53535  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept) -8.109e-01  6.009e-01  -1.349   0.1772  
snp12AB.XX   5.232e-01  9.718e-01   0.538   0.5903  
snp12BB.XX   1.504e+00  8.580e-01   1.753   0.0796 .
snp12AA.XY  -3.990e-16  8.498e-01   0.000   1.0000  
snp12AB.XY   1.658e+00  9.150e-01   1.812   0.0700 .
snp12BB.XY   1.658e+00  9.150e-01   1.812   0.0700 .
snp12AA.YY   1.504e+00  9.280e-01   1.621   0.1051  
snp12AB.YY   8.109e-01  8.333e-01   0.973   0.3305  
snp12BB.YY   2.231e-01  8.199e-01   0.272   0.7855  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 138.63  on 99  degrees of freedom
Residual deviance: 127.71  on 91  degrees of freedom
AIC: 145.71

Number of Fisher Scoring iterations: 4
</code></pre>

<p>So here I did a logistic regression for interaction between, lets say 2 mutations (each with 3 categories). Like shown above I can do it in 2 ways. My questions are,</p>

<ol>
<li>Are both output1 and output2 same ? </li>
<li>If same, which one is more appropriate?</li>
<li>How to interpret the coefficients (and odds ratios) in each case?</li>
</ol>
"
"0.260888534100544","0.261574181890298","228316","<p>I want to predict a binary response variable <code>y</code> using logistic regression. <code>x1</code> to <code>x4</code> are the log  of continuous variables and <code>x5</code> to <code>x7</code> are binary variables. </p>

<pre><code>Call:
glm(formula = y ~ x1 + x2 + x3 + x4 + x5 + 
    x6 + x7, family = binomial(), data = df)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6604  -0.5712   0.4691   0.6242   2.4095  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   -2.84633    0.31609  -9.005  &lt; 2e-16 ***
x1             0.14196    0.04828   2.940  0.00328 ** 
x2             4.05937    0.22702  17.881  &lt; 2e-16 ***
x3            -0.83492    0.08330 -10.023  &lt; 2e-16 ***
x4             0.05679    0.02109   2.693  0.00709 ** 
x5             0.08741    0.18955   0.461  0.64467    
x6            -2.21632    0.53202  -4.166  3.1e-05 ***
x7             0.25282    0.15716   1.609  0.10769    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1749.5  on 1329  degrees of freedom
Residual deviance: 1110.5  on 1322  degrees of freedom
AIC: 1126.5

Number of Fisher Scoring iterations: 5
</code></pre>

<p>The output of the GLM shows that most of my variables are significant for my model, but the various goodness of fit test I have done:</p>

<pre><code>anova &lt;- anova(model, test = ""Chisq"")   # Anova
1 - pchisq(sum(anova$Deviance, na.rm = TRUE),df = 7) # Null Model vs Most Complex Model
1 - pchisq(model$null.deviance - model$deviance, 
           df = (model$df.null - model$df.residual )) # Null Deviance - Residual Deviance ~ X^2
hoslem.test(model$y, model$fitted.values, g = 8)     # Homer Lemeshow test
pR2(model)                                            # Pseudo-R^2
</code></pre>

<p>tell me that there is a lack of evidence to support my model.</p>

<p>More over, I have a bimodal deviance plot. I suspect the bimodal distribution is caused by the sparsity of my binary variables.
 <a href=""http://i.stack.imgur.com/J27fL.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/J27fL.png"" alt=""enter image description here""></a></p>

<p>So I calculated the absolute error <code>abs(y - y_hat)</code>, and obtained the following:</p>

<ul>
<li>77% of my absolute errors were in [0;0.25], which I think is very good!</li>
</ul>

<p>On the following plot, Y=1 is red, and Y=0 is green. This model is better at predicting when Y will be 1 than 0.</p>

<p><a href=""http://i.stack.imgur.com/ZEGuv.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/ZEGuv.png"" alt=""enter image description here""></a></p>

<p>My question is thus the following:</p>

<p>The goodness of fit tests all assume that my null hypothesis follows a Chi square distribution of some sort. Is it correct to conclude that based on my absolute error, my model's prediction is OK, it's just that it doesn't follow a Chi square distribution and thus perform poorly with these tests? </p>
"
"0.191439846060547","0.191942973987479","229336","<p>I have a data set looking into whether a farm experienced a livestock disease or not in the year 2011 and 2012  and if several factors could be predictors for the livestock disease.</p>

<p>The independent variables were also collected for both years though some variables did not change e.g Thistles remained the same for both years.</p>

<p>I am looking for an appropriate method that will allow statistical comparison between the two years rather than treating analysis as two separate sets of analyses (i.e not to treating 2011 and 2012 as two separate data set)</p>

<p>Whilst trying to do the analysis I have created dependent variable as farm having the disease or not between year 2011 and 2012(Orf.Yes.No2011.2012)against the dependent variables using logistic regression:</p>

<p>I'm just wondering whether I doing the right thing or what could be the best statistical approach which will allow for statistical comparison between the two years? Any help will be very much appreciated</p>

<pre><code>Here is the R output and sample of dataset:





 &gt; mod=glm(Orf.Yes.No2011.2012~F2011+ F2012+as.factor(Breed)+ 
                                  D2011+D2012,family=binomial, data=orf)
      summary(mod)

    Call:
    glm(formula = Orf.Yes.No2011.2012 ~ F2011 + F2012 + as.factor(Breed) + 
        D2011 + D2012, family = binomial, data = orf)

    Deviance Residuals: 
       Min      1Q  Median      3Q     Max  
    -1.862  -1.293   1.023   1.065   1.318  

    Coefficients:
                        Estimate Std. Error z value Pr(&gt;|z|)  
    (Intercept)        0.3917290  0.1626769   2.408    0.016 *
    F2011              0.0003269  0.0002782   1.175    0.240  
    F2012             -0.0003596  0.0002786  -1.291    0.197  
    as.factor(Breed)2  0.0558285  0.1489246   0.375    0.708  
    D2011             -0.0311978  0.0272068  -1.147    0.252  
    D2012              0.0226963  0.0274981   0.825    0.409  
    Small sample data set:

    F2011   F2012   Breed   Orf.Yes.No2011  Orf.Yes.No2012  Orf.Yes.No2011.2012
    155     150     1       0               0               0
    740     760     2       0               1               1
    1000    850     1       0               0               0
    1630    1520    1       1               1               1
    0       460     1       0               0               0
    1300    1335    1       0               1               1
    450     450     1       0               0               0
    390     730     1       1               0               1
    390     380     2       0               0               0
    600     600     2       0               0               0
</code></pre>
"
"0.434303412829269","0.423676037842065","231872","<p>For a better understanding of how r is conducting a logistic regression I created the following test-data (the two predictors and the criterion are binary variables):</p>

<pre><code>   UV1 UV2 AV
1    1   1  1
2    1   1  1
3    1   1  1
4    1   1  1
5    1   1  1
6    1   1  1
7    1   1  1
8    0   0  1
9    0   0  1
10   0   0  1
11   1   1  0
12   1   1  0
13   1   0  0
14   1   0  0
15   1   0  0
16   1   0  0
17   1   0  0
18   0   0  0
19   0   0  0
20   0   0  0
</code></pre>

<p>AV = dependent variable/criterion</p>

<p>UV1 / UV2 = both independant variables/predictors</p>

<p>For measuring the UVs effect on the AV a logistic regression is necessary, as the AV is a binary variable. Hence i used the following code</p>

<pre><code>&gt; lrmodel &lt;- glm(AV ~ UV1 + UV2, data = lrdata, family = ""binomial"")
</code></pre>

<p>including <strong>""family = ""binomial""""</strong>. Is this correct ( I think so :-))?</p>

<p>Regarding my test-data, I was wondering about the whole model, especially
the estimators and sigificance:</p>

<pre><code>&gt; summary(lrmodel)


Call:
glm(formula = AV ~ UV1 + UV2, family = ""binomial"", data = lrdata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-1.7344  -0.2944   0.3544   0.7090   1.1774  

Coefficients:
              Estimate Std. Error z value Pr(&gt;|z|)
(Intercept) -4.065e-15  8.165e-01   0.000    1.000
UV1         -1.857e+01  2.917e+03  -0.006    0.995
UV2          1.982e+01  2.917e+03   0.007    0.995

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 27.726  on 19  degrees of freedom
Residual deviance: 17.852  on 17  degrees of freedom
AIC: 23.852

Number of Fisher Scoring iterations: 17
</code></pre>

<ol>
<li><p>Why is UV2 not significant. See therefore that for group AV = 1 there are 7 cases with UV2 = 1, and for group AV = 0 there are only 3 cases with UV2 = 1. 
I was expecting that UV2 is a significant discriminator.</p></li>
<li><p>Despite the not-significance of the UVs, the estimators are - in my opinion- very high (e.g. for UV2 = 1.982e+01). How is this possible?</p></li>
<li><p>Why isn't the intercept 0,5?? We have 5 cases with AV = 1 and 5 cases with AV = 0.</p></li>
</ol>

<p>Further: I created UV1 as a predictor I expected not to be significant:  for group AV = 1 there are 5 cases withe UV1 = 1, and for group AV = 0 there are 5 cases withe UV1 = 1 as well.</p>

<p>The whole ""picture"" I gained from the logistic is confusing me...</p>

<p>What was consuming me more:
When I run a ""NOT-logistic"" regression (by omitting <strong>""family = ""binomial""</strong>)</p>

<pre><code>&gt; lrmodel &lt;- glm(AV ~ UV1 + UV2, data = lrdata,)
</code></pre>

<p>I get the expected results</p>

<pre><code>Call:
glm(formula = AV ~ UV1 + UV2, data = lrdata)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.7778  -0.1250   0.1111   0.2222   0.5000  

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   0.5000     0.1731   2.889  0.01020 * 
UV1          -0.5000     0.2567  -1.948  0.06816 . 
UV2           0.7778     0.2365   3.289  0.00433 **
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for gaussian family taken to be 0.1797386)

    Null deviance: 5.0000  on 19  degrees of freedom
Residual deviance: 3.0556  on 17  degrees of freedom
AIC: 27.182

Number of Fisher Scoring iterations: 2
</code></pre>

<ol>
<li>UV1 is not significant! :-)</li>
<li>UV2 has an positive effect on AV = 1! :-)</li>
<li>The intercept is 0.5! :-)</li>
</ol>

<p>My overall question: Why isn't logistic regression (including ""family = ""binomial"") producing results as expected, but a ""NOT-logistic"" regression (not including ""family = ""binomial"") does?</p>

<p>Update:
are the observations described above because of the correlation of UV1 and UV 2. Corr = 0.56
After manipulating the UV2's data </p>

<p>AV: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0</p>

<p>UV1: 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0</p>

<p>UV2: <strong>0, 0, 0,</strong> 1, 1, 1, 1, <strong>1, 1, 1</strong>, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0</p>

<p>(I changed the positions of the three 0s with the three 1s in UV2 to gain a correlation &lt; 0.1 between UV1 and UV2) hence:</p>

<pre><code>UV1 UV2 AV
1    1   0  1
2    1   0  1
3    1   0  1
4    1   1  1
5    1   1  1
6    1   1  1
7    1   1  1
8    0   1  1
9    0   1  1
10   0   1  1
11   1   1  0
12   1   1  0
13   1   0  0
14   1   0  0
15   1   0  0
16   1   0  0
17   1   0  0
18   0   0  0
19   0   0  0
20   0   0  0
</code></pre>

<p>to avoid correlation, my results come closer to my expectations:</p>

<pre><code>Call:
glm(formula = AV ~ UV1 + UV2, family = ""binomial"", data = lrdata)

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-1.76465  -0.81583  -0.03095   0.74994   1.58873  

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)  -1.1248     1.0862  -1.036   0.3004  
UV1           0.1955     1.1393   0.172   0.8637  
UV2           2.2495     1.0566   2.129   0.0333 *
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 27.726  on 19  degrees of freedom
Residual deviance: 22.396  on 17  degrees of freedom
AIC: 28.396

Number of Fisher Scoring iterations: 4
</code></pre>

<p>But why does the correlation influence the results of the logistic regression and not the results of the ""not-logistic"" regression? </p>
"
"0.10232890201933","0.102597835208515","233063","<p>I have created a logistic regression in R and would like to use the trained model to create an predict function (lets say in Excel).  How can I convert the coefficients into a predict equation?</p>

<pre><code>glm(formula = is_bad ~ is_rent + dti + bc_util + open_acc +    pub_rec_bankruptcies + 
chargeoff_within_12_mths, family = binomial, data = df)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.8659  -0.5413  -0.4874  -0.4322   2.4289  

Coefficients:
                            Estimate Std. Error  z value Pr(&gt;|z|)    
(Intercept)              -2.9020574  0.0270641 -107.229  &lt; 2e-16 ***
is_rentTRUE               0.3105513  0.0128643   24.141  &lt; 2e-16 ***
dti                       0.0241821  0.0008331   29.025  &lt; 2e-16 ***
bc_util                   0.0044706  0.0002561   17.458  &lt; 2e-16 ***
open_acc                  0.0030552  0.0012694    2.407   0.0161 *  
pub_rec_bankruptcies      0.1117733  0.0163319    6.844 7.71e-12 ***
chargeoff_within_12_mths -0.0268015  0.0564621   -0.475   0.6350    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 173006  on 233017  degrees of freedom
Residual deviance: 170914  on 233011  degrees of freedom
(2613 observations deleted due to missingness)
AIC: 170928

Number of Fisher Scoring iterations: 4
</code></pre>
"
