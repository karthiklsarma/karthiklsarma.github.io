"V1","V2","V3","V4"
"0.0944384329299771","0.0936585811581694","  6513","<p>I want to predict inter-day electricity load. My data are electricity loads for 11 months, sampled in 30 minute intervals. I also got the weather-specific data from a meteorological station (temperature, relative humidity, wind direction, wind speed, sunlight). From this, I want to predict the electricity load until the end of the day. </p>

<p>I can run my algorithm until 10:00 of the present day and after that it should give the prediction of loads in 30 minute intervals. So, it should tell the load at 10:30, 11:00, 11:30 and so on until 24:00.</p>

<p>My first attempt was to create a <strong>linear model</strong> in R.</p>

<pre><code>BP.TS &lt;- ts(Buying.power, frequency = 48)
a &lt;- data.frame(
Time, BP.TS, Weekday, Pressure, Temperature, RelHumidity, AvgWindSpeed, AvgWindDirection, MaxWindSpeed, MaxWindDirection, SunLightTime,
m, Buying.2dayago, AfterHolidayAndBPYesterday8, MovingAvgLast7DaysMidnightTemp
)
a &lt;- a[(6*48+1):nrow(a),]

start = 9716
steps.ahead = 21
par(mfrow=c(5,2))
for (i in 1:10) {
    train &lt;- a[1:(start+(i-1)*48),]
    test &lt;- a[((i-1)*48+start+1):((i-1)*48+start+steps.ahead),]
    summary(reg &lt;- lm(log(BP.TS)~., data=train, na.action=NULL))
    pred &lt;- exp(predict(reg, test))

    plot(test$BP.TS, type=""o"")
    lines(pred, col=2)
    cat(""MAE"", mean(abs(test$BP.TS - pred)), ""\n"")
}
</code></pre>

<p>This is not very succesful. Now I try to model the data with ARIMA. I used auto.arima() from the <a href=""http://cran.r-project.org/web/packages/forecast/index.html"">forecast package</a>. These are the results I got:</p>

<pre><code>&gt; auto.arima(BP.TS)
Series: BP.TS 
ARIMA(2,0,1)(1,1,2)[48]                    

Call: auto.arima(x = BP.TS) 

Coefficients:
         ar1      ar2     ma1    sar1     sma1    sma2
      1.1816  -0.2627  -0.554  0.4381  -1.2415  0.3051
s.e.  0.0356   0.0286   0.033  0.0952   0.0982  0.0863

sigma^2 estimated as 256118:  log likelihood = -118939.7
AIC = 237893.5   AICc = 237893.5   BIC = 237947
</code></pre>

<p>Now if I try something like:</p>

<pre><code>reg = arima(train$BP.TS, order=c(2,0,1), xreg=cbind(
train$Time, 
train$Weekday, 
train$Pressure, 
train$Temperature, 
train$RelHumidity, 
train$AvgWindSpeed, 
train$AvgWindDirection, 
train$MaxWindSpeed, 
train$MaxWindDirection, 
train$SunLightTime,
train$Buying.2dayago,
train$MovingAvgLastNDaysLoad,
train$X1, train$X2, train$X3, train$X4, train$X5, train$X6, train$X7, train$X8, train$X9, 
train$X11, train$X12, train$X13, train$X14, train$X15, train$X16, train$X17, train$X18, 
train$MovingAvgLast7DaysMidnightTemp
))

p &lt;- predict(reg, n.ahead=21, newxreg=cbind(
test$Time, 
test$Weekday, 
test$Pressure, 
test$Temperature, 
test$RelHumidity, 
test$AvgWindSpeed, 
test$AvgWindDirection, 
test$MaxWindSpeed, 
test$MaxWindDirection, 
test$SunLightTime,
test$Buying.2dayago,
test$MovingAvgLastNDaysLoad,
test$X1, test$X2, test$X3, test$X4, test$X5, test$X6, test$X7, test$X8, test$X9, 
test$X11, test$X12, test$X13, test$X14, test$X15, test$X16, test$X17, test$X18, 
test$MovingAvgLast7DaysMidnightTemp
))

plot(test$BP.TS, type=""o"", ylim=c(6300,8300))
par(new=T)
plot(p$pred, col=2, ylim=c(6300,8300))
cat(""MAE"", mean(p$se), ""\n"")
</code></pre>

<p>I get even worse results. Why? I ran out of ideas, so please help. If there is additional information I need to give, please ask.</p>
"
"0","0.0573539334676404","  6967","<p>/edit: To clarify: The mtable function from the <a href=""http://cran.r-project.org/web/packages/memisc/index.html"" rel=""nofollow"">memisc</a> package does exactly what I need, but unfortunately does not work with arima models.</p>

<p>Similar to <a href=""http://stats.stackexchange.com/questions/6856/aggregating-results-from-linear-model-runs-r"">this question</a>: I have multiple Arima models, some of which I've also fit with dependent variables. I'd like an easy way to make a table/graph of the coefficients in each model, as well as summary statistics about each model.</p>

<p>Here is some example code:</p>

<pre><code>sim &lt;- arima.sim(list(order = c(1,1,0), ar = 0.7), n = 200)

ar1&lt;-arima(sim,order=c(1,1,0))
ar2&lt;-arima(sim,order=c(2,1,0))
ar3&lt;-arima(sim,order=c(3,1,0))
ar4&lt;-arima(sim,order=c(2,2,1))

#Try mtable
library(memisc)
mtable(""Model 1""=ar1,""Model 2""=ar2,""Model 3""=ar3,""Model 4""=ar4)
#&gt;Error in UseMethod(""getSummary"") : 
#  no applicable method for 'getSummary' applied to an object of class ""Arima""

#Try  apsrtable
library(apsrtable)
apsrtable(""Model 1""=ar1,""Model 2""=ar2,""Model 3""=ar3,""Model 4""=ar4)
#&gt;Error in est/x$se : non-numeric argument to binary operator
</code></pre>
"
"0.057831493196624","0.0573539334676404","  8750","<p>If I have an arima object like <code>a</code>:</p>

<pre><code>set.seed(100)
x1 &lt;- cumsum(runif(100))
x2 &lt;- c(rnorm(25, 20), rep(0, 75))
x3 &lt;- x1 + x2

dummy = c(rep(1, 25), rep(0, 75))

a &lt;- arima(x3, order=c(0, 1, 0), xreg=dummy)
print(a)
</code></pre>

<p>.</p>

<pre><code>Series: x3 
ARIMA(0,1,0)                    

Call: arima(x = x3, order = c(0, 1, 0), xreg = dummy) 

Coefficients:
        dummy
      17.7665
s.e.   1.1434

sigma^2 estimated as 1.307:  log likelihood = -153.74
AIC = 311.48   AICc = 311.6   BIC = 316.67
</code></pre>

<p>How do calculate the R squared of this regression?</p>
"
"0.057831493196624","0","  8868","<p>When doing time series  research in R, I found that <code>arima</code>  provides only the coefficient values and their standard errors of fitted model. However, I also want to get the p-value of the coefficients.</p>

<p>I did not find any function that provides the significance of coef.</p>

<p>So I wish to calculate it by myself, but I don't know the degree of freedom in the t or chisq distribution of the coefficients. So my question is how to get the p-values for the coefficients of fitted arima model in R?</p>
"
"0.100167084494127","0.0993399267798783"," 10697","<p>I'm studying R package dlm. So far it seems very powerful and flexible package, with nice programming interfaces and good documentation.</p>

<p>I've been able to successfully use dlmMLE and dlmModARMA to estimate the parameters of AR(1) process:</p>

<pre><code>u &lt;- arima.sim(list(ar = 0.3), 100)
fit &lt;- dlmMLE(u, parm = c(0.5, sd(u)),
              build = function(x)
                dlmModARMA(ar = x[1], sigma2 = x[2]^2))
fit$par
</code></pre>

<p>Now I'm trying to use similar code to estimate the parameters of simple linear regression model:</p>

<pre><code>r &lt;- rnorm(100)
u &lt;- -1*r + 0.5*rnorm(100)
fit &lt;- dlmMLE(u, parm = c(0, 1),
              build = function(x)
                dlmModReg(x[1]*r, FALSE, dV = x[2]^2))
fit$par
</code></pre>

<p>I expect fit$par to be close to c(-1, 0.5), but I keep getting something like</p>

<pre><code>[1] -0.0002118851  0.4884367070
</code></pre>

<p>The coefficient -1 is not estimated correctly. However, the strange thing is that the variance of the noise is returned correctly.</p>

<p>I understand that max-likelihood estimation might fail given bad initial values, but I observed that the likelihood function returned by dlmLL is very flat in the first coordinate.</p>

<p>So I wonder: can such model be estimated at all using dlm? I believe the model is ""non-singular"", however I'm not sure how the likelihood function is calculated inside the dlm.</p>

<p>Any hint greatly appreciated.</p>
"
"0.057831493196624","0.0573539334676404"," 10750","<p>I have a time series. I want to model it using ARMA, which will be used for forcasting. </p>

<p>In R I am using <code>arima()</code> function to get the coefficients. But <code>arima()</code> requires order(p,d,q) as input. What is the simplest way in R to arrive at a good value for p and q (with d = 0) so that I don't overfit?</p>
"
"0.163572164021906","0.162221421130763"," 13950","<p>As with my previous question, I'm looking at ways to impute missing data in a hierarchical time series data.</p>

<p>With al my other procedures, including the experimentation of imputation packages (<code>Amelia</code>, <code>HoltWinters</code> from <code>Forecast</code> and <code>MICE</code> imputation) I've only been able to use the time series data prior to the missing gap.</p>

<pre><code>     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
2001 220 194 238 190 217 244 242 225 242 259 267 244
2002 212 246 250 236 261 286 265 269 226 267 234 246
2003 202 199 297 272 236 266 235 226 260 183 226 265
2004 211 215 219 213 240 236 273 266 262 244 241 235
2005 212 198 233 251 259 282 305 267 241 264 222 269
2006 182 220 250 287 279 281 286 332 300 272 221 233
2007  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA
2008 193 215 235 242 246 315 326 280 279 239 236 258
2009 246 189 257 241 268 223 260 288 234 260 216 195
</code></pre>

<p>I'm trying to do simple imputation procedure that uses forecasting and backcasting estimates from the time series model. Forecasting using prior data to predict the future and backcasting  using the later data to â€œpredictâ€ the past.</p>

<p>I would then like to combine the forecast and backcast value to use as imputation. After which I will look at the fit etc.</p>

<p>How do I go about this in coding? </p>

<p>For example, I'm able to determine what SARIMA model exist for the first period 2001-end2006. But not the full period (because my basic functions I know from R does not support the NA values.)</p>

<p>This is only for the period 2001-end2006:</p>

<pre><code>ARIMA(2,0,2)(1,0,1)[12] with non-zero mean 

Call: auto.arima(x = ts.datt) 

Coefficients:
         ar1      ar2      ma1     ma2    sar1     sma1  intercept
      1.3610  -0.8258  -1.2407  0.9191  0.8982  -0.7560   244.8374
s.e.  0.0884   0.0960   0.0878  0.1127  0.2190   0.3335     6.1894

sigma^2 estimated as 605.9:  log likelihood = -335.01
AIC = 686.02   AICc = 688.3   BIC = 704.23
</code></pre>

<p>Should I just model the first period, predict by <code>forecast</code>; model then the last period separately and then backcast? How will I do this backcasting (ie. 'predicting' the past)?</p>

<p><strong>EDIT:</strong>
What I'm asking:
1) How do I use the data from years 2008 &amp; 2009 to BACKCAST? I already know how to use 2001-2006 to forecast. </p>

<p>2) How do I determine the SARIMA model for the whole period? (2001-2009) ie. </p>
"
"0.086747239794936","0.114707866935281"," 19549","<p>I have univariate time series data (windspeed at a particular place) measured at 1 hour interval for 5 years. </p>

<p>I used <code>auto.arima()</code> to get the following parameters:</p>

<pre><code>              ar1      ar2     ma1     ma2    intercept
             1.5314  -0.55   -0.1261  0.032    10.1223
     s.e.    0.0105  0.0103   0.011   0.006     0.1211

     sigma^2 estimated as 0.4865 : log likelihood = -83546.65
     AIC = 167105.3   AICc = 167105.3    BIC = 167161    
</code></pre>

<p>I am forecasting using the following equation:</p>

<pre><code>e[t] &lt;- rnorm(1, 0, sqrt(sigma^2))
x[t] &lt;- ar1*x[t-1] + ar2*x[t-2] + e[t] + ma1*e[t-1] + ma2*e[t-2]
</code></pre>

<p>When the result is compared with <code>forecast()</code> function, I get completely different answers. The freq spectrum of <code>forecast()</code> function's output resembles original time-series freq spectrum. While the manual forecast signal looks like noise in freq spectrum.</p>

<p>I can't use <code>forecast()</code> function because the application is in C++. Are the equations correct? What's the right way of forecasting from coefficients?    </p>
"
"0.143125643519168","0.162221421130763"," 20254","<p>With the arima function I found some nice results, however now I have trouble interpreting them for use outside R.
I am currently struggling with the MA terms, here is a short example:</p>

<pre><code>ser=c(1, 14, 3, 9)        #Example series
mod=arima(ser,c(0,0,1))   #From {stats} library
mod

#Series: ser
#ARIMA(0,0,1) with non-zero mean
#
#Coefficients:
#          ma1  intercept
#      -0.9999     7.1000
#s.e.   0.5982     0.8762
#
#sigma^2 estimated as 7.676:  log likelihood = -10.56
#AIC = 27.11   AICc = Inf   BIC = 25.27

mod$resid

#Time Series:
#Start = 1
#End = 4
#Frequency = 1
#[1] -4.3136670  3.1436951 -1.3280435  0.6708065

predict(mod,n.ahead=5)

#$pred
#Time Series:
#Start = 5
#End = 9
#Frequency = 1
#[1] 6.500081 7.100027 7.100027 7.100027 7.100027
#
#$se
#Time Series:
#Start = 5
#End = 9
#Frequency = 1
#[1] 3.034798 3.917908 3.917908 3.917908 3.917908
?arima
</code></pre>

<p>When looking at the specification this formula is presented:
<code>X[t] = a[1]X[t-1] + â€¦ + a[p]X[t-p] + e[t] + b[1]e[t-1] + â€¦ + b[q]e[t-q]</code></p>

<p>Given my choice of AR and MA terms, and considering that I have included a constant this should reduce to:
<code>X[t] =  e[t] + b[1]e[t-1] + constant</code></p>

<p>However this does not hold up when i compare the results from R with manual calculations:
<code>6.500081 != 6.429261 == -0.9999 * 0.6708065 + 7.1000</code></p>

<p>Furthermore I can also not succeed in reproducing the insample errors, assuming i know the first one this should be possible:
<code>-4.3136670 * -0.9999 +7.1000 !=  14 - 3.1436951</code>
<code>3.1436951 * -0.9999 +7.1000 !=   3 + 1.3280435</code>
<code>-1.3280435 * -0.9999 +7.1000 !=  9 - 0.6708065</code></p>

<p>I hope someone can shed some light on this matter so I will actually be able to use the nice results that I have obtained.</p>
"
"0.100167084494127","0.0662266178532522"," 23881","<p>I've got an ARIMA(1,1,4) model using external regressor with acceptable output but I'm not able to reproduce it outside the R. </p>

<p>this is the result for the model:</p>

<pre><code>Coefficients:
         ar1      ma1     ma2      ma3     ma4  XRegressor[1:39, ]_coeff
      0.9500  -1.0202  0.3977  -0.8283  0.6030                0.0084
s.e.  0.1106   0.1999  0.1953   0.2003  0.1526                0.0059

sigma^2 estimated as 9619542:  log likelihood=-360.56
AIC=735.11   AICc=738.84   BIC=746.57
</code></pre>

<p>The formula I'm using is as follows:</p>

<pre><code>x(t) = x(t-1)(1+ar1) - ar1*x(t-2) + XRegressor[1:39, ]_coeff*
  [xreg(t) - (1+ar1)*xreg(t-1) + ar1*xreg(t-2)] + 
  ma1*e(t-1) + ma2*e(t-2) + ma3*e(t-3) + ma4*e(t-4)
</code></pre>

<p>I'm using residuals as error term in above formula. I could get right result in one step ahead forecast and for further steps, I won't have residuals to substitute in formula. Even by deleting MA part from model, it's not working. Do I miss something here? Can I say by deleting MA part, I'm erasing residual effects?</p>

<p>Thanks a lot for your help in advance.</p>
"
"0.0408930410054765","0.0811107105653813"," 26926","<p>I had some problems fitting an ARIMA - the data are </p>

<pre><code>FTSE &lt;-log(EuStockMarkets[,""FTSE""]) 
</code></pre>

<p>The following link explains the problem  and gives the solution
<a href=""http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm#Issue2"" rel=""nofollow"">http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm#Issue2</a><br>
The solution sounded effective, untill I tried some $ARIMA(p,d,q)$ other than $ARIMA(1,1,0)$: with $ARIMA(1,1,1)$, $ARIMA(2,1,1)$ and $ARIMA(1,1,2)$ the procedure (1+) and the procedure (2) give different coefficients, in particular with the procedure (1+) it says that the AR part is not stationary (indeed changing method from 'css' to 'ml' the coeffiecient of $AR$ is 1 or above).<br>
  These are the codes for $ARIMA(1,1,1)$:</p>

<pre><code>dFTSE&lt;-diff(FTSE)
model2&lt;-Arima(dFTSE, order = c(1, 0, 1))
model2
model1pluscss&lt;-Arima(FTSE,order=c(1,1,1), xreg=1:length(FTSE))
model1plusml&lt;-Arima(FTSE,order=c(1,1,1), xreg=1:length(FTSE), method='ML')
model1plusml
</code></pre>

<p>On the other side the two procedures produce the same output also in $ARIMA(0,1,1)$ and $ARIMA(0,1,2)$. Is there a theoretical explanation that I can't see or something else?</p>
"
"0.115662986393248","0.0860309002014606"," 26999","<p>My data is a time series of employed population, L, and the time span, year.</p>

<pre><code>n.auto=auto.arima(log(L),xreg=year)
summary(n.auto)
Series: log(L) 
ARIMA(2,0,2) with non-zero mean 

Coefficients:
         ar1      ar2      ma1     ma2  intercept    year
      1.9122  -0.9567  -0.3082  0.0254    -3.5904  0.0074
s.e.     NaN      NaN      NaN     NaN     1.6058  0.0008

sigma^2 estimated as 1.503e-06:  log likelihood=107.55
AIC=-201.1   AICc=-192.49   BIC=-193.79

In-sample error measures:
           ME          RMSE           MAE           MPE          MAPE 
-7.285102e-06  1.225907e-03  9.234378e-04 -6.836173e-05  8.277295e-03 
         MASE 
 1.142899e-01 
Warning message:
In sqrt(diag(x$var.coef)) : NaNs produced
</code></pre>

<p>why does this happen? Why would auto.arima selects the best model with std error of these ar* ma* coefficients Not a Number? Is this selected model valid after all?</p>

<p>My goal is to estimate the parameter n in the model L=L_0*exp(n*year). Any suggestion of a better approach?</p>

<p>TIA.</p>

<p>data:</p>

<pre><code>L &lt;- structure(c(64749, 65491, 66152, 66808, 67455, 68065, 68950, 
69820, 70637, 71394, 72085, 72797, 73280, 73736, 74264, 74647, 
74978, 75321, 75564, 75828, 76105), .Tsp = c(1990, 2010, 1), class = ""ts"")
year &lt;- structure(1990:2010, .Tsp = c(1990, 2010, 1), class = ""ts"")
L
Time Series:
Start = 1990 
End = 2010 
Frequency = 1 
 [1] 64749 65491 66152 66808 67455 68065 68950 69820 70637 71394 72085 72797
[13] 73280 73736 74264 74647 74978 75321 75564 75828 76105
</code></pre>
"
"0.0408930410054765","0.0811107105653813"," 28472","<p>A Regression with ARIMA errors is given by the following formula (saw on Hyndman et al, 1998):</p>

<p>$Y_t = b_0 + b_1 X_{1,t} + \dots + b_k X_{k,t} + N_t$</p>

<p>where $N_t$ is modeled as an ARIMA process.</p>

<p>If we have that the model for $N_t$ is ARIMA$(0,0,0)$, then $N_t = e_t$, and $Y_t$ is modeled by an ordinary regression.</p>

<p>Suppose the following data:</p>

<pre><code>a &lt;- structure(c(29305, 9900, 9802, 17743, 49300, 17700, 24100, 11000, 
10625, 23644, 38011, 16404, 14900, 16300, 18700, 11814, 13934, 
12124, 18097, 30026, 3600, 15700, 12300, 14600), .Tsp = c(2010.25, 
2012.16666666667, 12), class = ""ts"")
b &lt;- structure(c(1.108528016, 1.136920872, 1.100239002, 1.057191265, 
1.044200511, 1.102063834, 1.083847756, 1.068585841, 1.084879628, 
1.232979511, 1.168894672, 1.257302058, 1.264967051, 1.234793782, 
1.306452369, 1.252644047, 1.178593218, 1.124432965, 1.132878661, 
1.189926986, 1.17249669, 1.176285957, 1.176552, 1.179178082), .Tsp = 
c(2010.25, 2012.16666666667, 12), class = ""ts"")
</code></pre>

<p>If I model it using <code>auto.arima</code> function, I have:</p>

<pre><code>auto.arima(a, xreg=b)
Series: a 
ARIMA(0,0,0) with zero mean     

Coefficients:
              b
      15639.266
s.e.   1773.186

sigma^2 estimated as 101878176:  log likelihood=-255.33
AIC=514.65   AICc=515.22   BIC=517.01

lm(a~b)

Call:
lm(formula = a ~ b)

Coefficients:
(Intercept)            b  
      48638       -26143  
</code></pre>

<p>Coefficients from the models differ. Shouldn't they be the same? What am I missing?</p>
"
"0.131149499096392","0.151744244666721"," 28737","<p>I have time series as </p>

<pre><code>0.4385487 0.7024281 0.9381081 0.8235792 0.7779642 1.1670665 1.1958634 1.1958634 0.8235792 0.8530141 0.8802216 1.1958634 1.1235897 1.3542734 1.3245534 0.9381081 1.1670665 1.1958634 0.8802216 1.3542734 1.1670665 4.9167998 0.9651803 0.8221709 1.1070461 1.2006974 1.3542734 0.9651803 0.9381081 0.9651803 0.8854192 1.3245534 1.1235897 1.2006974 1.1958634 0.4385487 1.3245534 4.9167998 1.2277843 0.8530141 1.0018480 0.3588158 0.8530141 0.8867365 1.3542734 1.1958634 1.1958634 0.9651803 0.8802216 0.8235792 4.9167998 1.1958634 0.9651803 0.8854192 0.8854192 1.2006974 0.8867365 0.9381081 0.8235792 0.9651803 0.4385487 0.9936722 0.8821301 1.3542734 1.1235897 1.6132899 1.3245534 1.3542734 0.8132233 0.8530141 1.1958634 1.2279813 0.8354292 1.3578511 1.1070461 0.8530141 0.9670581 1.1958634 0.7779642 1.2006974 1.1958634 0.8235792 1.3245534 0.5119648 2.3386331 0.8890464 0.8867365 4.9167998 1.2006974 1.2006974 0.6715839 4.9167998 0.7747481 4.9167998 0.8867365 1.2277843 0.8890464 1.2277843 0.8890464 1.0541099 0.8821301 
</code></pre>

<p>I am using package ""itsmr""-autofit(),""forecast""-auto.arima(),""package""--functions</p>

<ol>
<li><p>Autoregressive model</p>

<pre><code>&gt; ar(t)

Call:
    ar(x = t)

    Order selected 0  sigma^2 estimated as  0.9222 
</code></pre></li>
<li><p>ARMA model</p>

<pre><code>&gt; autofit(t)
    $phi
    [1] 0

    $theta
    [1] 0

    $sigma2
    [1] 0.9130698

    $aicc
    [1] 279.4807

    $se.phi
    [1] 0

    $se.theta
    [1] 0
</code></pre></li>
<li><p>ARIMA model</p>

<pre><code>    &gt; auto.arima(t)
    Series: t 
    ARIMA(0,0,0) with non-zero mean 

    Coefficients:
          intercept
             1.2623
    s.e.     0.0951

    sigma^2 estimated as 0.9131:  log likelihood=-138.72
    AIC=281.44   AICc=281.56   BIC=286.67
</code></pre>

<p>The auto.arima function automatically differences time series: we don't have to worry about transformation.</p>

<pre><code>&gt; auto.arima(AirPassengers)
Series: AirPassengers 
ARIMA(0,1,1)(0,1,0)[12]                    

Coefficients:
          ma1
      -0.3184
s.e.   0.0877

sigma^2 estimated as 137.3:  log likelihood=-508.32
AIC=1020.64   AICc=1020.73   BIC=1026.39`
</code></pre></li>
</ol>

<p>Which model should I select to get p,q values &amp; for forecasting purpose?</p>
"
"0.289371577427477","0.298019780339635"," 29336","<p><strong>Introduction</strong> </p>

<p>I am aiming to forecast the annual growth rates for a number of macroeconomic indicators (denote one by $Y_t$).
One of the tasks is to test the forecasting performance of rival time series models with and without exogenous variables ($X_t$, a $T\times k$ matrix). The list of rival models include:</p>

<ol>
<li>AR(I)MA model (annual growth rates are unlikely to have ""unit Roo"", though the latter is either assumed or tested) $$A(L)Y_t =\mu+ B(L)\varepsilon_t$$</li>
<li>linear regression model with ARMA errors $$Y_t = X_t\beta + \eta_t, \ \ A(L)\eta_t =  B(L)\varepsilon_t $$</li>
<li>lagged dependent variable model (autoregressive model with exogenous variables)
$$A(L)Y_t = X_t\beta + \varepsilon_t$$ </li>
<li>linear regression model
$$Y_t = X_t\beta + \varepsilon_t$$</li>
</ol>

<p>Where $\varepsilon_t$ is assumed to be a strong white noise, zero-mean constant variance i.i.d. process; $A(L)$ and $B(L)$ are autoregressive (of order $p$) and moving average (of order $q$) polynomials with $L$ - a back-shift (lag) operator.</p>

<p>Note that the primary and the only goal is forecasting performance, thus any ""good"" properties of parameter estimates are of the secondary concern. All I need is to test for the most parsimonious, robust to starting conditions forecaster. Decision will be made with one of the <code>accuracy()</code> options, but first I need to obtain the material for the comparison.</p>

<p>Models 1. and 2. are estimated by <code>auto.arima()</code> with default <code>""CSS-ML""</code> estimation method. Models 3. and 4. are estimated by ordinary least squares (<code>lm()</code>). $T$ is about $40$ quarters.</p>

<p><strong>Approaches tried so far</strong></p>

<p>To make the jack-knifed residuals the first approach denoted by ""rolling"" has been implemented. Starting from feasibly large sub-sample of time series data, parameters are estimated and an $h$ ahead forecast is done by the <code>predict()</code> function (EDIT: it is the same suggestion as in the first part Rob's answer to the second question). After that one point is added and the estimation\prediction steps are repeated. </p>

<p>A weak point of such experiments is that the number of time ticks (sample size) used to estimate the parameters is different. While I would like to test the robustness to the starting conditions, keeping the sample size for estimation fixed.</p>

<p>Bearing this in mind I tried to set the several subsequent values (EDIT: for the interval $k+p+q&lt;t_0&lt;t_1&lt;T-h+1$) in $Y_t$ being missing values (NA). In models 2.-4. this also implies dropping the corresponding subsequent rows in data matrix $X_t$. Prediction for 3. and 4. is straightforward (the same <code>predict()</code> with omitted $X_t$ data rows works well). All my concerns are about models 1. and 2.</p>

<p>With just the AR($p$) part the predictions are done sequentially $Y_{t+1|t} = \hat A(L)Y_t$. But with the presence of MA($q$) one could not (?) use the estimated parameters directly. From the Brockwell and Davis ""Introduction to Time Series and Forecasting"" Chapter 3.3 it follows that one needs an innovation algorithm to recursively estimate the $\theta_{n,j}$ from the specific system of equations that involves estimated autoregressive and moving average parameters. EDIT: these $\theta_{n,j}$ parameters are used to make the ARMA prediction, not the originally estimated parameters $\theta_{j}$. However it is remarked in the same chapter that $\theta_{n,j}$ asymptotically approaches $\theta_{j}$ if the process is invertible. It is not evident that 30-40 points is enough for the asymptotic result to be used even if is invertible. </p>

<p>Notes: I don't want to restrict $q$ to zero, since I am not doing so in true out-of-sample forecasting. EDIT: also not that it is not missing value imputation problem, but forecasting experiment, that the trajectory is not supposed to bridge two sub-samples by this imputing the missing values.</p>

<p><strong>Questions</strong></p>

<ol>
<li>Does <code>auto.arima()</code> performs correctly with the presence of missing values inside of the sample? [Already answered by Rob.]</li>
<li>(The actually crucial part of this post) How to correctly forecast (NOT impute) these missed points from the ARMA model when both $p&gt;0$ and $q&gt;0$? (I hope there are the ways already implemented in R language, but I simply is missing something.)</li>
</ol>

<p>EDIT: since the parameters for ARMA parts are estimated correctly could I legally rearrange the arima object to include the estimated parameters and the data only for the first subsample and then use a predict function? </p>

<p>EDIT2: I have tried to modify the estimated <code>mod</code> structure - the resulting forecast from <code>predict.Arima</code> is identical (double precision differences) to the forecast where I use the estimated MA and AR coefficients predicting $Y_{t+1|t}$ directly as $\hat A(L)(Y_t-X_t\hat \beta)+ X_t\hat \beta+\hat B(L)\hat \varepsilon_t $, without <code>KalmanForecast()</code>. This was expected since state space representation is supplied with the same estimated $\theta_j$, not $\theta_{n,j}$. So the only question remains is the difference between $\theta_j$ and $\theta_{n,j}$ significant to influence the point forecasts? I hope the answer is negative.</p>
"
"0.109291249246994","0.151744244666721"," 32634","<p>Is it better to difference a series (assuming it needs it) before using an Arima OR better to use the d parameter within Arima?</p>

<p>I was surprised how different the fitted values are depending on which route is taken with the same model and data. Or am I doing something incorrectly?</p>

<pre><code>install.packages(""forecast"")
library(forecast)

wineindT&lt;-window(wineind, start=c(1987,1), end=c(1994,8))
wineindT_diff &lt;-diff(wineindT)

#coefficients and other measures are similar
modA&lt;-Arima(wineindT,order=c(1,1,0))
summary(modA)
modB&lt;-Arima(wineindT_diff,order=c(1,0,0))
summary(modB)

#fitted values from modA
A&lt;-forecast.Arima(modA,1)$fitted

#fitted from modB, setting initial value to the first value in the original series
B&lt;-diffinv(forecast.Arima(modB,1)$fitted,xi=wineindT[1])


plot(A, col=""red"")
lines(B, col=""blue"")
</code></pre>

<p><strong>ADD:</strong></p>

<p>Please note I am differencing the series once and fitting arima (1,0,0) then I am fitting arima (1,1,0) to the original series. I am (I think) reversing the differencing on the fitted values for the arima(1,0,0) on the differenced file. </p>

<p>I am comparing the fitted values - not the predictions.</p>

<p>Here is the plot (red is arima(1,1,0) and blue is the arima (1,0,0) on the differenced series after changing back to the original scale)  :</p>

<p><img src=""http://i.stack.imgur.com/mQjAb.jpg"" alt=""enter image description here""></p>

<p><strong>Response to Dr. Hyndman's Answer:</strong></p>

<p>1) Can you illustrate in R code what I would need to do in order to get the two fitted values (and presumably forecasts) to match (allowing for small difference due to your first point in your answer) between Arima (1,1,0) and Arima(1,0,0) on the manually differenced series? I assume this has to do with the mean not being included in modA, but I am not entirely sure how to proceed.</p>

<p>2) Regarding your #3. I know I am missing the obvious, but are not $\hat{X}_t = X_{t-1} + \phi(X_{t-1}-X_{t-2}) $ and $\hat{Y}_t = \phi (X_{t-1}-X_{t-2})$ the same when $\hat{Y}_t$ is defined as $\hat{X}_t - X_{t-1}$? Are you saying I am ""undifferencing"" incorrectly?</p>
"
"0.0817860820109531","0.0811107105653813"," 32657","<p>I was playing with the <a href=""http://cran.r-project.org/web/packages/TSA/index.html"" rel=""nofollow"">TSA</a> package in R and wanted to test the <code>arimax</code> function to the solution provided in Pankratz's <em>Forecasting with Dynamic Regression Models</em>, chapter 8. The savings rate and the function seems to provide similar results as the ones in the book except for the IO weights which are quite different. I bet there is a transformation that I might be missing.</p>

<p>Any help on understanding why IO coefficients are so different would be appreciated...</p>

<p>the solution states </p>

<pre><code>AO @ t=82,43,89
LS @ t=99
IO @ t=62,55
</code></pre>

<p>with Parameters estimates</p>

<pre><code>C = 6.1635
w82 = 2.3346
w99 = -1.5114
w43 = 1.1378
w62 = 1.4574
w55 = -1.4915
w89 = -1.0702
AR1 = 0.7976
MA2 = -0.3762
</code></pre>

<p>To fit the model in R, I used
(<code>saving</code> is the data)</p>

<pre><code>arimax(saving, order = c(1,0,2), fixed=c(NA,0,NA,NA,NA,NA,NA,NA,NA,NA), io=c(55,62), 
       xreg=data.frame(AO82=1*(seq(saving)==82),
                       AO43=1*(seq(saving)==43),
                       AO89=1*(seq(saving)==89),
                       LS99=1*(seq(saving)&gt;=99)),
       method='ML')
</code></pre>

<p>The savings rate data is (100 points)</p>

<p>4.9
5.2
5.7
5.7
6.2
6.7
6.9
7.1
6.6
7
6.9
6.4
6.6
6.4
7
7.3
6
6.3
4.8
5.3
5.4
4.7
4.9
4.4
5.1
5.3
6
5.9
5.9
5.6
5.3
4.5
4.7
4.6
4.3
5
5.2
6.2
5.8
6.7
5.7
6.1
7.2
6.5
6.1
6.3
6.4
7
7.6
7.2
7.5
7.8
7.2
7.5
5.6
5.7
4.9
5.1
6.2
6
6.1
7.5
7.8
8
8
8.1
7.6
7.1
6.6
5.6
5.9
6.6
6.8
7.8
7.9
8.7
7.7
7.3
6.7
7.5
6.4
9.7
7.5
7.1
6.4
6
5.7
5
4.2
5.1
5.4
5.1
5.3
5
4.8
4.7
5
5.4
4.3
3.5</p>

<p>here it is my output</p>

<pre><code>&gt; arimax(saving, order = c(1,0,2),fixed=c(NA,0,NA,NA,NA,NA,NA,NA,NA,NA),io=c(55,62),xreg=data.frame(AO82=1*(seq(saving)==82),
+ AO43=1*(seq(saving)==43),AO89=1*(seq(saving)==89),LS99=1*(seq(saving)&gt;=99)),method='ML')

Call:
arimax(x = saving, order = c(1, 0, 2), xreg = data.frame(AO82 = 1 * (seq(saving) == 
    82), AO43 = 1 * (seq(saving) == 43), AO89 = 1 * (seq(saving) == 
    89), LS99 = 1 * (seq(saving) &gt;= 99)), fixed = c(NA, 0, NA, NA, NA, NA, 
    NA, NA, NA, NA), method = ""ML"", io = c(55, 62))

Coefficients:
         ar1  ma1     ma2  intercept    AO82    AO43     AO89     LS99    IO-55   IO-62
      0.7918    0  0.3406     6.0628  2.3800  1.1297  -1.0466  -1.4885  -0.5958  0.5517
s.e.  0.0674    0  0.1060     0.3209  0.3969  0.3780   0.3835   0.5150   0.4044  0.3772

sigma^2 estimated as 0.2611:  log likelihood = -75.57,  aic = 169.14
</code></pre>
"
"0.103452120022374","0.128247294010644"," 32694","<p>I'm using R together with the <code>forecast</code> package to set up a ARIMA model, that will be used to predict a energy related variable. I used <code>auto.arima()</code> to fit different models (according to geographic region), and I need to put the model coefficients in our database, so that the IT folks can automate things. That's exactly the problem: I simply don't know how set up the equations by looking at the model:</p>

<pre><code>ARIMA(1,0,1)(2,0,1)[12] with non-zero mean 

Coefficients:

       ar1     ma1    sar1    sar2     sma1   intercept    prec0    prec1
     0.3561  0.3290  0.6857  0.2855  -0.7079  11333.240   15.5291  28.0817

s.e. 0.2079  0.1845  0.2764  0.2251   0.3887   2211.302    6.2147   6.0906
</code></pre>

<p>I have 2 regressor variables (prec0 and prec1). Given the residuals, the ARIMA vector <code>ARIMA(1,0,1)(2,0,1)[12]</code>, the time series up to period $t$, the number $h$ of forecasting periods and the regressor matrix reg, how can I set a function to return the forecast values? I.e:</p>

<pre><code>do.forecast = function(residuals, ARIMA, timeSeries, h, regMatrix)
{
  p = ARIMA[1]
  q = ARIMA[3]

  ## arima equations here...
}
</code></pre>

<p>Thanks!  </p>

<p>PS: I know this is a possible duplicate of <a href=""http://stats.stackexchange.com/questions/23881/reproducing-arima-model-outside-r"">Reproducing ARIMA model outside R</a>, but my model seems very different, and I really don't know how to start with.</p>
"
"0.182879238989864","0.181369062527503"," 32735","<p>As a financial institution, we often run into analysis of time series data. A lot of times we end up doing regression using time series variables. As this happens, we often encounter residuals with time series structure that violates basic assumption of independent errors in OLS regression.  Recently we are building another model in which I believe we have regression with autocorrelated errors.The residuals from linear model have <code>lm(object)</code> has clearly a AR(1) structure, as evident from ACF and PACF.  I took two different approaches, the first one was obviously to fit the model using Generalized least squares <code>gls()</code> in R. My expectation was that the residuals from gls(object) would be a white noise (independent errors).  But the residuals from <code>gls(object)</code> still have the same ARIMA structure as in the ordinary regression. Unfortunately there is something wrong in what I am doing that I could not figure out.  Hence I decided to manually adjust the regression coefficients from the linear model (OLS estimates). Surprisingly that seems to be working when I plotted the residuals from adjusted regression (the residuals are white noise). I really want to use <code>gls()</code> in <code>nlme</code> package so that coding will be lot simpler and easier. What would be the approach I should take here? Am I supposed to use REML? or is my expectation of non-correlated residuals (white noise) from gls() object wrong?</p>

<pre><code>gls.bk_ai &lt;- gls(PRNP_BK_actINV ~ PRM_BK_INV_ENDING + NPRM_BK_INV_ENDING, 
                 correlation=corARMA(p=1), method='ML',  data  = fit.cap01A)

gls2.bk_ai  &lt;- update(gls.bk_ai, correlation = corARMA(p=2))

gls3.bk_ai &lt;- update(gls.bk_ai, correlation = corARMA(p=3))

gls0.bk_ai &lt;- update(gls.bk_ai, correlation = NULL)

anova(gls.bk_ai, gls2.bk_ai, gls3.bk_ai, gls0.bk_ai)  
     ## looking at the AIC value, gls model with AR(1) will be the best bet

acf2(residuals(gls.bk_ai)) # residuals are not white noise
</code></pre>

<p>Is there something wrong with what I am doing???????</p>
"
"0.131149499096392","0.151744244666721"," 38187","<p>I'm modelling a time series data using ARIMA. Now, I'm trying to test for the serial correlation of my model SARIMA(1,1,1) using the durbin watson test.</p>

<p>My problem is that I don't know what linear model I would put on the formula of the <code>dwtest</code> function in R. Here's the usage of the function,</p>

<pre><code>dwtest(formula, order.by = NULL, alternative = c(""greater"", ""two.sided"", ""less""),
       iterations = 15, exact = NULL, tol = 1e-10, data = list())
</code></pre>

<p>Here's my code below,</p>

<p>Data: <a href=""http://iitstat.weebly.com/uploads/7/3/4/0/7340846/chickenprod.rdata"" rel=""nofollow"">http://iitstat.weebly.com/uploads/7/3/4/0/7340846/chickenprod.rdata</a></p>

<p>To download the data just right click the link and click ""Save Link As...""</p>

<pre><code>library(forecast)
library(lmtest)
ChickenProd &lt;- ts(ChickenProd, start = 1980, frequency = 4)
SARIMA111 &lt;- Arima(ChickenProd, seasonal = list(order = c(1,1,1), period = 4))
</code></pre>

<p>The residuals of my model SARIMA111 is obtain by</p>

<pre><code>SARIMA111[[""residuals""]]
</code></pre>

<p>Now, I want to test the serial correlation of it using the Durbin-Watson test, but I don't know what linear model I would use in the <code>formula</code> argument of <code>dwtest</code> function in R. Is it the SARIMA(1,1,1) model? If so, how will I extract the coefficients of the SARIMA(1,1,1) model, and make a linear model formula in R?</p>

<p>Thank you in Advance!</p>
"
"0.129315150027968","0.128247294010644"," 41446","<p>I'm following an   undergraduate course on timeseries using OxMetrics and wanted to reproduce som results in R</p>

<p>Estimating an ARMA(3,3) model:</p>

<pre><code>arima(temp,c(3,0,3))
</code></pre>

<p>using stats package and also TSA package results in following error:</p>

<pre><code>Error in arima(temp, c(3, 0, 3)) : non-stationary AR part from CSS
</code></pre>

<p>Tried to use ML-method:</p>

<pre><code>arima(temp,c(3,0,3),method=""ML"")
</code></pre>

<p>no error so I get estimates, but not the estimates found in OxMetrics.</p>

<p>Then I tried installing the package FitARMA and used:</p>

<pre><code>FitARMA(temp,c(3,0,3),TRUE,FALSE)
</code></pre>

<p>Which results in the same estimates for the coefficients as when estimated in OxMetrics using exact MaxLikelyhood except for the constantterm. </p>

<p>Then I tried changing fourth argument of FitARMA from FALSE to TRUE:</p>

<pre><code>FitARMA(temp,c(3,0,3),TRUE,TRUE)
</code></pre>

<p>Estimating mean by max.likelyhood and then getting the same estimate for the constantterm but now the estimates for the coefficients change to approximately the same as when using arima in R.</p>

<p>I've already consulted four books on R and I can't really figure out why this is happening. Both OxMetrics and R use BFGS for one. Being quite new to timeseries I'm quite lost...</p>
"
"0.057831493196624","0.0573539334676404"," 43370","<p>I have two time-series, <code>x</code> and <code>y</code>. I would like to prewhiten <code>x</code> by fitting an ARMA(p,q) (or in my case ARMA(1,1)) process and then use the coefficients to filter <code>y</code>. This seems like a pretty standard thing to want to do.  However, the <code>stats:::filter</code> function does only MA or AR filtering it looks like.  What is the appropriate way to do this? Also, should one use the <code>arima</code> function in R to do this or are there other ways?</p>
"
"NaN","NaN"," 52507","<p>Running this example from Hyndman's textbook in Chapter 9.1:  </p>

<pre><code>auto.arima(austa,d=0,xreg=1:length(austa))
ARIMA(2,0,0) with non-zero mean 

Coefficients:
         ar1      ar2  intercept  1:length(austa)
      1.0371  -0.3379     0.4173           0.1715
s.e.  0.1675   0.1797     0.1866           0.0102

sigma^2 estimated as 0.02486:  log likelihood=12.7  
</code></pre>

<p>I wish to test if the trend is significant. </p>

<p>When using <code>lm</code>, I would need the degrees-of-freedom to get the p-values, e.g.:</p>

<pre><code>tstats &lt;- coef(test) / sqrt(diag(vcov(test)))
2 * pt(abs(tstats), df = df.residual(test), lower.tail = FALSE)
</code></pre>

<p>How do I compute d.o.f for this example (and in general for ARIMA models) to get the p-values?</p>
"
"0.0817860820109531","0.0811107105653813"," 55168","<p>Hi all I'm trying to do one step ahead forecast. Lets say I have 1000 data and fit an ARIMA model with it and then I do a forecast for one period ahead. When I get more data I would like to forecast another step using the new data without having to reestimate all coefficients and so on...</p>

<p>This is my code but for some reason it's very slow for a bigger dataset and am not too sure that is doing what I want:</p>

<pre><code>set.seed(1234)
y=ts(log(35+10*rnorm(1000)))
set.seed(4567)
new.data=ts(log(35+10*rnorm(10)))

library(forecast)
model = auto.arima(y)

onestep.for=forecast(model,h=1)
for (i in 1:10) {
  data=c()
  data=c(y,new.data[1:i])
  newfit=Arima(data, model=model)
  forec=forecast(newfit,h=1)
  onestep.for=c(onestep.for,forec)
}
</code></pre>
"
"0.100167084494127","0.0993399267798783"," 55423","<p>This is solved for Arima in the following <a href=""http://stats.stackexchange.com/questions/55168/one-step-ahead-forecast-with-new-data-collected-sequentially"">post</a></p>

<p>Now I would like to compare dshw to Arima but I didn't find the feature of passing fitted model to dshw to avoid reestimating the model every time we update the data set with new values. The following doesn't work:</p>

<pre><code>set.seed(1234)
y=ts(log(35+10*rnorm(1000)))
set.seed(4567)
new.data=ts(log(35+10*rnorm(10)))

library(forecast)
model &lt;- dshw(y)
newfit &lt;- dshw(c(y,new.data), model=model)
onestep.for &lt;- fitted(newfit)[1001:1010]
</code></pre>

<p>An alternative is doing a loop but I would like to avoid reestimating coefficients for each loop:</p>

<pre><code>set.seed(1234)
y=ts(log(35+10*rnorm(1000)))
set.seed(4567)
new.data=ts(log(35+10*rnorm(10)))

library(forecast)
model &lt;- dshw(y)

onestep.for=forecast(model,h=1)
onestep.for=onestep.for$mean
    for (i in 1:10) {
      data=c()
      data=c(y,new.data[1:i])
      model2= dshw(data)
      newfit=forecast(model2, h=1)
      onestep.for=c(onestep.for,newfit$mean)
}
</code></pre>

<p>Anyway I get the following error when running the code above</p>

<pre><code>Error in min(y) : invalid 'type' (list) of argument
</code></pre>
"
"NaN","NaN"," 55937","<p>I have fitted an ARIMA(1,1,2) to time series <code>TS1</code> as below:</p>

<pre><code>arima112 &lt;- arima(TS1, c(1,1,2))
</code></pre>

<p>Now I want to use the coefficients of AR and MA that I got from <code>arima112</code> to forecast another time series (<code>TS2</code>). How can I apply the <code>arima112</code> model on <code>TS2</code>?</p>
"
"0.156931661453885","0.190221477563171"," 56374","<p>as I am stepping into forecasting with ARIMA models, I am trying to understand how I can improve a forecast based on ARIMA fit with seasonality and drift. </p>

<p>My data is the following time series ( over 3 years, with clear trend upwards and visible seasonality, which seems to be not supported by autocorrelation at lags 12, 24, 36??). </p>

<pre><code>    &gt; bal2sum3years.ts
             Jan     Feb     Mar     Apr     May     Jun     Jul     Aug          
    2010 2540346 2139440 2218652 2176167 2287778 1861061 2000102 2560729 
    2011 3119573 2704986 2594432 2362869 2509506 2434504 2680088 2689888 
    2012 3619060 3204588 2800260 2973428 2737696 2744716 3043868 2867416 
             Sep     Oct     Nov     Dec
    2010 2232261 2394644 2468479 2816287
    2011 2480940 2699780 2760268 3206372
    2012 2951516 3119176 3032960 3738256
</code></pre>

<p>The model that was suggested by <code>auto.arima(bal2sum3years.ts)</code> gave me the following model:</p>

<pre><code>    Series: bal2sum3years.ts 
    ARIMA(0,0,0)(0,1,0)[12] with drift         

    Coefficients:
              drift
          31725.567
    s.e.   2651.693

    sigma^2 estimated as 2.43e+10:  log likelihood=-321.02
    AIC=646.04   AICc=646.61   BIC=648.39
</code></pre>

<p>However, the <code>acf(bal2sum3years.ts,max.lag=35)</code> does not show acf coefficients higher than 0.3. The seasonality of the data is, however, pretty obvious - spike at the beginning of every year. This is what the series looks like on the graph:
<img src=""http://i.stack.imgur.com/kQi5N.png"" alt=""Original Time Series""></p>

<p>The forecast using <code>fit=Arima(bal2sum3years.ts,seasonal=list(order=c(0,1,0),period=12),include.drift=TRUE)</code> , called by function <code>forecast(fit)</code>, results in the next 12months's means being equal to the last 12 months of the data plus constant. This can be seen by calling <code>plot(forecast(fit))</code>, </p>

<p><img src=""http://i.stack.imgur.com/GJqcG.png"" alt=""Actual and Forecasted Data""></p>

<p>I have also checked the residuals, which are not autocorrelated but have positive mean ( non zero). </p>

<p>The fit does not model the original time series precisely, in my opinion ( blue the original time series, red is the <code>fitted(fit)</code>:</p>

<p><img src=""http://i.stack.imgur.com/ux3i7.png"" alt=""Original vs fit""></p>

<p>The guestion is, is the model incorrect? Am I missing something? How can I improve the model? It seems that the model literally takes the last 12 months and adds a constant to achieve the next 12 months. </p>

<p>I am a relative beginner in time series forecasting models and statistics. </p>

<p>Thank you very much for your answers!</p>
"
"NaN","NaN"," 56429","<p>I am using the example from Shumway's book. How do I get the p-values for all the coefficients? Do I divide the coeffients by the standard errors?</p>

<pre><code> Call:
    arima(x = cmort, order = c(2, 0, 0), xreg = cbind(trend, temp, temp2, part))

    Coefficients:
             ar1     ar2  intercept    trend     temp   temp2    part
          0.3848  0.4326  3075.1482  -1.5165  -0.0190  0.0154  0.1545
    s.e.  0.0436  0.0400   834.7157   0.4226   0.0495  0.0020  0.0272

    sigma^2 estimated as 26.01:  log likelihood = -1549.04,  aic = 3114.07
</code></pre>
"
"0.057831493196624","0.0573539334676404"," 57123","<p>I need to estimate parameters of an AR model which is in the form of AR(1,11) it means that coefficients of AR orders from order 2 until order 10 are zero. How can I estimate these two parameters in <code>R</code> since <code>arima</code> function only accepts p as the order of the AR component. Note that this model has a different structure than Seasonal AR. </p>

<p>Thanks</p>
"
"0.174368512726539","0.190221477563171"," 58097","<p>Suppose I have the following ACF and PACF (<a href=""http://uploadeasy.net/upload/cygrd.rar"" rel=""nofollow"">data</a>:
<img src=""http://i.stack.imgur.com/A7B44.png"" alt=""ap"">
I want to fit an ARMA-GARCH process. Currently I want to do the first step, specify the mean equation. The first model just uses a constant $\mu$, so no ARMA. In the second model I was thinking about a modified ARMA(1,1) or ARMA(4,4), I don't know what this is called. I want to only use the 4th lag order in the AR and MA part. So this is basically an ARMA(4,4) where the coefficients of the first three lags are set to zero.
$r_t=\delta + \epsilon_t + \alpha_4 r_{t-4}+ b_4 \epsilon_{t-4}$</p>

<p>How can I fit this model in R?</p>

<p>I tried</p>

<pre><code>   arima(logloss, order=c(4,0,4),fixed=c(0,0,0,NA,0,0,0,NA,NA))
</code></pre>

<p>First of all: Is this correct?</p>

<p>Second: Does this make sense?</p>

<p>My output is the following:</p>

<p><img src=""http://i.stack.imgur.com/nfi5A.png"" alt=""ts""></p>

<p>If I calculate the p-values via</p>

<pre><code># p-values
(1-pnorm(abs(aa$coef)/sqrt(diag(aa$var.coef))))/2
</code></pre>

<p>I get</p>

<pre><code>&gt; (1-pnorm(abs(aa$coef)/sqrt(diag(aa$var.coef))))/2
         ar1          ar2          ar3          ar4          ma1          ma2 
2.500000e-01 2.500000e-01 2.500000e-01 4.431378e-08 2.500000e-01 2.500000e-01 
         ma3          ma4    intercept 
2.500000e-01 2.523225e-06 1.886732e-01 
&gt; 
</code></pre>

<p>So can I say, that the both coefficients of the 4th lag order are highly significant, but the intercept is not significant, correct? So should I also fix it to zero?</p>

<p>If I just fit a model with a mean, so no AR or MA, I get:
<img src=""http://i.stack.imgur.com/Mr8Gp.png"" alt=""ts2""></p>

<p>So the mean is also not significant. What should I do? Fit a GARCH without a mean equation? So no mean, no AR or MA part?</p>

<p>EDIT: I played around with it and I found, that an ARIMA(5,0,5) with the first 3 lags fixed to zero and the mean fixed to zero seems to be approrpriate. The output is:
<img src=""http://i.stack.imgur.com/VxuTJ.png"" alt=""ts4"">
The AIC is smaller than in case of the ARIMA(4,0,4) with mean fixed to zero and the residuals look ok. Are my model building steps correct?</p>
"
"0.182879238989864","0.181369062527503"," 58101","<p>I am doing predictions on monthly temperature data for 100 years, from 1901 to 2000 (i.e 1200 data points). I want to know if the method I follow is correct because in my output, I do not see the requisite ""randomness"" of temperature being reproduced in the prediction.  </p>

<p>Here is a link to the plot of the prediction (in red)<br>
<a href=""https://docs.google.com/file/d/0B1Lm03a_91xiYks5TVJDYU05VUE/edit?usp=sharing"" rel=""nofollow"">https://docs.google.com/file/d/0B1Lm03a_91xiYks5TVJDYU05VUE/edit?usp=sharing</a>  </p>

<p>EDIT: added the ACF and PACF of the detrended and de-seasonalised time series:
<a href=""https://docs.google.com/file/d/0B1Lm03a_91xia2RTOHZrajJtZXM/edit?usp=sharing"" rel=""nofollow"">https://docs.google.com/file/d/0B1Lm03a_91xia2RTOHZrajJtZXM/edit?usp=sharing</a></p>

<p>Below is the dput() of my data:</p>

<pre><code>&gt; dput(fr.monthly.temp.ts)
structure(c(2.7, 0.4, 4.7, 10, 13, 16.9, 19.2, 18.3, 15.7, 10.6,   
4.9, 3.5, 4.1, 3.2, 7.5, 10.3, 10, 15.1, 18.2, 17.4, 15, 10.2, 
6.3, 3.5, 3.8, 5.9, 7.6, 7.1, 12.9, 14.9, 17.6, 17.3, 15.5, 12.1, 
6.9, 2.7, 3, 4.6, 5.5, 10.3, 13.6, 16.3, 20.2, 18.5, 13.9, 11.2, 
5.4, 4.8, 1.7, 4, 7.4, 9.3, 11.9, 16.5, 20, 17.6, 14.7, 8.4, 
5.5, 3.8, 4.3, 3.1, 5.6, 8.5, 12.6, 16.1, 18.2, 18.9, 16, 12.7, 
7.4, 2.3, 2.5, 2.1, 6.3, 8.4, 12.7, 15.1, 16.5, 17.9, 16.2, 11.6, 
7.6, 5.6, 1.7, 4.8, 5, 7.7, 14.2, 16.8, 17.9, 17.1, 14.8, 12.1, 
6.5, 3.6, 2.2, 2, 4.7, 10.4, 12.8, 14.2, 16.3, 18, 14.2, 12.2, 
5, 4.9, 4, 5.4, 6.6, 8.5, 11.9, 16.1, 16.4, 17.3, 14.2, 11.9, 
5.9, 6, 1.6, 4.5, 6.4, 8.3, 13.6, 16.1, 20.8, 20.7, 17.5, 11.3, 
7.3, 6.6, 4.6, 6.8, 8.4, 9.2, 13.8, 15.5, 17.9, 15.5, 12.5, 10, 
5.5, 5.8, 5.4, 4.7, 7.9, 9.1, 13, 15.8, 16.5, 17.6, 15.4, 12.3, 
9.2, 4, 0.7, 6.5, 7.4, 11.2, 12.2, 15.3, 17.3, 18.2, 15.3, 10.6, 
6.3, 5.7, 3.5, 4.3, 5.7, 8.5, 14.2, 17, 17.2, 17.5, 14.7, 9.6, 
4.6, 7, 6.4, 4.8, 5.9, 9.5, 13.8, 14, 17.4, 18.4, 14.5, 11.5, 
7, 4.3, 1.1, 1.4, 4.4, 6.7, 15.1, 17.6, 18.3, 17.2, 16.4, 9.4, 
7.3, 1.4, 3.7, 5.4, 6.5, 8.4, 14.2, 15, 18, 18.1, 15.4, 9.7, 
6.4, 6.9, 3.3, 3.7, 6.2, 7.8, 13.8, 16.3, 15.9, 18.9, 16.2, 8.8, 
4.6, 5.5, 5, 6.4, 8.2, 9.9, 14.4, 16, 17.4, 16.5, 15.2, 11.5, 
6, 4, 6.4, 4.2, 7.2, 8.9, 13.7, 16.9, 20.6, 18, 17, 14.1, 4.7, 
4.5, 3.4, 4.7, 6.6, 8, 14.8, 16.3, 16.7, 16.9, 13.7, 9.2, 5.4, 
4.5, 3.7, 6.3, 7.6, 9.4, 12.2, 14.1, 19.9, 18.8, 15.1, 12.3, 
5.3, 3.8, 3.8, 2.4, 6.4, 9.2, 14.1, 16.2, 18, 15.9, 15.2, 11.7, 
7.1, 4.5, 4.8, 5.6, 4.3, 9.1, 12.9, 17, 18, 17.6, 13.3, 11.8, 
4.9, 3.9, 4.1, 8.3, 7.2, 10.3, 11.6, 14.5, 18.2, 18.7, 17.3, 
11.5, 8.3, 2.5, 4.3, 4.5, 7.7, 9.8, 13.7, 15.7, 18, 17.8, 15.2, 
11.3, 6.7, 2.9, 5, 6.4, 7.1, 9.3, 11.8, 16.1, 20.5, 19.3, 15.8, 
11.5, 8.2, 3.7, 0.3, -0.2, 6.7, 7.8, 13.2, 16.3, 19.1, 18.1, 
18.4, 11.4, 7.3, 6.4, 5.8, 3.3, 7, 9.7, 12.1, 17.7, 17.3, 18.2, 
15.9, 11.9, 8.6, 4.5, 3.7, 3.3, 5.8, 8.8, 13.8, 17.5, 17.7, 17, 
12.8, 10.6, 8.2, 3.2, 4.8, 1.4, 5.5, 8, 12.1, 15.8, 17.4, 20.4, 
17.2, 11, 7.4, 5, 1.8, 4.3, 7.8, 10.1, 13.1, 15.4, 19.5, 20.1, 
16.7, 12, 5.5, 0.3, 3.3, 3.1, 6.3, 10.4, 13.8, 17.2, 20, 17.5, 
17.1, 11.9, 5.8, 7.6, 2.6, 5.1, 6.2, 9.1, 11.6, 17.2, 19.5, 18.1, 
16.1, 10.7, 7, 3.9, 6.5, 4.6, 7.9, 8.3, 13.4, 16.1, 17.2, 18, 
16, 9.1, 6.6, 4.2, 5.3, 6.9, 5.6, 9.9, 14.2, 16.6, 18.6, 19.1, 
15.5, 11.7, 6.3, 3.2, 4.4, 3.9, 8.8, 7.7, 11.7, 16.8, 17.5, 18.2, 
15.6, 11.3, 9.3, 2.5, 5.3, 4.7, 5.4, 10.2, 11.5, 16.4, 17.3, 
18.1, 15.2, 10.3, 8.7, 2.6, -0.9, 4.5, 7.1, 9.6, 13.5, 17.1, 
17.1, 17.5, 15.6, 10.6, 7.6, 1.1, 0.7, 4.5, 7.3, 8.2, 10.3, 16.8, 
19.3, 16.9, 15.5, 10.8, 6.6, 3.7, -0.2, -0.1, 7.7, 10.6, 13.1, 
16.7, 18.1, 18.7, 16.7, 13.2, 5.5, 4.8, 4.8, 5.3, 8, 11.5, 14.2, 
16.4, 19.2, 19.2, 16, 12.4, 5.9, 3.4, 5.1, 2.2, 5.1, 11.1, 13.4, 
16, 18.6, 20.6, 15.2, 10.1, 7.1, 3.4, -1, 7.1, 8.4, 11.9, 14.8, 
17.8, 20, 18.1, 16.7, 12.3, 6.5, 4.8, 1.7, 6.4, 6.7, 11.2, 13.1, 
15.7, 18.9, 17.9, 16.2, 11.3, 7.1, 2.1, 1, 1.3, 7.3, 11.3, 14.8, 
17.9, 20.4, 20.9, 17.6, 12.1, 8.3, 3.8, 5.7, 4.5, 9.5, 10.4, 
14, 15.8, 17, 17.8, 15.5, 11.4, 7.2, 4.6, 4.5, 5.4, 5.7, 11.7, 
12.2, 16.8, 20.6, 19.8, 18.6, 13.4, 6.4, 5.1, 3, 6.4, 8, 8.7, 
14.2, 18.3, 20.2, 18.6, 15.2, 11.4, 7.4, 1.1, 4.6, 4.7, 5.8, 
9.1, 11.8, 16.1, 18.7, 17.5, 16.5, 10.5, 8.7, 4.9, 2.7, 2.8, 
8.1, 11.2, 14.5, 17.9, 20.2, 18.9, 13.1, 10.9, 5.5, 3.5, 1.1, 
3, 7.5, 10.1, 14.8, 15.4, 18, 18.8, 16.2, 12.1, 7, 6.8, 1.7, 
2.3, 7.5, 8.6, 12.6, 16, 16.4, 16.9, 15.5, 12.4, 8, 6.2, 4.4, 
3.6, 4.6, 10.3, 12.5, 16.4, 19.1, 19.2, 15.7, 10.4, 6.7, 6.4, 
4.4, -1.8, 6.7, 8.1, 13.8, 14.4, 17.8, 16.4, 16.4, 10.6, 5.3, 
5.2, 3.1, 6.9, 9.8, 9.6, 11.5, 17, 18.5, 17.6, 15.1, 11.8, 6.8, 
3.6, 3.7, 6.2, 4.9, 7.9, 13.9, 15.6, 17.9, 18.4, 17.3, 11.4, 
6.7, 5.1, 3.4, 4.5, 8.6, 10.2, 13.8, 17, 20.3, 18.9, 17.2, 12.2, 
6.8, 5.7, 3.5, 5, 8, 9.6, 14.5, 17.6, 16.8, 17.3, 14.5, 11.1, 
8.4, 3.5, 3.6, 7.6, 8.3, 11.7, 12.5, 16.6, 17.7, 18, 18.5, 12.3, 
6.4, 4.5, 4.8, 3.7, 3.9, 9.1, 11.5, 15.8, 17.6, 18.6, 15.5, 11.9, 
5.4, 1.3, -1.6, -0.3, 6.5, 9.6, 12.2, 15.8, 18.5, 16.5, 15.2, 
11.5, 9.3, 1.3, 1.5, 5.2, 5.6, 9.6, 14.5, 16.8, 19.6, 18.2, 16.7, 
9.6, 7.2, 3.2, 3.6, 1.7, 6.6, 8.7, 12.7, 16.1, 16.7, 17.1, 13.7, 
12.2, 6.3, 5.7, 2.6, 7.9, 6.2, 10.5, 13.2, 17, 16.8, 17.2, 16.6, 
12.7, 5, 5.3, 3.5, 5.5, 7.7, 8.8, 12.5, 15.6, 19.8, 18.1, 15.3, 
13.2, 7.1, 3, 3.3, 4.3, 6.8, 9.9, 11.8, 15.9, 17.8, 17.2, 15.1, 
13.5, 6.8, 3, 4.8, 2.1, 6.2, 9.2, 13.2, 15, 19.1, 18.1, 15.9, 
13.1, 7.1, 1.4, 4.1, 4.3, 4.4, 7.6, 12.8, 17.6, 17.8, 18.3, 16.6, 
11.3, 8.7, 2.6, 3.1, 4.2, 3.8, 10.5, 13.7, 14.8, 19.7, 18.7, 
15.7, 12.3, 5.8, 4.9, 3.2, 5.5, 7.9, 8.9, 11.7, 14.3, 18, 17.1, 
13.3, 10.9, 7.3, 4.5, 3, 3.4, 6.1, 7.6, 13.5, 17, 18.1, 19.9, 
16.7, 10.6, 6.8, 3.7, 6.2, 5.5, 7.3, 9.4, 12.5, 15.9, 17.7, 18.6, 
14.5, 8.2, 7.4, 6.8, 6.4, 5.5, 5.3, 9, 12.1, 15.9, 19.1, 19.8, 
16.1, 10.4, 6.7, 3.1, 4.1, 4.8, 6, 8.9, 14, 18.8, 20.1, 19, 14.8, 
11.8, 6.6, 3.1, 3.7, 6.6, 8.3, 8.3, 12.1, 14.8, 17.8, 16.9, 14.7, 
12.9, 7, 5.3, 3.3, 4, 7.2, 7.8, 12.3, 15.2, 17.3, 17.2, 15.6, 
11.8, 6.7, 5.1, 1.3, 4, 6.6, 8.2, 12.3, 16.5, 18.5, 17.1, 15.7, 
12.4, 6.7, 5.7, 2.2, 6.3, 6.2, 8.4, 11.9, 15, 16.4, 18.6, 16.5, 
10.8, 5.8, 3.1, 3.3, 2.9, 9.2, 10, 12.6, 16, 17.5, 18.8, 16.2, 
11.2, 7.2, 3.8, 4.6, 5, 6.3, 9.3, 13.4, 17.4, 20.1, 18, 17.4, 
11.4, 8.3, 4.9, 5.5, 2.5, 7, 8.9, 11.5, 17.1, 22.2, 19.3, 16.3, 
11.9, 7.6, 4.5, 4.2, 3.5, 5.2, 9.6, 10.4, 15.8, 18.8, 18.4, 14.7, 
11.9, 9, 4.5, -1, 3.8, 5.2, 9.7, 12.5, 15.3, 19.4, 17.6, 17.3, 
12.3, 4.4, 5.6, 3.9, -0.6, 5.9, 6.9, 13.7, 16.9, 18.7, 17.6, 
14.9, 13.1, 7.9, 5, -0.8, 3.7, 4.8, 10.9, 11.4, 15, 18.6, 18.6, 
17.8, 12.4, 7.1, 5.2, 6.4, 4.9, 6.5, 10.1, 13.8, 16.2, 17.8, 
18.7, 15.7, 12.9, 6.3, 6, 4.2, 5.6, 9.3, 8.2, 15.3, 16.9, 20.2, 
19.5, 16.5, 13.2, 7, 5.6, 4.8, 8.8, 8.7, 8.9, 15.3, 16, 19.7, 
20.4, 15.9, 13.3, 7.2, 3.1, 3.9, 1.9, 9, 8.7, 11.7, 14.9, 19.6, 
20.7, 17.9, 10.9, 6.9, 3.6, 2.8, 4.9, 7.6, 9.5, 15.3, 16.1, 19.1, 
19.9, 15.5, 9.6, 9, 4.8, 5.9, 3.5, 7, 10.4, 14.1, 17.3, 17.8, 
18.7, 14.7, 10.4, 4.8, 6.2, 5.2, 5.1, 9.4, 8.7, 13.6, 17.1, 21.4, 
19.9, 15, 12, 10.2, 6.5, 4.5, 7.5, 6.5, 9.9, 13.6, 16.1, 21.1, 
20.2, 14.5, 14.6, 7.5, 3.8, 5, 2.9, 6, 10, 12.2, 17.5, 18.7, 
18.2, 14.2, 11.9, 6.9, 3.4, 2.3, 6.9, 9.3, 10, 14.2, 16.3, 18.6, 
21, 17, 12.4, 8.4, 5.5, 5, 5.9, 8.1, 9, 14.9, 17, 18.5, 19.4, 
16.1, 11.6, 5.2, 4.5, 5.3, 4.3, 8, 10, 15.2, 16.3, 20.2, 19.4, 
17.9, 12.2, 6.4, 5, 3.7, 6.6, 7.5, 9.9, 15, 17.8, 17.5, 19.6, 
16.9, 12.2, 8.2, 7.1), .Tsp = c(1901, 2000.91666666667, 12), class = ""ts"")  
</code></pre>

<p>I run <code>stl()</code> on it to remove the seasonality:  </p>

<pre><code># calculate and remove the seasonality  
fr.monthly.temp.ts.stl &lt;- stl(fr.monthly.temp.ts, s.window=""periodic"")    # get the    components  
fr.monthly.temp.seas &lt;- fr.monthly.temp.ts.stl$time.series[,""seasonal""]  
#plot(fr.monthly.temp.seas)  

fr.monthly.temp.ts.noseas &lt;- fr.monthly.temp.ts - fr.monthly.temp.seas  
#plot(fr.monthly.temp.ts.noseas)  
</code></pre>

<p>Then remove the trend with a regression:</p>

<pre><code>fr.mtrend.noseas &lt;- lm(fr.monthly.temp.ts.noseas~t)  
summary(fr.mtrend.noseas)  
</code></pre>

<p>and then use the residuals of this model to fit an ARIMA model (after checking the ACF and PACF for which one is appropriate):</p>

<pre><code># create time series of residuals..this is our ""detrended"" series..for now use only linear trend result  
fr.monthly.temp.ts.new &lt;- ts(fr.mtrend.noseas$resid, start=c(1901,1), frequency=12)
#plot.ts(fr.monthly.temp.ts.new, main=""Detrended and de-seasonalized time series"")

# ARIMA 1,1,1  
fit6 &lt;- arima(fr.monthly.temp.ts.new,order=c(1,1,1))  
fit6  
tsdiag(fit6)  
</code></pre>

<p>I then make a prediction on the stationary time series:</p>

<pre><code>#forecast for the stationary TS, for next 50 yrs months  
forecast &lt;- predict(fit6,n.ahead=600)  
</code></pre>

<p>And then add back the trend and seasonality:</p>

<pre><code>t.new &lt;- (n+1):(n+600)  

#initial time series = stationaryTS + seasonality + trend  
fr.monthly.temp.ts.init &lt;- fr.monthly.temp.ts.new + fr.monthly.temp.seas +
                            fr.mtrend.noseas$coefficients[1] + t * fr.mtrend.noseas$coefficients[2]  

#same for the prediction: we need to add seasonality and trend  
pred.Xt &lt;- forecast$pred + fr.monthly.temp.seas[1:(1+50*12 - 1)] + 
                                fr.mtrend.noseas$coefficients[1] + t.new * fr.mtrend.noseas$coefficients[2]  

plot(fr.monthly.temp.ts.init,type=""l"",xlim=c(1940,2060))  
lines(pred.Xt,col=""red"",lwd=2)  
</code></pre>

<p>So going back to my question: Do I need to add some white noise to the prediction to be able to realistically predict temperature? And more generally, is my method correct?</p>
"
"0.0817860820109531","0.0811107105653813"," 58265","<p>I'm currently sifting through my copy of Analysis of Financial Time Series 2nd Edition by Ruey Tsay, and one of the sections involves fitting a MA model to certain data (data set is <a href=""http://faculty.chicagobooth.edu/ruey.tsay/teaching/fts/m-ew.dat"" rel=""nofollow"">here</a>). Here's the fit with exact maximum likelihood according to the text, with certain insignificant parameters removed:</p>

<p>rt = 0.013 + a(t) + 0.181a(tâˆ’1) âˆ’ 0.121a(tâˆ’3) + 0.122a(tâˆ’9)</p>

<p>Ïƒ(a) = 0.0724</p>

<p>However, when I try to fit it with R...</p>

<pre><code>&gt; mew = read.table(""m-ew.dat"")
&gt; arima(mew,order = c(0,0,9),fixed = c(NA,0,NA,rep(0,5),NA,NA),method = ""ML"")
Call:
arima(x = mew, order = c(0, 0, 9), fixed = c(NA, 0, NA, rep(0, 5), NA, NA), 
method = ""ML"")

Coefficients:
        ma1  ma2      ma3  ma4  ma5  ma6  ma7  ma8     ma9  intercept
      0.180    0  -0.1318    0    0    0    0    0  0.1373     0.0132
s.e.  0.031    0   0.0362    0    0    0    0    0  0.0327     0.0029

sigma^2 estimated as 0.005282:  log likelihood = 1039.1,  aic = -2068.21
</code></pre>

<p>As you can see, the ma1 coefficients are the same, but ma3 and ma9 are different, even with method = ""ML"", i.e. maximum likelihood. Why is this?</p>

<p>Also, from a practical standpoint, while ma2 and ma4-ma8 may be 0 (their 95% confidence intervals overlap with 0), removing them from the model raises the AIC, lowers the p-value with regards to the Ljung-Box test on the residuals, and also lowers the log-likelihood value. Is it even worth removing these parameters if such things happen?</p>
"
"0.194116355365255","0.22213082915966"," 58657","<p>I'm using a daily time series of sales data that contains about 2 years of daily data points. Based on some of the online-tutorials / examples I tried to identify the seasonality in the data. It seems that there is a weekly, monthly and probably a yearly periodicity / seasonality.</p>

<p>For example, there are paydays, particularly on 1st payday of the month effect that lasts for few days during the week. There are also some specific Holiday effects, clearly identifiable by noting the observations.</p>

<p>Equipped with some of these observations, I tried the following:</p>

<ol>
<li><p>ARIMA (with <code>Arima</code> and <code>auto.arima</code> from R-forecast package), using regressor (and other default values needed in the function).  The regressor I created is basically a matrix of 0/1 values:</p>

<ul>
<li>11 month (n-1) variables</li>
<li>12 holiday variables</li>
<li>Could not figure out the payday part...since it's little more complicated effect than I thought. The payday effect works differently, depending on the weekday of the 1st of month.</li>
</ul>

<p>I used 7 (i.e., weekly frequency) to model the time series. I tried the test - forecasting 7 days at a time. The results are reasonable: average accuracy for a forecast of 11 weeks comes to weekly avg RMSE to 5%.</p></li>
<li><p>TBATS model (from R-forecast package) - using multiple seasonality (7, 30.4375, 365.25) and obviously no regressor. The accuracy is surprisingly better than the ARIMA model at weekly avg RMSE 3.5% .</p>

<p>In this case, the model without ARMA errors perform slightly better. Now If I apply the coefficients for just the Holiday Effects from the ARIMA model described in #1, to the results of the TBATS model the weekly avg RMSE improves to 2.95%</p></li>
</ol>

<p>Now without having much background or knowledge on the underlying theories of these models, I'm in a dilemma whether this TBATS approach is even a valid one. Even though it's improving the RMSE significantly in the 11 weeks test, I'm wondering whether it can sustain this accuracy in the future. Or even if applying Holiday effects from ARIMA to the TBATS result is justifiable. Any thoughts from any / all the contributors will be highly appreciated. </p>

<p><a href=""https://s3.amazonaws.com/CKI-FILE-SHARE/TS+Test+Data.txt"">Link for Test Data</a></p>

<p>Note: Do ""Save Link As"", to download the file.</p>
"
"0.0817860820109531","0.0811107105653813"," 59712","<p>I am trying to understand the way MA(q) models work.
For this purpose I have created a simple data set with only
three values. I then adapted a MA(1) model to it. The results
are shown below:</p>

<pre><code>x&lt;-c(2,5,3)
m&lt;-arima(x,order=c(0,0,1))

Series: x 
ARIMA(0,0,1) with non-zero mean 

Coefficients:
          ma1  intercept
      -1.0000     3.5000
s.e.   0.8165     0.3163

sigma^2 estimated as 0.5:  log likelihood=-3.91
AIC=13.82   AICc=-10.18   BIC=11.12
</code></pre>

<p>While the MA(1) model looks like this: 
$$X_t = c +a_t - \theta*a_{t-1}$$</p>

<p>and $a_t$ is White Noise.</p>

<p>What I cant figure out is how to get the fitted values:</p>

<pre><code>library(forecast)
fitted(m)
Time Series:
Start = 1 
End = 3 
Frequency = 1 
[1] 3.060660 4.387627 3.000000
</code></pre>

<p>I tried different ways, but I cant find out how the fitted values (<code>3.060660</code>, <code>4.387627</code> and <code>3.000000</code>) are calculated.</p>

<p>I would be very thankful for an answer!</p>
"
"0.200334168988253","0.182123199096444"," 60648","<p>I am trying to forecast electricity consumption in GWh for 2 years ahead (from June 2013 ahead), using R (the forecast package). For that purpose, I tried regression with ARIMA errors. I fitted the model using the <code>auto.arima</code> function, and I used the following variables in the <code>xreg</code> argument in the <code>forecast.Arima</code> function: </p>

<p>- Heating and Cooling Degree Days,<br>
- Dummies for all 12 months and<br>
- Moving holidays dummies (Easter and Ramadan)  </p>

<p>I have several questions regarding the model:</p>

<p>1) Is it correct to use all 12 dummies for monthly seasonality, since when I tried to include 11, the function returned error. The <code>Auto.arima</code> function returned the model ARIMA(0,1,2)</p>

<p>2)The model returned the following coefficients (I won't specify all of them as there are too many coefficients):</p>

<pre><code>ma1      ma2     HDD     CDD   January  February  March     April
-0.52 -0.16      0.27    0.12  525.84   475.13    472.57    399.01
</code></pre>

<p>I am trying to determine the influence of the temperature component over electricity load. In percentages, (interpreting the coefficients just as with the usual regression) the temperature components (<code>HDD</code>+<code>CDD</code>) account for 11,3% of the electricity consumption. Isn't this too little, considering the fact that the electricity consumption is mostly influenced by the weather component? On the other hand, taking look at the dummies' coefficients, it turns out that the seasonality accounts for the greater part of the load. Why is this? Is the model completely incorrect?</p>

<p>I tried linear regression, and the temperature component accounts for 20%, but it is still a low percentage. Why is this?</p>

<p>3) I am obviously making some mistakes in the use of <code>forecast.Arima</code> or the plot function parameters since when I plot the forecasts, I get a picture of the original time series which is continued (merged) with the forecasts for the whole time series period (from 2004 until 2015). I don't know how to explain this better, I tried to paste the picture, but it seems I cannot paste pictures here.</p>
"
"NaN","NaN"," 60803","<p>I would like to know more details about R issues mentioned in <a href=""http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm"" rel=""nofollow"">Time Series Analysis and Its Applications: With R Examples</a>. </p>

<p>For e.g. the first problem still exists in R version 3.0.1</p>

<pre><code># generate an AR(1) with mean 50
set.seed(66)      # so you can reproduce these results
x = arima.sim(list(order=c(1,0,0), ar=.9), n=100) + 50   
mean(x)  
  [1] 50.60668   # the sample mean is close
arima(x, order = c(1, 0, 0))  
  Coefficients:
           ar1  intercept  &lt;--  here's the problem
        0.8971    50.6304  &lt;--  or here, one of these has to change
  s.e.  0.0409     0.8365
</code></pre>

<p>*direct copy from the webpage</p>

<p>Theoretical model of above simulation is:
$X_t = 5 + 0.9 X_{t-1} + Z_t$, where $\{ Z_t\} $ is the white noise</p>

<p>Is R following particular model convention or is R wrong?  If it is wrong, it is still in R core package and I wonder why it isn't changed.</p>

<p>Also, it would be very helpful if I get some hint on other five issues.</p>
"
"0.129315150027968","0.128247294010644"," 65585","<p>I have a daily weather data set, which has, unsurprisingly, very strong seasonal effect.</p>

<p><img src=""http://i.stack.imgur.com/B5Zpo.jpg"" alt=""enter image description here""></p>

<p>I adapted an ARIMA model to this data set using the function auto.arima from forecast package.
To my surprise the function does not apply any seasonal operations- seasonal differencing, seasonal ar or ma components. Here is the model it estimated:</p>

<pre><code>library(forecast)
data&lt;-ts(data,frequency=365)
auto.arima(Berlin)

Series: data
ARIMA(3,0,1) with non-zero mean 

Coefficients:
         ar1      ar2     ar3      ma1  intercept
      1.7722  -0.9166  0.1412  -0.8487   283.0378
s.e.  0.0260   0.0326  0.0177   0.0214     1.7990

sigma^2 estimated as 5.56:  log likelihood=-8313.74
AIC=16639.49   AICc=16639.51   BIC=16676.7
</code></pre>

<p>And also the forecasts using this model are not really satisfying. Here is the plot of the forecast:
<img src=""http://i.stack.imgur.com/IkpIq.jpg"" alt=""enter image description here""></p>

<p>Can anyone give me a hint what is wrong here?</p>
"
"0.141657649394966","0.140487871737254"," 66369","<p>I've found two definitions in the literature for the autocorrelation time of a weakly stationary time series:</p>

<p>$$
\tau_a = 1+2\sum_{k=1}^\infty \rho_k \quad \text{versus} \quad \tau_b = 1+2\sum_{k=1}^\infty \left|\rho_k\right|
$$</p>

<p>where $\rho_k = \frac{\text{Cov}[X_t,X_{t+h}]}{\text{Var}[X_t]}$ is the autocorrelation at lag $k$.  </p>

<p>One application of the autocorrelation time is to find the ""effective sample size"": if you have $n$ observations of a time series, and you know its autocorrelation time $\tau$, then you can pretend that you have</p>

<p>$$
n_\text{eff} = \frac{n}{\tau}
$$</p>

<p>independent samples instead of $n$ correlated ones for the purposes of finding the mean.  Estimating $\tau$ from data is non-trivial, but there are a few ways of doing it (see <a href=""http://arxiv.org/abs/1011.0175"">Thompson 2010</a>).</p>

<p>The definition without absolute values, $\tau_a$, seems more common in the literature; but it admits the possibility of $\tau_a&lt;1$.  Using R and the ""coda"" package:</p>

<pre><code>require(coda)
ts.uncorr &lt;- arima.sim(model=list(),n=10000)         # white noise 
ts.corr &lt;- arima.sim(model=list(ar=-0.5),n=10000)    # AR(1)
effectiveSize(ts.uncorr)                             # Sanity check
    # result should be close to 10000
effectiveSize(ts.corr)
    # result is in the neighborhood of 30000... ???
</code></pre>

<p>The ""effectiveSize"" function in ""coda"" uses a definition of the autocorrelation time equivalent to $\tau_a$, above.  There are some other R packages out there that compute effective sample size or autocorrelation time, and all the ones I've tried give results consistent with this:  that an AR(1) process with a negative AR coefficient has <em>more</em> effective samples than the correlated time series.  This seems strange.  </p>

<p>Obviously, this can never happen in the $\tau_b$ definition of autocorrelation time.</p>

<p>What is the correct definition of autocorrelation time?  Is there something wrong with my understanding of effective sample sizes?  The $n_\text{eff} &gt; n$ result shown above seems like it must be wrong... what's going on?</p>
"
"0.057831493196624","0.0573539334676404"," 68966","<p>I am trying to manually estimate the non-seasonal components of an SARIMA (p,d,q)x(P,D,Q)[s]. I thought the estimation is going the same way like in ARIMA, but the output says somehow something different. </p>

<p>I have an autocorrelation in the acf correlogram and one significance bound at lag 1 in the pacf. That means I have an autocorrelation first order.</p>

<p>I'm confused now, why <code>auto.arima</code> is giving me the result (0,1,1)x(0,0,1)[12] instead of (1,1,0)x(0,0,1)[12]</p>

<p>Here is my code example:</p>

<pre><code>timeseries &lt;- ts(daten, start=c(1955,1), freq=12)

&gt; timeseries
      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
1955  1.8  1.7  1.5  1.2  1.5  1.5  1.6  1.8  1.5  1.5  1.6  1.3
1956  0.7  0.6  0.4  0.9  0.9  0.8  0.8  0.6  0.6  0.4  0.4  0.2
1957  0.2  0.1  0.6  0.8  0.3  0.4  0.5  0.7  0.8  0.9  1.0  1.3
1958  1.7  1.7  1.4  1.0  0.9  1.3  1.3  1.0  1.5  1.4  1.4  2.2
1959  1.3  1.7  1.7  2.2  2.8  2.5  2.2  2.3  1.8  1.6  1.3  1.4
1960  2.2  1.8  1.9  1.6  1.1  0.8  1.1  1.1  1.1  1.4  1.2  1.2
1961  0.9  1.2  1.3  0.9  0.7  0.8  0.8  1.2  1.0  1.0  1.4  1.0
1962  1.1  0.8  1.1  1.7  2.1  2.0  2.1  2.1  2.0  2.3  2.0  2.3
1963  1.6  1.9  1.6  1.4  1.6  1.8  1.8  1.9  2.5  2.3  2.2  2.1
1964  2.1  2.1  1.9  2.3  2.1  2.0  2.1  1.8  1.0  1.1  1.5  1.4
1965  1.8  1.9  2.0  2.0  2.0  2.0  2.0  2.0  2.7  2.7  3.3  3.1
1966  2.9  3.0  3.3  2.6  3.1  3.4  3.5  3.3  3.0  2.5  1.4  1.1
1967  0.9  1.0  0.4  0.8  0.0  0.0 -0.7 -0.1 -0.5 -0.1  0.3  0.8
1968  0.8  0.5  1.2  1.0  1.2  0.8  1.2  1.0  1.3  1.3  1.6  1.9
1969  2.0  2.2  2.3  2.7  2.4  2.4  2.6  2.5  2.9  2.9  2.8  2.3
1970  2.3  2.5  2.3  2.2  2.2  2.0  1.9  2.2  2.1  2.1  1.9  2.0
1971  1.9  1.8  1.8  1.1  1.6  1.9  1.9   NA 

diffts &lt;- diff(timeseries,12)
tsdisplay(diffts, lag.max=36)
</code></pre>

<p><img src=""http://i.stack.imgur.com/2MgzU.jpg"" alt=""enter image description here""></p>

<p>But <code>auto.arima</code> is giving me the following output:</p>

<pre><code>auto.arima(timeseries)

Series: timeseries 
ARIMA(0,1,1)(0,0,1)[12]                    

Coefficients:
          ma1     sma1
      -0.1280  -0.7260
s.e.   0.0684   0.0584

sigma^2 estimated as 0.07113:  log likelihood=-23.77
AIC=53.54   AICc=53.66   BIC=63.42
</code></pre>
"
"0.100167084494127","0.0993399267798783"," 69405","<p>I am fitting a model using the <code>auto.arima</code> function in package <code>forecast</code>. I get a model that is AR(1), for example. I then extract residuals from this model. How does this generate the same number of residuals as the original vector? If this is an AR(1) model then the number of residuals should be 1 less than the dimensionality of the original time series. What am I missing?</p>

<p>Example:</p>

<pre><code>require(forecast)
arprocess = as.numeric(arima.sim(model = list(ar=.5), n=100))
#auto.arima(arprocess, d=0, D=0, ic=""bic"", stationary=T)
#  Series: arprocess 
#  ARIMA(1,0,0) with zero mean     

#  Coefficients:
#          ar1
#       0.5198
# s.e.  0.0867

# sigma^2 estimated as 1.403:  log likelihood=-158.99
# AIC=321.97   AICc=322.1   BIC=327.18
r = resid(auto.arima(arprocess, d=0, D=0, ic=""bic"", stationary=T))
&gt; length(r)
  [1] 100
</code></pre>

<p>Update: Digging into the code of auto.arima, I see that it uses Arima which in turn uses <code>stats:::arima</code>. Therefore the question is really how does <code>stats:::arima</code> compute residuals for the very first observation?</p>
"
"0.129315150027968","0.0769483764063866"," 70866","<p>I have a modelling dilemma. I am creating a model that attempts to predict demand (leads not sales) based upon the correlation to advertising spend. We know that without advertising spend, demand is driven by seasonality. So our models include seasonal factors like month of the year and even day of the week. 
If I were building a regular linear regression model, I would fit a linear regression model to a training dataset, to get estimates of the coefficients of the seasonal factors and advertising spend to demand. In order to get an estimate of future baseline demand, I would forecast demand using all the coefficients from the model and then I would estimate a baseline by setting adspend equal to zero. 
For ARIMA models, there are additional factors such as AR and MA terms. Would I estimate my baseline the same way by just setting the coefficient on advertising spend equal to zero?
Thanks for any thoughts.</p>
"
"0.185473400320556","0.214598768819738"," 76761","<p><strong>Problem:</strong> I would like to extract the BIC and AICc from an arima() object in R.</p>

<p><strong>Background:</strong> The arima() function produces an output of results, which includes the estimated coefficients, standard errors, AIC, BIC, and AICc. Let's run some sample code to see what this looks like:</p>

<pre><code># Load the sunspots dataset
data(sunspots)
# Build an ARIMA(2,0,2) model and store as an object
model &lt;- arima(x=sunspots, order=c(2,0,2), method=""ML"")
# Show a summary of the model
model 
</code></pre>

<p>The output of results for the model appears like this:</p>

<pre><code>Series: sunspots 
ARIMA(2,0,2) with non-zero mean 

Coefficients:
         ar1     ar2      ma1      ma2  intercept
      0.9822  0.0004  -0.3997  -0.1135    51.2652
s.e.  0.1221  0.1196   0.1206   0.0574     8.1441

sigma^2 estimated as 247.9:  log likelihood=-11775.69
AIC=23563.39   AICc=23563.42   BIC=23599.05
</code></pre>

<p>On the bottom line, we can see values for AIC, BIC, and AICc. (Note: this is the output shown by arima() when the forecast package has been loaded, i.e. library(forecast))</p>

<p>Accessing the AIC value is quite easy. One can simply type:</p>

<pre><code>&gt; model$aic
[1] 23563.39
</code></pre>

<p>Access to the AIC value in this manner is made possible due to the fact that it's stored as one of the model's attributes. The following code and output will make this clear:</p>

<pre><code>&gt; attributes(model)
$names
 [1] ""coef""      ""sigma2""    ""var.coef""  ""mask""      ""loglik""   
 [6] ""aic""       ""arma""      ""residuals"" ""call""      ""series""   
[11] ""code""      ""n.cond""    ""model""    

$class
[1] ""Arima""
</code></pre>

<p>Notice, however, that bic and aicc are not model attributes, so the following code is no use to us:</p>

<pre><code>&gt; model$bic
NULL
&gt; model$aicc
NULL
</code></pre>

<p>The BIC and AICc values are, indeed, calculated by the arima() function, but the object that it returns does not give us direct access to their values. This is inconvenient and I've come across others who've raised the issue. Unfortunately, I've not found a solution to the problem.</p>

<p>Can anyone out there help? Which method can I use to access the BIC and AICc from the Arima class of object.</p>

<p><strong>Note:</strong> I've suggested an answer below, but would like to hear improvements and suggestions.</p>

<p>Edit (Version details as requested):</p>

<pre><code>&gt; R.Version()
$platform
[1] ""i686-pc-linux-gnu""

$arch
[1] ""i686""

$os
[1] ""linux-gnu""

$system
[1] ""i686, linux-gnu""

$status
[1] """"

$major
[1] ""3""

$minor
[1] ""0.2""

$year
[1] ""2013""

$month
[1] ""09""

$day
[1] ""25""

$`svn rev`
[1] ""63987""

$language
[1] ""R""

$version.string
[1] ""R version 3.0.2 (2013-09-25)""

$nickname
[1] ""Frisbee Sailing""
</code></pre>
"
"0.191805363999193","0.172928615966519"," 77285","<p>I have two groups of time-series, each group represents one type of data. However within each group, each time series may be fitted with a different ARIMA(p,d,q) from the other time series in the same group. </p>

<p>I need to create a single model for each group (<code>Model_group1</code>, <code>Model_group2</code>). I tried the approach mentioned by Rob Hyndman in: 
<a href=""http://stats.stackexchange.com/questions/23036/estimating-same-model-over-multiple-time-series"">Estimating same model over multiple time series</a>.</p>

<p>I need to use these two models to classify any time series to one of these two groups. For each time series, I calculated the AIC of <code>Model_group1</code> and <code>Model_group2</code>, and the model with smaller AIC will mean that the time series belongs to its corresponding group. </p>

<p>I have three problems: </p>

<ol>
<li><p>I received a warning message </p>

<pre><code>Series: ts 
ARIMA(3,0,2) with non-zero mean 

Coefficients:
         ar1     ar2     ar3     ma1      ma2  intercept
      0.0714  0.1417  0.0000  0.0893  -0.0871     0.1169
s.e.     NaN  0.1381  0.0127     NaN   0.1436     0.0026

sigma^2 estimated as 0.2202:  log likelihood=-33822.63
AIC=67659.26   AICc=67659.26   BIC=67725.99
Warning message:
In sqrt(diag(x$var.coef)) : NaNs produced
</code></pre>

<p>This message was returned by only one of the group models. Does that mean that the fitted model is not correct? </p></li>
<li><p>I got two different results using </p>

<pre><code>auto.arima(ts, allowdrift=FALSE, stepwise=FALSE)
auto.arima(ts, allowdrift=FALSE, stepwise=TRUE)
</code></pre></li>
<li><p>When I tested the resulting models, the majority of the time-series were classified as <code>group_1</code>, even when I test one of the time series used to build the long time series of <code>group_2</code>. I need to mention here that the composed time series of <code>group_1</code> is quite shorter than the time series of <code>group_2</code>. Are there any expected reasons for that? </p></li>
</ol>
"
"0.0817860820109531","0.0811107105653813"," 77531","<p>I have obtained the following estimations and forecasts in R for a seasonal ARIMA(1, 0, 1)(1, 0, 1)[7]</p>

<blockquote>
  <p>model1</p>
</blockquote>

<p>Series: PO </p>

<p>ARIMA(1,0,1)(1,0,1)[7] with zero mean     </p>

<p>Coefficients:</p>

<pre><code>      ar1      ma1    sar1     sma1
      0.9895  -0.8241  0.9974  -0.9551
s.e.  0.0053   0.0223  0.0018   0.0136
  sigma^2 estimated as 0.07273:  log likelihood=-109.35
   AIC=228.7   AICc=228.76   BIC=252.96
</code></pre>

<blockquote>
  <p>forecast(model1, h=2)</p>
</blockquote>

<p>Point   Forecast     Lo 80    Hi 80     Lo 95    Hi 95</p>

<p>t+1      <strong>1.404053</strong> 1.0584363 1.749670 0.8754777 1.932629</p>

<p>t+2      1.266133 0.9158214 1.616444 0.7303778 1.801888</p>

<p>However, considering the back errors and observed values from below, I cannot seem to replicate the forecast for t+1 which is 1.404053, using the formula:</p>

<pre><code>x[t+1]=0.9895*x[t]+0.9974*x[t-6]-0.9895*0.9974*x[t-7]-(-0.8241)*e[t]-(-0.9551)*e[t-6]+(-0.8241)*(-0.9551)*e[t-7]
</code></pre>

<p>Instead of 1.404053 I get 1.34755</p>

<p>Point   Errors      Fitted          Observed</p>

<p>... ...</p>

<p>t-8 0.091543793 1.439935124     1.5314789</p>

<p>t-7 -0.146540485    1.40181299      1.2552725</p>

<p>t-6 -0.031449518    1.235569501     1.20412</p>

<p>t-5 -0.008707829    1.263980334     1.2552725</p>

<p>t-4 -0.009736316    1.472134314     1.462398</p>

<p>t-3 0.079273123 1.477029378     1.5563025</p>

<p>t-1 0.064970255 1.440179723     1.50515</p>

<p>t   0.135555386 1.444228211     1.5797836</p>

<p>Can you please help me understand what I am doing wrong?
Thank you!</p>
"
"0.0817860820109531","0.0811107105653813"," 77915","<p>I have a time series $X_t$, which is shown in the first plot. In the second plot, I am doing a linear regression on $X_t\sim X_{t-1}$. The regression line is very close to $y=x$. But this is tricky since if if we look at the bottom left or the top right part of the data, they are almost random. From the diagnosis of residuals, it is not a good regression either. But the model passes all the $t$ tests and $F$ tests. How can I say it's not a good model then? Is there a statistic  to describe (not visually) the failure of this modelling?</p>

<p>Here are the <code>R</code> codes I used to generate the plots:</p>

<pre><code># Generating X_t
x=c(arima.sim(list(order = c(1,0,0),ar=0.1),n=64,sd=1),3,5,7,11,14,17,rep(20,64)+arima.sim(list(order = c(1,0,0),ar=0.1),n=64,sd=1))
# Regression X_t~X_{t-1}
reg=lm(x[2:length(x)]~x[1:(length(x)-1)])
# Plotting
par(mfrow=c(3,2))
plot(x,xlab='',ylab=expression(X[t]),ty='l')
plot(x[1:(length(x)-1)],x[2:length(x)],xlab=expression(x[t-1]),ylab=expression(x[t]) ,main=paste('coeff= ',round(reg$coefficients[2],2)))
# Plotting the regression line
abline(reg,col=2)
# Plotting the residual diagnose
plot(reg)
</code></pre>

<p><img src=""http://i.stack.imgur.com/2xJ65.png"" alt=""enter image description here""></p>
"
"0.103452120022374","0.128247294010644"," 78741","<p>In R (2.15.2) I fitted once an ARIMA(3,1,3) on a time series and once an ARMA(3,3) on the once differenced timeseries. The fitted parameters differ, which I attributed to the fitting method in ARIMA. </p>

<p>Also, fitting an ARIMA(3,0,3) on the same data as ARMA(3,3) will not result in identical parameters, no matter the fitting method I use.</p>

<p>I am interested in identifying where the difference comes from and with what parameters i can (if at all) fit the ARIMA to get the same coefficients of the fit as from the ARMA.</p>

<p>Sample code to demonstrate:</p>

<pre><code>library(tseries)
set.seed(2)
#getting a time series manually
x&lt;-c(1,2,1)
e&lt;-c(0,0.3,-0.2)
n&lt;-45
AR&lt;-c(0.5,-0.4,-0.1)
MA&lt;-c(0.4,0.3,-0.2)
for(i in 4:n){
tt&lt;-rnorm(1)
t&lt;-x[length(x)]+tt+x[i-1]*AR[1]+x[i-2]*AR[2]+x[i-3]*AR[3]+e[i-1]*MA[1]+e[i-2]*MA[2]+e[i-3]*MA[3]
x&lt;-c(x,t)
e&lt;-c(e,tt)
}
par(mfrow=c(2,1))
plot(x)
plot(diff(x,1))

#fitting different versions. What I would like to get is fit1 with ARIMA()
fit1&lt;-arma(diff(x,1,lag=1),c(3,3),include.intercept=F)
fit2&lt;-arima(x,c(3,1,3),include.mean=F)
fit3&lt;-arima(diff(x,1),c(3,0,3),include.mean=F)
fit4&lt;-arima(x,c(3,1,3),method=""CSS"",include.mean=F)
fit5&lt;-arima(diff(x,1),c(3,0,3),method=""CSS"",include.mean=F)

cbind(fit1$coe,fit2$coe,fit3$coe,fit4$coe,fit5$coe)
</code></pre>

<p>Edit: Using the conditional sum of squares comes pretty close, but is not quite there. Thanks for the hint for the fit1!</p>

<p>Edit2: I do not think this is a duplicate. Points 2 and 3 address different problems than mine, and even if I override the initialisation mentioned in point 1 by </p>

<pre><code>fit4&lt;-arima(x,c(3,1,3),method=""CSS"",include.mean=F,init=fit1$coe)
</code></pre>

<p>I still get different coefficients</p>
"
"0.0667780563294178","0.0993399267798783"," 84255","<p>I am new to R and the ARIMA model and I am attemping to forecast 1440 values into the future using a base of roughly 5000 numbers. It is data extracted roughly every minute from a machine log(performance values). The intend to forecast 1 day into the future, which explains the 1440 values(as they are minutes).</p>

<p>Here is my result using the following commands:
    datats&lt;-c(data);
    arima&lt;-auto.arima(datats);
    fcast&lt;-forecast(arima, h=1440);</p>

<p><img src=""http://i.imgur.com/N7aCqvx.png"" alt=""forecast""> </p>

<p>The prediction begins at the flat line on the right hand side.</p>

<p>Forecast method: ARIMA(0,1,1)                   </p>

<p>Model Information:
Series: datats 
ARIMA(0,1,1)                    </p>

<p>Coefficients:
          ma1
      -0.9373
s.e.   0.0071</p>

<p>sigma^2 estimated as 86737:  log likelihood=-21221.46
AIC=42446.93   AICc=42446.93   BIC=42458.93</p>

<p>Error measures:
                    ME     RMSE      MAE       MPE     MAPE      MASE
Training set 0.6506441 294.4619 196.7211 -59.85254 85.45473 0.7637028
                   ACF1
Training set 0.01519673</p>

<p>Dataset here: <a href=""http://pastebin.com/92ssDExn"" rel=""nofollow"">http://pastebin.com/92ssDExn</a></p>

<p>Is the issue too little past values?
To many values to be predicted?</p>

<p>Any information or advice would be extremely welcomed, any other information required will be provided. </p>
"
"0.057831493196624","0.0573539334676404"," 88722","<p>I am building a regression model of time series data in R, where my primary interest is the coefficients of the independent variables. The data exhibit strong seasonality with a trend.</p>

<p><img src=""http://i.stack.imgur.com/GYxaU.png"" alt=""Original data""></p>

<p>The model looks good, with four of the six regressors significant:
<img src=""http://i.stack.imgur.com/ZmoSd.png"" alt=""Model""></p>

<p>Here are the OLS residuals:
<img src=""http://i.stack.imgur.com/EIybo.png"" alt=""Residuals""></p>

<p>I used auto.arima to select the sARIMA structure, and it returns the model (0,1,1)(1,1,0)[12].</p>

<pre><code>fit.ar &lt;- auto.arima(at.ts, xreg = xreg1, stepwise=FALSE, approximation=FALSE)
summary(fit.ar)

Series: at.ts 
ARIMA(0,1,1)(1,1,0)[12]                    

Coefficients:
          ma1    sar1      v1       v2      v3       v4         v5
      -0.7058  0.3974  0.0342  -0.0160  0.0349  -0.0042  -113.4196
s.e.   0.1298  0.2043  0.0239   0.0567  0.0555   0.0333   117.1205

sigma^2 estimated as 3.86e+10:  log likelihood=-458.13
AIC=932.26   AICc=936.05   BIC=947.06

Training set error measures:
                   ME     RMSE      MAE       MPE     MAPE      MASE
Training set 7906.896 147920.3 103060.4 0.1590107 3.048322 0.1150526
</code></pre>

<p>My question is this: based on the parameter estimates and s.e. of the regressors, I believe that none of them are significant - is this correct, and if so, what does it imply if my goal is to interpret the relative importance of these predictors as opposed to forecasting?</p>

<p>Any other advice relative to the process of building this model is welcome and appreciated.</p>

<p>Here are the ACF and PACF for the residuals:</p>

<p><img src=""http://i.stack.imgur.com/a3Gvy.png"" alt=""ACF-PACF""></p>

<pre><code>&gt; durbinWatsonTest(mod.ols, max.lag=12)
 lag Autocorrelation D-W Statistic p-value
   1     0.120522674     1.6705144   0.106
   2     0.212723044     1.4816530   0.024
   3     0.159828108     1.5814771   0.114
   4     0.031083831     1.8352377   0.744
   5     0.081081308     1.6787808   0.418
   6    -0.024202465     1.8587561   0.954
   7    -0.008399949     1.7720761   0.944
   8     0.040751905     1.6022835   0.512
   9     0.129788310     1.4214391   0.178
  10    -0.015442379     1.6611922   0.822
  11     0.004506292     1.6133994   0.770
  12     0.376037337     0.7191359   0.000
 Alternative hypothesis: rho[lag] != 0
</code></pre>
"
"0.200929517013936","0.214598768819738"," 89808","<p>I am trying to model daily sales for a take out restaurant. They are only open on business days - no holidays or weekends - as their primary clients are office workers on their lunch breaks.</p>

<p>Below is what two years of the daily sales time series looks like.</p>

<p><img src=""http://i.stack.imgur.com/UhHDR.png"" alt=""enter image description here""></p>

<p>The days with zero sales, as you can see above, are the days that the restaurant was closed due to a public holiday (Easter Monday etc.). There is definitely a weekly pattern: sales tend to peak on Thursdays. Furthermore, the presence of a holiday changes the sales pattern in the surrounding weeks (the week before and the week after).</p>

<p>You might notice that there are sales spikes before or after certain holidays. An example of this: if Monday is a holiday, sales tend to be much lower on the Friday before that long weekend - presumably office workers leaving work early.</p>

<p>There are also yearly seasonal patterns. Sales are lower in the summer, for example, presumably, in part, because many office workers are taking their vacations.</p>

<p>My approach has been to use a ARIMAX model to fit the data (using R). I've followed the approach suggested by Rob Hyndman <a href=""http://stats.stackexchange.com/questions/41070/how-to-setup-xreg-argument-in-auto-arima-in-r"">here</a>. The difference is that I'm using only Mon-Fri, so my frequency is 5, and I've added dummy variables for all of the days that the restaurant is closed (holidays).</p>

<p>The model fit is not very good so far, of course. I haven't done anything to take into account the effect of a holiday on the surrounding days. Further, I'm including the holidays as days with sales equal to zero, so this must throw off the model.</p>

<p>Here is what R returns:</p>

<pre><code>ARIMA(0,1,1)(1,0,1)[5]                    

Coefficients:
     ma1     sar1    sma1      Mon       Tue       Wed      Thu     Day    Newyears   FamilyDay  GoodFriday      Easter  VictoriaDay   CanadaDay    CivicDay
  -0.804  -0.2608  0.3255  54.4530  113.8052  152.0052  -6.3025  0.0388  -1545.1973  -1604.5038  -1581.6740  -1586.8710    -1628.253  -1437.6075  -1181.0054
s.e.   0.028   0.4641  0.4529  23.2788   23.3748   23.4900  23.4367  1.5546    117.6128    113.6446    113.8825    114.5609      114.786    112.7561    114.0031
   LabourDay  Thanksgiving
  -1310.3416    -1332.8028
s.e.    113.5081      113.5179

sigma^2 estimated as 28269:  log likelihood=-3305.08
AIC=6646.16   AICc=6647.56   BIC=6722.2
</code></pre>

<p>I think I should include the month of the year as a dummy variable to capture yearly seasonal effects as well.</p>

<p>My questions:</p>

<ol>
<li>What can I do to capture ""long weekend effects""? Should I included a dummy variable for every Friday that proceeds a long weekend etc?</li>
<li>How should I deal with the holidays that the restaurant was closed for? If I remove them, then the week lengths will not be the same. If I include them, then they are outliers that throw everything off.</li>
<li>What else can I do to improve my model?</li>
</ol>

<p>Thanks very much for any input.</p>
"
"0.216385633707315","0.214598768819738"," 89851","<p>I've heard a bit about using neural networks to forecast time series. </p>

<p>How can I compare, which method for forecasting my time-series (daily retail data) is better: auto.arima(x), ets(x) or nnetar(x).</p>

<p>I can compare auto.arima with ets by AIC or BIC. But how I can compare them with neural networks?</p>

<p>For example:</p>

<pre><code>   &gt; dput(x)
 c(1774, 1706, 1288, 1276, 2350, 1821, 1712, 1654, 1680, 1451, 
 1275, 2140, 1747, 1749, 1770, 1797, 1485, 1299, 2330, 1822, 1627, 
 1847, 1797, 1452, 1328, 2363, 1998, 1864, 2088, 2084, 594, 884, 
 1968, 1858, 1640, 1823, 1938, 1490, 1312, 2312, 1937, 1617, 1643, 
 1468, 1381, 1276, 2228, 1756, 1465, 1716, 1601, 1340, 1192, 2231, 
 1768, 1623, 1444, 1575, 1375, 1267, 2475, 1630, 1505, 1810, 1601, 
 1123, 1324, 2245, 1844, 1613, 1710, 1546, 1290, 1366, 2427, 1783, 
 1588, 1505, 1398, 1226, 1321, 2299, 1047, 1735, 1633, 1508, 1323, 
 1317, 2323, 1826, 1615, 1750, 1572, 1273, 1365, 2373, 2074, 1809, 
 1889, 1521, 1314, 1512, 2462, 1836, 1750, 1808, 1585, 1387, 1428, 
 2176, 1732, 1752, 1665, 1425, 1028, 1194, 2159, 1840, 1684, 1711, 
 1653, 1360, 1422, 2328, 1798, 1723, 1827, 1499, 1289, 1476, 2219, 
 1824, 1606, 1627, 1459, 1324, 1354, 2150, 1728, 1743, 1697, 1511, 
 1285, 1426, 2076, 1792, 1519, 1478, 1191, 1122, 1241, 2105, 1818, 
 1599, 1663, 1319, 1219, 1452, 2091, 1771, 1710, 2000, 1518, 1479, 
 1586, 1848, 2113, 1648, 1542, 1220, 1299, 1452, 2290, 1944, 1701, 
 1709, 1462, 1312, 1365, 2326, 1971, 1709, 1700, 1687, 1493, 1523, 
 2382, 1938, 1658, 1713, 1525, 1413, 1363, 2349, 1923, 1726, 1862, 
 1686, 1534, 1280, 2233, 1733, 1520, 1537, 1569, 1367, 1129, 2024, 
 1645, 1510, 1469, 1533, 1281, 1212, 2099, 1769, 1684, 1842, 1654, 
 1369, 1353, 2415, 1948, 1841, 1928, 1790, 1547, 1465, 2260, 1895, 
 1700, 1838, 1614, 1528, 1268, 2192, 1705, 1494, 1697, 1588, 1324, 
 1193, 2049, 1672, 1801, 1487, 1319, 1289, 1302, 2316, 1945, 1771, 
 2027, 2053, 1639, 1372, 2198, 1692, 1546, 1809, 1787, 1360, 1182, 
 2157, 1690, 1494, 1731, 1633, 1299, 1291, 2164, 1667, 1535, 1822, 
 1813, 1510, 1396, 2308, 2110, 2128, 2316, 2249, 1789, 1886, 2463, 
 2257, 2212, 2608, 2284, 2034, 1996, 2686, 2459, 2340, 2383, 2507, 
 2304, 2740, 1869, 654, 1068, 1720, 1904, 1666, 1877, 2100, 504, 
 1482, 1686, 1707, 1306, 1417, 2135, 1787, 1675, 1934, 1931, 1456)
</code></pre>

<p>Using auto.arima:</p>

<pre><code>y=auto.arima(x)
plot(forecast(y,h=30))
points(1:length(x),fitted(y),type=""l"",col=""green"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/uwSqY.png"" alt=""enter image description here""></p>

<pre><code>&gt; summary(y)
Series: x 
ARIMA(5,1,5)                    

Coefficients:
         ar1      ar2     ar3      ar4      ar5      ma1     ma2      ma3     ma4      ma5
      0.2560  -1.0056  0.0716  -0.5516  -0.4822  -0.9584  1.2627  -1.0745  0.8545  -0.2819
s.e.  0.1014   0.0778  0.1296   0.0859   0.0844   0.1184  0.1322   0.1289  0.1388   0.0903

sigma^2 estimated as 58026:  log likelihood=-2191.97
AIC=4405.95   AICc=4406.81   BIC=4447.3

Training set error measures:
                   ME     RMSE      MAE       MPE     MAPE      MASE
Training set 1.457729 240.5059 173.9242 -2.312207 11.62531 0.6157512
</code></pre>

<p>Using ets:</p>

<pre><code>fit &lt;- ets(x)
plot(forecast(fit,h=30))
points(1:length(x),fitted(fit),type=""l"",col=""red"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/9UngX.png"" alt=""enter image description here""></p>

<pre><code> &gt; summary(fit)
 ETS(M,N,N) 

 Call:
  ets(y = x) 

   Smoothing parameters:
     alpha = 0.0449 

   Initial states:
     l = 1689.128 

   sigma:  0.2094

      AIC     AICc      BIC 
 5570.373 5570.411 5577.897 

 Training set error measures:
                    ME     RMSE      MAE      MPE     MAPE      MASE
 Training set 7.842061 359.3611 276.4327 -4.81967 17.98136 0.9786665
</code></pre>

<p>In this case auto.arima fits better then ets.</p>

<p>Let's try sing neural network:</p>

<pre><code> library(caret)
 fit &lt;- nnetar(x)
 plot(forecast(fit,h=60))
 points(1:length(x),fitted(fit),type=""l"",col=""green"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/M8HIT.png"" alt=""enter image description here""></p>

<p>From the graph, I can see, that neural network model fits quite well, but how can I compare it with auto.arima/ets? How can I compute AIC?</p>

<p>Another question is, how to add confidence interval for neural network,if it is possible, like it is added automatically for auto.arima/ets.?</p>

<p>Any help and advises would be really appreciated.</p>
"
"0.118048041162471","0.140487871737254"," 95709","<p>I am fitting a regression with ARMA errors using the base R function <code>arima()</code> and the <code>Arima()</code> function from the <code>forecast</code> package.  </p>

<p>The estimated coefficients from both are identical. My problem comes from using <code>arima.errors()</code> on these two models, and using <code>tsdisplay()</code> to view these structural residuals (that is, the residuals straight from the regression, before any ARMA model is fit on them). These ARMA errors (and their corresponding ACFs, PACFs) are different between the two, and I don't know why. Even more curious is that the final residuals from both are in fact the same, which would make me think the structural residuals would have to be the same. I have put a MWE below.</p>

<pre><code>library('forecast')
data(usconsumption, package='fpp')

fit1 = arima(usconsumption[ ,1], xreg=usconsumption[ ,2], order=c(2,0,0))
tsdisplay(arima.errors(fit1), main=""ARIMA errors, arima function"") # not the same as the other


fit2 = Arima(usconsumption[,1], xreg=usconsumption[,2], order=c(2,0,0))
dev.new()
tsdisplay(arima.errors(fit2), main=""ARIMA errors, Arima function"") # not the same as the other


View(cbind(resid(fit1), resid(fit2))) # final residuals are the same
</code></pre>

<p>Note this example is from <a href=""https://www.otexts.org/fpp/9/1"" rel=""nofollow"">https://www.otexts.org/fpp/9/1</a></p>
"
"0.141657649394966","0.117073226447712","100702","<p>A particular series (std), seems to exhibit a trend-like behavior. According to the ADF test for this series:</p>

<pre><code>Dickey-Fuller = -2.8618, Lag order = 6, p-value = 0.2131
</code></pre>

<p>Therefore, I am taking the first difference of std with this code</p>

<pre><code>stddif1&lt;- diff(std)
</code></pre>

<p>Here is the tricky part, the acf and pacf suggest that this would be an ARMA process (2,1), with a d=1. But the code shows both different estimates and different AIC values, when (I think) this <em>shouldn't</em> be the case:</p>

<p>For std with no difference:</p>

<pre><code>&gt; arima(std, order=c(2,1,1))

Call:
arima(x = std, order = c(2, 1, 1))

Coefficients:
     ar1     ar2      ma1
  0.5206  0.2697  -0.7638
s.e.  0.1218  0.0552   0.1153

sigma^2 estimated as 0.06355:  log likelihood = -13.3,  aic = 34.6
</code></pre>

<p>And, for the differenced std (stddif):</p>

<pre><code>&gt; arima(stddif, order=c(2,0,1))

Call:
arima(x = stddif, order = c(2, 0, 1))

Coefficients:
     ar1     ar2      ma1  intercept
  0.5188  0.2695  -0.7620    -0.0003
s.e.  0.1223  0.0554   0.1159     0.0157

sigma^2 estimated as 0.06355:  log likelihood = -13.3,  aic = 36.6
</code></pre>

<p>The values for the AR1, AR2, MA1 as well as the AIC are different. Why is this?</p>

<p>This was all done in R, the relevant package is 'tseries'.</p>
"
"0.146303391191891","0.126958343769252","103129","<p>I am trying to understand what the reported intercept is showing when I use <code>arima()</code> with <code>xreg=</code>. The documentation says</p>

<p>""If am xreg term is included, a linear regression (with a constant term if include.mean is true and there is no differencing) is fitted with an ARMA model for the error term.""</p>

<p>Thus I expect the intercept shown to come from the regression using <code>xreg=</code> as the X variables, before any arima model is done on those residuals. </p>

<p>However I tried to double check this by actually doing the regression with <code>lm()</code> and the intercept from that does not match what is reported from <code>arima()</code> (although the slope coefficient is pretty close). </p>

<p>Here is my example:</p>

<pre><code>set.seed(456)
v = rnorm(100,1,1)
x = cumsum(v)  ; x = as.xts(ts(x)) 

# Fit AR(1) after taking out a time trend (aka, drift)
model5 = arima(x, order=c(1,0,0), xreg=1:length(x), include.mean=TRUE)
# Coefficients:
#         ar1     intercept  1:length(x)
#       0.8995     0.8815       1.1113
# s.e.  0.0422     1.6193       0.0265


# Double check
MyTime = 1:length(x)
model5_Part1 = lm(x ~ MyTime )
# Coefficients:
#      (Intercept)       MyTime  
#         1.856           1.096
</code></pre>

<p>The intercepts do not match, thus I do not know what the intercept is showing from the arima with xreg.</p>

<p>Note the example shown is based on ""Issue 2"" shown here <a href=""http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm"" rel=""nofollow"">http://www.stat.pitt.edu/stoffer/tsa3/Rissues.htm</a></p>

<p>Also note that this isn't a problem particular to modeling drift. Here is another example, where in addition to the intercept not matching, even the slope coefficient on the <code>xreg=</code> variable doesn't match what is shown from using <code>lm()</code>. This example has nothing to do with drift and uses the cars dataset as if it were time series data.</p>

<pre><code>data(cars)
cars = as.xts(ts(cars, start=c(1980,1), freq=12))
model6 = arima(cars$speed, xreg=cars$dist, order=c(1,0,0), include.mean=TRUE)
# Coefficients:
#         ar1    intercept   dist
#       0.9979    15.2890  -0.0172
# s.e.  0.0030    10.5452   0.0055

model6_Part1 = lm(cars$speed ~ cars$dist)
# Coefficients:
#      (Intercept)    cars$dist  
#        8.2839        0.1656 
</code></pre>

<p>Intercepts do not match, slope coefficient does not match.</p>
"
"0.185473400320556","0.199270285332614","104977","<p>I understand we should use ARIMA for modelling a non-stationary time series. Also, everything I read says ARMA should only be used for stationary time series.</p>

<p>What I'm trying to understand is, what happens in practice when misclassifying a model, and assuming <code>d = 0</code> for a time series that's non-stationary? For example: </p>

<pre><code>controlData &lt;- arima.sim(list(order = c(1,1,1), ar = .5, ma = .5), n = 44)
</code></pre>

<p>control data looks like this:</p>

<pre><code> [1]   0.0000000   0.1240838  -1.4544087  -3.1943094  -5.6205257
 [6]  -8.5636126 -10.1573548  -9.2822666 -10.0174493 -11.0105225
[11] -11.4726127 -13.8827001 -16.6040541 -19.1966633 -22.0543414
[16] -24.8542959 -25.2883155 -23.6519271 -21.8270981 -21.4351267
[21] -22.6155812 -21.9189036 -20.2064343 -18.2516852 -15.5822178
[26] -13.2248230 -13.4220158 -13.8823855 -14.6122867 -16.4143756
[31] -16.8726071 -15.8499558 -14.0805114 -11.4016515  -9.3330560
[36]  -7.5676563  -6.3691600  -6.8471371  -7.5982880  -8.9692152
[41] -10.6733419 -11.6865440 -12.2503202 -13.5314306 -13.4654890
</code></pre>

<p>Assuming I didn't know the data was <code>ARIMA(1,1,1)</code>, I might have a look at <code>pacf(controlData)</code>.</p>

<p><img src=""http://i.stack.imgur.com/IOXJf.jpg"" alt=""pacf(controlData)""></p>

<p>Then I use Dickey-Fuller to see if the data is non-stationary:</p>

<pre><code>require('tseries')
adf.test(controlData)

# Augmented Dickey-Fuller Test
#
# data:  controlData
# Dickey-Fuller = -2.4133, Lag order = 3, p-value = 0.4099
# alternative hypothesis: stationary

adf.test(controlData, k = 1)

# Augmented Dickey-Fuller Test
#
#data:  controlData
# Dickey-Fuller = -3.1469, Lag order = 1, p-value = 0.1188
# alternative hypothesis: stationary
</code></pre>

<p>So, I might assume the data is ARIMA(2,0,*) Then use <code>auto.arima(controlData)</code> to try to get a best fit?</p>

<pre><code>require('forecast')
naiveFit &lt;- auto.arima(controlData)
navifeFit
# Series: controlData 
# ARIMA(2,0,1) with non-zero mean 
# 
# Coefficients:
#          ar1      ar2     ma1  intercept
#      1.4985  -0.5637  0.6427   -11.8690
# s.e.  0.1508   0.1546  0.1912     3.2647
#
# sigma^2 estimated as 0.8936:  log likelihood=-64.01
# AIC=138.02   AICc=139.56   BIC=147.05
</code></pre>

<p>So, even though the past and future data is ARIMA(1,1,1), I might be tempted to classify it as ARIMA(2,0,1). <code>tsdata(auto.arima(controlData))</code> looks good too.</p>

<p>Here is what an informed modeler would find:</p>

<pre><code>informedFit &lt;- arima(controlData, order = c(1,1,1))
# informedFit
# Series: controlData 
# ARIMA(1,1,1)                    
#
# Coefficients:
#          ar1     ma1
#       0.4936  0.6859
# s.e.  0.1564  0.1764
#
# sigma^2 estimated as 0.9571:  log likelihood=-62.22
# AIC=130.44   AICc=131.04   BIC=135.79
</code></pre>

<p>1) Why are these information criterion better than the model selected by <code>auto.arima(controlData)</code>?</p>

<p>Now, I just graphically compare the real data, and the 2 models:</p>

<pre><code>plot(controlData)
lines(fitted(naiveFit), col = ""red"")
lines(fitted(informedFit), col = ""blue"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/sy3YR.jpg"" alt=""tsPlots""></p>

<p>2) Playing devil's advocate, what kind of consequences would I pay by using an ARIMA(2, 0, 1) as a model? What are the risks of this error? </p>

<p>3) I'm mostly concerned about any implications for multi-period forward predictions. I assume they would be less accurate? I'm just looking for some proof.</p>

<p>4) Would you suggest an alternative method for model selection? Are there any problems with my reasoning as an ""uninformed"" modeler?</p>

<p>I'm really curious what are the other consequences of this kind of misclassification. I've been looking for some sources and just couldn't find anything. All the literature I could find only touches on this subject, instead just stating the data should be stationary before performing ARMA, and if it's non-stationary, then it needs to be differenced d times.</p>

<p>Thanks!</p>
"
"0.118048041162471","0.117073226447712","105367","<p>I have the weekly revenue data for an electronics company the decomposed plot of which is as follows:  </p>

<p><img src=""http://i.stack.imgur.com/9HWE6.png"" alt=""enter image description here""></p>

<p>I have decided to keep the seasonality and apply a suitable forecasting technique. I tried auto.arima:</p>

<pre><code>&gt; Elec &lt;- read.xlsx(""C:/Users/Himanshu.raunak/Revenue/Electronics.xlsx"", 1)
&gt; Elec$Date &lt;- as.Date(Elec$Date, format=""%Y-%m-%d"")
&gt; ElecTimeSeries &lt;- ts(Elec$Revenue, frequency=52)
&gt; ElecArima &lt;- auto.arima(ElecTimeSeries)
&gt; plot(forecast(ElecArima))
</code></pre>

<p>I get the following plot:</p>

<p><img src=""http://i.stack.imgur.com/fYKNN.png"" alt=""enter image description here""> </p>

<p>And the following warning messages:</p>

<p>1: In myarima(x, order = c(p, d, q), seasonal = c(P, D, Q),  ... :
  Unable to check for unit roots</p>

<p>2: In myarima(x, order = c(p, d, q), seasonal = c(P, D, Q),  ... :
  Unable to check for unit roots</p>

<p>3: In myarima(x, order = c(max.p > 0, d, 0), seasonal = c((m >  ... :
  Unable to check for unit roots</p>

<p>and so on.</p>

<p>The ARIMA parameters come out to be as follows:</p>

<p>ARIMA(2,1,2)(0,0,1)[52] with drift</p>

<p>Coefficients:</p>

<pre><code>       ar1      ar2      ma1     ma2    sma1     drift

      0.5282  -0.0316  -1.3125  0.3225  0.2283  2497.993

s.e.    NaN      NaN      NaN     NaN    0.0728    NaN

sigma^2 estimated as 3.563e+11:  log likelihood=-2931.26

AIC=5876.51   AICc=5877.1   BIC=5899.6
</code></pre>

<p>I realize that the AIC values are quite large.</p>

<p>Could you please point out at what I am doing incorrectly (warning messages and large ARIMA parameters) and provide a better solution. Also I need help understanding the ARIMA plot.</p>
"
"0.200929517013936","0.199270285332614","108374","<p>I have a monthly time series with an intervention and I would like to quantify the effect of this intervention on the outcome. I realize the series is rather short and the effect is not yet concluded.</p>

<p><strong>The Data</strong></p>

<pre><code>  cds&lt;- structure(c(2580L, 2263L, 3679L, 3461L, 3645L, 3716L, 3955L, 
    3362L, 2637L, 2524L, 2084L, 2031L, 2256L, 2401L, 3253L, 2881L, 
    2555L, 2585L, 3015L, 2608L, 3676L, 5763L, 4626L, 3848L, 4523L, 
    4186L, 4070L, 4000L, 3498L), .Dim = c(29L, 1L), .Dimnames = list(
        NULL, ""CD""), .Tsp = c(2012, 2014.33333333333, 12), class = ""ts"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/lNOEk.jpg"" alt=""enter image description here""></p>

<p><strong>The methodology</strong></p>

<p>1) The pre-intervention series (up until October 2013) was used with the <code>auto.arima</code> function. The model suggested was ARIMA(1,0,0) with non-zero mean. The ACF plot looked good.</p>

<pre><code>pre&lt;-window(cds,start = c(2012,01), end=c(2013,09))

mod.pre&lt;-auto.arima(log(pre))

Coefficients:
         ar1  intercept
      0.5821     7.9652
s.e.  0.1763     0.0810

sigma^2 estimated as 0.02709:  log likelihood=7.89
AIC=-9.77   AICc=-8.36   BIC=-6.64
</code></pre>

<p>2) Given the plot of the full series, the pulse response was chosen below, with T = Oct 2013,</p>

<p><img src=""http://i.stack.imgur.com/YU3nB.jpg"" alt=""enter image description here""></p>

<p>which according to cryer and chan can be fit as follows with the arimax function:</p>

<pre><code>   mod.arimax&lt;-arimax(log(cds), order=c(1,0,0), seasonal=list(order=c(0,0,0),frequency=12), include.mean = TRUE,       
            xtransf=data.frame(Oct13=1*(seq(cds)==22)),
            transfer=list(c(1,1))
          )

    mod.arimax


Series: log(cds) 
ARIMA(1,0,0) with non-zero mean 

Coefficients:
         ar1  intercept  Oct13-AR1  Oct13-MA0  Oct13-MA1
      0.7619     8.0345    -0.4429     0.4261     0.3567
s.e.  0.1206     0.1090     0.3993     0.1340     0.1557

sigma^2 estimated as 0.02289:  log likelihood=12.71
AIC=-15.42   AICc=-11.61   BIC=-7.22
</code></pre>

<p>The residuals from this appeared OK:</p>

<p><img src=""http://i.stack.imgur.com/wvdXD.jpg"" alt=""enter image description here""></p>

<p>The plot of fitted and actuals:</p>

<pre><code>plot(fitted(mod.arimax),col=""red"", type=""b"")
lines(window(log(cds),start=c(2012,02)),type=""b"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/kJ1pj.jpg"" alt=""enter image description here""></p>

<p><strong>The Questions</strong></p>

<p>1) Is this methodology correct for intervention analysis?</p>

<p>2) Can I look at estimate/SE for the components of the transfer function and say that the effect of the intervention was significant?</p>

<p>3) How can one visualize the transfer function effect (plot it?)</p>

<p>4) Is there a way to estimate how much the intervention increased the output after 'x' months? I guess for this (and maybe #3) I am asking how to work with an equation of the model - if this were simple linear regression with dummy variables (for example) I could run scenarios with and without the intervention and measure the impact - but I am just unsure how to work this this type of model.</p>

<p><strong>ADD</strong></p>

<p>Per request, here are the residuals from the two parametrizations.</p>

<p>First from the fit:</p>

<pre><code>fit &lt;- arimax(log(cds), order = c(1,0,0), 
              xtransf = data.frame(Oct13a = 1*(seq_along(cds)==22), Oct13b = 1*(seq_along(cds)==22)),
              transfer = list(c(0,0), c(1,0)))

plot(resid(fit), type=""b"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/sqMZN.jpg"" alt=""enter image description here""></p>

<p>Then, from this fit</p>

<pre><code>mod.arimax&lt;-arimax(log(cds), order=c(1,0,0), seasonal=list(order=c(0,0,0),frequency=12), include.mean = TRUE,       
                   xtransf=data.frame(Oct13=1*(seq(cds)==22)),
                   transfer=list(c(1,1))
)

mod.arimax
plot(resid(mod.arimax), type=""b"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/DjAyu.jpg"" alt=""enter image description here""></p>
"
"0.143125643519168","0.141943743489417","110589","<p>I'm using R to do some time series estimation.  I'm trying to rebuild the fitted values from an Arima model by hand to use in an Excel spreadsheet using the estimated coefficients and the input data. I can use the fitted command, but I'm trying to understand more how it works. Ex:  </p>

<pre><code>library(MASS)
library(tseries)
library(forecast)

set.seed(1)
N = ts(mvrnorm(50, mu=c(0,0), Sigma=matrix(c(1,0.56,0.56,1), ncol=2), 
       empirical=TRUE), frequency=12)
head(N)

&gt;            [,1]       [,2]
&gt;[1,] -0.05270976  0.7239571
&gt;[2,] -0.67232349 -0.6631604
&gt;[3,] -0.20193415  0.8176053
&gt;[4,] -0.54278281 -2.0458285
&gt;[5,]  1.38279994  0.9405811
&gt;[6,]  1.39979731  2.1717733

# Model: x(t) = a * x(t-1) + e(t)
fit = Arima(N[,1], order=c(1,0,0), include.constant=FALSE)

&gt; fit  
&gt;Series: N[, 1]  
&gt;ARIMA(1,0,0) with zero mean          
&gt;
&gt;Coefficients:  
&gt;         ar1  
&gt;       0.0293
&gt;s.e.   0.1400  
&gt;
&gt;sigma^2 estimated as 0.9791:  log likelihood=-70.42
&gt;AIC=144.84   AICc=145.1   BIC=148.66

# Build the fitted values: x(t)=a * x(t-1) 
pred  = fit$coef[1] * lag(fit$x, -1) 
pred1 = fitted(fit)
head(cbind(pred, pred1))   

&gt;             pred         pred1
&gt;[1,]           NA -2.255567e-05
&gt;[2,] -0.001541849 -1.541849e-03
&gt;[3,] -0.019666597 -1.966660e-02
&gt;[4,] -0.005906915 -5.906915e-03
&gt;[5,] -0.015877313 -1.587731e-02
&gt;[6,]  0.040449232  4.044923e-02 
</code></pre>

<p>In this case, <code>pred</code> and <code>pred1</code> match.  </p>

<p>However when I add in an <code>xreg</code>:  </p>

<pre><code># Model: x(t) = a*x(t-1) + b*xreg + e(t)
fit1 = Arima(N[,1], order=c(1,0,0), xreg=N[,2], include.constant=FALSE)

&gt;fit  
&gt;Series: N[, 1]  
&gt;ARIMA(1,0,0) with zero mean         
&gt;
&gt;Coefficients:  
&gt;         ar1  N[, 5]  
&gt;       0.0860  0.5606  
&gt;s.e.   0.1401  0.1155  
&gt;
&gt;sigma^2 estimated as 0.6675:  log likelihood=-60.85
&gt;AIC=127.69   AICc=128.22   BIC=133.4

# Build the fitted values: x(t) = a*x(t-1) + b*xreg 
pred2  = fit1$coef[1]*lag(fit1$x, -1) + fit1$coef[2]*fit1$xreg 
pred21 = fitted(fit1) 
head(cbind(pred2, pred21))

&gt;              pred2     pred21
&gt;[1,]         NA  0.4041670
&gt;[2,]  0.4013329 -0.4112205
&gt;[3,] -0.4296032  0.4325201
&gt;[4,]  0.4410005 -1.2037229
&gt;[5,] -1.1936161  0.5792684
&gt;[6,]  0.6462336  1.2911169
</code></pre>

<p>In this case, <code>pred2</code> and <code>pred21</code> do not match, and the only thing changed was adding an <code>xreg</code>. The only time I cannot build out the fitted values by hand is when the AR part is included. I was able to do it when only MA parts were included with the <code>xreg</code>.  I would really appreciate knowing how <code>Arima</code> treats <code>xreg</code> when generating the fitted values. </p>
"
"0.212279271240542","0.236842105263158","110611","<p>Note that this is a simplified example:</p>

<p>I have some time series that I made stationary by differencing twice. Then I ran <code>arima</code> on it, and set d = 0 to prevent additional differencing (I'm aware that <code>auto.arima</code> could detect the order of integration, but I'm hard-coding this myself for other reasons). Now I want to use <code>fitted</code> data from my <code>arima</code> object to determine what the <em>non-stationary</em> fit would look like.</p>

<p>For example:</p>

<pre><code>library('forecast')
# simulate ARIMA(1,2,0) time series:
rawData &lt;- arima.sim(n = 20, list(order = c(1,2,0), ar = 0.7)) 
# use diff function to make the series stationary:
stationaryData &lt;- diff(diff(rawData))

# fit ARIMA on them appropriately
rawDataFit &lt;- arima(rawData, c(1,2,0)) # include.mean = FALSE by default
stationaryDataFit &lt;- arima(stationaryData, c(1,0,0), include.mean = FALSE) # stationaryData is already twice differenced

# notice that there is very small variance between the AR(1) coefficients:
coef(rawDataFit)
coef(stationaryDataFit)
</code></pre>

<p>In this particular instance, my AR(1) coefficeints are 0.5511049 and 0.5511048. I also forced my ARIMA to exclude an intercept, so these ARIMA objects so be similar.</p>

<pre><code># plot of rawData and the fitted values
plot(rawData, type = ""l"")
lines(fitted(rawDataFit), col = ""slategrey"")
</code></pre>

<p>Here's an example of what that plot could look like:
<img src=""http://i.stack.imgur.com/5R0cM.png"" alt=""Here&#39;s an example of what that plot could look like""></p>

<p>I want to recreate the above plot, <em>without</em> using the rawDataFit object</p>

<pre><code># using the diffinv function, I can easily replicate the rawData:
recoveredRawData &lt;- diffinv(stationaryData, differences = 2, xi = rawData[1:2])

# Now I also want to ""recover"" the non-stationary data from the fitted AR(1) object:
recoveredFit &lt;- diffinv(fitted(stationaryDataFit), differences = 2, xi = c(0,0))

# plot of rawData and the fitted values
plot(recoveredRawData, type = ""l"")    
lines(recoveredFit, col = ""slategrey"")
</code></pre>

<p>Here's the attempt to recreate the above plot, using the results from my stationaryDataFit:</p>

<p><img src=""http://i.stack.imgur.com/xZuKH.png"" alt=""Here&#39;s the attempt to recreate the above plot, using the results from my stationaryDataFit""></p>

<p>The shape looks correct, but the values are clearly off. I am <em>not</em> expecting to recover exactly the same results from both methods of fitting, but I still expect them to be reasonably close. </p>

<p>I strongly suspect the problem is with my choice of xi in the <code>diffinv</code> function, since that's really the only place I'm making any assumptions. But I'm having trouble reconciling the issue.</p>

<p>To integrate the data, <code>diffinv</code> requires the first observations of the integrated data. This is how I can convert the stationaryData back to the rawData, by passing the first two values of rawData to the <code>diffinv</code> xi argument. But I'm unsure what to use as the starting values to integrate <code>fitted(stationaryDataFit)</code>. The first two values of the (integrated) rawData are 0, so that's what I'm trying for now...</p>

<p>Any ideas?</p>

<p><strong>EDIT:</strong> Is this a legitimate work-around? Take the residuals from my stationaryDataFit object, and just subtract those from my rawData? For example:</p>

<pre><code># prefix 2 zeros, so the vectors are the same length (due to secord-differencing):
recoveredFit &lt;- rawData - c(rep(0, 2), stationaryDataFit$residuals)
</code></pre>

<p>My concern is about whether I need to transform my residuals from the stationaryDataFit somehow? In fact, the residuals from both fits are extremely close (within several decimals).</p>

<p>Thank you!</p>
"
"0.0817860820109531","0.0811107105653813","111103","<p>I'm trying to apply R output to generate a scenario using external data, I'm not sure how exactly to use the coefficients in each from the R output.</p>

<p>I have an ARMAX(1, 1) model</p>

<ul>
<li>Coefficient of AR1: $A$</li>
<li>Coefficient of MA1: $M$</li>
<li>Intercept = $k$</li>
<li>Coefficient of external regressors: $B_1$, $B_2$</li>
<li>External regressors: $X_1$, $X_2$</li>
<li>Y actual = $Y_a$</li>
<li>Y predicted = $Y_p$</li>
</ul>

<p>The formula I'm using is $Y_p = k + A*(Y_a(t-1)-k) - M*(Y_a(t-1) - Y_p(t-1)) + B_1*(X_1(t) - X_1(t-1)) + B_2*(X_2(t) - X_2(t-1))$</p>

<p>Is there anything wrong with the formula I'm using?
I'm asking because of two things, one is that while AIC is much better for this model, the sum of squared errors is actually higher than if I just used AR(1) model; another thing is that when I adjust the AR term, the sum of squared residuals gets reduced, but I thought the model is supposed to minimize the sum of squared residuals for each of the terms?</p>

<p>I'm using the same data set for generating the model and to fit the model, I need to test  to see how much improvement this model offers compared to simpler models. I'm doing the fitting in Excel.</p>

<p>Any help would be greatly appreciated, and if additional information is needed to answer this please ask.</p>

<p>This is my R output</p>

<pre><code>ARMA11R2R30


Call:
arima(x = YieldReOLD[, 5], order = c(1, 0, 1), xreg = cbind(YieldReOLD[, 2], 
    YieldReOLD[, 4]))

Coefficients:
         ar1      ma1  intercept  cbind(YieldReOLD[, 2], YieldReOLD[, 4])1
      0.9872  -0.1970    -6.2862                                   -0.1867
s.e.  0.0072   0.0489     0.3743                                    0.0566

      cbind(YieldReOLD[, 2], YieldReOLD[, 4])2
                                       -0.3999
s.e.                                    0.1140
</code></pre>
"
"0.163572164021906","0.162221421130763","114675","<p>I really want to understand how the math is working here. I am trying to get the standard error of the fitted values for a time series regression model. In the non-time series regression, I know I can take the transpose of the data multiplied by the variance - covariance matrix of the model coefficients and then multiply by the data values again to get the standard errors of the fitted values.</p>

<p>But I'm not sure how to do this when I am including an autoregressive term.</p>

<pre><code>require(forecast)
require(tserieS)
</code></pre>

<p>Response variable</p>

<pre><code>Sablects &lt;- rnorm(10)
</code></pre>

<p>Covariates</p>

<pre><code>my.xreg &lt;- cbind(rnorm(10),rbinom(10,1,0.5))
</code></pre>

<p>In my actual data, values are normalized so I set the intercept equal to zero here.</p>

<pre><code>m4&lt;-arima(Sablects, order=c(2,0,0),fixed=c(0,NA,0,NA,NA),xreg=my.xreg) 
</code></pre>

<p>The predict function will give me standard errors on my in-sample prediction (the fitted values of my model).</p>

<pre><code>my.se &lt;- predict(m4, newxreg = my.xreg, n.ahead = 10)$se         

my.se
</code></pre>

<p>Now to compare the output of my.se, I want to do this mathematically but I don't know what to use for the values of the ar2 term. I use 1's as a placeholder to demonstrate that my output does not equal the values from <code>my.se</code> above</p>

<pre><code>C &lt;- cbind(rep(1, nrow(my.xreg)), my.xreg[, 1], my.xreg[, 2])

C
</code></pre>

<p>I think this value should equal the first value in my.se, but is not producing the same value as my.se</p>

<pre><code>sqrt(t(C[1, ]) %*% vcov(m4) %*% C[1, ])
</code></pre>

<p>Also, I'm not so great with matrix multiplication but here is my work around for getting all of the se values.</p>

<pre><code>se.output &lt;- matrix(nrow=nrow(C))
</code></pre>

<p>Specify that the max number of i is equal to number of rows of <code>C</code>.</p>

<pre><code>  for(i in 1:nrow(C)){

    # Loop through your multiplication for each row (i) of `C`. For each iteration, save the new data into the new row of se.output

    se.output[i] &lt;- sqrt(t(C[i, ]) %*% vcov(m4) %*% C[i, ])  
    }

se.output
</code></pre>
"
"0","0.0573539334676404","116842","<p>I have a SarimaX model with three regressor variables:</p>

<pre><code>ARIMA(1,0,0)(0,1,1)[7]                    

Coefficients:
          ar1       sma1   C1 (for xreg1)   C2 (for xreg2)   C3 (for xreg3)
      -0.0260    -0.9216          -0.0354           0.0316           0.9404
s.e.   0.0291     0.0350           0.0016           0.0017           0.0128
</code></pre>

<p>I would like to know how to use these coefficients to obtain the actual equation, like:</p>

<pre><code>y[t] = f(ar1, sma1, C1|xreg1[t], C2|xreg2[t], C3|xreg3[t])
</code></pre>

<p>I have read the following:</p>

<p><a href=""https://www.otexts.org/fpp/8/9"" rel=""nofollow"">https://www.otexts.org/fpp/8/9</a> - I'm using the forecast package in R, so I'm quite grateful for Mr. Hyndman's work,</p>

<p><a href=""http://people.duke.edu/~rnau/arimreg.htm"" rel=""nofollow"">http://people.duke.edu/~rnau/arimreg.htm</a></p>

<p>and others, and I devised some formulas, but they generated values less acurate than those from the R forecast. Somehow, my error-related terms are probably wrong.</p>

<hr>

<p><strong>EDIT</strong>: This is what I have so far:</p>

<p>$$ \ (1-ar1*B)*(1-B^7)*y_t=$$
$$ = (1-ar1*B)*(1-B^7)*(C1*xreg1_t + C2*xreg2_t+C3*xreg3_t)+ $$
$$ + e_t + sma1*e_{t-7}$$</p>

<p>I would like to know if this formula is correct, could anyone please help? Thank you.</p>
"
"0.0817860820109531","0.0811107105653813","117474","<p>A dataset I am working with (from the OECD), for harmonised unemployment seems to be seasonally adjusted:</p>

<blockquote>
  <p>The unemployment rates  shown here are calculated as the number of unemployed persons as a percentage of the labour force (i.e., the unemployed plus those in employment) and are seasonally adjusted.</p>
</blockquote>

<p>This is taken from their <a href=""http://www.oecd.org/std/labour-stats/44743407.pdf"" rel=""nofollow"">methodology notes</a>. Yet, while working with it, R (the software that I am using) shows a seasonal component in the decomposition of the series.</p>

<p>Working backwards (with <code>auto.arima</code>) for the series, this is the result I get for the series:</p>

<pre><code> Series: std 
 ARIMA(2,1,1)(0,0,2)[12]                    

 Coefficients:
     ar1     ar2      ma1     sma1    sma2
  0.5194  0.3131  -0.7888  -0.1570  0.0918
 s.e.  0.1031  0.0552   0.0957   0.0569  0.0569

 sigma^2 estimated as 0.06156:  log likelihood=-8.39
 AIC=28.77   AICc=29.04   BIC=51.44

 Training set error measures:
                   ME      RMSE       MAE       MPE     MAPE      MASE
 Training set 0.0006069076 0.2477273 0.1866529 -0.210822 5.128619 0.2163681
</code></pre>

<p>Whose criterions and error measurements seem to be unequivocally lower than any other model I have come up with <em>without</em> any seasonal component.</p>

<p>R suggests <em>two</em> Seasonal Moving Average components for this series, but I am unsure of the validity of this, given the fact that the series was already adjusted according to the OECD. A minor problem is that the MPE is negative.</p>

<p>I am worried about over estimation of the relevant parameters.</p>

<p>Here is the structure of the data:</p>

<pre><code> &gt; dput(std)
 structure(c(4.5, 4.7, 4.2, 4.4, 3.9, 3.9, 3.7, 3.7, 3.4, 3.6, 
 3.5, 3.1, 3.5, 3.3, 3.7, 3.7, 3.7, 3.8, 3.6, 3.5, 3.5, 3.3, 3.5, 
 3.5, 3.4, 3.1, 3, 2.9, 3.1, 2.9, 2.8, 3.1, 2.8, 2.5, 2.7, 2.7, 
 2.5, 2.5, 2.5, 2.7, 2.8, 3, 3.2, 3.1, 2.4, 3, 2.6, 2.6, 2.7, 
 2.6, 2.9, 2.6, 2.3, 2.2, 2.4, 3.3, 2.8, 2.9, 2.9, 2.8, 2.8, 3.1, 
 2.7, 2.7, 2.9, 2.8, 2.8, 2.6, 2.4, 2.6, 3.3, 2.8, 3, 3.5, 3.5, 
 3, 3.3, 3.2, 3.3, 4, 3.7, 3.4, 3.5, 3.6, 3.7, 3.6, 3.5, 3.6, 
 3.3, 3.4, 3.5, 3.6, 3.6, 3.9, 4.1, 4, 4.4, 5.1, 5.6, 6.1, 6.5, 
 6.7, 6.8, 7.6, 6.7, 6.6, 6.4, 6.6, 6.2, 6.1, 5.8, 5.8, 5.4, 5.6, 
 5.4, 5.3, 5.4, 5, 5.1, 4.4, 4.3, 3.8, 4.1, 4, 4, 3.6, 4, 3.6, 
 3.4, 3.3, 3.4, 3.1, 3.5, 3.4, 3.3, 3.1, 3.3, 3.3, 3.3, 3.1, 3.2, 
 3.1, 3, 3.1, 2.6, 3.1, 2.7, 2.8, 2.6, 2.7, 2.3, 2.5, 2.3, 2.4, 
 2.3, 2.4, 2.3, 2.1, 2.2, 2.8, 2.7, 2.7, 2.5, 2.7, 2.6, 2.5, 2.4, 
 2.5, 2.5, 3.2, 2.7, 2.7, 2.8, 2.7, 2.8, 2.3, 2.5, 2.9, 3, 3.1, 
 3.4, 3, 3, 3.1, 3.1, 3, 2.9, 2.8, 2.9, 2.8, 3, 2.7, 2.9, 3, 3.1, 
 3.1, 3.2, 3.3, 3.6, 3.7, 3.8, 3.8, 4, 3.4, 3.8, 4, 3.9, 4, 3.9, 
 4, 3.8, 4, 3.8, 3.9, 3.9, 4, 3.9, 3.6, 3.7, 3.8, 3.7, 3.9, 3.7, 
 3.5, 3.6, 3.4, 3.1, 3.2, 3.3, 3.6, 3.5, 3.4, 3.3, 3.6, 3.6, 3.8, 
 3.8, 3.7, 3.7, 3.8, 3.7, 3.9, 4.1, 3.7, 3.6, 3.5, 3.6, 3.7, 3.7, 
 3.8, 3.6, 3.8, 3.8, 3.8, 4, 3.7, 3.6, 3.7, 3.8, 4, 4, 4, 4.6, 
 4.8, 4.7, 5.2, 5.1, 5.4, 5.7, 5.4, 5.7, 5.9, 6, 5.8, 5.4, 5.3, 
 5.6, 5.4, 5.2, 5.5, 5.4, 5.2, 5.3, 5.1, 5.3, 5.6, 5.5, 5.5, 5.2, 
 5.4, 5, 5.2, 5.4, 5.5, 5.3, 5.4, 5.3, 4.9, 5.1, 5, 4.7, 5.3, 
 5, 4.9, 5, 4.9, 4.7, 5.1, 4.7, 4.9, 5.3, 5, 5.2, 4.9, 4.9, 5.1, 
 5.1, 5, 4.8, 4.9, 5, 4.9, 4.6, 4.8), .Tsp = c(1987, 2013.91666666667, 
 12), class = ""ts"")
</code></pre>
"
"0.131149499096392","0.151744244666721","118297","<p>I am learning arima by this site:</p>

<p><a href=""http://people.duke.edu/~rnau/411home.htm"" rel=""nofollow"">http://people.duke.edu/~rnau/411home.htm</a></p>

<p>and I want to get the same result as following notes:</p>

<p><a href=""http://people.duke.edu/~rnau/Review_of_basic_statistics_and_the_mean_model_for_forecasting--Robert_Nau.pdf"" rel=""nofollow"">http://people.duke.edu/~rnau/Review_of_basic_statistics_and_the_mean_model_for_forecasting--Robert_Nau.pdf</a></p>

<p>I was thinking that an arima with order [0, 0, 0] is the mean model, but the results is different from the notes, Here is the code:</p>

<pre><code>require(forecast);
x &lt;- c(114, 126, 123, 112, 68, 116, 50, 108, 163, 79,
      67, 98, 131, 83, 56, 109, 81, 61, 90, 92);
m &lt;- arima(x, order=c(0, 0, 0));
print(m);
print(forecast(m, 1));
print(predict(m)$se);
</code></pre>

<p>the output:</p>

<pre><code>&gt; print(m);
Series: x 
ARIMA(0,0,0) with non-zero mean 

Coefficients:
      intercept
        96.3500
s.e.     6.3124

sigma^2 estimated as 796.9:  log likelihood=-95.19
AIC=194.37   AICc=195.08   BIC=196.36

&gt; print(forecast(m, 1));
   Point Forecast    Lo 80    Hi 80   Lo 95    Hi 95
21          96.35 60.17192 132.5281 41.0204 151.6796

&gt; print(predict(m)$se);
Time Series:
Start = 21 
End = 21 
Frequency = 1 
[1] 28.2299
</code></pre>

<p>but the results in the notes are:</p>

<pre><code>SE_fcst = 29.68  (R result: 28.2299)
95% confidence intervals = 34, 158  (R result: 41, 152)
</code></pre>

<p>Where am I wrong?</p>

<p><strong>edit</strong></p>

<p>I do the simulation with random numbers, and the result is the same as the notes.</p>

<ol>
<li>make 21 normal random numbers with mu=100, sigma=30</li>
<li>calculate the error between the mean of first 20 numbers and the last number.</li>
<li>repeat 1 &amp; 2 for 100000 times</li>
</ol>

<p>Here is the python code that to do the simulation:</p>

<pre><code>import numpy as np
N = 1000000
n = 20
x = np.random.normal(100, 30, (N, n))
p = np.mean(x, axis=1)
nx = np.random.normal(100, 30, N)

err = p - nx
print (err**2).mean()**0.5

s = np.std(x, axis=1, ddof=1)
SE_mean = s / n**0.5
print (s**2 + SE_mean**2).mean()**0.5
</code></pre>

<p>the output is:</p>

<pre><code>30.7480552149 (the real standard error of forecast)
30.7375157915 (the estimated standard error of forecast by sqrt(s**2 + SE_mean**2))
</code></pre>
"
"0.103452120022374","0.102597835208515","120008","<p>I am interested in fitting an ARIMAX model using R.
As known, ARIMAX can be understood as a composition of ARIMA models and regression models with exogenous (independent) variables. I have a time series $Y_i$, and want to estimate the ARIMA and nonlinear coefficients. The nonlinear model is the following:</p>

<p>$y_i=Î²_0+Î²_1t_i+Î²_2d+Î²_3 sin(2Ï€t_i/Î²_4 )+Î²_5 (-1^{t_i})+Îµ_i$,  nonlinear 
regression with an exogenous variable.
Where 
$t_i$ =1, 2â€¦, 60
and</p>

<p>d = dummy variable with 20 0's and 40 number 1's</p>

<pre><code>d=c(rep(0,20),rep(1,40))
</code></pre>

<p>And an ARIMA model (1,1,1) for $Y_i$. Therefore, I want to estimate simultaneously the $Î²_i$ and the ARIMA coefficients in order to avoid the confusion between the exogenous coefficients and ARIMA coefficients.  I know that $arima()$ can deal with this formulation but, how do the nonlinear model can be set within function function?. It seems that the <em>xreg</em> term only deals with linear parameters.</p>
"
"0.131149499096392","0.086710996952412","121566","<p>Here is a problem that was puzzling me. Suppose I simulate the AR(2) process with constant and trend using the code below (I apologize for inefficiency and inelegance - the aim was to get job done at this point; also - it may seem strangely constructed, but it has some other purpose too for which is irrelevant here).</p>

<p>My question is - why the constant estimates are so poor? The true value is <code>70</code> but if we average 1000 regressions each over 1000 observations I get an average of <code>381.9234</code>. </p>

<p>Is it because I interpret something wrong or the did I make a mistake somwhere?</p>

<pre><code>set.key(123)

#parameter values
V=7
P=10
S=4
r1 = 50/(50+P)
r2 = V/(30+V)
mu = 10*P
l2 = 10*(S+V)
a0 = 10*V
d0 = 10*P
a1 = 0
d1 = P+V
s2 = 2*(P+V+S)

#simulate and estimate the parameters
data&lt;-NULL
data50 &lt;- NULL

for (firm in 1:1000){

  y_zero &lt;- rnorm(1, mean = mu, sd = l2)
  gamma_0 &lt;- rnorm(1, mean = a0, sd = d0)
  gamma_1 &lt;- rnorm(1, mean = a1, sd = d1)

  y_first &lt;- r1*y_zero + gamma_0 + gamma_1 + rnorm(1, mean = 0, sd = s2)
  y_second &lt;- r1*y_first - r2*(y_first - y_zero) + gamma_0 + 2*gamma_1 + rnorm(1, mean = 0, sd = s2)
  y_third &lt;- r1*y_second - r2*(y_second - y_first) + gamma_0 + 3*gamma_1 + rnorm(1, mean = 0, sd = s2)
  y_fourth &lt;- r1*y_third - r2*(y_third - y_second) + gamma_0 + 4*gamma_1 + rnorm(1, mean = 0, sd = s2)

  column &lt;- cbind(""firm"" = firm, ""t"" = 1:4, ""y"" = c(y_first, y_second, y_third, y_fourth))

  data &lt;- rbind(data, column)
  ###################################################################################
  firm50 &lt;- NULL

  y_fifth &lt;- r1*y_fourth - r2*(y_fourth - y_third) + gamma_0 + 5*gamma_1 + rnorm(1, mean = 0, sd = s2)
  y_sixth &lt;- r1*y_fifth - r2*(y_fifth - y_fourth) + gamma_0 + 6*gamma_1 + rnorm(1, mean = 0, sd = s2)

  y_previous1 &lt;- y_sixth
  y_previous2 &lt;- y_fifth

  firm50 &lt;- cbind(""firm"" = firm, ""t"" = c(5,6), ""y"" = c(y_fifth, y_sixth), ""ro1-ro2"" = c(y_fourth, y_fifth), ""ro2"" = c(y_third, y_fourth))

  for (run in 1:5000){
    time &lt;- run + 6

    the_y &lt;- r1 * y_previous1 - r2 * (y_previous1 - y_previous2) + gamma_0 + time*gamma_1 + rnorm(1, mean = 0, sd = s2)

    firm50 &lt;- rbind(firm50, cbind(""firm"" = firm, ""t"" = time, ""y"" = the_y, ""ro1-ro2"" = y_previous1, ""ro2"" = y_previous2))

    y_previous2 &lt;- y_previous1
    y_previous1 &lt;- the_y

  }
  firm50 &lt;- cbind(firm50, ""gamma0"" = gamma_0, ""gamma1"" = gamma_1)
  data50 &lt;- rbind(data50, firm50)
}

#estimate the coefficients
data &lt;- data.table(as.data.frame(data50))[t %in% c(4000:5000)]
coefs &lt;- NULL
for(i in 1:1000){
  coefs &lt;- rbind(coefs, t(coef(arima(data[firm==i, y], c(2,0,0), xreg = data[firm==i, t])))
}
</code></pre>
"
"0.0817860820109531","0.0811107105653813","121882","<p>I am facing a strange issue with auto.arima. On a dataset named data, I run the following code</p>

<pre><code>auto.arima(data,d=0,D=1,xreg=1:length(data),max.p=3,max.q=3,max.order=10,
       seasonal=TRUE,stepwise=FALSE,approximation=FALSE,ic=(""aic""),parallel=TRUE)
</code></pre>

<p>The outcome is </p>

<pre><code>   Series: data 
   ARIMA(1,0,3)(2,1,2)[12]                    

 Coefficients:
        ar1      ma1      ma2     ma3    sar1     sar2     sma1    sma2  1:length(data)
        0.6939  -0.6417  -0.2391  0.4350  0.6197  -0.5055  -1.3211  0.6027   5e-04
  s.e.  0.1349   0.1654   0.1169  0.1502  0.3040   0.1762   0.3907  0.4269   3e-04

 sigma^2 estimated as 0.001792:  log likelihood=143.69
 AIC=-267.38   AICc=-264.79   BIC=-241.73
</code></pre>

<p>Then I try to fit this model using the Arima function:</p>

<pre><code> Arima(data,order=c(1,0,3),seasonal=list(order=c(2,1,2),period=12),
       xreg=1:length(data),method=""ML"")
</code></pre>

<p>but I get the following error message:</p>

<pre><code> Error in optim(init[mask], armafn, method = optim.method, hessian = TRUE,  : 
   non-finite finite-difference value [1]
</code></pre>

<p>Does someone understand why this appears ? Thanks.</p>
"
"0.285080520221978","0.293197735804187","122270","<p>This is a long post but it is <em>not</em> conceptually difficult. Please bear with me.</p>

<p>I am trying to model the <strong>seasonality</strong> of production volume of an agricultural commodity. I do not care about the structure of the model (as long as it produces sensible output) nor about explaining seasonality; my goal is to adjust the series for seasonality before proceeding to forecasting. </p>

<p>I know the seasonality is due to supply (weather is a key determinant) as well as demand (higher demand around Christmas and Easter, etc.). </p>

<p>My <strong>data is weekly</strong>, and I am following the approach by prof. Hyndman of modelling the time series as an <strong>ARMA process with Fourier terms</strong> to account for seasonality (see <a href=""http://robjhyndman.com/hyndsight/longseasonality/"" rel=""nofollow"">here</a>). I also include Christmas and Easter dummies together with Fourier terms. </p>

<p>You might think I do not need a Christmas dummy since Christmas is always the 25th of December and thus Fourier terms would account for it, unlike for Easter which jumps back and forth in March-April from year to year. However, Christmas sometimes occur in week 51 and sometimes in week 52 (at least in my calendar), and Fourier terms will not account for that; hence a Christmas dummy is actually relevant.</p>

<p>Actually, I would like to include up to four dummies for Christmas (from two weeks before Christmas to one week after Christmas) as the seasonal effect is not concentrated on just the Christmas week but also spread out a little in time. The same is with Easter.</p>

<p>Thus I end up with $4+4=8$ dummies, up to 25 pairs of Fourier terms and an unknown ARMA order, which could be as high as (5,5), perhaps. This gives me an <strong>awfully large pool of models to choose from</strong>. Thus I have trouble replicating the approach used in the source above because of <strong>limited computational resources</strong>. Recall that in the original source there were no dummies, so the model pool was $2^{4+4}=256$ times smaller than mine and it was possible to try out a reasonably large proportion of all possible models, and then choose one of them by AIC. </p>

<p>Even worse, I would like to repeat my exercise multiple times (100 times) using a rolling window on the data I have. Thus the <strong>computational requirements</strong> for my exercise <strong>become exorbitant</strong>. I am looking for a solution, and hope someone could help me out.</p>

<p>Here are a few ideas I have:</p>

<ol>
<li><p>Drop the ARMA terms all together. </p>

<ul>
<li>This will make the estimates of coefficients on Fourier terms and dummies biased and inconsistent, thus the seasonal component (the Fourier terms times their coefficients plus dummies times their coefficients) might be rubbish. However, if ARMA patterns are pretty weak, maybe the bias and inconsistency of the coefficient estimates will not be too bad?</li>
</ul></li>
<li><p>Estimate only some models from the pool of all possible models. E.g. select the ARMA order by <code>auto.arima()</code> function in <code>forecast</code> package in <code>R</code>: <code>auto.arima()</code> does not consider all possible ARMA orders but only non-restricted ones (e.g. an AR(2) model with the AR(1) coefficient restricted to zero is not considered) and takes some other shortcuts. Also, I could force all dummies to be present without questioning whether all of them are really relevant. </p>

<ul>
<li>This indeed reduces the model pool considerably (by a factor of $2^{4+4}=256$ only due to dummies), but it comes at a cost of likely inclusion of irrelevant variables. Not sure how bad that could be. </li>
</ul></li>
<li><p>Use a different estimation method: conditional sum of squares (CSS) instead of maximum likelihood (ML) when possible, something else? </p>

<ul>
<li>Unfortunately, CSS in place of ML does not seem to reduce the computational time enough in practice (I tested a few examples).</li>
</ul></li>
<li><p>Do the estimation in two (or more) steps: select the ARMA order independently of the number of Fourier terms and inclusion/exclusion of dummies, then select the number of Fourier terms, then select the number of dummies, or something similar. </p>

<ul>
<li>This would reduce the model pool to the following: the number of all possible ARMA models (e.g. $2^{5+5}$) plus 26 (0 pairs of Fourier terms, 1 pair of Fourier terms, ..., 25 pairs of Fourier terms) plus $2^{4+4}$ (all combinations of dummies). This particular division into stages certainly does not make sense, I admit. But perhaps there exists a smart way to divide model selection into steps? I guess we need mutual orthogonality of regressors to be able to consider their inclusion/exclusion from the model one by one, or something similar. I need some insight here...</li>
</ul></li>
<li><p>Do something along the lines of Cochrane-Orcutt correction: <strong>(1)</strong> estimate a model without any ARMA terms (thus a simple OLS regression of production volume on Fourier terms and dummies); <strong>(2)</strong> examine the ARMA patterns in residuals and determine the relevant ARMA order; <strong>(3)</strong> estimate the corresponding ARMA model with Fourier terms and dummies as exogenous regressors. <br>(I know Cochrane-Orcutt does not consider ARMA(p,q) but just AR(1), but I thought maybe I could generalize it? Not sure, perhaps I am making a mistake here?)</p>

<ul>
<li>This would reduce the model pool to be estimated by a factor of $2^{5+5}$ if we would otherwise consider ARMA(5,5) and all sub-models nested in it, which is very nice. However, Cochrane-Orcutt correction is not as good as getting the model order correct in the first place. (I lack a theoretical argument there, but I suspect you do not always end up with the correct ARMA order if you use Cochrane-Orcutt or something similar.)</li>
</ul></li>
</ol>

<p>I would appreaciate any comments on the ideas above and, even more, your own ideas on how to save computational time.</p>

<p><strong>Thank you!</strong></p>

<p>P.S. Here is the data (2007 week 1 to 2012 week 52): <br><code>6809  8281  8553  8179  8257  7426  8098  8584  8942  9049  9449 10099 10544  6351  8667  9395  9062  8602 10500  8723  9919  9120 10068  9937  9998  9379  9432  8751 10250  7690  6857  8199  8299  9204 11755  9861 10193 10452  9769 10289 10399 10181 10419 10324 11347 11692 12571 13049 13712 15381 13180  3704  5833  9909  8979  8883  9599  9034  9617  9710  9878 10872 12246  7122  8071  9656  9157  9729  8814  8704 10724  9294 10176 10394  9633 10872 10353  9400  9692  9244  8921  7698  8191  8494  8681  9420  8947  9287 10043  9953 10136 10235 10027 10137 11187 10383 11321 12023 11824 13752 13907 14658 14634  5353  5603 11607  9512  9537  9775  8558  9227  9146  9673 10225 10794 10646 10545 12375  7742  9269 11134  9588 10890 10061 10244 11275  9428 10301 11039 10779 10580  9215  9538  9717  9966 10678 10821 10898 11458 11090 12080 10904 12990 12325 12257 12246 12351 12408 11732 12702 14181 14963 15027 16657 17766  8265  7552 11067 10808 10891 10967 10826 10929 10891  9293 10902 11640 11921 13320  7751  9929 11632 11073 10955 11785 10533 10629 11535 12513 11780 12639 12280 12245 11817 11275 10242 10625  9884 10182 11048 12120 12697 13132 12597 13516 13536 13279 13935 13539 14335 13748 13988 14497 15255 15346 17626 17716 10713  7752  9309 11133 11853 11570 10320 10817 10982 10585 10941 12801 12165 11899 10941 12729 13763  8130  9888 11889 13036 10413 12609 10992 13201 11833 13159 12880 12160 13277 12758 10897 11197 12169 12639 13788 13819 14804 14613 14992 16079 16648 16376 16207 15906 15301 16194 17327 18890 18710 19953 22369 16499  9721 11785 12528 13994 12990 13226 12883 13613 14382 15829 15525 16395 17175 18334  9286 15530 16510 15370 13019 16526 14425 16542 15328 16993 17607 16734 15826 16555 16064 14412 14355 15238 15064 15317 15533 16542 16474 17354 18359 18459 17312 17499 18298 17301 17795 17867 18453 19372 19394 21897 23674 23219  7356</code></p>
"
"0.246997889787912","0.266258951776441","123576","<p>I am trying to test the effect on the heat flux between indoors and outdoors before and after removing insulation.</p>

<p>Briefly, I have 26 sensors on a wall, measuring heat flow between indoors and outdoors over a number of days. The wall was part of a real world experimental setup so that the insulation on the wall was removed halfway through the experiment. Â What I care about is to have a measure of the effect of the removal of the insulation (I am not interested in any form of forecasting). Â I am exploring the use of a SARIMA/ARIMAX models with one regressor because, aside from the removal of the insulation, the heat flow between indoors and outdoors was affected by daily cyclical and random environmental effects (heating on or off, daily temperature changes, wind, etc).  Here I will present that data and analysis of one sensor.  My data has been collected hourly, and I have transformed the variable â€˜insulatedâ€™ â€˜not insulatedâ€™ as a factor of 0s and 1s as indicator.</p>

<pre><code>heat.flux = c(8.677048,6.558642,5.920314,5.583614,5.373176,5.253928,4.938272,7.358305,9.743266,10.46577,11.06201,10.90067,11.49691,13.15236,12.10017,10.60606,10.45875,10.03788,9.588945,9.287318,8.578844,8.024691,10.26936,11.8757,10.20623,8.634961,8.305275,8.101852,8.12991,7.947531,7.814254,10.40264,13.08221,14.3729,14.94809,15.08838,15.20763,15.75477,14.57632,12.79461,11.97391,10.97082,10.33249,9.701178,9.715208,9.083895,10.63412,12.07912,9.736251,7.638889,6.453423,5.983446,5.499439,5.099607,4.70679,6.972503,9.259259,9.981762,10.24832,10.17116,10.27637,10.27637,9.546857,7.568743,7.168911,6.867284,6.705948,6.916386,8.319304,8.424523,11.41274,13.52413,11.70034,9.532828,8.957632,9.07688,9.694164,9.301347,9.048822,12.28255,14.95511,15.22868,15.24972,15.12346,15.08838,15.17256,13.68547,12.18434,12.1633,12.13524,11.81257,11.58109,11.44781,11.27946,13.87486,15.92312,14.07828,11.90376,10.46577,9.518799,8.978676,8.803311,8.684063,11.65123,14.39394,15.69865,16.61756,16.828,16.83502,16.16863,14.23962,12.19837,12.09315,11.5881,11.20932,10.50786,10.59203,10.64815,13.51712,15.71268,13.92396,12.10718,12.2615,11.65123,11.05499,10.31846,9.834456,12.9349,15.41807,15.78283,15.8179,16.11953,15.95118,15.63552,13.1243,11.22334,10.21324,8.705107,7.526655,6.15881,5.30303,5.597643,8.599888,11.17424,9.631033,8.038721,7.638889,7.203984,7.161897,6.76908,6.888328,9.518799,12.40881,13.21549,14.28872,14.43603,14.8078,14.81481,13.60129,12.59119,11.86167,11.91779,11.73541,12.04405,11.51796,11.74242,13.7486,15.85999,14.84989,12.63328,10.68322,9.343434,8.592873,8.333333,8.445567,10.97783,13.82576,15.12346,16.58249,17.61364,18.30808,19.10774,17.97138,16.62458,15.867,16.07744,15.63552,16.0073,15.42508,15.01122,17.10157,18.94641,22.44669,18.94641,16.01431,14.55527,13.88889,12.77357,11.66526,12.46493,15.41807,16.75786,17.27694,17.03143,16.84905,16.828,16.02834,16.35802,16.04237,15.03928,14.00112,14.1344,13.86785,13.99411,15.30584,18.20286,19.49355,16.16162,14.05022,12.05107,12.27553,13.01207,12.5491,13.72054,16.91218,18.62374,18.79209,20.80527,19.50758,20.18799,20.63692,18.49747,17.25589,17.38215,18.40629,18.60269,19.12177,18.66582,21.09989,24.45286,26.71156,23.54798,20.01964,17.98541,14.83586,14.31678,15.15152,15.30584,17.95735,19.71801,20.30724,20.19501,20.2862,20.1459,20.10382,18.20988,16.54742,15.22868,13.96605,12.71044,11.61616,10.71829,12.12121,14.77273,14.04321,12.44388,10.94978,10.2413,9.708193,9.638047,9.322391,11.27245,14.24663,14.77273,14.75168,14.92705,15.47419,15.48822,14.73765,13.68547,12.65432,12.35269,12.34568,12.32464,12.7385,12.84371,14.16947,17.34007,17.09456,15.0954,13.40488,11.70735,10.8165,10.64815,12.01599,13.55219,16.7298,17.45932,17.61364,19.58474,20.02666,19.79517,19.38833,17.32604,16.11953,15.62851,15.01122,14.70258,14.5693,14.35887,16.28086,18.69388,18.92536,16.56846,15.97222,13.34877,12.81566,12.04405,13.23653,14.1835,16.75786,17.55752,17.98541,18.85522,18.8482,19.02357,18.96044,17.31201,15.42508,14.38692,13.57323,12.36672,12.03002,11.41274,13.15236,15.88103,14.66049,12.8858,11.67228,11.03395,9.399551,8.375421,8.073793,10.6271,13.57323,13.61532,14.31678,14.73765,15.08838,15.62149,16.6807,15.28479,14.07127,13.14534,12.61223,12.57015,12.02301,12.17031,14.33782,18.83418,20.45455,18.67985,18.40629,16.51235,14.45006,14.61841,15.20763,15.57941,18.06958,19.88636,20.51066,21.633,23.24635,24.28451,24.70539,24.19332,22.81145,21.97671,21.58389,21.3945,21.21212,20.89646,21.1069,23.86364)

insulation = c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
</code></pre>

<p>First off, the time series plot of the heat flux is this (the red line is when the insulation is removed):</p>

<p><img src=""http://i.stack.imgur.com/SYSQj.jpg"" alt=""Time series plot of heat flux""></p>

<p>Than this are the ACF and PACF plots of the same data:</p>

<p><img src=""http://i.stack.imgur.com/7keT7.jpg"" alt=""ACF and PACF of the data""></p>

<p>For my data, an <code>stl()</code> decomposition, run as <code>stl(ts(heat.flux, frequency = 24), 'period')</code></p>

<p>shows a strong â€˜seasonalâ€™ (i.e daily) component and a trend in the series. Â </p>

<p><img src=""http://i.stack.imgur.com/CUsta.jpg"" alt=""STL of the data""></p>

<p>Firs off I am trying to determine the best parameters for a SARIMA or ARIMAX model so that I can get an estimation of the effect removing the insulation. Despite the fact I can produce the ACF and PACF plots there is no way I can figure out the proper orders, so I load the library <code>forecast</code> and I run:</p>

<pre><code>library(forecast)
auto.arima(ts(heat.flux, frequency = 24), xreg = insulation, max.p = 10, max.q = 10, max.P = 10, max.Q = 10, stationary = F)Â 
</code></pre>

<p>The reason why I do not specify a stationary model is because of the trend I see with <code>stl()</code> and because I assume an effect of removing the insulation.</p>

<p>from <code>auto.arima()</code> I get:</p>

<pre><code>Series: ts(heat.flux, frequency = 24) 
ARIMA(2,0,2)(1,0,1)[24] with non-zero mean 

Coefficients:
         ar1      ar2      ma1      ma2    sar1     sma1  intercept  carp.hour$interv
      1.9414  -0.9495  -0.7423  -0.1793  0.9717  -0.6009    11.2449            4.3338
s.e.  0.0231   0.0221   0.0570   0.0544  0.0104   0.0544     2.1075            0.5548

sigma^2 estimated as 0.4484:  log likelihood=-411.28
AIC=840.55   AICc=841.03   BIC=876.11
</code></pre>

<p>If I try to use the <code>TSA</code> package and use <code>arimax()</code> with those orders I get basically the same stuff:</p>

<pre><code>library(TSA)
arimax(ts(heat.flux, frequency = 24), xreg = insulation, order = c(2,0,2), seasonal = list(order = c(1,0,1), frequency = 24))
Series: x 
ARIMA(2,0,2)(1,0,1)[24] with non-zero mean 

Coefficients:
         ar1      ar2      ma1      ma2    sar1     sma1  intercept    xreg
      1.9414  -0.9495  -0.7423  -0.1793  0.9717  -0.6009    11.2449  4.3338
s.e.  0.0231   0.0221   0.0570   0.0544  0.0104   0.0544     2.1075  0.5548

sigma^2 estimated as 0.4484:  log likelihood=-411.28
AIC=838.55   AICc=839.03   BIC=874.11
</code></pre>

<p>And all is apparently well (Irrespective of the function I choose I get an estimate of the effect of the removal of the insulation and a se with it with is what I want). Â Unfortunately, when I test the fit of this model with the function <code>sarima()</code> from the <code>astsa</code>package I get significant Ljung-Box p-values for all my sensors and for all the lags:</p>

<pre><code>library(astsa)
sarima(ts(heat.flux, frequency = 24), p = 2, d = 0, q = 2, P =1, D = 0, Q = 1, S = 24, xreg = insulation)
$fit

Call:
stats::arima(x = xdata, order = c(p, d, q), seasonal = list(order = c(P, D, 
Q), period = S), xreg = xreg, optim.control = list(trace = trc, REPORT = 1, 
reltol = tol))

Coefficients:
         ar1      ar2      ma1      ma2    sar1     sma1  intercept    xreg
      1.9414  -0.9495  -0.7423  -0.1793  0.9717  -0.6009    11.2449  4.3338
s.e.  0.0231   0.0221   0.0570   0.0544  0.0104   0.0544     2.1075  0.5548

sigma^2 estimated as 0.4484:  log likelihood = -411.28,  aic = 840.55
</code></pre>

<p>but the plot that comes with is shows that at every single lag the Ljung-Box statistics is significant:</p>

<p><img src=""http://i.stack.imgur.com/ZMGKN.jpg"" alt=""SARIMA""></p>

<p>What is going on?  To sum it up:</p>

<ol>
<li>which of these models is the most correct to estimate the effect of insulation?</li>
<li>why are the Ljung-Box p-values all significant?  I would have though that the ARIMA/ARIMAX/SARIMA would have sorted that issue</li>
<li>If the orders calculated by <code>auto.arima()</code> are the problem, how could I find them in a different way (which is computationally feasible and does not take days).</li>
</ol>

<p>Finally, two notes.  I also have collected variables such as internal and external temperatures, windspeed, etc, but I would have though that integrating these in the model would be superfluous given the fact it is already an ARIMA model to start with.  Second, I am not at all wedded to this kind of analysis, but I am aware that a straightforward linear model would not be acceptable given the autocorrelation between the data points.</p>
"
"0.0408930410054765","0.0811107105653813","124351","<p>I'm trying to explain in detail step by step what my code does and I am stuck at explaining what the coefficients are in an Arima model and where they are from/what relevance they have.</p>

<p>Could someone please explain to me what <code>ma1</code>, <code>sar1</code>, <code>sar2</code>, <code>ar1</code>, <code>ar2</code>, <code>ar3</code>, <code>sma1</code> are and if possible show with a formula where they may appear in the equation for an ARIMA process? (The equation is not high priority as long as they are explained well)</p>

<p>Here is an ARIMA model found using <code>?Arima</code> just you can see what i mean by the coefficients</p>

<pre><code>fit &lt;- Arima(WWWusage,order=c(3,1,0))
</code></pre>
"
"0.057831493196624","0.0573539334676404","128709","<p>I wonder how the Arima() function in R computes the AIC. Applying the standard formula AIC= 2*k - 2 LN(L) (with k number of parameters and L maximized value of likelihood) doesn't reproduce the displayed result. Does the estimated variance counts as additional parameter?</p>

<p>Thank you for helping,</p>

<p>laterstat </p>

<p>PS: Here is an example:</p>

<pre><code>arima(x = example, order = c(2, 0, 2), method = ""ML"")

Coefficients:
          ar1      ar2     ma1     ma2  intercept
      -0.7508  -0.0367  1.3156  0.5433    -0.0183
s.e.   0.2591   0.1772  0.2424  0.1958     0.0244

sigma^2 estimated as 0.03748:  log likelihood = 35.67,  aic = -59.33

&gt; 5*2-2*35.67
</code></pre>

<p>[1] -61.34</p>
"
"0.0817860820109531","0.0811107105653813","128730","<p>If i understand correctly, the ARIMA function produces an estimate for the mean of the process instead of the intercept. It is possible to transform the mean into the intercept: mean= 1-Sum(AR-Coefficients). Is it also possible to transform the standard error of the mean into standard error of the intercept? </p>

<p>As an example:</p>

<pre><code>arima(x = example, order = c(2, 0, 2), method = ""ML"")

Coefficients:
          ar1      ar2     ma1     ma2  intercept
      -0.7508  -0.0367  1.3156  0.5433    -0.0183
s.e.   0.2591   0.1772  0.2424  0.1958     0.0244

sigma^2 estimated as 0.03748:  log likelihood = 35.67,  aic = -59.33

# mean:
&gt; 1+0.7508+0.0367 
[1] 1.7875
</code></pre>

<p>Thanks a lot</p>

<p>laterstat     </p>
"
"0.115662986393248","0.114707866935281","130152","<p>This is out of my curiosity trying to compare time series input to an ARMA model and reconstructed series after an ARMA estimate is obtained. These are the steps I am thinking:</p>

<ol>
<li><p>Construct simulation time series</p>

<pre><code>arma.sim &lt;- arima.sim(model=list(ar=c(0.9),ma=c(0.2)),n = 100)
</code></pre>

<p>estimate the model from arma.sim, assuming we know it is a (1,0,1) model</p>

<pre><code>arma.est1 &lt;- arima(arma.sim, order=c(1,0,1))
</code></pre></li>
<li><p>also say we get arma.est1 in this form, which is close to the original (0.9,0,0.2):</p>

<pre><code>Coefficients:
 ar1     ma1  intercept
 0.9115  0.0104    -0.4486
s.e.  0.0456  0.1270     1.1396

sigma^2 estimated as 1.15:  log likelihood = -149.79,  aic = 307.57
</code></pre></li>
<li><p>If I try to reconstruct another time series from <code>arma.est1</code>, how do I incorporate intercept or s.e. in <code>arima.sim</code>? Something like this doesn't seem to work well because <code>arma.sim</code> and <code>arma.rec</code> are far off:</p>

<pre><code>arma.rec &lt;- arima.sim(n=100, list(ar=c(0.9115),ma=c(0.0104)))
</code></pre></li>
</ol>

<p>Normally we use <code>predict()</code> to check the estimate. But is this a legit way to look at the estimate?</p>
"
"0.166945140823544","0.182123199096444","132845","<p>I have a problem in interpreting what the <code>arima</code> function in R is doing.  I have the following code:</p>

<pre><code>x &lt;- 1000*.8^(0:100)
arima(x, order = c(1,0,0), include.mean = F)
</code></pre>

<p>The resulting coefficient is ""0.9988"".  But I would think the coefficient should be exactly ""0.8"", since <code>x[t] = 0.8 * x[t-1]</code>.</p>

<p>I must be missing something that R is doing in processing the data.</p>

<p>Any help would be appreciated.</p>

<p><strong>New Info I:</strong>
If I change the function to </p>

<pre><code>arima(x, order = c(1,0,0), include.mean = F, method=""CSS"")
</code></pre>

<p>then it solves for the correct coefficient of 0.8.</p>

<p>My problem that I am generally finding that the function <code>arima</code> with <code>order = c(1,0,0)</code> is often producing different results to:</p>

<pre><code>lm(x[-1] ~ I(x[-length(x)]))
</code></pre>

<p>for all sorts of different time series that I am reviewing. </p>

<p><strong>New Info II:</strong>
Some of the comments and answers below are concerned that there is no random fluctuation in my data.  I did this to make the problem as simple as possible, but even if you add in random fluctuation, <code>arima</code> still produces the same wrong results in the default case.  To add insult to injury, <code>arima</code> will sometimes get the right answer if you change <code>method = ""CSS""</code>. This suggest that there is perhaps a computational issue with <code>arima</code> and not my misunderstanding the statistical model. Here is an extended set of two examples that highlight the problem (I ignore the intercept difference between <code>lm</code> and <code>arima</code> as these two items are not the same thing, but the coefficients should be.</p>

<pre><code>set.seed(1)
# Example 2
x &lt;- rep(1000,200)
for (i in 2:200) x[i]=x[i-1]*.8 + runif(1)*100 
plot(x,type=""l"")
arima(x, order = c(1,0,0))  #Incorrect answer:  coefficient = 0.9944
arima(x, order = c(1,0,0), method=""CSS"") # correct answer: coefficient = 0.7915
lm(x[-1] ~ I(x[-length(x)])) # correct answer: coefficient = 0.7914

# Example 3
x &lt;- rep(0,200)
for (i in 2:200) x[i]=x[i-1]*.8 + runif(1)*.2 
plot(x,type=""l"")
arima(x, order = c(1,0,0))  #Incorrect answer:  coefficient = 0.8836
arima(x, order = c(1,0,0), method=""CSS"") # correct answer: coefficient = 0.8158
lm(x[-1] ~ I(x[-length(x)])) # correct answer: coefficient = 0.8158
</code></pre>
"
"0.197350013242542","0.216322481400461","135565","<p>I have a few questions about turing a univariate time series into a multivariate time series and optimizing the predictors. Here is the univariate data:</p>

<pre><code>index
22
26
34
33
40
39
39
45
50
58
64
78
51
60
80
80
93
100
96
108
111
119
140
164
103
112
154
135
156
170
146
156
166
176
193
204
</code></pre>

<p>My first step here was to of course create a ts object in R and visualize the data:</p>

<pre><code>tsData &lt;- ts(data = dummyData, start = c(2012,1), end = c(2014,12), frequency = 12)

     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
2012  22  26  34  33  40  39  39  45  50  58  64  78
2013  51  60  80  80  93 100  96 108 111 119 140 164
2014 103 112 154 135 156 170 146 156 166 176 193 204

plot(tsData)
</code></pre>

<p>I interpreted this plot as a deterministic time series with a trend and perhaps a bit of seasonality</p>

<p><img src=""http://i.stack.imgur.com/YD0vW.png"" alt=""enter image description here"">
Examining the acf and pacf plot confirms the trend component of the time series</p>

<p><img src=""http://i.stack.imgur.com/c8eu3.png"" alt=""enter image description here""></p>

<p>My first question has to do with creating trend &amp; seasonal variables for the time series using the decompose() function in R which yields the following plots:</p>

<p><img src=""http://i.stack.imgur.com/9xXYx.png"" alt=""enter image description here""></p>

<p>I understand that the decompose() function in R has created a list of vectors for the trend, seasonal and random components of the original time series but what am I suppose to do with them? Should I cbind() them to my univariate data and model:</p>

<pre><code>lm(index ~ trend + seasonal + random)

         index     trend    seasonal       random
Jan 2012    22        NA -23.8940972           NA
Feb 2012    26        NA -19.4357639           NA
Mar 2012    34        NA   6.8350694           NA
Apr 2012    33        NA  -7.5399306           NA
May 2012    40        NA   4.3142361           NA
Jun 2012    39        NA   9.5017361           NA
Jul 2012    39  45.20833  -6.3524306   0.14409722
Aug 2012    45  47.83333  -0.8315972  -2.00173611
Sep 2012    50  51.16667  -1.1232639  -0.04340278
Oct 2012    58  55.04167   2.2517361   0.70659722
Nov 2012    64  59.20833  11.2100694  -6.41840278
Dec 2012    78  63.95833  25.0642361 -11.02256944
Jan 2013    51  68.87500 -23.8940972   6.01909722
Feb 2013    60  73.87500 -19.4357639   5.56076389
Mar 2013    80  79.04167   6.8350694  -5.87673611
Apr 2013    80  84.12500  -7.5399306   3.41493056
May 2013    93  89.83333   4.3142361  -1.14756944
Jun 2013   100  96.58333   9.5017361  -6.08506944
Jul 2013    96 102.33333  -6.3524306   0.01909722
Aug 2013   108 106.66667  -0.8315972   2.16493056
Sep 2013   111 111.91667  -1.1232639   0.20659722
Oct 2013   119 117.29167   2.2517361  -0.54340278
Nov 2013   140 122.20833  11.2100694   6.58159722
Dec 2013   164 127.75000  25.0642361  11.18576389
Jan 2014   103 132.75000 -23.8940972  -5.85590278
Feb 2014   112 136.83333 -19.4357639  -5.39756944
Mar 2014   154 141.12500   6.8350694   6.03993056
Apr 2014   135 145.79167  -7.5399306  -3.25173611
May 2014   156 150.37500   4.3142361   1.31076389
Jun 2014   170 154.25000   9.5017361   6.24826389
Jul 2014   146        NA  -6.3524306           NA
Aug 2014   156        NA  -0.8315972           NA
Sep 2014   166        NA  -1.1232639           NA
Oct 2014   176        NA   2.2517361           NA
Nov 2014   193        NA  11.2100694           NA
Dec 2014   204        NA  25.0642361           NA
</code></pre>

<p>When I use the auto.arima function in the forecast package is this all happening under the hood? It seems to me that the auto.arima() selected a MA(1) term and a differencing term to deal with the trend? Is my interpretation correct? What is drift?</p>

<pre><code>plot(forecast(auto.arima(tsData, stepwise=FALSE)))

Forecast method: ARIMA(0,0,1)(0,1,0)[12] with drift        

Model Information:
Series: tsData 
ARIMA(0,0,1)(0,1,0)[12] with drift         

Coefficients:
         ma1   drift
      0.9622  4.5780
s.e.  0.4698  0.4352

sigma^2 estimated as 176.6:  log likelihood=-44.52
AIC=95.05   AICc=96.25   BIC=98.58

Error measures:
                    ME     RMSE      MAE        MPE     MAPE       MASE
Training set 0.2459764 7.673429 4.967187 -0.7272714 4.661455 0.08876581
                   ACF1
Training set -0.0791942
</code></pre>

<p><img src=""http://i.stack.imgur.com/3TWL6.png"" alt=""enter image description here""></p>

<p>What happens if I'm interested in expanding the model to include other time series variables such as spend_1 and spend_2? do I need to create trend and seasonal and random variables for each of these spend variables or do I just plug them into the auto.arima as external variables:</p>

<pre><code>auto.ariam(tsData, xreg=spendData, stepwise= FALSE)

spend_1 spend_2
0   0
0   0
0   0
0   0
0   0
0   209
0   0
0   0
0   239
0   0
0   553
0   216
0   0
0   161
0   449
107 0
53  0
120 81
242 0
100 80
482 0
708 81
54  240
688 0
80  0
254 108
183 84
104 191
183 84
243 167
0   108
0   0
0   191
0   191
0   167
0   0
</code></pre>

<p>Once I build this multivariate time series model how do I interpret the coefficients for spend_1 and spend_2? How do to optimize them in order to maximize the index variable where the model was something like:</p>

<pre><code>lm(index ~ spend_1 + spend_2 + trend + seasonal + random)
</code></pre>

<p>Thanks all for the advice please let me know if I can clarify anything further.</p>
"
"0.0817860820109531","0.0405553552826906","143636","<p>I have daily visitors data for the last 10 years. I want to do some basic tests like which is the busiest day, which is the busiest month, busiest week etc. I used <code>auto.arima</code> function with argument <code>xreg</code> to find out the coefficients of all the days of the week, week of the month. This is the output I got:</p>

<pre><code>&gt; summary(arima1)
Series: dailysea 
ARIMA(1,1,2)                    

Coefficients:
          ar1      ma1      ma2         Sun        Mon         Tue        Wed         Thu
      -0.1250  -0.4506  -0.3712  -1466.6853  -3623.175  -3895.0555  -3722.146  -3327.4288
s.e.   0.1207   0.1117   0.0891    325.7253    386.738    379.8793    379.883    386.7512
            Fri
      -2146.910
s.e.    325.736

sigma^2 estimated as 7776468:  log likelihood=-6808.5
AIC=13637   AICc=13637.31   BIC=13682.92

Training set error measures:
                   ME     RMSE      MAE  MPE MAPE      MASE         ACF1
Training set 59.63838 2784.809 1952.625 -Inf  Inf 0.8353728 -0.001839015
</code></pre>

<p>Can I use these coefficients to conclude that Saturday is the busiest followed by Sunday, Friday etc.? Also I have infinite MAPE which is not making sense to me.</p>
"
"0.154217315190997","0.152943822580375","144158","<p>I am trying to do time series analysis and am new to this field. I have daily count of an event from 2006-2009 and I want to fit a time series model to it. Here is the progress that I have made:</p>

<pre><code>timeSeriesObj = ts(x,start=c(2006,1,1),frequency=365.25)
plot.ts(timeSeriesObj)
</code></pre>

<p>The resulting plot I get is:</p>

<p><img src=""http://i.stack.imgur.com/q2Gf5.jpg"" alt=""Time Series Plot""></p>

<p>In order to verify whether there is seasonality and trend in the data or not, I follow the steps mentioned in this <a href=""http://stats.stackexchange.com/questions/57705/identify-seasonality-in-time-series-data"">post</a> :</p>

<pre><code>ets(x)
fit &lt;- tbats(x)
seasonal &lt;- !is.null(fit$seasonal)
seasonal
</code></pre>

<p>and in Rob J Hyndman's <a href=""http://robjhyndman.com/hyndsight/detecting-seasonality/"" rel=""nofollow"">blog</a>:</p>

<pre><code>library(fma)
fit1 &lt;- ets(x)
fit2 &lt;- ets(x,model=""ANN"")

deviance &lt;- 2*c(logLik(fit1) - logLik(fit2))
df &lt;- attributes(logLik(fit1))$df - attributes(logLik(fit2))$df 
#P value
1-pchisq(deviance,df)
</code></pre>

<p>Both cases indicate that there is no seasonality.</p>

<p>When I plot the ACF &amp; PACF of the series, here is what I get:</p>

<p><img src=""http://i.stack.imgur.com/mgBav.jpg"" alt=""ACF"">
<img src=""http://i.stack.imgur.com/p4DYo.jpg"" alt=""PACF""></p>

<p>My questions are:</p>

<ol>
<li><p>Is this the way to handle daily time series data? This <a href=""http://www.r-bloggers.com/forecasting-with-daily-data/"" rel=""nofollow"">page</a> suggests that I should be looking at both weekly and annual patterns but the approach is not clear to me.</p></li>
<li><p>I do not know how to proceed once I have the ACF and PACF plots.</p></li>
<li><p>Can I simply use the auto.arima function?</p>

<p>fit &lt;- arima(myts, order=c(p, d, q)</p></li>
</ol>

<p>*****Updated Auto.Arima results******</p>

<p>When i change the frequency of the data to 7 according to Rob Hyndman's comments <a href=""http://stats.stackexchange.com/questions/14742/auto-arima-with-daily-data-how-to-capture-seasonality-periodicity"">here</a>, auto.arima selects a seasonal ARIMA model and outputs:</p>

<pre><code>Series: timeSeriesObj 
ARIMA(1,1,2)(1,0,1)[7]                    

Coefficients:
       ar1      ma1     ma2    sar1     sma1
      0.89  -1.7877  0.7892  0.9870  -0.9278
s.e.   NaN      NaN     NaN  0.0061   0.0162

sigma^2 estimated as 21.72:  log likelihood=-4319.23
AIC=8650.46   AICc=8650.52   BIC=8682.18 
</code></pre>

<p>******Updated Seasonality Check******</p>

<p>When I test seasonality with frequency 7, it outputs True but with seasonality 365.25, it outputs false. <strong>Is this enough to conclude a lack of yearly seasonality?</strong></p>

<pre><code>timeSeriesObj = ts(x,start=c(2006,1,1),frequency=7)
fit &lt;- tbats(timeSeriesObj)
seasonal &lt;- !is.null(fit$seasonal)
seasonal
</code></pre>

<p>returns:</p>

<pre><code>True
</code></pre>

<p>while </p>

<pre><code>timeSeriesObj = ts(x,start=c(2006,1,1),frequency=365.25)
fit &lt;- tbats(timeSeriesObj)
seasonal &lt;- !is.null(fit$seasonal)
seasonal
</code></pre>

<p>returns:</p>

<pre><code>False
</code></pre>
"
"0.444733062391534","0.412605035087742","144745","<p>I have 17 years (1995 to 2011) of death certificate data related to suicide deaths for a state in the U.S. There is a lot of mythology out there about suicides and the months/seasons, much of it contradictory, and of the literature I've reviewed, I do not get a clear sense of methods used or confidence in results.</p>

<p>So I've set out to see if I can determine whether suicides are more or less likely to occur in any given month within my data set. All of my analyses are done in R.</p>

<p>The total number of suicides in the data is 13,909.</p>

<p>If you look at the year with the fewest suicides, they occur on 309/365 days (85%). If you look at the year with the most suicides, they occur on 339/365 days (93%).</p>

<p>So there are a fair number of days each year without suicides. However, when aggregated across all 17 years, there are suicides on every day of the year, including February 29 (although only 5 when the average is 38).</p>

<p><img src=""http://i.stack.imgur.com/VMQYa.jpg"" alt=""enter image description here""></p>

<p>Simply adding up the number of suicides on each day of the year doesn't indicate a clear seasonality (to my eye).</p>

<p>Aggregated at the monthly level, average suicides per month range from:</p>

<p>(m=65, sd=7.4, to m=72, sd=11.1)</p>

<p>My first approach was to aggregate the data set by month for all years and do a chi-square test after computing the expected probabilities for the null hypothesis, that there was no systematic variance in suicide counts by month. I computed the probabilities for each month taking into account the number of days (and adjusting February for leap years).</p>

<p>The chi-square results indicated no significant variation by month:</p>

<pre><code># So does the sample match  expected values?
chisq.test(monthDat$suicideCounts, p=monthlyProb)
# Yes, X-squared = 12.7048, df = 11, p-value = 0.3131
</code></pre>

<p>The image below indicates total counts per month. The horizontal red lines are positioned at the expected values for February, 30 day months, and 31 day months respectively. Consistent with the chi-square test, no month is outside the 95% confidence interval for expected counts.
<img src=""http://i.stack.imgur.com/XRCzM.jpg"" alt=""enter image description here""></p>

<p>I thought I was done until I started to investigate time series data. As I imagine many people do, I started with the non-parametric seasonal decomposition method using the <code>stl</code> function in the stats package. </p>

<p>To create the time series data, I started with the aggregated monthly data:</p>

<pre><code>suicideByMonthTs &lt;- ts(suicideByMonth$monthlySuicideCount, start=c(1995, 1), end=c(2011, 12), frequency=12) 

# Plot the monthly suicide count, note the trend, but seasonality?
plot(suicideByMonthTs, xlab=""Year"",
  ylab=""Annual  monthly  suicides"")
</code></pre>

<p><img src=""http://i.stack.imgur.com/xSWJm.jpg"" alt=""enter image description here""></p>

<pre><code>     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
1995  62  47  55  74  71  70  67  69  61  76  68  68
1996  64  69  68  53  72  73  62  63  64  72  55  61
1997  71  61  64  63  60  64  67  50  48  49  59  72
1998  67  54  72  69  78  45  59  53  48  65  64  44
1999  69  64  65  58  73  83  70  73  58  75  71  58
2000  60  54  67  59  54  69  62  60  58  61  68  56
2001  67  60  54  57  51  61  67  63  55  70  54  55
2002  65  68  65  72  79  72  64  70  59  66  63  66
2003  69  50  59  67  73  77  64  66  71  68  59  69
2004  68  61  66  62  69  84  73  62  71  64  59  70
2005  67  53  76  65  77  68  65  60  68  71  60  79
2006  65  54  65  68  69  68  81  64  69  71  67  67
2007  77  63  61  78  73  69  92  68  72  61  65  77
2008  67  73  81  73  66  63  96  71  75  74  81  63
2009  80  68  76  65  82  69  74  88  80  86  78  76
2010  80  77  82  80  77  70  81  89  91  82  71  73
2011  93  64  87  75 101  89  87  78 106  84  64  71
</code></pre>

<p>And then performed the <code>stl()</code> decomposition</p>

<pre><code># Seasonal decomposition
suicideByMonthFit &lt;- stl(suicideByMonthTs, s.window=""periodic"")
plot(suicideByMonthFit)
</code></pre>

<p><img src=""http://i.stack.imgur.com/cS5pE.jpg"" alt=""enter image description here""></p>

<p>At this point I became concerned because it appears to me that there is both a seasonal component and a trend. After much internet research I decided to follow the instructions of Rob Hyndman and George AthanaÂ­sopouÂ­los as laid out in their on-line text ""Forecasting: principles and practice"", specifically to apply a seasonal ARIMA model.</p>

<p>I used <code>adf.test()</code> and <code>kpss.test()</code> to assess for <em>stationarity</em> and got conflicting results. They both rejected the null hypothesis (noting that they test the opposite hypothesis).</p>

<pre><code>adfResults &lt;- adf.test(suicideByMonthTs, alternative = ""stationary"") # The p &lt; .05 value 
adfResults

    Augmented Dickey-Fuller Test

data:  suicideByMonthTs
Dickey-Fuller = -4.5033, Lag order = 5, p-value = 0.01
alternative hypothesis: stationary

kpssResults &lt;- kpss.test(suicideByMonthTs)
kpssResults

    KPSS Test for Level Stationarity

data:  suicideByMonthTs
KPSS Level = 2.9954, Truncation lag parameter = 3, p-value = 0.01
</code></pre>

<p>I then used the algorithm in the book to see if I could determine the amount of differencing that needed to be done for both the trend and season. I ended  with 
nd = 1, ns = 0.</p>

<p>I then ran <code>auto.arima</code>, which chose a model that had both a trend and a seasonal component along with a ""drift"" type constant.</p>

<pre><code># Extract the best model, it takes time as I've turned off the shortcuts (results differ with it on)
bestFit &lt;- auto.arima(suicideByMonthTs, stepwise=FALSE, approximation=FALSE)
plot(theForecast &lt;- forecast(bestFit, h=12))
theForecast
</code></pre>

<p><img src=""http://i.stack.imgur.com/qTUi9.jpg"" alt=""enter image description here""></p>

<pre><code>&gt; summary(bestFit)
Series: suicideByMonthFromMonthTs 
ARIMA(0,1,1)(1,0,1)[12] with drift         

Coefficients:
          ma1    sar1     sma1   drift
      -0.9299  0.8930  -0.7728  0.0921
s.e.   0.0278  0.1123   0.1621  0.0700

sigma^2 estimated as 64.95:  log likelihood=-709.55
AIC=1429.1   AICc=1429.4   BIC=1445.67

Training set error measures:
                    ME    RMSE     MAE       MPE     MAPE     MASE       ACF1
Training set 0.2753657 8.01942 6.32144 -1.045278 9.512259 0.707026 0.03813434
</code></pre>

<p>Finally, I looked at the residuals from the fit and if I understand this correctly, since all values are within the threshold limits, they are behaving like white noise and thus the model is fairly reasonable. I ran a <em>portmanteau test</em> as described in the text, which had a p value well above 0.05, but I'm not sure that I have the parameters correct.</p>

<pre><code>Acf(residuals(bestFit))
</code></pre>

<p><img src=""http://i.stack.imgur.com/gso3q.jpg"" alt=""enter image description here""></p>

<pre><code>Box.test(residuals(bestFit), lag=12, fitdf=4, type=""Ljung"")

    Box-Ljung test

data:  residuals(bestFit)
X-squared = 7.5201, df = 8, p-value = 0.4817
</code></pre>

<p>Having gone back and read the chapter on arima modeling again, I realize now that <code>auto.arima</code> did choose to model trend and season. And I'm also realizing that forecasting is not specifically the analysis I should probably be doing. I want to know if a specific month (or more generally time of year) should be flagged as a high risk month. It seems that the tools in the forecasting literature are highly pertinent, but perhaps not the best for my question. Any and all input is much appreciated.</p>

<p>I'm posting a link to a csv file that contains the daily counts. The file looks like this:</p>

<pre><code>head(suicideByDay)

        date year month day_of_month t count
1 1995-01-01 1995    01           01 1     2
2 1995-01-03 1995    01           03 2     1
3 1995-01-04 1995    01           04 3     3
4 1995-01-05 1995    01           05 4     2
5 1995-01-06 1995    01           06 5     3
6 1995-01-07 1995    01           07 6     2
</code></pre>

<p><a href=""https://dl.dropboxusercontent.com/u/1252082/daily_suicide_counts.csv"" rel=""nofollow"">daily_suicide_data.csv</a></p>

<p>Count is the number of suicides that happened on that day. ""t"" is a numeric sequence from 1 to the total number of days in the table (5533).</p>

<p>I've taken note of comments below and thought about two things related to modeling suicide and seasons. First, with respect to my question, months are simply proxies for marking change of season, I am not interested in wether or not a particular month is different from others (that of course is an interesting question, but it's not what I set out to investigate). Hence, I think it makes sense to <strong>equalize</strong> the months by simply using the first 28 days of all months. When you do this, you get a slightly worse fit, which I am interpreting as more evidence towards a lack of seasonality. In the output below, the first fit is a reproduction from an answer below using months with their true number of days, followed by a data set <strong>suicideByShortMonth</strong> in which suicide counts were computed from the first 28 days of all months. I'm interested in what people think about wether or not this adjustment is a good idea, not necessary, or harmful?</p>

<pre><code>&gt; summary(seasonFit)

Call:
glm(formula = count ~ t + days_in_month + cos(2 * pi * t/12) + 
    sin(2 * pi * t/12), family = ""poisson"", data = suicideByMonth)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.4782  -0.7095  -0.0544   0.6471   3.2236  

Coefficients:
                     Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)         2.8662459  0.3382020   8.475  &lt; 2e-16 ***
t                   0.0013711  0.0001444   9.493  &lt; 2e-16 ***
days_in_month       0.0397990  0.0110877   3.589 0.000331 ***
cos(2 * pi * t/12) -0.0299170  0.0120295  -2.487 0.012884 *  
sin(2 * pi * t/12)  0.0026999  0.0123930   0.218 0.827541    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 302.67  on 203  degrees of freedom
Residual deviance: 190.37  on 199  degrees of freedom
AIC: 1434.9

Number of Fisher Scoring iterations: 4

&gt; summary(shortSeasonFit)

Call:
glm(formula = shortMonthCount ~ t + cos(2 * pi * t/12) + sin(2 * 
    pi * t/12), family = ""poisson"", data = suicideByShortMonth)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.2414  -0.7588  -0.0710   0.7170   3.3074  

Coefficients:
                     Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)         4.0022084  0.0182211 219.647   &lt;2e-16 ***
t                   0.0013738  0.0001501   9.153   &lt;2e-16 ***
cos(2 * pi * t/12) -0.0281767  0.0124693  -2.260   0.0238 *  
sin(2 * pi * t/12)  0.0143912  0.0124712   1.154   0.2485    
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 295.41  on 203  degrees of freedom
Residual deviance: 205.30  on 200  degrees of freedom
AIC: 1432

Number of Fisher Scoring iterations: 4
</code></pre>

<p>The second thing I've looked into more is the issue of using month as a proxy for season. Perhaps a better indicator of season is the number of daylight hours an area receives. This data comes from a northern state that has substantial variation in daylight. Below is a graph of the daylight from the year 2002. </p>

<p><img src=""http://i.stack.imgur.com/yvVXl.jpg"" alt=""enter image description here""></p>

<p>When I use this data rather than month of the year, the effect is still significant, but the effect is very, very small. The residual deviance is much larger than the models above. If daylight hours is a better model for seasons, and the fit is not as good, is this more evidence of very small seasonal effect? </p>

<pre><code>&gt; summary(daylightFit)

Call:
glm(formula = aggregatedDailyCount ~ t + daylightMinutes, family = ""poisson"", 
    data = aggregatedDailyNoLeap)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-3.0003  -0.6684  -0.0407   0.5930   3.8269  

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)      3.545e+00  4.759e-02  74.493   &lt;2e-16 ***
t               -5.230e-05  8.216e-05  -0.637   0.5244    
daylightMinutes  1.418e-04  5.720e-05   2.479   0.0132 *  
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 380.22  on 364  degrees of freedom
Residual deviance: 373.01  on 362  degrees of freedom
AIC: 2375

Number of Fisher Scoring iterations: 4
</code></pre>

<p>I'm posting the daylight hours in case anyone wants to play around with this. Note, this is not a leap year, so if you want to put in the minutes for the leap years, either extrapolate or retrieve the data.</p>

<p><a href=""https://dl.dropboxusercontent.com/u/1252082/state.daylight.2002.csv"" rel=""nofollow"">state.daylight.2002.csv</a></p>

<p>[<strong>Edit</strong> to add plot from deleted answer (hopefully rnso doesn't mind me moving the plot in the deleted answer up here to the question. svannoy, if you don't want this added after all, you can revert it)]</p>

<p><img src=""http://i.stack.imgur.com/WiuvE.png"" alt=""enter image description here""></p>
"
"0.141657649394966","0.117073226447712","147840","<p>I'm a beginner at Econometrics, and I'm trying to learn the main econometric techniques in <code>R</code>. My doubt is on how to normalize the cointegration matrix to ensure that the coefficient of the cointegration relations is 1 from the output of the <code>ca.jo</code> function for Johansen procedure.</p>

<p>I simulated a multivariate process with 4 series, which 2 are cointegration relations and 2 are common trend:</p>

<pre><code>sigma&lt;-diag(0.5,4)
u&lt;-mvrnorm(n=250,mu=c(0,0,0,0),sigma)
ut1&lt;-arima.sim(n=250,list(order=c(1,0,0),ar=c(0.3)),innov=u[,1])
ut2&lt;-arima.sim(n=250,list(order=c(1,0,0),ar=c(0.5)),innov=u[,2])
y2&lt;-cumsum(u[,3]) ##trend (random walk)
y3&lt;-cumsum(u[,4]) ##trend (random walk)
y1&lt;-0.2*y2+ut1  ##cointegration relation
y4&lt;-0.8*y3+ut2  ##cointegration relation

{ts.plot(y1,y2,y3,y4,col=c(1:4),main=""Simulazione di un sistema con 2 relazioni di cointegrazione"")
legend(""topleft"",legend=c(""y1-cointegrata1"",""y2-common_trend1"",""y3-common_trend2"",""cointegrata2""),pch=15,col=c(1:4))}
</code></pre>

<p>Then for testing the presence of <code>0.2</code> and <code>0.8</code> of my relations in the cointegration matrix, I use <code>ca.jo</code>, this is the output of interest:</p>

<pre><code>xx&lt;-ca.jo(cbind(y1,y2,y3,y4),type=""eigen"",ecdet=""none"",K=2,spec=""transitory"")

xx@Vorg
           y1.l1       y2.l1       y3.l1        y4.l1
y1.l1  1.4948016  0.36787213 -0.02461994 -0.040606696
y2.l1 -0.2951314 -0.07362746  0.05016916  0.362012720
y3.l1 -0.1873146  1.07028673  0.59184042  0.021477244
y4.l1  0.2217581 -1.40606285 -0.05629814  0.009461934
</code></pre>

<p>As I understand, now I have to normalize the parameters for the cointegration relations that are <code>y1</code> and <code>y4</code>, I do in this way:</p>

<pre><code>X&lt;-xx@Vorg
beta.y1 &lt;- X[, 1]/X[1, 1]
beta.y1
     y1.l1      y2.l1      y3.l1      y4.l1 
 1.0000000 -0.1974385 -0.1253107  0.1483528
</code></pre>

<p>As I expected for <code>y2.l1</code> there's a value really close to <code>-0.2</code>...reasoning in the same way for <code>y4</code> I expected to find ""my"" <code>-0.8</code>:</p>

<pre><code>beta.y4 &lt;- X[, 4]/X[4, 4]
beta.y4
    y1.l1     y2.l1     y3.l1     y4.l1 
-4.291585 38.259906  2.269858  1.000000 
</code></pre>

<p>Instead there isn't -0.8 -- I find it is like this:</p>

<pre><code>beta.y4 &lt;- X[, 2]/X[4, 2]
beta.y4
      y1.l1       y2.l1       y3.l1       y4.l1 
-0.26163278  0.05236427 -0.76119409  1.00000000
</code></pre>

<p><code>-0.76</code> for <code>y3.l1</code>. I cannot understand why for the first relation, I divided the first column of the matrix for the element <code>[1,1]</code>, while for the second relation I have to divided the second column (that is the common trend) and not the fourth.</p>
"
"0.141657649394966","0.140487871737254","149377","<p>I have an interrupted time series consisting of 200 observations that I've cleaved into two subseries: a sub-series of 150 pre-interrupted observations, and a sub-series of 50 post-interrupted observations. So the overall structure looks like this:</p>

<p>series = pre-interrupted + post-interrupted</p>

<p>I've fitted the pre-interrupted series with an ARIMA(1, 0, 0) model, and everything looks good. When I run the model in R I get good residual plots and something like this:</p>

<pre><code>&gt; arima(pre-interrupted, 1, 0, 0)

## Coefficients:
##           ar1   xmean
##         0.792  51.472
## s.e.    0.082   2.418
</code></pre>

<p>I created an indicator variable, which to my understanding functions like a dummy variable. It looks like this:</p>

<pre><code>indvar &lt;- c(rep(1, 150), rep(0, 50))
</code></pre>

<p>And then I run the arima command with that included:</p>

<pre><code>&gt; arima(series, c(1, 0, 0), xreg = indicator)
</code></pre>

<p>And get something like this:</p>

<pre><code>## Coefficients:
##           ar1   intercept      indvar
##         0.761      59.721      -8.178
## s.e.    0.082       2.996       1.842
</code></pre>

<p>And I'm not exactly sure how to interpret this. Specifically:</p>

<p>Why did the xmean change to intercept? </p>

<p>What is the role of indvar in the context of the output?</p>
"
"0.141657649394966","0.140487871737254","151652","<p>I fitted a number of SARIMA models using R and chose the ARIMA(0,0,0)(3,1,0)[12] as the best fitted model to the univariate data with 180 points (periodicity=12). This model is chosen as the best model according to the criteria of lowest MAPE among other fitted 624 models.</p>

<p>The residuals of the model violates the assumption of independently distributed residuals (and same for the 2nd best, 3rd best model etc.). Actually the residuals are also non-normally distributed; however the model is fitted with the method of conditional sum of squares in order to bypass the violation of normality assumption. </p>

<p>In the data, the most of the values are close to zero and this does not allow any data transformation. </p>

<p>The data represent the evolution of coefficents of a 11th degree polynomial equation (in total 15 equations representing different years of electricity load duration curves). The purpose is to forecast the coefficients of e.g. the 16th equation and so the corresponding load duration curve.</p>

<p>Can anybody sugggest/provide any solutions to this case?</p>

<pre><code>x=c(1.887090e+04, -6.023007e+00,  1.193635e-02, -1.455856e-05,  1.064251e-08, -4.953592e-12,  1.517229e-15, -3.090332e-19,
4.137144e-23, -3.491891e-27,  1.682794e-31, -3.527046e-36,  1.904962e+04, -7.394189e+00,  1.600849e-02, -2.077511e-05,
1.585519e-08,-7.587987e-12,    2.363570e-15, -4.859251e-19,  6.534816e-23, -5.525202e-27,  2.663420e-31, -5.580438e-36,
2.009098e+04, -1.061082e+01,  2.319182e-02, -2.917768e-05,  2.171827e-08, -1.019917e-11,  3.133564e-15, -6.379905e-19,
8.520995e-23, -7.168462e-27,  3.442102e-31, -7.188143e-36,  2.067028e+04, -8.034999e+00,  1.761326e-02, -2.240562e-05,
1.680919e-08, -7.961614e-12,  2.469832e-15, -5.081494e-19,  6.861040e-23, -5.835236e-27,  2.831898e-31, -5.974519e-36,
2.233604e+04, -1.033148e+01,  2.287039e-02, -2.952031e-05,  2.255568e-08, -1.086351e-11,  3.419260e-15, -7.123005e-19,
9.720229e-23, -8.341734e-27,  4.079166e-31, -8.660882e-36,  2.392045e+04, -8.246481e+00,  1.585412e-02, -2.056180e-05,
1.636424e-08, -8.253437e-12,  2.710813e-15, -5.858824e-19,  8.245204e-23, -7.258003e-27,  3.624039e-31, -7.827743e-36,
2.636514e+04, -9.886355e+00,  1.951992e-02, -2.504930e-05,  1.963158e-08, -9.789139e-12,  3.190186e-15, -6.856046e-19,
9.606813e-23, -8.427664e-27,  4.196799e-31, -9.046539e-36,  2.866210e+04, -8.866902e+00,  1.734494e-02, -2.387617e-05,
1.957175e-08, -9.993900e-12,  3.300201e-15, -7.152619e-19,  1.008517e-22, -8.892694e-27,  4.448060e-31, -9.626143e-36,
3.002254e+04, -1.007403e+01,  2.151203e-02, -2.984675e-05,  2.427803e-08, -1.226036e-11,  3.997630e-15, -8.550747e-19,
1.190499e-22, -1.037815e-26,  5.140218e-31, -1.103334e-35,  2.929311e+04, -1.123255e+01,  2.282206e-02, -2.968240e-05,
2.323868e-08, -1.146069e-11,  3.677709e-15, -7.777557e-19,  1.073806e-22, -9.301478e-27,  4.584147e-31, -9.800725e-36,
3.306894e+04, -1.396117e+01,  2.326777e-02, -2.724425e-05,  2.023428e-08, -9.690231e-12,  3.055811e-15, -6.392630e-19,
8.763020e-23, -7.552202e-27,  3.707622e-31, -7.901994e-36,  3.491666e+04, -1.315883e+01,  2.554492e-02, -3.194439e-05,
2.437661e-08, -1.184053e-11,  3.762542e-15, -7.896499e-19,  1.082565e-22, -9.310722e-27,  4.554895e-31, -9.664092e-36,
3.775600e+04, -2.101521e+01,  4.695457e-02, -6.000206e-05,  4.510264e-08, -2.134088e-11,  6.600784e-15, -1.352465e-18,
1.817468e-22, -1.538166e-26,  7.429410e-31, -1.560507e-35,  3.699341e+04, -1.019327e+01,  1.761360e-02, -2.428662e-05,
2.084200e-08, -1.112473e-11,  3.796505e-15, -8.415154e-19,  1.204392e-22, -1.072641e-26,  5.402195e-31, -1.174885e-35,
4.009280e+04, -1.887174e+01,  3.441926e-02, -4.161190e-05,  3.152055e-08, -1.535050e-11,  4.911316e-15, -1.040003e-18,
1.440215e-22, -1.251900e-26,  6.190925e-31, -1.327693e-35)

fit=arima(x, order = c(0, 0, 0),seasonal = list(order = c(3, 1, 0), period =12),method=c(""CSS""))

par(mfrow=c(1,2)) 
x1&lt;-acf(fit$residuals,180,ylab=""Sample ACF"",main ="""",xaxt=""n"")
axis(1, at=seq(0, 15, by=2), labels = TRUE)
abline(v=(seq(0,15,1)), col=""black"", lty=""dotted"")

x2&lt;-pacf(fit$residuals,180,ylab=""Sample PACF"",main ="""",xaxt=""n"")
axis(1, at=seq(0, 15, by=2), labels = TRUE)
abline(v=(seq(0,15,by=1)), col=""black"", lty=""dotted"")
</code></pre>
"
"0.289954044533636","0.287559667918556","151657","<p>I am running X-13 SEATS on r for monthly data in six years of observations and I think I got a (sufficiently) reasonable fit for the ARIMA model, but the output also shows me that my original series does not have significant seasonality, as it follows:</p>

<pre><code> Call:
seas(x = data_r[, 1], transform.function = ""log"", regression.aictest = NULL, 
    outlier = NULL, arima.model = ""(0 1 1)(1 1 0)"")

Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
AR-Seasonal-12     -0.6194     0.1110  -5.581 2.39e-08 ***
MA-Nonseasonal-01   0.6220     0.1093   5.690 1.27e-08 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

SEATS adj.  ARIMA: (0 1 1)(1 1 0)  Obs.: 60  Transform: log
AICc: 773.4, BIC: 778.4  QS (no seasonality in final):    0  
Box-Ljung (no autocorr.): 20.04   Shapiro (normality): 0.9754
    &gt; 
                qs p-val
    qsori        0     1
    qsorievadj   0     1
    qsrsd        0     1
    qssadj       0     1
    qssadjevadj  0     1
    qsirr        0     1
    qsirrevadj   0     1
</code></pre>

<p>(Still, there is also the fact that the irregular component seems to dominate the SI ratio for some specific months in some years. So maybe there is some dummy variable in the pre-adjustment that I am missing (right?)) </p>

<p>But when I run a regression on Stata for yearly and monthly dummies on the original series -- assuming the seasonality is deterministic --, I cannot reject with an F test that they are all equal to zero. What does this show me? That my ARIMA fit is not correct?</p>

<p>Also, if someone could point me out the difference in interpretation that you should have when running a regression on seasonal dummies and deseasonalizing data with a X-13 SEATS, it would be also very helpful. Maybe that is what I am missing here.</p>

<p>Edit: is it by any chance a common practice, in some particular situations (when you are deseasonalizing a set of series), still deseasonalize a given series even if that series does not show significant seasonality?</p>

<p>Edit2: Adding the results of the automatic adjustment:</p>

<pre><code>Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
Constant            59.1761    38.0551   1.555  0.11994    
Easter[15]        -903.6151   341.1891  -2.648  0.00809 ** 
MA-Nonseasonal-01    0.4974     0.1138   4.370 1.24e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

SEATS adj.  ARIMA: (0 1 1)  Obs.: 60  Transform: none
AICc: 925.6, BIC: 933.2  QS (no seasonality in final):    0  
Box-Ljung (no autocorr.):  21.9   Shapiro (normality): 0.9498 *

            qs p-val
qsori        0     1
qsorievadj   0     1
qsrsd        0     1
qssadj       0     1
qssadjevadj  0     1
qsirr        0     1
qsirrevadj   0     1 
</code></pre>

<p>I also, I get the following error for the monthplot function with the automatic adjustment: </p>

<pre><code>Error in `[.default`(x$data, , ""seasonal"") : subscript out of bounds
</code></pre>

<p>Following this result from the automatic adjustment, the use of the dummy for easter, with the original specification, does not change that much the first output:</p>

<pre><code>Coefficients:
                  Estimate Std. Error z value Pr(&gt;|z|)    
Easter[15]        -0.08307    0.02690  -3.088  0.00202 ** 
AR-Seasonal-12    -0.63353    0.10816  -5.858  4.7e-09 ***
MA-Nonseasonal-01  0.50391    0.12075   4.173  3.0e-05 ***
---
Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

SEATS adj.  ARIMA: (0 1 1)(1 1 0)  Obs.: 60  Transform: log
AICc: 767.9, BIC: 774.3  QS (no seasonality in final):    0  
Box-Ljung (no autocorr.): 29.37   Shapiro (normality): 0.9721  
            qs p-val
qsori        0     1
qsorievadj   0     1
qsrsd        0     1
qssadj       0     1
qssadjevadj  0     1
qsirr        0     1
qsirrevadj   0     1
</code></pre>

<p>Most recent observation: Now I Think I am fairly sure that there is no significant seasonality in this series, but I would be thankful if someone could show me other problems that I might not be considering. Still, I would like a possible canonical/scholarly answer on why I can reject the null hypothesis for the whole set of seasonal dummies being zero (though I had a small result for the F test with my data, ~4, but I still reject the null) and still get a reasonable ARIMA fit with which I cannot reject no seasonality in my original data. Does that have something to do with the difference of the adjustment with ARIMA models and deterministic seasonality? An intuitive answer on this difference would be of some help.</p>
"
"0.19083419135889","0.243332131696144","154641","<p>This question is similar to the following <a href=""http://stats.stackexchange.com/questions/32634/difference-time-series-before-arima-or-within-arima"">question</a> in the sense I am currently doing the differencing and mean removal of the time series outside the <code>Arima</code> function in R. And I do not know how to do these steps within <code>Arima</code> function in R. The reason is that I am trying to perform the following procedure (data <code>dowj_ts</code> can be found at the bottom): </p>

<pre><code>dowj_ts_d1 &lt;- diff(dowj_ts) # differencing at lag 1 (1-B)
drift &lt;- mean(diff(dowj_ts))
dowj_ts_d1_demeaned &lt;- dowj_ts_d1 - mean(dowj_ts_d1) # mean removal
# Maximum Likelihood AR(1) for the mean-corrected differences X_t
fit &lt;- Arima(dowj_ts_d1_demeaned, order=c(1,0,0),include.mean=F, transform.pars = T)
</code></pre>

<p>Note that the <code>drift</code> is actually <code>0.1336364</code>. And <code>summary(fit)</code> gives the table below:</p>

<pre><code>Series: dowj_ts_d1_demeaned 
ARIMA(1,0,0) with zero mean     

Coefficients:
         ar1
      0.4471
s.e.  0.1051

sigma^2 estimated as 0.1455:  log likelihood=-35.16
AIC=74.32   AICc=74.48   BIC=79.01

Training set error measures:
                       ME     RMSE       MAE       MPE     MAPE      MASE
Training set -0.004721362 0.381457 0.2982851 -9.337089 209.6878 0.8477813
                    ACF1
Training set -0.04852626
</code></pre>

<p>Ultimately, I want to predict 2-step ahead forecast of <strong>the original series</strong>, and this starts to become ugly: </p>

<pre><code> tail(c(dowj_ts[1], dowj_ts[1] + cumsum(c(dowj_ts_d1_demeaned,forecast.Arima(fit,h=2)$mean) + drift)),2)
</code></pre>

<p>And currently these are all done outside the <code>Arima</code> function from the <code>forecast</code> package. I know I can do differencing within Arima like this: </p>

<pre><code> Arima(dowj_ts, order=c(1,1,0),include.drift=T,transform.pars = F)
</code></pre>

<p>This gives:</p>

<pre><code>Series: dowj_ts 
ARIMA(1,1,0) with drift         

Coefficients:
         ar1   drift
      0.4478  0.1204
s.e.  0.1059  0.0786

sigma^2 estimated as 0.1474:  log likelihood=-34.69
AIC=75.38   AICc=75.71   BIC=82.41
</code></pre>

<p>But the drift term computed by R is different from the <code>drift = 0.1336364</code> that I computed manually.</p>

<p>So <strong>my question is: how can I differenced the series and then remove the mean of the differenced series within the Arima function ?</strong></p>

<p><strong>Second question:</strong> Why is the drift term estimated by <code>Arima</code> different from the drift term I computed ? In fact, what does the <strong>mathematical model</strong> look like when <code>include.drift = T</code> ? This really confuses me. </p>

<p>Data can be found below: </p>

<pre><code>structure(c(110.94, 110.69, 110.43, 110.56, 110.75, 110.84, 110.46, 
110.56, 110.46, 110.05, 109.6, 109.31, 109.31, 109.25, 109.02, 
108.54, 108.77, 109.02, 109.44, 109.38, 109.53, 109.89, 110.56, 
110.56, 110.72, 111.23, 111.48, 111.58, 111.9, 112.19, 112.06, 
111.96, 111.68, 111.36, 111.42, 112, 112.22, 112.7, 113.15, 114.36, 
114.65, 115.06, 115.86, 116.4, 116.44, 116.88, 118.07, 118.51, 
119.28, 119.79, 119.7, 119.28, 119.66, 120.14, 120.97, 121.13, 
121.55, 121.96, 122.26, 123.79, 124.11, 124.14, 123.37, 123.02, 
122.86, 123.02, 123.11, 123.05, 123.05, 122.83, 123.18, 122.67, 
122.73, 122.86, 122.67, 122.09, 122, 121.23), .Tsp = c(1, 78, 
1), class = ""ts"")
</code></pre>
"
"0.146303391191891","0.181369062527503","156449","<p>I am working with workersâ€™ remittance quarterly data for Bangladesh. Here I am doing time series forecasting using R. I am applying auto.arima model and exponential smoothing model. I want to compare between them to check which best fits the data and gives better forecast.</p>

<p>Here is the output:</p>

<p>fit1 &lt;- auto.arima(lremit, d=1, D=NA, stationary=FALSE,
+                    seasonal=TRUE,ic=""aic"",trace=TRUE,
+                    allowdrift=FALSE,allowmean=TRUE)</p>

<p>Best model: ARIMA(2,1,3)(0,1,1)[4]                    </p>

<blockquote>
  <p>summary(fit1)
  Series: lremit 
  ARIMA(2,1,3)(0,1,1)[4]<br>
  Coefficients:
            ar1      ar2     ma1     ma2      ma3     sma1
        -0.5024  -0.1691  0.3940  0.1516  -0.1899  -0.9605
  s.e.   0.6321   0.4860  0.6298  0.4465   0.1060   0.1098
  sigma^2 estimated as 0.007314:  log likelihood=135.59
  AIC=-257.18   AICc=-256.3   BIC=-236.84</p>
</blockquote>

<p>Training set error measures:
                       ME       RMSE        MAE         MPE     MAPE      MASE         ACF1
Training set -0.003608938 0.08398593 0.06532171 -0.09985958 1.110818 0.4381367 -0.004851439</p>

<blockquote>
  <p>fit1 &lt;- Arima(lremit,order=c (2,1,3),seasonal=c (0,1,1))
  h11=plot(forecast(fit1,h=20))
  h11
  $mean
           Qtr1     Qtr2     Qtr3     Qtr4
  2015 8.256047 8.283843 8.300686 8.341204
  2016 8.372717 8.406483 8.413318 8.457855
  2017 8.489041 8.522291 8.529440 8.573906
  2018 8.605075 8.638346 8.645488 8.689954
  2019 8.721124 8.754394 8.761536 8.806002</p>
  
  <h2>ETS</h2>
  
  <p>fit2&lt;-ets(lremit)
  summary(fit2)</p>
</blockquote>

<p>ETS(A,A,N) </p>

<p>Call:
 ets(y = lremit) </p>

<p>Smoothing parameters:
    alpha = 0.8594 
    beta  = 1e-04 </p>

<p>Initial states:
    l = 4.2135 </p>

<p>sigma:  0.0858</p>

<pre><code> AIC     AICc      BIC 
</code></pre>

<p>12.20515 12.50145 23.97172 </p>

<p>Training set error measures:
                        ME       RMSE        MAE         MPE     MAPE      MASE         ACF1
Training set -7.229862e-05 0.08579429 0.06800397 -0.01942594 1.169213 0.4561276 -0.002900248</p>

<p>It is my first work using R and I am facing problems regarding this. They are:</p>

<ol>
<li>auto.arima output shows seasonality in every 4th quarter, but exponential smoothing shows non seasonality, what is the interpretation of this contradictory result?</li>
<li>How can I compare between them, what is the proper measure?</li>
<li>What is the command for in sample forecast in auto.arima? If I write h=0, then it shows error</li>
<li>Where can I find elaborate interpretation of auto.arima and exponential smoothing output and about the comparison?</li>
<li>Which error measure should I prefer like ME, MAPE, RMSE etc. as they are almost same for the two models?</li>
<li>In case of auto.arima it shows same output for allowing drift or no drift</li>
</ol>
"
"0.0408930410054765","0.0811107105653813","159605","<p>I'm new on time series. I'm trying to solve an exercise on the simulation of an ARMA process. </p>

<p>The problem is the following: 
Generate 100 simulations, each with n=60 elements of an ARMA(1,2) process with mean $\mu=1.25$ and parameters $\phi_1=-0.5$, $\theta_1=0.5$, $\theta_2=-0.7$ and $\sigma^2=0.5$
For each simulation estimate the mean and the first two correlation coefficients and find in how many simulations they are contained in the theoretical confidence intervals. </p>

<p>Ok so, I think that for one simulation of the ARMA(1,2) I should do something like: </p>

<pre><code>x &lt;- arima.sim(list(order = c(1,0,2), ar = -0.5 , ma=c(0.5, -0.7)), sd=sqrt(0.5), n = 60)
</code></pre>

<p>And this is one simulation, right? But then, for generate the other 99 simulation what should I do? Can I construct a kind of a loop? </p>

<p>Thank you in advance ! Cheers</p>
"
"0.100167084494127","0.0993399267798783","159741","<p>I have 100 simulations of an ARMA(1,2) process, created with R is such a way: </p>

<pre><code>M &lt;- replicate(100, arima.sim(list(order=c(1,0,2),ar=-0.5,ma=c(0.5,-0.7)), mean=1.25,sd=sqrt(0.5),n=60))
M &lt;- data.matrix(M)
</code></pre>

<p>Thus each column represents a time series.</p>

<p>Now, my next step is to compute the first two correlation coefficients of each simulation. 
This is the point in which I'm stuck. 
My idea is first do a loop over the columns of M, in order to compute the correlation coefficient for each time series and allocate the result in a matrix. (that should be 3x100) </p>

<p>What I have tryed to do in R is the following:</p>

<pre><code>CorrCoeff&lt;- list()
length(CorrCoeff) &lt;- 300
dim(CorrCoeff) &lt;- c(3,100)
CorrCoeff &lt;- data.matrix(CorrCoeff) #empty matrix that I will fill with the loop 

for(i in 1:ncol(M) #loop over the colums
  { CorrCoeff[,i] &lt;- cbind(acf(M[,i],2)) } 
CorrCoeff
</code></pre>

<p>But unfortunately this code doesn't work. </p>

<p>Then I have tried also: </p>

<pre><code>a &lt;- vector(mode=""numeric"")
for(i in 1:ncol(M))
  { a[i] &lt;- cbind(acf(M[,i],2)) } 
</code></pre>

<p>Here I get the acf for each time series but the output is presented is a strange way and I don't know how to put these results in a matrix. </p>

<p>Can someone tell me where I'm wrong or give me some suggestions? 
Thank you! Cheers</p>
"
"0.176435273432909","0.190885428892733","159769","<p>I was checking for seasonality and other dependencies and this is the curve I get . There's no apparent seasonality....but what exctly does the falling slope mean? Any help would be appreciated. Thanks!</p>

<p>Actual Time Series:
<img src=""http://i.stack.imgur.com/JtJiu.png"" alt=""enter image description here""></p>

<p><img src=""http://i.stack.imgur.com/xTvlQ.png"" alt=""Autocorelation curve for a time series with data over last 9 years""></p>

<p>EDIT: Adding other plots:
<img src=""http://i.stack.imgur.com/hhStk.png"" alt=""PACF of original time series""></p>

<p>Here is the ACF and PACF of once-differenced
<img src=""http://i.stack.imgur.com/pGGJM.png"" alt=""ACF,once differentiated"">
 <img src=""http://i.stack.imgur.com/DyHFW.png"" alt=""PACF, differentiated once""></p>

<p>Some results from running the ARIMA model:</p>

<pre><code>Call:
**arima(x = meanT2$MeanUnit, order = c(1, 0, 1))**

Coefficients:
         ar1      ma1  intercept
      0.9840  -0.3525  1002.8215
s.e.  0.0169   0.0927   184.1689

Call:
**arima(x = meanT2$MeanUnit, order = c(1, 0, 0))**

Coefficients:
         ar1  intercept
      0.9456  1031.3660
s.e.  0.0319   110.2209

sigma^2 estimated as 5312:  log likelihood = -651.81,  aic = 1309.62

Call:
**arima(x = meanT2$MeanUnit, order = c(2, 0, 1))**

Coefficients:
         ar1      ar2      ma1  intercept
      1.0455  -0.0599  -0.4046   1002.210
s.e.  0.2324   0.2258   0.2091    185.629

Call:
**arima(x = meanT2$MeanUnit, order = c(2, 0, 0))**

Coefficients:
         ar1     ar2  intercept
      0.6907  0.2753  1016.3942
s.e.  0.0898  0.0912   151.4378

sigma^2 estimated as 4908:  log likelihood = -647.45,  aic = 1302.91
</code></pre>

<p>Edited to add: The residuals plot of the ARIMA(1,0,1) case. For ARIMA(1,0,0) its almost the same 
<img src=""http://i.stack.imgur.com/8sK5s.png"" alt=""enter image description here""></p>

<p>ACF plot of ARIMA(1,0,1)<img src=""http://i.stack.imgur.com/P63P8.png"" alt=""enter image description here""></p>
"
"0.103452120022374","0.128247294010644","160435","<p>I'm diving into arima models and was trying to repreduce the results of auto regression.</p>

<p>here is a reproducable example:</p>

<pre><code>set.seed(1)
z=arima.sim(n = 101, list(ar = c(0.8)))
</code></pre>

<p>when running ar(1) without an intercept </p>

<pre><code>&gt; ceof(arima(z, order = c(1,0,0),include.mean =FALSE))
ar1 
0.7622461
</code></pre>

<p>when comparing to a linear regression </p>

<pre><code>&gt; coef(lm(z[2:101] ~ z[1:100] + 0))
z[1:100] 
0.7586725 
</code></pre>

<p>which are very similar and can be explained by the different methods used.
However when I do this comparison with models that include an intercept, I get again similar results in the ar1 coefficient but very different measures for the intercept. while the intercept that I get in the arima model is the one that makes less sense to me.</p>

<pre><code>&gt; coef(arima(z, order = c(1,0,0)))
      ar1 intercept 
0.7274511 0.4241322 
&gt; coef(lm(z[2:101] ~ z[1:100]))
(Intercept)    z[1:100] 
  0.1578015   0.7130261 
</code></pre>

<p>Any ideas on these differencing and in what way the arima procedure is different?</p>
"
"0.187952352889028","0.200738767136742","160675","<p>I'm interested in determining both the slope regression coefficient and plotting regression lines for autocorrelated time-series datasets of rainfall.  Specifically, I'd like to identify the best approach in R that would allow me to visualize the regression line on the original (undifferenced) time-series plot when I need to difference the data to remove stationarity (i.e, when d>0 in an arima model).</p>

<p>As a start, I'm exploring the use of auto.arima (from the forecast package) and sarima (from the astsa package) which can output regression coefficients in the presence of autocorrelation.</p>

<p>For example:</p>

<ol>
<li><p>Using auto.arima. The 'drift' of -5.009 represents the slope (see <a href=""http://robjhyndman.com/hyndsight/arima-trends/"" rel=""nofollow"">http://robjhyndman.com/hyndsight/arima-trends/</a>) </p>

<pre><code>&gt; min.ar &lt;- auto.arima(dec.yr.mmin$min_prcp)
&gt; summary(min.ar)

Series: dec.yr.mmin$min_prcp 
ARIMA(1,1,0) with drift         

Coefficients:
          ar1    drift
      -0.5138  -5.0089
s.e.   0.2465   5.7986

sigma^2 estimated as 949:  log likelihood=-57.82
AIC=121.64   AICc=124.31   BIC=123.34

Training set error measures:
                     ME     RMSE      MAE       MPE     MAPE      MASE       ACF1
Training set -0.9479987 28.52129 23.83494 -2.484233 16.12547 0.7957998 -0.2617352
</code></pre></li>
<li><p>Using sarima to fit the model and output the slope</p>

<pre><code>  &gt; fit.min &lt;- sarima(dec.yr.mmin$min_prcp, 1,1,0,                       reg=dec.yr.mmin$decade)
initial  value 3.542448 
  iter   2 value 3.488927
  iter   3 value 3.386967
  iter   4 value 3.383464
  iter   5 value 3.382408
  iter   6 value 3.382051
  iter   7 value 3.382024
  iter   8 value 3.382020
  iter   9 value 3.381925
  iter   9 value 3.381925
  iter   9 value 3.381925
  final  value 3.381925 
  converged
  initial  value 3.400729 
  iter   2 value 3.399523
  iter   3 value 3.399490
  iter   4 value 3.399488
  iter   4 value 3.399488
  iter   4 value 3.399488
  final  value 3.399488 
  converged
</code></pre></li>
</ol>

<p>3.Output coefficients</p>

<pre><code>      &gt; fit.min$fit$coef
             ar1       xreg 
      -0.5137696 -0.5009045 
</code></pre>

<ol start=""4"">
<li><p>For comparison, this is the output from an OLS regression which may give an incorrect slope due to autocorrelation.</p>

<pre><code>  &gt; m3 &lt;- lm(dec.yr.mmin$min_prcp ~ dec.yr.mmin$decade)
  &gt; summary(m3)

  Call:
  lm(formula = dec.yr.mmin$min_prcp ~ dec.yr.mmin$decade)

  Residuals:
      Min      1Q  Median      3Q     Max 
  -45.504  -8.048   1.892  13.650  38.357 

  Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)   
  (Intercept)        1014.1570   319.9461   3.170  0.00807 **
  dec.yr.mmin$decade   -0.4222     0.1580  -2.672  0.02032 * 
  ---
  Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1

  Residual standard error: 23.83 on 12 degrees of freedom
  Multiple R-squared:  0.3731,  Adjusted R-squared:  0.3209 
  F-statistic: 7.142 on 1 and 12 DF,  p-value: 0.02032
</code></pre>

<p>`</p></li>
</ol>

<p>The output from sarima identifies the slope coefficient and also intercept when d=0. When differencing is required (e.g., ARIMA (1,1,0) as output above), sarima only outputs the slope. </p>

<p>My question: when d = 1 or more, what approaches in R would allow me to add/visualize the regression line onto the original undifferenced time-series plot. Is it possible to derive the fitted values of the regression line, or derive intercept values from sarima/auto.arima or other package?</p>

<p>Many thanks in advance for your suggestions.</p>
"
"0.086747239794936","0.114707866935281","161182","<p>I am trying to fit and forecast log returns of a price data using ARIMA model in R. For reproducibility, data is provided <a href=""https://docs.google.com/spreadsheets/d/1U619rL30yGcNRWxoiiIsfy-C-VOH2W2tnEivuIUOVq4/edit?usp=sharing"" rel=""nofollow"">here</a>. </p>

<p><strong>Steps Followed, Code and Results obtained</strong> </p>

<ol>
<li><p>Check for outliers (Package: <code>forecast</code>) - No outliers detected. </p>

<pre><code>outliers &lt;- tsoutliers(log.rtn)
</code></pre></li>
<li><p>Stationarity Check using ADF test (Package: fUnitRoots) - Series found to be stationary</p>

<pre><code>stationary &lt;- adfTest(log.rtn, lags = m1$order, type = c(""c""))
</code></pre></li>
<li><p>Determination of p,d,q using ACF and PACF (Package: astsa) - Based on my understanding, p = 2, d = 0, q = 2</p>

<pre><code>acf2(log.rtn, lags = 20)
</code></pre></li>
<li><p>Fitting ARIMA (Package: forecast)</p>

<pre><code>fit &lt;- auto.arima(log.rtn, stepwise=FALSE, trace=TRUE, approximation=FALSE)
</code></pre>

<p>Model obtained : ARIMA(2,0,1)</p>

<pre><code>Series: log.rtn 

  ARIMA(2,0,1) with zero mean     

Coefficients:
          ar1     ar2     ma1
      -0.5705  0.1557  0.6025
s.e.   0.1549  0.0532  0.1519

sigma^2 estimated as 0.001086:  log likelihood=775.57
AIC=-1543.14   AICc=-1543.04   BIC=-1527.29
</code></pre></li>
<li><p>Prediction (Package:forecast)</p>

<pre><code>fcast &lt;- forecast(fit, n.ahead=5)
plot(fcast)

    Point Forecast       Lo 80      Hi 80       Lo 95      Hi 95
390   1.416920e-03 -0.04080849 0.04364233 -0.06316127 0.06599511
391   8.228924e-04 -0.04142414 0.04306993 -0.06378837 0.06543416
392  -2.488236e-04 -0.04289257 0.04239493 -0.06546681 0.06496917
393   2.700663e-04 -0.04248622 0.04302635 -0.06512003 0.06566016
394  -1.928045e-04 -0.04303250 0.04264690 -0.06571047 0.06532486
395   1.520366e-04 -0.04273465 0.04303872 -0.06543749 0.06574156
396  -1.167506e-04 -0.04303183 0.04279833 -0.06574971 0.06551621
397   9.027370e-05 -0.04284167 0.04302221 -0.06556846 0.06574901
398  -6.967566e-05 -0.04301167 0.04287232 -0.06574379 0.06560444
399   5.380284e-05 -0.04289419 0.04300179 -0.06562948 0.06573708
</code></pre></li>
</ol>

<p>I am quite confused why the model is predicting so badly.</p>
"
"0.0817860820109531","0.0811107105653813","163774","<p>I have a relatively simple problem, but yet taking some time to solve it. I am using the <code>arimax()</code> function from the <code>TSA</code> package. <em>(Note: not <code>arima()</code> from the <code>stats</code> package.)</em> This is the model: </p>

<pre><code>out &lt;- arimax(sub_s_t_series, order=c(2,0,1), xreg=sub_r_t_series, method=c(""ML""))
</code></pre>

<p>and these are my coefficients:</p>

<pre><code>Call
arimax(x = sub_s_t_series, order = c(2, 0, 1), xreg = sub_r_t_series, method = c(""ML""))

Coefficients:
         ar1      ar2      ma1  intercept     xreg
      1.4825  -0.6613  -0.8516  52745.107  -1.0132
s.e.  0.0295   0.0294   0.0064     40.828   0.0012

sigma^2 estimated as 0.08929:  log likelihood = -105.98,  aic = 221.97
</code></pre>

<p>All I am trying to do is to interpret the results. According to my understanding and the help given in the TSA package, the above ARIMAX(2,0,1) model is represented as follows:
$$
{\rm sub\_s\_t\_series\_hat[k]} = {\rm intercept} + xreg\times {\rm sub\_r\_t\_series[k]} + 
\frac{a_{t[k]}+ma1*a_{t[k-1]}}{a_{t[k]}-ar1*a_{t[k-1]}-ar2*a_{t[k-2]}}  \tag{1} 
$$
where $a_t$ are the residuals. When I use e_t = fitted(out)-sub_s_t_series_hat to measure the error / residuals myself, e_t matches exactly to the values obtained by <code>out[[""residuals""]]</code>.</p>

<p>But when I use (1) as follows: e_t_hat = sub_s_t_series_hat - sub_s_t_series, 
e_t_hat does not match with <code>out[[""residuals""]]</code>, in fact the results deviate by a magnitude of almost 4.</p>

<p><strong>My questions is:</strong> did an ARIMAX(2,0,1) fit would result in (1) or am I missing something?</p>
"
"0.086747239794936","0.114707866935281","163878","<p>I want to estimate an ARIMA model on my timeseries, then represent it in state space format, mainly because it will be more responsive to change in pattern.
I used <code>auto.arima</code> from <code>forecast</code> package to find the best ARIMA, and then, if it didn't need differencing, tried to estimate the same ARMA using <code>dlm</code>package. </p>

<pre><code>fit.arima &lt;- auto.arima(training_data_list, seasonal = FALSE)
Series: training_data_list 
ARIMA(1,0,1) with zero mean     

Coefficients:
         ar1      ma1
      0.8247  -0.4913
s.e.  0.0395   0.0618

sigma^2 estimated as 489.7:  log likelihood=-3161.25
AIC=6328.5   AICc=6328.53   BIC=6342.15
</code></pre>

<p>Now the same thing using <code>dlm</code> package:</p>

<pre><code>test.model.arma &lt;- function(u){
  arma  &lt;- dlmModARMA(ar = ARtransPars(u[1]), ma = u[2], sigma2 = exp(u[3]))   # ma = c(u[4]),
  return(arma)
}
init &lt;-c(rep(0,3))
outMLE2 &lt;- dlmMLE(training_data_list, init, test.model.arma,method = ""Nelder-Mead"")
# outMLE2 &lt;- dlmMLE(training_data_list, init, test.model.arma)
if(outMLE2$convergence != 0) {print(""MLE did NOT converge!"")}

dlmModel4 &lt;- test.model.arma(outMLE2$par)
</code></pre>

<p>Now the loglikelihood from the later one is $2523.158$, while the <code>auto.arima</code> gives $3161.25$. the coefficients for $ar$ and $ma$ are very close, so I think it might be unlikely to be the reason.</p>

<pre><code>dput(training_data_list)
structure(c(0.92, 3.76, 2.64, 2.72, -4.48, 4.68, 6.2, 4.16, 22.32, 
28.96, 5.72, 3.44, 29.56, 37.28, 38.16, 31.28, 32.04, 21.32, 
2.88, 7.08000000000001, 52.32, 9.80000000000001, 8.56, 2.24000000000001, 
29.8, 49.2, 23.88, 42.32, -0.08, 3.76, -0.359999999999999, 2.72, 
8.52, 26.68, 7.2, -18.84, -13.68, -3.03999999999999, 10.72, -14.56, 
-16.44, 44.28, -17.84, -8.72000000000003, 3.04000000000002, 30.32, 
-21.12, -13.92, -3.68000000000001, -17.2, -16.44, -7.75999999999999, 
39.8, -1.80000000000001, 25.88, 9.31999999999999, -0.08, 1.76, 
2.64, -5.28, -4.48, 3.68, 1.2, -10.84, -21.68, -1.03999999999999, 
-6.28, 22.44, 62.56, 27.28, 1.16000000000003, -8.72000000000003, 
23.04, -11.68, -40.12, -33.92, -43.68, -26.2, -58.44, 5.24000000000001, 
-33.2, -18.8, -48.12, -57.68, -0.08, 3.76, -2.36, -7.28, -1.48, 
-1.32, 2.2, -6.84, 14.32, 23.96, -6.28, -11.56, -13.44, 14.28, 
-38.84, -31.72, 4.04000000000002, 4.31999999999999, 24.88, -3.91999999999999, 
-19.68, 30.8, 13.56, 4.24000000000001, 22.8, 36.2, 44.88, -17.68, 
-0.08, -1.24, -4.36, -1.28, -5.48, 7.68, 1.2, 14.16, -1.68000000000001, 
9.96000000000001, -3.28, 8.44, 59.56, 33.28, 23.16, 72.28, 48.04, 
36.32, 41.88, 7.08000000000001, 13.32, 20.8, 19.56, -0.759999999999991, 
-4.19999999999999, 31.2, 40.88, -10.68, -0.08, 6.76, 2.64, 2.72, 
7.52, 1.68, 1.2, -8.84, -7.68000000000001, 11.96, 31.72, -5.56, 
38.56, 27.28, -15.84, 60.28, 21.04, -22.68, 33.88, 55.08, 41.32, 
24.8, 6.56, 20.24, 60.8, 36.2, -9.12, 42.32, -0.08, 2.76, 2.64, 
1.72, -1.48, 2.68, 8.2, -18.84, -24.68, -4.03999999999999, 2.72, 
-31.56, -9.44, -11.72, -48.84, -5.72000000000003, 2.04000000000002, 
-19.68, -2.12, 27.08, 7.31999999999999, -22.2, 42.56, 11.24, 
9.80000000000001, 17.2, 25.88, 55.32, -0.08, -3.24, -4.36, 1.72, 
-6.48, 0.68, -0.799999999999997, 6.16, -13.68, -14.04, -2.28, 
12.44, -24.44, -15.72, 13.16, 1.27999999999997, -16.96, -40.68, 
-76.12, -50.92, -49.68, -58.2, -42.44, -36.76, -8.19999999999999, 
-43.8, -71.12, -62.68, -0.08, -3.24, -2.36, -1.28, 8.52, 4.68, 
-0.799999999999997, 18.16, 16.32, -18.04, 14.72, -18.56, 6.56, 
14.28, 53.16, 41.28, 35.04, -40.68, -12.12, -5.91999999999999, 
22.32, 11.8, -16.44, -6.75999999999999, -36.2, 3.19999999999999, 
-8.12, -12.68, -0.08, 3.76, 2.64, -3.28, -0.48, 13.68, 11.2, 
10.16, 9.31999999999999, -15.04, -6.28, -22.56, 14.56, -5.72000000000003, 
53.16, 36.28, 45.04, -12.68, -0.120000000000005, 21.08, -24.68, 
-10.2, -17.44, 3.24000000000001, 8.80000000000001, -11.8, -26.12, 
-27.68, -0.08, 2.76, 0.640000000000001, 2.72, -4.48, -2.32, -4.8, 
18.16, 7.31999999999999, 12.96, 45.72, 37.44, -22.44, 9.27999999999997, 
36.16, 51.28, 7.04000000000002, 54.32, 5.88, -1.91999999999999, 
25.32, 27.8, 15.56, 22.24, 18.8, -38.8, 31.88, 31.32, -0.08, 
6.76, -0.359999999999999, -0.279999999999999, 1.52, 1.68, -3.8, 
18.16, -8.68000000000001, 7.96000000000001, -7.28, 30.44, 12.56, 
51.28, 9.16000000000003, 16.28, -14.96, 50.32, -18.12, -32.92, 
10.32, -8.19999999999999, -5.44, 22.24, 23.8, 33.2, -12.12, 51.32, 
-0.08, -4.24, -2.36, -0.279999999999999, -2.48, -4.32, -4.8, 
0.159999999999997, -17.68, 7.96000000000001, 9.72, 9.44, 1.56, 
-15.72, 4.16000000000003, 6.27999999999997, -28.96, -38.68, -18.12, 
-36.92, -34.68, -25.2, -23.44, -43.76, -59.2, -37.8, -54.12, 
-61.68, -0.08, 0.76, 2.64, 9.72, -1.48, 2.68, 21.2, 13.16, -1.68000000000001, 
10.96, 20.72, 22.44, 23.56, 18.28, -3.83999999999997, -16.72, 
-19.96, 46.32, 47.88, 25.08, 0.319999999999993, 21.8, 14.56, 
32.24, 1.80000000000001, -5.80000000000001, -12.12, 1.31999999999999, 
-0.08, 5.76, -4.36, 4.72, -3.48, -5.32, 4.2, 4.16, -12.68, -14.04, 
-11.28, 0.439999999999998, -13.44, 25.28, 58.16, 29.28, 32.04, 
38.32, 14.88, 32.08, 39.32, 47.8, 16.56, 17.24, -25.2, 13.2, 
27.88, -6.68000000000001, -0.08, -6.24, -2.36, -6.28, -3.48, 
3.68, -1.8, -9.84, 11.32, 4.96000000000001, -26.28, -32.56, -38.44, 
-49.72, -62.84, -40.72, -20.96, -13.68, -52.12, -24.92, -49.68, 
-25.2, -19.44, -82.76, -36.2, -51.8, -60.12, -65.68, 0.92, -3.24, 
-1.36, -0.279999999999999, -19.48, -34.32, -22.8, 1.16, 19.32, 
-2.03999999999999, 27.72, 4.44, 12.56, -53.72, -35.84, -60.72, 
24.04, -15.68, 27.88, 11.08, 12.32, 33.8, 5.56, 3.24000000000001, 
24.8, -21.8, 18.88, -15.68, -0.08, -3.24, -1.36, -0.279999999999999, 
8.52, -5.32, 7.2, -12.84, 9.31999999999999, -0.039999999999992, 
-19.28, 13.44, -4.44, -5.72000000000003, -75.84, -82.72, -39.96, 
-60.68, 17.88, 23.08, 11.32, 38.8, 2.56, -6.75999999999999, 26.8, 
36.2, 27.88, 48.32, -0.08, -2.24, 1.64, 2.72, 2.52, -5.32, 0.200000000000003, 
-10.84, -4.68000000000001, -16.04, -15.28, -9.56, -27.44, -32.72, 
-63.84, -32.72, -49.96, -37.68, 38.88, 27.08, 7.31999999999999, 
5.80000000000001, 5.56, 10.24, -13.2, -20.8, 39.88, 36.32, -0.08, 
-3.24, 1.64, -9.28, -3.48, 1.68, -13.8, -2.84, -12.68, -15.04, 
8.72, 16.44, 7.56, 1.27999999999997, -23.84, -4.72000000000003, 
21.04, -22.68, -47.12, -16.92, -29.68, -32.2, -25.44, -40.76, 
-72.2, -50.8, -54.12, -99.68, -0.08, -4.24, 0.640000000000001, 
11.72, 4.52, -10.32, 1.2, 8.16, 15.32, -5.03999999999999, -14.28, 
-12.56, -34.44, -1.72000000000003, -11.84, -56.72, -25.96, -5.68000000000001, 
10.88, -4.91999999999999, 4.31999999999999, -40.2, 46.56, 20.24, 
5.80000000000001, 21.2, -1.12, 38.32, -0.08, -2.24, 2.64, -1.28, 
4.52, -1.32, -3.8, 1.16, 13.32, -0.039999999999992, 3.72, 2.44, 
19.56, 4.27999999999997, -41.84, -21.72, -29.96, 15.32, 39.88, 
-22.92, 28.32, -11.2, 67.56, 23.24, 25.8, -9.80000000000001, 
54.88, 18.32, -0.08, -1.24, 2.64, -1.28, 10.52, -4.32, -7.8, 
2.16, 16.32, -9.03999999999999, -0.280000000000001, 8.44, -47.44, 
-35.72, 51.16, 12.28, 15.04, 27.32, 19.88, 38.08, 50.32, 35.8, 
-16.44, 25.24, -1.19999999999999, 15.2, 25.88, 21.32, -0.08, 
-2.24, 1.64, 0.720000000000001, -0.48, 2.68, 6.2, -5.84, 13.32, 
11.96, -33.28, -32.56, -39.44, -50.72, 42.16, -38.72, -12.96, 
49.32, -4.12, -21.92, -13.68, -11.2, 2.56, 25.24, 16.8, 34.2, 
25.88, 56.32, -0.08, -2.24, -1.36, -6.28, 6.52, -4.32, -13.8, 
-12.84, -26.68, -15.04, -30.28, -0.560000000000002, 2.56, -28.72, 
58.16, 52.28, -51.96, -30.68, -36.12, -1.91999999999999, -56.68, 
-22.2, -26.44, -21.76, -27.2, -12.8, -58.12, -13.68), .Tsp = c(1, 
25.9642857142857, 28), class = ""ts"")
</code></pre>
"
"0.086747239794936","0.0860309002014606","164421","<p>I have a balanced panel data (N= 190, T=5) on income and personal characteristics of the householder.</p>

<p>I would like to estimate the coefficients and variances of a temporary and of a permanent income shock. </p>

<p>I fitted an OLS regression model as follows:
$log(income)=sex+age+age^2+study+ public administration + type of house + country$</p>

<p>I then took the residuals and regressed them on a ARMA (1,1) model. The coefficient of AR(1) should be the permanent part and should be around 1, the MA(1) should be the temporary part. I also found that the AR(1) coefficient is only 0.2 instead of about 1. Moreover, AUTOARIMA fits them with an ARMA(2,2). How can I read the coefficients of the ARMA (2,2) to find out the temporary and permanent shock on the income?</p>

<p>I would like also to find the variance of the income (which is the residuals of the ARMA regression) but is it right even if the model is not correct?</p>
"
"0.153007748945791","0.151744244666721","165004","<p>I'm trying to find the best fit line for this data below but no matter what I try, the fit line seems to never be able to account for the lower values as shown below.</p>

<p>The x-values are just dates from 1/1/2014 to 7/20/2015 (566 values), but I don't know how to give you guys the y-values. I have it in my Environment but I don't know how to give you that without copying and pasting from the Console output.</p>

<p><a href=""http://i.stack.imgur.com/KA2LC.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/KA2LC.png"" alt=""Data with sinusodial fit""></a></p>

<p>This is the code that I'm using to get that fit line:</p>

<pre><code>wb.loglik=function(theta,y,x,null=NA)
{
  a=theta[1]
  b=theta[2]
  c=theta[3]
  d=theta[4]

  if(!is.na(null))
  {
    d=null
  }

  s2=theta[5]
  n=length(y)
  return((-n/2)*log(s2)-1/(2*s2)*sum((y-(a+b*cos(2*pi*((x-c)/d))))^2))
}
result=optim(par=c(mean(wbbcf),sd(wbbcf),1,365.25,var(wbbcf)/2),
fn=wb.loglik,x=Time,y=wbbcf,control=list(fnscale=-1))
theta=result$par
theta
value=result$value
value
</code></pre>

<p>This is the code to get the plot above:</p>

<pre><code>plot(date,wbbcf,xlim=c(as.Date(""2014-01-01""),as.Date(""2015-07-
    20"")),ylim=range(c(-3.2,0)),xlab=""Date (1/1/2014 to
    7/20/2015)"",ylab=""Total Net with Storage (bcf)"",main=""Total Burn with
    Model"")
par(new=T)
curve(-0.9740582-0.7857229*cos(2*pi*(x-5.9582996)/385.1581090),1,566,
    ylim=range(c(-3.2,0)),col=""blue"",xlab="""",ylab="""",xaxt='n',yaxt='n')
</code></pre>

<p>What else can I do to generate a better fit line for this data? Also, if there's a good way to predict future data, I would appreciate help with that as well.</p>

<p>Sorry in advance, if I'm not giving enough information. Please feel free to ask for any information you need and I will promptly edit the post.</p>

<p>EDIT: I have added the work I did with ARIMA below.</p>

<p>I inputted the following code and got the following results:</p>

<pre><code>forecast::auto.arima(wbbcf)
fit.arima = arima(wbbcf,order=c(0,1,2))
pred.arima = predict(fit.arima,n.ahead=500)
plot(wbbcf,xlim=c(1,800),ylim=range(c(-3.2,1)))
lines(pred.arima$pred,col=""red"")
lines(pred.arima$pred+1.96*pred.arima$se,col=""blue"",lty=3)
lines(pred.arima$pred-1.96*pred.arima$se,col=""green"",lty=3)
</code></pre>

<p><a href=""http://i.stack.imgur.com/W8Hqt.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/W8Hqt.png"" alt=""ARIMA predictions""></a></p>

<p>Here's the <code>auto.arima()</code> output:</p>

<pre><code>Series: wbbcf 
ARIMA(0,1,2)                    

Coefficients:
          ma1      ma2
      -0.3023  -0.3188
s.e.   0.0397   0.0396

sigma^2 estimated as 0.05788:  log likelihood=3.02
AIC=-0.04   AICc=0.01   BIC=12.98
</code></pre>

<p>Is something wrong with what I'm doing with ARIMA?</p>
"
"0.0817860820109531","0.0811107105653813","167432","<p>I'm using <code>auto.arima</code> function to analyze my data. And here's what I get:</p>

<pre><code>Series: data 
ARIMA(2,1,2) with drift         

Coefficients:
         ar1      ar2      ma1     ma2   drift
      1.6679  -0.8005  -1.2424  0.3125  0.4225
s.e.  0.1007   0.1107   0.1396  0.1413  0.1895

sigma^2 estimated as 17.34:  log likelihood=-438.37
AIC=888.73   AICc=889.3   BIC=906.99
</code></pre>

<p>I'm trying to perform a heteroscedastic test to my residual model using bptest from <code>lmtest</code> package with this code:</p>

<pre><code>&gt; bp&lt;-bptest(lm(residuals(model)~1))
&gt; bp

    studentized Breusch-Pagan test

data:  lm(residuals(model) ~ 1)
BP = 1.231e-30, df = 0, p-value &lt; 2.2e-16
</code></pre>

<p>Am I doing <code>bptest</code> right? When I analyze another data with this code I always get the same <code>df</code> and <code>p-value</code>. </p>

<p><strong>edit:</strong>
here is the data :</p>

<pre><code>    World_Oil_Prices
[1-10] [11-20] [21-30] [31-40] [41-50] [51-60] [61-70] [71-80] [81-90] [91-100] [101-110] [111-120] [121-130] [131-140] [141-150] [151-156]
17.79   22.25   18.73   12.72   16.12   27.49   25.95   18.69   28.28   28.59   37.63   48.75   59.67   53.53   75.91   131.22
17.69   23.51   20.12   12.49   16.24   23.45   27.24   18.52   27.53   29.68   35.54   46.00   54.17   57.22   81.27   121.87
19.46   23.29   19.16   13.80   18.75   27.23   25.02   19.15   24.79   26.88   37.93   43.67   56.63   50.14   90.54   96.85
20.78   20.54   17.24   13.26   20.21   29.62   25.66   19.98   27.89   29.01   42.08   52.55   66.85   54.46   89.76   69.16
19.12   19.42   15.07   11.88   22.37   28.16   27.55   23.64   30.77   29.12   41.65   52.24   63.49   57.78   85.53   46.03
18.56   17.98   14.18   10.41   22.19   29.41   26.97   25.43   32.88   29.95   46.87   58.74   62.26   63.25   93.51   38.60
19.56   19.47   13.24   11.32   24.22   32.08   24.80   25.69   30.36   31.40   42.23   58.20   68.08   66.75   99.32   
20.19   18.02   13.39   10.75   25.01   31.40   25.81   24.49   25.49   31.32   39.09   53.32   66.45   68.29   111.03  
22.14   18.45   13.97   12.86   25.21   32.33   25.03   25.75   26.06   33.67   42.76   49.41   56.38   73.69   123.35  
23.43   18.79   12.48   15.73   27.15   25.28   20.73   26.78   27.91   33.71   44.35   51.66   53.58   67.10   128.33  
</code></pre>

<p>And this is the R code:</p>

<pre><code>library(forecast)
model&lt;-auto.arima(data)
model
library(lmtest)
bp&lt;-bptest(lm(residuals(model)~1))
bp
</code></pre>
"
"0.23881418014561","0.25","168655","<p>I have got monthly data from 1993 to 2015 and would like to do forecasting on these data. I used tsoutliers package to detect the outliers, but I do not know how do I continue to forecast with my set of data .</p>

<p>This is my code:</p>

<pre><code>product.outlier&lt;-tso(product,types=c(""AO"",""LS"",""TC""))
plot(product.outlier)
</code></pre>

<p>This is my output from tsoutliers package</p>

<pre><code>ARIMA(0,1,0)(0,0,1)[12]                    

Coefficients:
        sma1    LS46    LS51    LS61    TC133   LS181   AO183   AO184   LS185   TC186    TC193    TC200
      0.1700  0.4316  0.6166  0.5793  -0.5127  0.5422  0.5138  0.9264  3.0762  0.5688  -0.4775  -0.4386
s.e.  0.0768  0.1109  0.1105  0.1106   0.1021  0.1120  0.1119  0.1567  0.1918  0.1037   0.1033   0.1040
       LS207    AO237    TC248    AO260    AO266
      0.4228  -0.3815  -0.4082  -0.4830  -0.5183
s.e.  0.1129   0.0782   0.1030   0.0801   0.0805

sigma^2 estimated as 0.01258:  log likelihood=205.91
AIC=-375.83   AICc=-373.08   BIC=-311.19

 Outliers:
    type ind    time coefhat  tstat
1    LS  46 1996:10  0.4316  3.891
2    LS  51 1997:03  0.6166  5.579
3    LS  61 1998:01  0.5793  5.236
4    TC 133 2004:01 -0.5127 -5.019
5    LS 181 2008:01  0.5422  4.841 
6    AO 183 2008:03  0.5138  4.592
7    AO 184 2008:04  0.9264  5.911
8    LS 185 2008:05  3.0762 16.038
9    TC 186 2008:06  0.5688  5.483
10   TC 193 2009:01 -0.4775 -4.624
11   TC 200 2009:08 -0.4386 -4.217
12   LS 207 2010:03  0.4228  3.746
13   AO 237 2012:09 -0.3815 -4.877
14   TC 248 2013:08 -0.4082 -3.965
15   AO 260 2014:08 -0.4830 -6.027
16   AO 266 2015:02 -0.5183 -6.442
</code></pre>

<p><a href=""http://i.stack.imgur.com/qKI4N.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/qKI4N.jpg"" alt=""This is my plot""></a></p>

<p>I have these warning messages as well.</p>

<pre><code>Warning messages:
1: In locate.outliers.iloop(resid = resid, pars = pars, cval = cval,  :
  stopped when â€˜maxitâ€™ was reached
2: In locate.outliers.iloop(resid = resid, pars = pars, cval = cval,  :
  stopped when â€˜maxitâ€™ was reached
3: In locate.outliers.oloop(y = y, fit = fit, types = types, cval = cval,  :
  stopped when â€˜maxitâ€™ was reached
4: In arima(x, order = c(1, d, 0), xreg = xreg) :
  possible convergence problem: optim gave code = 1
5: In auto.arima(x = c(5.77, 5.79, 5.79, 5.79, 5.79, 5.79, 5.78, 5.78,  :
  Unable to fit final model using maximum likelihood. AIC value approximated
</code></pre>

<p><strong>Doubts:</strong></p>

<ol>
<li>If I am not wrong, tsoutliers package will remove the outliers it detect and through the use of the dataset with outliers removed, it
will give us the best arima model suited for the data set, is it
correct?</li>
<li>The adjust series data set is being shifted down by a lot due to remove of the level shift,etc. Doesn't this mean that if the forecasting is done on the adjusted series, the output of the forecast will be very inaccurate, since the more recent data are already more than 12, while adjusted data shift it to around 7-8.</li>
<li>What does warning message 4 and 5 means? Does it mean it cannot do auto.arima using the adjusted series?</li>
<li>What does the [12] in ARIMA(0,1,0)(0,0,1)[12] mean? Is it just my frequency/periodicity of my dataset, which I set it to monthly? And does this also means that my data series is seasonal as well? </li>
<li>How do I detect seasonality in my data set? As from the visualisation of the time series plot, I cant see any obvious trend, and if I use the decompose function, it will assume that there is a seasonal trend? So do I just believe what the tsoutliers tell me, where there is seasonal trend, since there is MA of order 1?</li>
<li>How do I continue to do my forecasting with this data after identifying these outliers?</li>
<li><strong>How to incorporate these outliers to other forecasting models - Exponential Smoothing, ARIMA, Strutural Model, Random Walk, theta? I am sure I cannot remove the outliers since there are level shift, and if I only take adjusted series data, the values will be too small, so what do I do?</strong></li>
</ol>

<p><strong>Do I need to add these outliers as regressor in the auto.arima for forecasting? How does this work then?</strong></p>
"
"0.214537729387595","0.262828741518923","169468","<p>I have monthly time series data, and would like to do forecasting with detection of outliers .</p>

<p><strong>This is the sample of my data set:</strong></p>

<pre><code>       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec
2006  7.55  7.63  7.62  7.50  7.47  7.53  7.55  7.47  7.65  7.72  7.78  7.81
2007  7.71  7.67  7.85  7.82  7.91  7.91  8.00  7.82  7.90  7.93  7.99  7.93
2008  8.46  8.48  9.03  9.43 11.58 12.19 12.23 11.98 12.26 12.31 12.13 11.99
2009 11.51 11.75 11.87 11.91 11.87 11.69 11.66 11.23 11.37 11.71 11.88 11.93
2010 11.99 11.84 12.33 12.55 12.58 12.67 12.57 12.35 12.30 12.67 12.71 12.63
2011 12.60 12.41 12.68 12.48 12.50 12.30 12.39 12.16 12.38 12.36 12.52 12.63
</code></pre>

<p>I have referred to <a href=""http://stats.stackexchange.com/questions/140163/timeseries-analysis-procedure-and-methods-using-r?lq=1"">Timeseries analysis procedure and methods using R</a>, to do a series of different model of forecasting, however it does not seems to be accurate. In additional, I am not sure how to incorporate the tsoutliers into it as well.</p>

<p>I have got another post regarding my enquiry of tsoutliers and arima modelling and procedure over <a href=""http://stats.stackexchange.com/questions/168655/how-to-interpret-and-do-forecasting-using-tsoutliers-package-and-auto-arima/168869#168869"">here</a> as well.</p>

<p>So these are my code currently, which is similar to link no.1.</p>

<p><strong>Code:</strong></p>

<pre><code>product&lt;-ts(product, start=c(1993,1),frequency=12)

#Modelling product Retail Price

#Training set
product.mod&lt;-window(product,end=c(2012,12))
#Test set
product.test&lt;-window(product,start=c(2013,1))
#Range of time of test set
period&lt;-(end(product.test)[1]-start(product.test)[1])*12 + #No of month * no. of yr
(end(product.test)[2]-start(product.test)[2]+1) #No of months
#Model using different method
#arima, expo smooth, theta, random walk, structural time series
models&lt;-list(
#arima
product.arima&lt;-forecast(auto.arima(product.mod),h=period),
#exp smoothing
product.ets&lt;-forecast(ets(product.mod),h=period),
#theta
product.tht&lt;-thetaf(product.mod,h=period),
#random walk
product.rwf&lt;-rwf(product.mod,h=period),
#Structts
product.struc&lt;-forecast(StructTS(product.mod),h=period)
)

##Compare the training set forecast with test set
par(mfrow=c(2, 3))
for (f in models){
    plot(f)
    lines(product.test,col='red')
}

##To see its accuracy on its Test set, 
#as training set would be ""accurate"" in the first place
acc.test&lt;-lapply(models, function(f){
    accuracy(f, product.test)[2,]
})
acc.test &lt;- Reduce(rbind, acc.test)
row.names(acc.test)&lt;-c(""arima"",""expsmooth"",""theta"",""randomwalk"",""struc"")
acc.test &lt;- acc.test[order(acc.test[,'MASE']),]

##Look at training set to see if there are overfitting of the forecasting
##on training set
acc.train&lt;-lapply(models, function(f){
    accuracy(f, product.test)[1,]
})
acc.train &lt;- Reduce(rbind, acc.train)
row.names(acc.train)&lt;-c(""arima"",""expsmooth"",""theta"",""randomwalk"",""struc"")
acc.train &lt;- acc.train[order(acc.train[,'MASE']),]

 ##Note that we look at MAE, MAPE or MASE value. The lower the better the fit.
</code></pre>

<p>This is the plot of my different forecasting, which doesn't seem very reliable/accurate, through the comparison of the red""test set"", and blue""forecasted"" set.
<strong>Plot of different forecast</strong>
<a href=""http://i.stack.imgur.com/WZSNq.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/WZSNq.jpg"" alt=""Different forecast""></a></p>

<p><strong>Different accuracy of the respective models of test and training set</strong></p>

<pre><code>Test set
                    ME      RMSE       MAE        MPE     MAPE      MASE      ACF1 Theil's U
theta      -0.07408833 0.2277015 0.1881167 -0.6037191 1.460549 0.2944165 0.1956893 0.8322151
expsmooth  -0.12237967 0.2681452 0.2268248 -0.9823104 1.765287 0.3549976 0.3432275 0.9847223
randomwalk  0.11965517 0.2916008 0.2362069  0.8823040 1.807434 0.3696813 0.4529428 1.0626775
arima      -0.32556886 0.3943527 0.3255689 -2.5326397 2.532640 0.5095394 0.2076844 1.4452932
struc      -0.39735804 0.4573140 0.3973580 -3.0794740 3.079474 0.6218948 0.3841505 1.6767075

Training set
                     ME      RMSE       MAE         MPE     MAPE      MASE    ACF1 Theil's U
theta      2.934494e-02 0.2101747 0.1046614  0.30793753 1.143115 0.1638029  0.2191889194        NA
randomwalk 2.953975e-02 0.2106058 0.1050209  0.31049479 1.146559 0.1643655  0.2190857676        NA
expsmooth  1.277048e-02 0.2037005 0.1078265  0.14375355 1.176651 0.1687565 -0.0007393747        NA
arima      4.001011e-05 0.2006623 0.1079862 -0.03405395 1.192417 0.1690063 -0.0091275716        NA
struc      5.011615e-03 1.0068396 0.5520857  0.18206018 5.989414 0.8640550  0.1499843508        NA
</code></pre>

<p>From the models accuracy, we can see that the most accurate model would be theta model.
I am not sure why is the forecast very inaccurate, and I think that one of the reasons would be that, I did not treat the ""outliers"" in my data set, resulting in a bad forecast for all model.</p>

<p><strong>This is my outliers plot</strong></p>

<p><strong>Outliers Plot</strong>
<a href=""http://i.stack.imgur.com/bZDQv.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/bZDQv.jpg"" alt=""Outliers""></a></p>

<p><strong>tsoutliers output</strong></p>

<pre><code>ARIMA(0,1,0)(0,0,1)[12]                    

Coefficients:
        sma1    LS46    LS51    LS61    TC133   LS181   AO183   AO184   LS185   TC186    TC193    TC200
      0.1700  0.4316  0.6166  0.5793  -0.5127  0.5422  0.5138  0.9264  3.0762  0.5688  -0.4775  -0.4386
s.e.  0.0768  0.1109  0.1105  0.1106   0.1021  0.1120  0.1119  0.1567  0.1918  0.1037   0.1033   0.1040
       LS207    AO237    TC248    AO260    AO266
      0.4228  -0.3815  -0.4082  -0.4830  -0.5183
s.e.  0.1129   0.0782   0.1030   0.0801   0.0805

sigma^2 estimated as 0.01258:  log likelihood=205.91
AIC=-375.83   AICc=-373.08   BIC=-311.19

 Outliers:
    type ind    time coefhat  tstat
1    LS  46 1996:10  0.4316  3.891
2    LS  51 1997:03  0.6166  5.579
3    LS  61 1998:01  0.5793  5.236
4    TC 133 2004:01 -0.5127 -5.019
5    LS 181 2008:01  0.5422  4.841 
6    AO 183 2008:03  0.5138  4.592
7    AO 184 2008:04  0.9264  5.911
8    LS 185 2008:05  3.0762 16.038
9    TC 186 2008:06  0.5688  5.483
10   TC 193 2009:01 -0.4775 -4.624
11   TC 200 2009:08 -0.4386 -4.217
12   LS 207 2010:03  0.4228  3.746
13   AO 237 2012:09 -0.3815 -4.877
14   TC 248 2013:08 -0.4082 -3.965
15   AO 260 2014:08 -0.4830 -6.027
16   AO 266 2015:02 -0.5183 -6.442
</code></pre>

<p>I would like to know how can I further ""analyse""/forecast my data, with these relevant data set and detection of outliers, etc.
Please do help me in treatment of my outliers as well to do my forecasting as well . </p>

<p>Lastly, I would like to know how to combined the different model forecasting together, as from what @forecaster had mentioned in link no.1, combining the different model will most likely result in a better forecasting/prediction.</p>

<p><strong>EDITED</strong></p>

<p>I would like to incorporate the outliers in other models are well.</p>

<p>I have tried some codes, eg. </p>

<pre><code>forecast.ets( res$fit ,h=period,xreg=newxreg)
    Error in if (object$components[1] == ""A"" &amp; is.element(object$components[2], : argument is of length zero

forecast.StructTS(res$fit,h=period,xreg=newxreg)
Error in predict.Arima(object, n.ahead = h) : 'xreg' and 'newxreg' have different numbers of columns
</code></pre>

<p>There are some errors produced, and I am unsure about the correct code to incorporate the outliers as regressors.
Furthermore, how do I work with thetaf or rwf, as there are no forecast.theta or forecast.rwf?</p>
"
"0.103452120022374","0.102597835208515","169564","<p>The <code>arimax</code> function in the <code>TSA</code> package is to my knowledge the only <code>R</code> package that will fit a transfer function for intervention models. It lacks a <a href=""http://stats.stackexchange.com/questions/34106/forecasting-with-arimax-model-including-xtransf"">predict function</a> though which is sometimes needed.</p>

<p>Is the following a work-around for this issue, leveraging the excellent <code>forecast</code> package? Will the predictive intervals be correct? In my example, the std errors are ""close"" for the components.</p>

<ol>
<li>Use the forecast package arima function to determine the pre-intervention noise series and add any outlier adjustment.</li>
<li>Fit the same model in <code>arimax</code> but add the transfer function</li>
<li>Take the fitted values for the transfer function (coefficients from <code>arimax</code>) and add them as xreg in <code>arima</code>. </li>
<li>Forecast with <code>arima</code></li>
</ol>

<blockquote>
<pre><code>library(TSA)
library(forecast)
data(airmiles)
air.m1&lt;-arimax(log(airmiles),order=c(0,0,1),
              xtransf=data.frame(I911=1*(seq(airmiles)==69)),
              transfer=list(c(1,0))
              )
</code></pre>
  
  <p>air.m1</p>
</blockquote>

<p>Output:</p>

<pre><code>Coefficients:
  ma1  intercept  I911-AR1  I911-MA0
0.5197    17.5172    0.5521   -0.4937
s.e.  0.0798     0.0165    0.2273    0.1103

sigma^2 estimated as 0.01223:  log likelihood=88.33
AIC=-168.65   AICc=-168.09   BIC=-155.02
</code></pre>

<p>This is the filter, extended out 5 more periods that the data</p>

<pre><code>tf&lt;-filter(1*(seq(1:(length(airmiles)+5))==69),filter=0.5521330,method='recursive',side=1)*(-0.4936508)
forecast.arima&lt;-Arima(log(airmiles),order=c(0,0,1),xreg=tf[1:(length(tf)-5)])
forecast.arima
</code></pre>

<p>Output:</p>

<pre><code>Coefficients:
         ma1  intercept  tf[1:(length(tf) - 5)]
      0.5197    17.5173                  1.0000
s.e.  0.0792     0.0159                  0.2183

sigma^2 estimated as 0.01223:  log likelihood=88.33
AIC=-168.65   AICc=-168.28   BIC=-157.74
</code></pre>

<p>Then to Predict</p>

<pre><code>predict(forecast.arima,n.ahead = 5, newxreg=tf[114:length(tf)])
</code></pre>
"
"0.232767270050342","0.243669858620224","172226","<p>Let's assume an analytical model predicts an epidemic trend over time, i.e. number of infections over time. We also have a computer simulation results over time to verify the performance of the model. The goal is to prove the simulation results and predicted values of the analytical model (which are both a time series) are statistically close or similar. By similarity I mean the model predicts the values close to what simulation is providing.</p>

<p><strong>Background</strong>:
Researching around this topic, I came across the following posts:</p>

<ol>
<li><p><a href=""http://stackoverflow.com/questions/13835924/similarity-of-trends-in-time-series-analysis"">http://stackoverflow.com/questions/13835924/similarity-of-trends-in-time-series-analysis</a></p></li>
<li><p><a href=""http://stats.stackexchange.com/questions/19103/how-to-statistically-compare-two-time-series"">How to statistically compare two time series?</a></p></li>
</ol>

<p>Both discussions suggest three approaches, where I am interested in two of them basically:</p>

<p>(1). Use of ARIMA; 
 (2). Use of Granger test</p>

<p>For the first suggested solution, this is what has been written there in regards to ARIMA, in (1):</p>

<blockquote>
  <p>Run ARIMA on both data sets. (The basic idea here is to see if the same set of parameters (which make up the ARIMA model) can describe both your temp time series. If you run auto.arima() in forecast (R), then it will select the parameters p,d,q for your data, a great convenience.</p>
</blockquote>

<p>I ran auto.arima on the simulation values and then ran forecast, here are the results:</p>

<pre><code>ARIMA(2,0,0) with zero mean     

Coefficients:
         ar1      ar2
      1.4848  -0.5619
s.e.  0.1876   0.1873

sigma^2 estimated as 121434:  log likelihood=-110.64
AIC=227.27   AICc=229.46   BIC=229.4
</code></pre>

<p>I ran auto.arima on predicted model values and then forecast. This is the result of the predicted model:</p>

<pre><code>ARIMA(2,0,0) with non-zero mean 

Coefficients:
         ar1      ar2  intercept
      1.5170  -0.7996  1478.8843
s.e.  0.1329   0.1412   290.4144

sigma^2 estimated as 85627:  log likelihood=-108.11
AIC=224.21   AICc=228.21   BIC=227.05
</code></pre>

<p><strong>Question 1</strong> What are the values that need to be compared to prove that the two series are similar especially the trend over time?</p>

<p>Regarding the second suggested option, I have read about it and found that Granger test is usually used to see if the values of series <em>A</em> at time <em>t</em> can predict the values of Series <em>B</em> at time <em>t+1</em>. </p>

<p><strong>Question 2</strong> Basically, in my case I want to compare the values of time series A and B at the same time, how this one is relevant to my case then?</p>

<p><strong>Question 3</strong> Is there any available method can be used to prove that the trend of two time-series over time is similar?</p>

<p>FYI. I saw another method which is using Pearson Correlation Coefficient and I could follow the reasoning there. Moreover, verifying analytical models with simulations has been widely used in the literature. see:</p>

<ol>
<li><a href=""http://users.ece.gatech.edu/~jic/tnn05.pdf"" rel=""nofollow"">Spatial-Temporal Modeling of Malware Propagation in Networks Modeling</a></li>
<li><a href=""http://cs.ucf.edu/~czou/research/emailWorm-TDSC.pdf"" rel=""nofollow"">Modeling and Simulation Study of the Propagation and Defense of Internet Email Worm</a></li>
</ol>
"
"0.129315150027968","0.128247294010644","175833","<p>I am a forecasting professional and have recently started using R.</p>

<p>I'm currently trying to forecast this using this code:</p>

<pre><code>library(forecast)
library(tseries)
p=scan()
#scans 54 variables
p.ts=ts(p, frequency=12, start=c(2011, 01))
p.ts

       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec
2011 102.0 102.2 102.8 103.2 103.3 103.5 103.6 104.0 104.2 103.9 104.2 104.1
2012 104.5 104.8 104.9 105.3 105.5 105.5 105.4 105.1 105.6 105.8 106.3 106.4
2013 106.4 106.4 106.6 106.8 106.4 107.0 107.5 107.4 107.6 107.9 107.9 107.7
2014 107.8 108.1 108.2 108.9 108.7 109.0 109.1 109.4 109.1 109.9 109.8 109.9
2015 109.8 109.5 109.6 109.5 109.5 109.7 110.2 110.6

plot(p.ts)
</code></pre>

<p><a href=""http://i.stack.imgur.com/rIbtu.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/rIbtu.png"" alt=""Looks like it isn&#39;t a stationary process""></a></p>

<pre><code>plot(diff(p.ts))
</code></pre>

<p><a href=""http://i.stack.imgur.com/2Tv0R.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/2Tv0R.png"" alt=""looks like stationary but with high variability""></a></p>

<p>Then I had a look at the ACF and PACF plots
<img src=""http://i.stack.imgur.com/35gUK.jpg"" alt=""enter image description here""></p>

<p>It looks like a MA(1) process too. But not an AR process at all. </p>

<p>Hence, I chose to model it as ARIMA(0,1,1) process</p>

<pre><code>a=arima(p.ts, order=c(0,1,1))
summary(a)

Call:
arima(x = p.ts, order = c(0, 1, 1))

Coefficients:
         ma1
      0.0757
s.e.  0.1119

sigma^2 estimated as 0.09556:  log likelihood = -13.47,  aic = 30.95

Training set error measures:
                    ME      RMSE       MAE     MPE      MAPE      MASE
Training set 0.1450371 0.3066561 0.2472274 0.13619 0.2314932 0.9853266
                   ACF1
Training set -0.2479716
</code></pre>

<p>Then forecasted the numbers.</p>

<pre><code>f=forecast(a)

plot(f)
</code></pre>

<p><img src=""http://i.stack.imgur.com/Km94S.jpg"" alt=""The forecast is just not true.""></p>

<p>Can you help me understand where I went wrong? And how can I correct this?</p>

<p>This is one of five cases that I forecast. In such a case I generally model it with HoltWinters and get a decent response (one that comes very close to the realized values too).</p>
"
"0.118048041162471","0.140487871737254","175996","<p>I have been studying a few simple statistical models for (univariate) time series. From my understanding,</p>

<ul>
<li><p>ARIMA and its siblings are used to model the <em>mean</em> of a time series. Rather than a static measure like <code>mean()</code>, the result is a series estimating the mean.</p></li>
<li><p>ARCH and its brothers are used to model the <em>volatility</em> of a time series. Rather than the usual <code>sd()</code>, the result is a series estimating the variance. </p></li>
</ul>

<h2>Question</h2>

<p>What would be a credible model for the correlation of two time series?</p>

<h2>Notes</h2>

<p>While mean models explore the idea of regressing lagged values of the time series, volatility models (eg. ARCH model) explore the idea of regressing lagged residuals where residuals are the difference of a mean model to its original time series.</p>

<p>In its general sense and for a variety of reasons, ARIMA and ARCH are <em>superior</em> models than rolling windows with <code>mean()</code> (popularly known as moving averages outside statistics world) and <code>sd()</code>.</p>

<p>However, there is no such a thing for the <em>correlation</em> of two time series X and Y to my knowledge.</p>

<p>The closest thing would be rolling a sad, straight window with <code>cor()</code>, Pearson's coefficient function in R, and work around the resulting series.</p>

<h2>A poor solution</h2>

<p>Trying to replicate Pearson's correlation model,</p>

<pre><code>p_(X,Y) = cov(X,Y) / (sd(X) sd(Y))
        = E((X-mean(X))(Y-mean(Y))) / (sd(X) sd(Y)),
</code></pre>

<p>to the time series world, I had the above without the intended success.</p>

<pre><code>library('forecast')
library('fGarch')

X &lt;- 1:200 + rnorm(200, sd=10)
Y &lt;- 50 + (1:200)/100 + rnorm(200, sd=5)

plot(1:200, X, t='l', main=""What would be a resulting ts correlation of X and Y?"")
lines(1:200, Y, t='l', col='blue')

# Mimic Pearson correlation, cov(X,Y)/(sd(X)*sd(Y)).
Xm &lt;- as.vector(X) - as.vector(fitted(Arima(X, order=c(2,0,1))))
Ym &lt;- as.vector(Y) - as.vector(fitted(Arima(Y, order=c(2,0,1))))

Xv &lt;- garchFit(formula=~arma(2,1) + garch(2,1), data=X)@sigma.t
Yv &lt;- garchFit(formula=~arma(2,1) + garch(2,1), data=Y)@sigma.t

correlation &lt;- Xm * Ym / (Xv * Yv)    # this can be forecast

plot(correlation, t='l', col='blue', ylim=c(-2, 2), main='Correlation models')
abline(h=c(-1, 1))
abline(h=cor(X, Y), col='red', lwd=5)

# Correlation rolling window of size 10.
df &lt;- data.frame(X, Y)
crw &lt;- rep(NA, 10)
for (i in 11:nrow(df))
  crw &lt;- c(crw, cor(df[(i-10):i, 1], df[(i-10):i, 2]))

lines(crw, col='darkgreen', lwd=5)

legend('topright',
  c('pearson mimic', 'static cor()', 'rolling cor() like moving averages'),
  col=c('blue', 'red', 'darkgreen'), lwd=c(1, 5, 5))
</code></pre>
"
"0.115662986393248","0.0860309002014606","176477","<p>The code given below estimates a VEC model with 4 cointegrating vectors. It is a reproducible code, so just copy and paste into your R console (or script editor).</p>

<pre><code>nobs = 200
e = rmvnorm(n=nobs,sigma=diag(c(.5,.5,.5,.5,.5)))
e1.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,1])
e2.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,2])
e3.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,3])
e4.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,4])
y5 = cumsum(e[,5])
y1 = y5 + e1.ar1
y2 = y5 + e2.ar1
y3 = y5 + e3.ar1
y4 = y5 + e4.ar1
data = cbind(y1,y2,y3,y4,y5)

jcointt = ca.jo(data,ecdet=""const"",type=""trace"",K=2,spec=""transitory"")
summary(jcointt)

vecm &lt;- cajorls(jcointt,r=4)
summary(vecm$rlm)
print(vecm)
</code></pre>

<p>I want to re-estimate the model with the following restrictions put on the coinegrating vectors: </p>

<pre><code>            ect1   ect2  ect3   ect4
y1.l1        1      0      0     0
y2.l1      b1.1     1      0     0
y3.l1      b2.1     0      1     0
y4.l1      b3.1     0      0     1
y5.l1      b4.1    b4.2   b4.3   b4.4
constant    c1      c2     c3    c4
</code></pre>

<p>here, b1.1 through to b4.1 are the coefficients ($\beta_1, \beta_2, \beta_3, \beta_4 $) of the first cointegrating vector. Similarly, b4.4 and c4 are coefficients of the fourth cointegrating equation. Then, in order to test the restrictions on Coinegrating Vectors, I run the following code:</p>

<pre><code>test &lt;- blrtest(jcointt,H=H1,r=4)
</code></pre>

<p>However, I do not know how I should specify the <code>H1</code> matrix in this instance. I was wondering if someone could demonstrate how I should go ahead with testing the restrictions on long run equations and then re-estimate the model using the above restrictions:</p>

<pre><code>vecm2 &lt;- cajorls(test,r=4)
summary(vecm2$rlm)
print(vecm2)
</code></pre>
"
"0.100167084494127","0.0993399267798783","178014","<p>As the title states, I want to generate a time series that follows an AR(1) proces and thus has a certain overall level of autocorrelation.</p>

<p>I'm using the <code>arima.sim</code> function (which is implemented as standard in R).</p>

<p>I thought that for example the following command:</p>

<pre><code>arima.sim(model=list(Ar=-0.5),n=400)
</code></pre>

<p>would generate a time series of length 400 and an autocorrelation of -0.5.
However, I've noticed that the values you can give to the <code>Ar</code> parameter are not limited to [-1; 1]. For example, you could input <code>10 000</code>.</p>

<p>Can anyone explain to me what the <code>Ar</code> parameter actually represents? Because it apparently is not a correlation coefficient...</p>

<p>After reading on the internet it seems to me that there's not a lot of information there for people who want to simulate time series data using a model as opposed to people who want to fit data to a model...</p>
"
"0.100167084494127","0.0993399267798783","180217","<p>I'm using time series data containing both trend and seasonality. I also have 2 endogenous predictor variables that I would like to include in my model.</p>

<p>In R I've used the forecast package to develop a dynamic regression model with use of <code>auto.arima()</code> and the <code>xreg</code> argument from the <code>forecast package</code>. I understand this procedure takes a regression and then attempts to fit the residuals with an ARMA Model.</p>

<p>I've also developed what seems to be an appropriate model using the forecasting Module in SPSS by specifying a Seasonal ARIMA model and including my covariates. However, one of the coefficients on one of my endogeneous predictors has a negative sign which makes no sense intuitively. </p>

<p>I've read Dr. Hyndman's article <a href=""http://robjhyndman.com/hyndsight/arimax/"" rel=""nofollow"">The ARIMAX model muddle</a> and found it to be extremely insightful and useful. However, I have not been able to find any documentation on what type of statistical procedure SPSS uses to fit an ARIMA model with covariates, so I'm not sure how I should interpret the coefficients or how concerned I should be with a flipped sign. Any help clarifying the modelling procedure used by SPSS would be tremendously appreciated. </p>
"
"0.218096218695875","0.229813679935247","180246","<p>I have two questions related to transfer functions.  The first is a general question regarding how to compute values of $Y_t$ from a rational transfer polynomial function of the form popularized by Box and Jenkins.  The second is related to the arimax() function in the TSA package in R. 
It is my understanding that the rational transfer function can be expressed as (ignoring any noise terms):</p>

<p>$Y_t = \frac{\omega(B)^sB^d}{\delta(B)^r}X_t$</p>

<p>Lets first make it easy and assume r = 1, s = 0 and d = 0.  Then the equation should simplify to:</p>

<p>$Y_t = \frac{\omega_0}{(1-\delta_1B^1)}X_t$ (equation 1)</p>

<p>My first intuition would be to multiply both sides by ${(1-\delta_1 B^1)}$ then re-arrange to solve for $Y_t$:</p>

<p>$Y_t = \omega_oX_t+\delta_1 Y_{t-1}$ (equation 2)</p>

<p>However, I've seen <a href=""https://support.sas.com/documentation/cdl/en/etsug/60372/HTML/default/viewer.htm#etsug_arima_sect014.htm"" rel=""nofollow"">here</a> and <a href=""http://www.stat.pitt.edu/stoffer/tsa3/tsa3.pdf"" rel=""nofollow"">here</a> (pg. 286) that you can express the transfer function as so:</p>

<p>$Y_t = \frac{\omega_0}{(1-\delta_1B^1)}X_t = \omega_o(1+\delta_1 B^1)X_t$ </p>

<p>This would yield a different equation for $Y_t$:</p>

<p>$Y_t = \omega_oX_t+\delta_1\omega_o X_{t-1}$ (equation 3)</p>

<p>So is equation 2 the correct way to calculate $Y_t$ or is it equation 3? If $d \neq 0$, say r = 0, s = 1 and d = 1, could you re-write the equation 1 as:</p>

<p>$Y_t = \frac{\omega_0}{(1-\delta_1B^1)}X_{t-1}$</p>

<p>and then solve for $Y_t$ by one of the equations above?</p>

<p>Finally, for a related R question.  Assuming one of the two ways above is correct for solving for $Y_t$, I would like to check the fitted values that are calculated using the arimax() function in the TSA package.  I will use the Box and Jenkins sales and lead data, and use their transfer function.  The arimax() function is taken from <a href=""https://stackoverflow.com/questions/25224155/transfer-function-models-arimax-in-tsa"">this post</a> and gives correct coefficients:</p>

<pre><code> &gt;library(astsa)
 &gt;library(TSA)

 &gt;d.lead &lt;- diff(BJsales.lead) #first difference
 &gt;d.sale &lt;- diff(BJsales) #first difference
 &gt;center.d.lead &lt;- d.lead - mean(d.lead) # mean centered, first difference
 &gt;center.d.sale &lt;- d.sale - mean(d.sale) # mean centered, first difference

 &gt;mod &lt;- arimax(center.d.sale,
               order=c(0,0,1),
               include.mean=TRUE,
               fixed=c(NA,NA,NA,0,0,0,NA),
               xtransf=center.d.lead,
               transfer=list(c(1,3)),
               method=""ML"")

 &gt;mod
 Coefficients:
           ma1  intercept  T1-AR1  T1-MA0  T1-MA1  T1-MA2  T1-MA3
       -0.4500    -0.0055  0.7253       0       0       0  4.7008
 s.e.   0.0772     0.0107  0.0048       0       0       0  0.0613

&gt;fitted(mod)[1:5]
[1]         NA         NA         NA  0.1264714  1.3631528
</code></pre>

<p>Now, I would like to calculate by hand the fitted values of mod.  Assuming equation 1 above is correct $Y_t$ (center.d.sale) equals (again ignoring noise):</p>

<p>$Y_t = \omega_3X_{t-3}+\delta_1 Y_{t-1}$</p>

<p>If $\omega_3 = 4.7008$ and $\delta_1 = 0.7253$ then the first calculated value ($Y_4$) should be:</p>

<pre><code> &gt;4.7008*center.d.lead[1] + 0.7253*center.d.sale[3]
 -0.4922764
</code></pre>

<p>This is clearly not the same as the fitted value:</p>

<pre><code> &gt;fitted(mod)[4]
 0.1264714
</code></pre>

<p>Even including the intercept, the values aren't the same. Do you know how arimax() calculates the fitted values, or if my equation is wrong, the proper way to calculate the fitted values from the transfer function coefficients?</p>
"
"0.115662986393248","0.114707866935281","184425","<p>I've sampled 100 variables from a Gauss distribution with mean 0 and standard deviation 1.</p>

<pre><code>&gt; set.seed(1)
&gt; wn=rnorm(100)
</code></pre>

<p>Then I've fitted an AR(1) model with the arima command and sent the results to the wnF variable</p>

<pre><code>&gt; wnF=arima(wn, order=c(1,0,0))
</code></pre>

<p>Finally I've requested the estimated coefficients</p>

<pre><code>&gt; wnF$coef
         ar1    intercept 
-0.003655755  0.108935363 
</code></pre>

<p>Now I want to replicate the computation R. I exported the data to an Excel file (<a href=""https://www.dropbox.com/s/6c8ukcbtxe9gqp1/DataTester.xlsx?dl=0"" rel=""nofollow"">https://www.dropbox.com/s/6c8ukcbtxe9gqp1/DataTester.xlsx?dl=0</a>) and computed the following model:</p>

<p>$$
x{_t}-\mu = \psi_1x_{t-1}+\omega_t
$$</p>

<p>I've replaced $\mu$ and $\psi_1$ with the <strong>intercept</strong> and <strong>ar1</strong> coefficients reported by the <code>wnF$coef</code> command. I've also replaced $\omega_t$ with zero, since I've sampled the data from a zero-mean population.</p>

<p>Finally I've compared the residuals from the R computed model (<code>wnF$residuals</code>) with the residuals I've computed in the Excel file and I've noticed that they differ about $\delta&lt;0.0005$ in absolute value.</p>

<p>I know that 0.0005 is not much, but when dealing with such small values it may not be negligible.</p>

<p>I also find strange that there is no difference up the fourth decimal place.</p>

<p>Can you please help me finding the origin of the difference?</p>
"
"0.191805363999193","0.190221477563171","186725","<p>Short version: How would one be able to quantify an intervention effect in time-series analysis when the intervention decreases seasonal amplitude variation but doesn't directly effect the median?</p>

<p><a href=""https://www.dropbox.com/s/hb3g7j17igeqnoc/dat.csv?dl=0"" rel=""nofollow"">Here</a> is a link to my raw data.</p>

<p>I have a complex time-series of daily incidence numbers for a population over 7 years, totaling 2557 observations. There is a strong weekly and yearly seasonality (high incidence in winter months and low incidence in summer months). There is a baseline negative trend which is orders of magnitude smaller than the seasonality. An intervention was introduced at time = 1700. This intervention should theoretically not cause a level shift. My aim is to detect whether the intervention increases the baseline negative trend.</p>

<p>I have attempted to fit a dynamic linear regression with ARIMA errors in R using <code>auto.arima()</code> in the <code>forecast</code> package. I modeled the weekly season using a dummy variable for each weekday and the weekend. I modeled the monthly seasonality with harmonics using <code>fourier()</code> function in the <code>forecast</code> package. An the intervention effect was coded in by specifying the time index and post-intervention times as independent variables using the methods described in <a href=""http://isites.harvard.edu/fs/docs/icb.topic79832.files/L06_Program_Evaluation_2/Segmented_Regression.Wagner.2002.pdf"" rel=""nofollow"">Segmented regression analysis of interrupted time series studies in medication use research</a>. With these variables specified <code>auto.arima()</code> suggests an ARMA(7,7) process. The coefficients for baseline trend and post-intervention trend are however non-significant.  </p>

<p>I am concerned that by using fourier terms to model away the seasonality I am artificially removing any intervention effect, as visual analysis of the time series indicates that the intervention is specifically decreasing incidence during the winter months and therefore reducing the yearly seasonal variability. </p>
"
"0.100167084494127","0.0993399267798783","190586","<p>I am using cross correlation to demonstrate a potential link between two time series (ext &amp; co). Both series are strongly autocorrelated, so it is difficult to assess the dependence between the two series. For a quick preliminary analysis, the cross correlation shows a clear (somehow delayed) link between the two time series, although it might spurious. <a href=""http://i.stack.imgur.com/eHUnj.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/eHUnj.jpg"" alt=""CCF""></a>. Prewhitening seems to be the best option; I will prewhiten my x variable by fitting an ARIMA process and then use the coefficients to filter my variable y. My question is if I should estimate the coefficients of the ARIMA process (for example using <code>auto.arima</code>) using my series x or by using the residuals of the OLS regression of x on y.</p>
"
"0.115662986393248","0.114707866935281","194400","<p>I have data on newspaper articles about police cracking down on crime, and data on crimes reported to the police. The data are daily, covering about six months and the same city.</p>

<p>I want to try an ARIMA model on these data to forecast the deterrent effect of newspaper coverage of law enforcement operations on crime.</p>

<p>I'm using the most recent forecast package in R, but as I have little experience with this sort of stuff I am unsure of the results. I am hoping that someone more knowledgeable can tell me if I need to massage the data for the analysis. I have read up on the forecast package and I'm unsure of how much of the hard work the code below is actually doing for me.</p>

<pre><code>rate &lt;- ts(crime$rate,frequency=7)
news &lt;- ts(crime$news,frequency=7)
fit &lt;- auto.arima(rate, xreg=news)
summary(fit)
</code></pre>

<p>My understanding, based on the answer to <a href=""http://stats.stackexchange.com/questions/14742/auto-arima-with-daily-data-how-to-capture-seasonality-periodicity"">this</a> question, is that the <code>frequency=7</code> here adjusts the data for daily seasonality (which is present in both datasets. There are fewer articles published and fewer crimes reported on Sundays). Are further adjustments required for these seasonal effects?</p>

<p>Output:</p>

<pre><code>ARIMA(2,1,0)(1,0,0)[7]                    

Coefficients:
          ar1      ar2    sar1         m2
      -0.4469  -0.2135  0.6080  1598.3622
s.e.   0.0907   0.0865  0.0727   612.6812

sigma^2 estimated as 1.93e+09:  log likelihood=-1635.99
AIC=3281.99   AICc=3282.45   BIC=3296.55

Training set error measures:
                    ME     RMSE      MAE       MPE     MAPE      MASE         ACF1
Training set -601.4693 43614.13 34018.82 -4.343747 20.00794 0.8864897 -0.004283847
</code></pre>

<p>Assuming that there is no missing data, and if the seasonality is already adjusted for, are there other things I need to check?</p>
"
"0.141657649394966","0.140487871737254","194468","<p>I am using function <code>prewhiten</code> from ""TSA"" package in R. I get an error about <code>NA</code> values, but I don't understand it, because I don't have <code>NA</code> values in my data. Here is the error message:</p>

<pre><code>whitedata &lt;- prewhiten(xhr, ypred, mod1)

Error in na.omit.ts(as.ts(x)) : all times contain an NA
</code></pre>

<p>It works fine for some data files, but not for others. When I print <code>xhr</code> and <code>ypred</code> I don't see any <code>NA</code> values. </p>

<p>Both are time series: </p>

<pre><code>xhr &lt;- ts(data$hr_z,start=1,frequency=10) #convert to a time series
ypred &lt;- ts(data$pred_z,start=1,frequency=10) #convert to a time series
</code></pre>

<p>Strangely, if I run it with a different model (one built on <code>ypred</code>), it runs just fine. The model I am using is: </p>

<pre><code>ARIMA(2,1,2)                    

Coefficients:
         ar1      ar2      ma1     ma2
      1.4835  -0.7641  -0.9574  0.4021
s.e.  0.1136   0.0826   0.1365  0.0910

sigma^2 estimated as 0.02589:  log likelihood=79.98
AIC=-149.96   AICc=-149.65   BIC=-133.55
</code></pre>
"
"0.0708288246974828","0.117073226447712","194941","<p>I'm using <code>auto.arima</code> to get the best model for the <code>MASS</code> dataset <code>deaths</code>. However, <code>auto.arima</code> does not seem to give the best model by measures of AIC, AICc, or BIC. <code>auto.arima</code> code below:</p>

<pre><code>&gt; data(deaths, package='MASS')
&gt; deaths
      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec
1974 3035 2552 2704 2554 2014 1655 1721 1524 1596 2074 2199 2512
1975 2933 2889 2938 2497 1870 1726 1607 1545 1396 1787 2076 2837
1976 2787 3891 3179 2011 1636 1580 1489 1300 1356 1653 2013 2823
1977 3102 2294 2385 2444 1748 1554 1498 1361 1346 1564 1640 2293
1978 2815 3137 2679 1969 1870 1633 1529 1366 1357 1570 1535 2491
1979 3084 2605 2573 2143 1693 1504 1461 1354 1333 1492 1781 1915

&gt; library(forecast)
&gt; auto.arima(deaths)
Series: deaths 
ARIMA(1,0,0)(2,0,0)[12] with non-zero mean 

Coefficients:
         ar1    sar1    sar2  intercept
      0.4418  0.3098  0.5078  2058.2234
s.e.  0.1345  0.0973  0.0998   175.8665

sigma^2 estimated as 79455:  log likelihood=-515.07
AIC=1040.13   AICc=1041.04   BIC=1051.51
</code></pre>

<p>If I instead fit a ARIMA(2,1,1)x(1,1,1) model, it is better by all measures: </p>

<pre><code>&gt; Arima(deaths, order=c(2,1,1), seasonal=c(1,1,1))
Series: deaths 
ARIMA(2,1,1)(1,1,1)[12]                    

Coefficients:
         ar1      ar2      ma1     sar1     sma1
      0.2729  -0.3270  -1.0000  -0.2985  -0.9999
s.e.  0.1356   0.1396   0.1305   0.1426   1.0106

sigma^2 estimated as 39753:  log likelihood=-413.08
AIC=838.17   AICc=839.79   BIC=850.64
</code></pre>
"
"0.200929517013936","0.214598768819738","195443","<p>I am looking at two time series, from 01/01/2000 to the present: <br></p>

<ul>
<li>The <a href=""https://research.stlouisfed.org/fred2/series/NAPMNOI/"" rel=""nofollow"" title=""ISM Manufacturing: New Orders Index"">ISM Manufacturing: New Orders Index</a>, only available seasonally adjusted</li>
<li>The manufacturing industry unemployment rate, only available unadjusted (<a href=""https://research.stlouisfed.org/fred2/series/LNU04032232"" rel=""nofollow"">https://research.stlouisfed.org/fred2/series/LNU04032232</a>)</li>
</ul>

<p>I was <em>hoping</em> to construct a multivariate ts model, and use the <strong>New Orders Index</strong> to forecast the <strong>manufacturing industry unemployment rate</strong>. However, am I correct in assuming it is not 'ideal' to use seasonally adjusted data to predict another time series? Because doesn't SA cause (ideally) all the seasonal time series structure to be removed from the data?</p>

<h3>EDIT:</h3>

<p>Sorry, it just now hit me to link to the data I was using by putting it on Google Drive. It's in .csv files, for easy viewing with any program.</p>

<ul>
<li>Manufacturing new orders index data, in <strong>OrdersIndex.csv</strong><br><a href=""https://drive.google.com/file/d/0B2Y54SySHrVwZXczR1N4LXZMdXc/view?usp=sharing"" rel=""nofollow"">https://drive.google.com/file/d/0B2Y54SySHrVwZXczR1N4LXZMdXc/view?usp=sharing</a></li>
<li>Manufacturing industry unemployment rate, in <strong>Unem.csv</strong>
<br><a href=""https://drive.google.com/file/d/0B2Y54SySHrVweFVpRjJFanAwQmc/view?usp=sharing"" rel=""nofollow"">https://drive.google.com/file/d/0B2Y54SySHrVweFVpRjJFanAwQmc/view?usp=sharing</a></li>
</ul>

<p>Below is the New Orders Index time series, with the dashed line indicating the mean of 54.61. It looks fairly stationary to me; a decent spike in 2008, but definitely reverts to the mean.</p>

<pre><code>&gt; plot.ts(OrdersIndex[,2])
&gt; mean(OrdersIndex[,2])
[1] 54.60829
&gt; abline(h=c(54.61), lty=2)
&gt; 
</code></pre>

<p><a href=""http://i.stack.imgur.com/C61sm.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/C61sm.png"" alt=""New Orders Index""></a></p>

<p>The ACF and PACF of the series are below. ACF displays dampened sine-wave behavior, PACF has a sharp cut-off after lag 1. This suggests an AR(1) model, as the ACF's slow dying off (at lags > 1) is due to the auto correlation at lag 1.</p>

<pre><code>&gt; Acf(OrdersIndex[,2], plot=T)   #the Acf() function is part of 'forecast' package
&gt; Acf(OrdersIndex[,2], plot=T, type=c('partial'))
&gt;
</code></pre>

<p><a href=""http://i.stack.imgur.com/Dg2Es.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Dg2Es.png"" alt=""ACF plot""></a>
<a href=""http://i.stack.imgur.com/0PqBR.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/0PqBR.png"" alt=""PACF plot""></a></p>

<p>After running an arima(1,0,0) model with a mean, the ACF and PACF of the residuals do not show significant spikes at any lags.</p>

<pre><code>&gt; OrdersIndex100 &lt;- arima(OrdersIndex[,2], order=c(1,0,0))
&gt; OrdersIndex100

Call:
arima(x = OrdersIndex[, 2], order = c(1, 0, 0))

Coefficients:
         ar1  intercept
      0.8738    54.6979
s.e.  0.0341     1.9399

sigma^2 estimated as 12.39:  log likelihood = -517.44,  aic = 1040.88
&gt;
</code></pre>

<p>Running an Ljung-Box test on the residuals indicates there is not any time series structure left in the data.</p>

<pre><code>&gt; LBQPlot(OrdersIndex100$residuals, k=1)   # LBQPlot() is part of 'FitAR' package
&gt;
</code></pre>

<p><a href=""http://i.stack.imgur.com/xXQKc.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/xXQKc.png"" alt=""Ljung-Box Test""></a></p>

<h3>Conclusion</h3>

<p>The conclusion I arrive at is that the seasonally adjusting done to the data by the ISM (Institute of Supply Management) effectively removed all the seasonality from the data. So, this SA data would be less useful in modeling than non-SA data (this is assuming that I would be using this data series as the Input, and the unemployment data series as the Output). Is this a valid conclusion? You all see any glaring problems with my analysis?</p>
"
"0.118048041162471","0.140487871737254","197625","<p>I have been fitting ARIMA models to panel data.  My goal is to develop a single ARIMA model that explains growth across a number of different regions.  To do this, I followed Rob Hyndman's excellent advice in this CV thread: <a href=""http://stats.stackexchange.com/questions/23036/"">Estimating same model over multiple time series</a>.  Hyndman suggests applying <code>auto.arima</code> to a single time series separated by NAs.</p>

<p>Using this approach, <code>auto.arima</code> enables me to automatically select from a range of different AR models. In theory, <code>auto.arima</code> should also consider ARMA and MA models.</p>

<p>But <code>auto.arima</code> dismisses all models with MA terms. <code>auto.arima</code> produces an AIC of <code>Inf *</code> <strong>every</strong> single time it investigates a model with one or more MA terms.  </p>

<p>The thread <a href=""http://stats.stackexchange.com/questions/160612/""><code>auto.arima</code> doesn't calculate AIC values for the majority of models</a> suggests that <code>auto.arima</code> may produce infinite AICs because the MA terms are non-invertible.  </p>

<p>But I don't think non-invertible MAs are the problem! The <code>trace</code> command shows that <code>auto.arima</code> is producing infinite AICs EVERY single time, and across a range of industries. <code>auto.arima</code> also produces infinite AICs even if the MAs do not look non-invertible. For example, <code>auto.arima</code> deemed the model below to be non-invertible:</p>

<pre><code>arima(x = reim_arma$demean_gdp_growth, order = c(0, 0, 1), include.mean = FALSE)

Coefficients: 
ma1   -0.18
s.e.   0.08

sigma^2 estimated as 0.00823:  log likelihood = 132,  aic = -261
</code></pre>

<p>Does anyone have any idea why <code>auto.arima</code> would work fine with AR terms but <strong>always</strong> produce infinite AICs when MA terms are included? I am wondering if it is some way related to my inclusion of NA terms?</p>
"
"NaN","NaN","198494","<p>I am using arimax model to calculate incremental sales due to promotions. Arima code is as below</p>

<pre><code>**out &lt;- try(Arima(unlist(final_data$total_sales), order=c(1,1,0),seasonal=c(0,0,0), xreg=reg_inp, include.mean=TRUE,include.drift=TRUE,transform.pars=TRUE,fixed=NULL, init=NULL, method=""ML"",kappa=1e6))**  
</code></pre>

<p>Co-Efficients of the arima produces negative values for some predictors and I use these coefficients to calculate incremental sales</p>

<p><a href=""http://i.stack.imgur.com/Ak93N.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Ak93N.jpg"" alt=""Co_efficients""></a> </p>

<p>So my question is an is there any way to restrict my coefficients to give me only positive numbers?</p>
"
"0.156931661453885","0.172928615966519","202319","<p>I have daily sales data for a department store for the past 850 days. I have indicators on the major holidays and the days leading up to the major holidays. The number of days before the holidays that are included was chosen by AIC. The issue I'm having is that there are outliers throughout the data that I'm not sure how to handle. Or, at least that's what I think is happening since I don't seem to get accurate forecasts. I'm using a CV to calculate the MAPE of forecasts two weeks out, using the first 450 days as the initial training set and the rest to see how well the model forecasts the data.</p>

<p>I've used tso() from the tsoutliers package and tsoutliers from the forecast package to find outliers. They both give different results.</p>

<pre><code>tsoutliers(data$Sales)

$index
[1] 230 270 271 328 635

$replacements
[1] 2222.160 2088.573 2231.577 1812.380 2138.655

train = 454
trainingdata = data$Sales[1:train]
trainingdata = ts(trainingdata,frequency = 7)
tso(trainingdata,types = c(""AO"", ""LS"", ""TC""))

Series: trainingdata 
ARIMA(2,1,1)(2,0,0)[7]                    

Coefficients:
     ar1     ar2      ma1    sar1    sar2      AO52      TC68       TC80      AO86
  0.2872  0.1331  -0.9717  0.3567  0.4607  885.2061  890.3690  -863.4296  836.8638
s.e.  0.0508  0.0480   0.0107  0.0436  0.0429  169.2521  163.4243   166.0282  169.8535
     AO111     AO121      TC229     AO259      TC270     AO328     AO416
  754.1791  691.0849  1236.8523  711.3954  1790.0292  764.9712  920.1783
s.e.  169.2042  167.7273   163.1458  167.9835   163.9663  170.0103  168.9235

sigma^2 estimated as 44080:  log likelihood=-3064.92
AIC=6152.24   AICc=6153.65   BIC=6222.21

Outliers:
type ind  time coefhat  tstat
1    AO  52  8:03   885.2  5.230
2    TC  68 10:05   890.4  5.448
3    TC  80 12:03  -863.4 -5.200
4    AO  86 13:02   836.9  4.927
5    AO 111 16:06   754.2  4.457
6    AO 121 18:02   691.1  4.120
7    TC 229 33:05  1236.9  7.581
8    AO 259 37:07   711.4  4.235
9    TC 270 39:04  1790.0 10.917
10   AO 328 47:06   765.0  4.500
11   AO 416 60:03   920.2  5.447
</code></pre>

<p>Running BoxCox on the data it recommends a transform of the data</p>

<pre><code>lambda &lt;- BoxCox.lambda(data$Sales)
trainingdata = BoxCox(trainingdata,lambda)
tso(trainingdata,types = c(""AO"", ""LS"", ""TC""))
Series: trainingdata 
ARIMA(3,1,1)(2,0,0)[7]                    

Coefficients:
     ar1     ar2      ar3      ma1    sar1    sar2      LS3    AO52     AO53    TC68
  0.3918  0.0993  -0.0587  -0.9856  0.3632  0.4144  13.5805  5.7218  -7.7957  6.3960
s.e.  0.0383  0.0418   0.0416   0.0142  0.0361  0.0341   1.3201  1.2980   1.3041  1.2763
      AO80   AO121   TC229   TC270   AO416     AO445   TC634   AO780
  -23.3707  5.5352  5.8088  7.0446  7.9304  -23.6372  5.5475  6.7194
s.e.    1.2376  1.2307  1.2594  1.2640  1.2476    1.2393  1.2598  1.2353

sigma^2 estimated as 2.332:  log likelihood=-1482.63
AIC=3003.26   AICc=3004.23   BIC=3092.34

Outliers:
type ind   time coefhat   tstat
1    LS   3   1:03  13.581  10.287
2    AO  52   8:03   5.722   4.408
3    AO  53   8:04  -7.796  -5.978
4    TC  68  10:05   6.396   5.012
5    AO  80  12:03 -23.371 -18.883
6    AO 121  18:02   5.535   4.498
7    TC 229  33:05   5.809   4.612
8    TC 270  39:04   7.045   5.573
9    AO 416  60:03   7.930   6.356
10   AO 445  64:04 -23.637 -19.073
11   TC 634  91:04   5.547   4.404
12   AO 780 112:03   6.719   5.439
</code></pre>

<p>Some of these outliers are already taken care of since they're the holidays. I'm not sure how to handle the rest of the outliers when fitting the model and in the CV.</p>

<p>What is the best way to go about taking care of the outliers? I can reset the values of the training data where it's predicted as an outliers to the recommended value if it's not a holiday for fitting the model and then still calculate the MAPE off of the original data. However, there's a LS at index 3 so I'm not sure that would make sense for that.</p>
"
"0","0.0405553552826906","203105","<p>My apologies in advance for asking what I suspect is a dumb question. I have looked around and I can't figure this out.</p>

<p>I've done an auto.arima model in r.</p>

<pre><code>revenue = ts(arima$both.markets, frequency = 7)
    media=ts (arima$all_media, frequency = 7)
xreg &lt;- cbind(media=model.matrix(~as.factor(media)))
xreg &lt;- xreg[,-1]
modArima &lt;- auto.arima(revenue, xreg=xreg)
</code></pre>

<p>The output includes this:</p>

<pre><code>                ma1     ma2     sar1    (media)1    (media)2    (media)3    media)4 (media)5    (media)6    (media)7    (media)8    (media)9    (media)11   (media)13   (media)17   (media)18   (media)20   (media)23   (media)39
Coefficients:   -0.4081 -0.5391 0.6145  -8345.84    20129.82    1809.952    -14906.92   -42454.82   1885.815    -101350.54  12055.98    56197.28    -49130.22   128427.87   45600.38    -28911.02   46118.11    -95280.16   62833.34
s.e.            0.0791  0.0778  0.0718  11672.8     13384.69    21822.541   34298.06    23533.55    30755.171   35534.13    57394.97    44116.15    55263.58    55887.56    56920.24    60269.17    40252.73    49884.66    63023.11
</code></pre>

<p>Are the various <code>media</code> outputs lags of the media variable? If not, how can I include lags in the model?</p>
"
"0.100167084494127","0.0662266178532522","204678","<p>I have created a random walk model ARIMA(0,1,0) in R. The coefficients and R output is as shown below:</p>

<pre><code>arima(x = Y, order = c(0, 1, 0), xreg = Indp_varbl)
Coefficients:
          t2       t3
      9.1993  18.0351
s.e.  0.4921   7.7715
</code></pre>

<p>I wanted to ask how I can forecast points using these coefficients through an equation? I have gone through papers but was not able to find exact equation using regressors as well:</p>

<pre><code>Yt = Yt-1 + mean error 
</code></pre>

<p>is generally used. How can I get the equation for the same?</p>
"
"0.173494479589872","0.172061800402921","204763","<p>Using linear regression as an equation for prediction is straightforward with,</p>

<p>$$ Y_i = \beta_0 + \beta_1 X_i. $$</p>

<p>Once the betas are estimated I can insert different values of $X$ to use as a what-if analysis for different scenarios. </p>

<p>But trying to do the same with ARIMA models is proving difficult to translate. For example with an ARIMA(2,1,1) model, how do I create an equation where I can try out different scenarios to see how the projection changes? </p>

<p>Below I have the output for a projection of sales based on past sales and extra regressors. I see that a unit change in <code>poc0_3_PER</code> results in a <code>135.2229</code> change in sales. But how do I account for the moving average and auto-regression components?</p>

<pre><code>arima(ts.count, order=c(2,1,1), xreg=df.back[3:4])

Call:
arima(x = ts.count, order = c(2, 1, 1), xreg = df.back[3:4])

Coefficients:
          ar1     ar2     ma1  poc0_3_PER
      -0.4569  0.2458  0.9455    135.2229
</code></pre>

<p>I have <code>ar1</code> and <code>ar2</code> estimates along with <code>ma1</code> and the extra regressors. How do I convert this into a working equation wherein I can try out different scenarios for the extra regressors to see how the prediction is affected?</p>

<p>I'm hoping that the solution is not an equation like <a href=""http://stats.stackexchange.com/questions/69407/how-do-i-write-a-mathematical-equation-for-arima-2-1-0-x-0-2-2-period-12?rq=1"">this post here</a>. I do have SARIMA models at times with orders like <code>SARIMA(2,0,1)(1,0,1)[12]</code>.</p>
"
"0.057831493196624","0.0860309002014606","206327","<p>I have time series data on drug trade revenue in a city over a four-month period (DP). I also have data on police crackdowns and raids in the same period, in the same city (IV). I want to see if the crackdowns/raids have any effect on the trade volume.</p>

<p>This is fairly straightforward and easy to follow, I think. However, when I do an ARIMA model with the DP and a bunch of lagged versions of the IV, the output is... Hard to understand, and even harder to explain. </p>

<p>Take the plot below, for example. In this model the IV is included (as xreg), but the graph is not very intuitive. Is there a way to illustrate both variables and how they impact each other (if at all) in a more intuitive way?</p>

<p><a href=""http://i.stack.imgur.com/gSAWY.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/gSAWY.png"" alt=""enter image description here""></a></p>

<p>I also have a hard time understanding the actual output. The model below is the correct ARIMA model, but as the coefficients are useless in ARIMA models, what can I really say based on these numbers? Can I say anything about how the IV affects the DP?</p>

<p>Most textbook resources I've found online, such as R.H. Shumway &amp; D.S. Stoffer's and Hyndman's, are mostly about how to find the best ARIMA model etc. and relatively little about how we can interpret and explain findings from an ARIMA+xreg model.</p>

<p>I hope someone can help!</p>

<pre><code>Series: revenue 
ARIMA(0,1,2)(2,0,0)[7]                    

Coefficients:
          ma1      ma2    sar1    sar2  (media)1  (media)2  (media)3
      -0.4801  -0.4825  0.4974  0.1835           14530.95           14153.26          -40388.58
s.e.   0.0834   0.0818  0.0945  0.1016           12270.92           16683.66           31806.25
      (media)4  (media)5  (media)6  (media)7  (media)8
              -20874.23          -32847.12          -22016.12           29745.91           13306.47
s.e.           29056.25           25904.39           34676.39           39702.54           55336.30
      (media)9  (media)11  (media)13  (media)17  (media)23
               12164.75            29435.90            87281.65            19487.28          -187469.01
s.e.           48021.79            54428.17            55982.59            57683.76            55452.48
      (media)25
                42058.20
s.e.            53967.83

sigma^2 estimated as 3.325e+09:  log likelihood=-1549.47
AIC=3136.93   AICc=3144.1   BIC=3190.82

Training set error measures:
                   ME     RMSE      MAE       MPE     MAPE      MASE      ACF1
Training set 4718.048 57203.09 43598.36 -2.884122 16.07953 0.7763964 0.0171537
</code></pre>
"
"0.100167084494127","0.0993399267798783","208271","<p>I simulated a MA(3) process using: </p>

<pre><code>set.seed(66)
w &lt;- rnorm(100,0,3.6)
p1 &lt;- 0.4; p2 &lt;- -0.2; p3 &lt;- 0.3;
ma3 &lt;- w[1]
ma3[2] &lt;- w[2] + p1*w[1] 
ma3[3] &lt;- w[3] + p1*w[2] + p2*w[1]
for (t in 4:100) ma3[t] &lt;- w[t] + p1*w[t-1] + p2*w[t-2] + p3*w[t-3]
</code></pre>

<p>Running auto.arima on the time series gives:</p>

<pre><code>&gt; auto.arima(ma3)                                   
Series: ma3 
ARIMA(0,0,1) with zero mean     

Coefficients:
         ma1
      0.3854
s.e.  0.1152

sigma^2 estimated as 14.41:  log likelihood=-275.39
AIC=554.77   AICc=554.89   BIC=559.98
</code></pre>

<p>However, fitting the series to a MA(3) model gives a lower AIC:</p>

<pre><code>&gt; arima(ma3, order=c(0,0,3))

Call:
arima(x = ma3, order = c(0, 0, 3))

Coefficients:
         ma1      ma2     ma3  intercept
      0.4039  -0.0836  0.5125     0.2752
s.e.  0.1158   0.0905  0.1039     0.6078

sigma^2 estimated as 11.2:  log likelihood = -264.67,  aic = 539.34
</code></pre>

<p>I'm not sure what's going on. I thought that auto.arima selected the best model based on the AIC. </p>
"
"0.118048041162471","0.140487871737254","208515","<p>I'm trying to understand the steps in Rob Hyndman's Multi-step forecasts without re-estimation example below.  I'm wondering what the purpose is of </p>

<pre><code>refit &lt;- Arima(x, model=fit)
</code></pre>

<p>The model has already been determined and trained by auto.arima in the ""fit"" step.  So in the ""refit"" step are we re-training the model on a new data set?  If so, what is the point of retraining the same model on a new data set?</p>

<p>url:
<a href=""http://robjhyndman.com/hyndsight/rolling-forecasts/"" rel=""nofollow"">http://robjhyndman.com/hyndsight/rolling-forecasts/</a></p>

<p>Code:</p>

<pre><code>library(fpp)

h &lt;- 5
train &lt;- window(hsales,end=1989.99)
test &lt;- window(hsales,start=1990)
n &lt;- length(test) - h + 1
fit &lt;- auto.arima(train)
fc &lt;- ts(numeric(n), start=1990+(h-1)/12, freq=12)
for(i in 1:n)
{  
  x &lt;- window(hsales, end=1989.99 + (i-1)/12)
  refit &lt;- Arima(x, model=fit)
  fc[i] &lt;- forecast(refit, h=h)$mean[h]
}
</code></pre>

<p>Updated Code to re-estimate coefficients:</p>

<pre><code>h &lt;- 5
train &lt;- window(hsales,end=1989.99)
test &lt;- window(hsales,start=1990)
n &lt;- length(test) - h + 1
fit &lt;- auto.arima(train)
order &lt;- arimaorder(fit)
fc &lt;- ts(numeric(n), start=1990+(h-1)/12, freq=12)
for(i in 1:n)
{  
  x &lt;- window(hsales, end=1989.99 + (i-1)/12)
  refit &lt;- Arima(x, order=order[1:3],seasonal=order[4:6])
  fc[i] &lt;- forecast(refit, h=h)$mean[h]
}
</code></pre>
"
"0.154217315190997","0.133825844757828","208526","<p>Assume I have a time series $ x_t $ that I want to fit using an ARIMA(1,1,0) model of the form:</p>

<blockquote>
  <p>$ \Delta x_t = \alpha \Delta x_{t-1} + w_t  $</p>
</blockquote>

<p>This could be rewritten as: </p>

<blockquote>
  <p>$ x_t - x_{t-1} = \alpha ( x_{t-1} - x_{t-2} )+ w_t  $</p>
  
  <p>$ x_t = ( 1 + \alpha)x_{t-1} - \alpha x_{t-2} + w_t  $</p>
</blockquote>

<p>The last equation describes an AR(2) model with coefficients $1+\alpha$ and $-\alpha$. I recognize that, depending on $\alpha$, this AR(2) model might be non-stationary. However, if I was taking a diff to begin with, then the series I am modeling shouldn't be stationary.</p>

<p>I know that if the model is non-stationary, a diff should be used. But how would the results differ if I used a AR(2) model vs an ARIMA(1,1,0) model? I assume (as hinted by R) that it has an issue with convergence. However, when I ask R to perform the fits, it will do both of them, and the coefficients are (mostly) consistent with my observations above. The forecasts are definitely different, though.</p>

<p>If anyone could shed some light on this, or point me to a good reference, I would appreciate it. </p>

<p>Here is the R code I used to generate both models. </p>

<pre><code>&gt; set.seed(2)
&gt; x &lt;- arima.sim(n = 1000, model=list(order=c(1,1,0), ar=c(0.3)))
&gt; plot(x)
&gt; arima(x, order=c(1,1,0))

Call:
arima(x = x, order = c(1, 1, 0))

Coefficients:
         ar1
      0.3291
s.e.  0.0298

sigma^2 estimated as 1.03:  log likelihood = -1433.91,  aic = 2871.81
&gt; arima(x, order=c(2,0,0))

Call:
arima(x = x, order = c(2, 0, 0))

Coefficients:
         ar1      ar2  intercept
      1.3290  -0.3294    50.9803
s.e.  0.0298   0.0299    35.9741

sigma^2 estimated as 1.03:  log likelihood = -1438.93,  aic = 2885.86
Warning messages:
1: In log(s2) : NaNs produced
2: In log(s2) : NaNs produced
3: In log(s2) : NaNs produced
4: In arima(x, order = c(2, 0, 0)) :
  possible convergence problem: optim gave code = 1
</code></pre>
"
"0.0667780563294178","0.0662266178532522","210885","<p>I can't seem to make sense of the following results. The time-series looks more non-stationary than stationary, and when I fit an ARMA(1, 0, 0) it estimates the AR(1) term to be very close to unity (0.99). From this I would expect a simple Dickey-Fuller test with no augmented autoregressive components to either fail or just marginally succeed to reject the null of a unit root. However, the test rejects the null with a p-value of less than 0.01.</p>

<p>I've read all the other questions on the ADF test, but still fail to understand the intuition behind these results.</p>

<p>(when the ADF test is run without specifying the k-order it picks an order of 6, if that helps).</p>

<p><a href=""http://i.stack.imgur.com/TTqiE.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/TTqiE.png"" alt=""enter image description here""></a></p>

<pre><code>df &lt;- structure(c(31.5, 29.2, 30.5, 30.5, 28.1, 27.7, 24.7, 24.3, 23, 
            19.8, 16.6, 14.9, 15.4, 13.4, 10.7, 9.4, 9.7, 8.9, 10.1, 10.3, 
            9.5, 9.4, 9.2, 8.5, 6.5, 6.3, 6.7, 6.9, 6.9, 6, 5.2, 4.5, 4.3, 
            4.7, 3.5, 3.1, 3.1, 2.8, 2.2, 1.8, 1.1, 1.8, 0.8, 1, 1.9, 0.3, 
            0.2, 0.4, 0.9, 0.9, 1, 0.9, 0.5, 1.3, 1.4, 1, 0.5, 1.3, 1.7, 
            1.7, -0.1, 0.1, 0.8, 1, 2, 2, 1.4, 2.7, 2.3, 2.4, 2, 2, 3.2, 
            2.8, 1.7, 1.4, 0.5, -0.4, 0.1, -1, -1.4, -1, -0.9, -0.9, -1.8, 
            -1.9, -1.1, -0.9, -0.8, -0.3, -0.8, -1, -0.8, -1.3, -1, -1.3, 
            -1.2, -1.2, -0.9, -0.6, 1, 1, 1.8, 2.2, 3.1, 3.1, 2.9, 2.8, 2.9, 
            3.2, 3.3, 3.2, 1.9, 2, 1.8, 2.3, 2.6, 3, 2.9, 3, 3.5, 3.4, 3.1, 
            3.4, 3.6, 3.7, 4.4, 4.2, 3.3, 3.7, 4.4, 4.6, 4, 4.4, 4.7, 4.9, 
            5, 5, 5.1, 5.5, 7.1, 7.6, 7.9, 8.2, 10, 10.9, 11.4, 11.9, 12.3, 
            12.7, 12.4, 12.2, 11.3, 10.7, 9.2, 8.5, 9.5, 8.5, 7.4, 5.9, 4.9, 
            3.9, 2.6, 2.2, 2.3, 1, 1.3, 1.2, -0.3, -0.6, -0.4, 0.2, 0.5, 
            0.9, 1.8, 1.8, 1.8, 2.6, 2.5, 3.6, 2.8, 3, 3.7, 4.4, 5, 4.8, 
            4.6, 4.4, 4.7, 4.2, 4.4, 3.5, 3.4, 3.7, 3.7, 3.3, 2.6, 2.6, 2.9, 
            3.4, 3.3, 3.2, 2.8, 2.9, 2.7, 2.3, 1.6, 1.4, 1.5, 1.3, 0.6, 0.5, 
            0.5, 0.5, 0.6, 0.5, 0.2, 0.3, 0.4, 0.3, 0.1, 0.3, 0.5, 0.3, 0, 
            0.3, 0.4, -0.1, -1.4, -1.5, -1.1, -0.6, 0, -0.2, -0.2, -1, -0.8, 
            -0.4, -0.5, -0.2, 0.7, 0.5, 0.8), .Tsp = c(1996, 2016.16666666667, 
                                                       12), class = ""ts"")

arima(df, order = c(1, 0, 0))

&gt; Call: arima(x = df, order = c(1, 0, 0))
&gt; 
&gt; Coefficients:
&gt;          ar1  intercept
&gt;       0.9986    14.2496 s.e.  0.0018    13.6263
&gt; 
&gt; sigma^2 estimated as 0.6027:  log likelihood = -286.21,  aic = 578.42

tseries::adf.test(df, k = 0)

&gt;   Augmented Dickey-Fuller Test
&gt; 
&gt; data:  df Dickey-Fuller = -5.6878, Lag order = 0, p-value = 0.01
&gt; alternative hypothesis: stationary
</code></pre>
"
"0.23844535493687","0.236476325731729","211079","<p>This question is also linked to <a href=""http://stats.stackexchange.com/questions/209790/how-to-detect-a-relatively-small-level-shiftleakage-in-an-hourly-water-flux-ti"">How to detect a relatively small level shift(leakage) in an hourly water flux time series in an area?</a> which I asked a week ago...</p>

<h3>Background</h3>

<p>I've got a series of water flux data among about four month. The data is hourly collected, and I'm trying to develop an approach to justify whether there is a leakage or not. In the end, I want to implement my approach in R.<br>
As the other post mentioned, since I'm kind of new to the field of time series analysis, I've already tried some approaches or black boxes to solve the problem, but the result seems not good. And in the course of digging deep into the problem, I start to suspect the approaches I used.<br>
<strong>So I'm here to ask for help, is there any advices/procedures/references which I could refer to?</strong></p>

<h3>What I've tried</h3>

<ol>
<li>I used ARIMA,ETS,TBATS,STLM models provided by the forecests package to directly get a model to predict, and I try to using the model to predict, and then compare the prediction with the test value. The accuracy test showed it's not a good idea. Since non of the prediction is better than the snaive, which also got a MASE > 1.  </li>
<li>I detected the single outliers, and replaced it with a moving average of nearest 7 days. Then using the tsoutliers::tso with the only type of ""LS"", but the outcomes even failed at the manually modificated data I created.  </li>
<li>I seperated the data at zero and other points(totally 24 groups), and within each group I used the same idea as the first to find a model, make a prediction, and then check the residuals in series. This time with the cross validation, results showed an ARIMA model fits the best averagely. But then I got lost the model I got returns an intercept which is constantly increasing. Definitely, there exists other effects such as temperature which could interpret this variation. This somehow leads me crestfallen, since I've only got four month data, without comparing with the last year data, <strong>is it possible to estimate the appropriate coefficient with the temperature, and solve the problem in the meantime???</strong>   

<blockquote>
  <p>mod_arima  0.369<br>
  naive     0.725<br>
  mod_exp   0.891<br>
  mod_stl   0.913<br>
  mod_tbats 1.067  </p>
</blockquote></li>
</ol>

<h3>Characteristics of the data</h3>

<p>I think there are some characteristics to help you have a better understanding of my data.  </p>

<ol>
<li><p>In my view, the leackage I want to detect is relatively small(I doubt, there's only about 5%/10% of the mean value).  </p>

<blockquote>
  <p>train_h &lt;- ts(data_h$Navigator[1393:(1392+14*24)], frequency = 24)<br>
  excess &lt;- ts(c(rep(0,279),rep(mean(train_h,na.rm = T)*0.1,57)),frequency = 24)<br>
  plot(train_h)<br>
  lines(train_h+excess,col = ""red"")<br>
  <a href=""http://i.stack.imgur.com/Qcm3g.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Qcm3g.jpg"" alt=""enter image description here""></a>
  As you could see there isn't so much difference...</p>
</blockquote></li>
<li><p>There's a huge calendar effect in my data during the Chinese New Year, So all the approaches I explored above only used the time span I think could ignore this effect.  </p>

<blockquote>
  <p>tsdata_d &lt;- ts(data_d$Navigator[1:114],frequency = 7)<br>
  plot(tsdata_d)
  <a href=""http://i.stack.imgur.com/gl6BY.jpg"" rel=""nofollow""><img src=""http://i.stack.imgur.com/gl6BY.jpg"" alt=""enter image description here""></a>
  And I used the second half.</p>
</blockquote></li>
<li><p>There are other effect could not be interpreted simply by the two-weeks or one-month prediciton model, but it's crutial. I personally think it's the varied temperature along the whole year.</p></li>
</ol>
"
"0.252397328691289","0.250313087160879","217955","<p>I'm doing some time series modeling using R and the <code>forecast</code> package, and found a minor difference I couldn't figure out. I'll reproduce my steps below. </p>

<p>First, I generate some data. While I have ""real"" data, I'll just use simulated data so that anyone can reproduce them (it makes no difference). The generated data is divided into training and test sets.</p>

<pre><code>&gt; set.seed(1234)
&gt; mydata &lt;- arima.sim(list(order = c(1,0,0), ar = 0.8), n = 500)
&gt; training &lt;- mydata[1:400]   # training set
&gt; testing &lt;- mydata[401:500]  # test set
</code></pre>

<p>Then, I fit a model to my training data:</p>

<pre><code>&gt; library(forecast)
&gt; (fit &lt;- Arima(training, order=c(1,0,0)))
Series: training 
ARIMA(1,0,0) with non-zero mean 

Coefficients:
         ar1  intercept
      0.8336     0.0462
s.e.  0.0274     0.2987

sigma^2 estimated as 1.013:  log likelihood=-570.68
AIC=1147.37   AICc=1147.43   BIC=1159.34
</code></pre>

<p>Next, I calculate one-step ahead forecasts using the test set:</p>

<pre><code>&gt; refit &lt;- Arima(testing, model=fit)
</code></pre>

<p>For my purposes, a forecast horizon of 1 is fine. So, I should evaluate model accuracy comparing the one-step ahead forecasts -- given by  <code>fitted(forecast(refit))</code> -- to the test set (<code>testing</code>).</p>

<p>I thought the first forecast value obtained using the original model (<code>fit</code>) should be equal to the first point forecast using the <code>refit</code> model, since (I assume) both forecasts are calculated from the training data. However, they're different:</p>

<pre><code>&gt; fitted(refit)[1]
[1] 0.02706320

&gt; forecast(fit)$mean[1]
[1] 1.3180435
</code></pre>

<p>Could anyone explain this difference, please? Am I assuming something wrong here?</p>

<p>For what it's worth, this particular system has R 3.2.5 with <code>forecast</code> version 5.4, but an installation with the latest <code>forecast</code> exhibits the same behavior.</p>

<pre><code>&gt; R.version.string
[1] ""R version 3.2.5 (2016-04-14)""

&gt; packageVersion(""forecast"")
[1] â€˜5.4â€™
</code></pre>

<p>EDIT 1: I had erroneously fit the model to the entire dataset, not just the training set. I corrected it above.</p>

<p>EDIT 2: Stephan's answer below prompted me to dig a little deeper. <code>forecast(refit)</code> gives forecasts past the end of the test set:</p>

<pre><code>&gt; forecast(refit, h=3)
    Point Forecast     Lo 80    Hi 80     Lo 95    Hi 95
101     -0.1714176 -1.633258 1.290423 -2.407110 2.064275
102     -0.1352187 -2.038402 1.767965 -3.045887 2.775450
103     -0.1050416 -2.262407 2.052323 -3.404447 3.194363
</code></pre>

<p>So, it doesn't seem to be what I want (one-step ahead forecasts using observed data).</p>

<p>The AR(1) model obtained using <code>auto.arima()</code> is $\hat{y}_t=0.8336y_{t-1} + 0.0462 + e_t$. I calculated by hand the first few forecasts using this model:</p>

<pre><code>&gt; (test.5 &lt;- mydata[400:404])  # last observation from the training set, first four from the test set
[1]  1.571841404  0.003474084  0.744644046 -0.627186378 -2.420643234

&gt; 0.8336*test.5 + 0.0462  # forecasts for y(401)...y(405)
[1]  1.3564870  0.0490960  0.6669353 -0.4766226 -1.9716482

&gt; fitted(refit)[1:5]
[1]  0.02706320  0.01057917  0.62845310 -0.51516887 -2.01027834
</code></pre>

<p>With the exception of the first forecast, the numbers agree (assuming the differences are due to rounding). On the other hand, the first forecast calculated by hand (1.3565) is not too different from the first forecast given by <code>forecast(fit)</code>, which is 1.3180. So, it seems that <code>fitted(refit)</code> is what I'm after, I just don't understand why it gives a different value for the first forecast.</p>

<p>EDIT 3: Rob's answer below mostly solves the issue. I'm still puzzled by the fact that the forecasts given by <code>forecast()</code> differ from those calculated by hand, and by a seemingly fixed amount:</p>

<pre><code>&gt; (by.hand &lt;- coef(fit)['ar1']*test.5 + coef(fit)['intercept'])
[1]  1.35654540  0.04908109  0.66695502 -0.47666695 -1.97177642

&gt; (auto &lt;- c(forecast(fit)$mean[1], fitted(refit)[2:5]))
[1]  1.31804348  0.01057917  0.62845310 -0.51516887 -2.01027834

&gt; by.hand - auto
[1] 0.03850192 0.03850192 0.03850192 0.03850192 0.03850192
</code></pre>

<p>Can anybody shed some light on this?</p>
"
"0.200334168988253","0.198679853559757","219792","<p>My objective it to manually compute one-step ahead forecast using the estimated coefficientes given by the <code>arima</code> function in R.</p>

<p>I will consider the specific model ARIMA(0,0,0)(0,1,3) with weekly seasonality (<code>period = 7</code>). The equation for this model is:</p>

<p>$$ x_{t} = x_{t-7} + \Theta_{1}e_{t-7} + \Theta_{2}e_{t-14} + \Theta_{3}e_{t-21} + e_{t} $$</p>

<p>I will start by computing the one-step ahead forecast using the <code>predict</code> function and then compare it's value with the result given from the above equation. So first I will have to compute <code>theta</code> vector and the residuals vector <code>e_t</code>.</p>

<p>My data consists of daily observations for 35 days.</p>

<pre><code>data &lt;- c(2570,4530,3990,4480,5880,3380,1340,4180,4600,4170,1980,5170,2900,940,7430,6330,7310,9210,8460,3080,1020,4400,2980,5090,7230,3670,2440,1980,2090,3380,2410,3630,3930,2450,1590)
</code></pre>

<p>I start by fitting the model:</p>

<pre><code>fit &lt;- arima(data, order=c(0,0,0), seasonal=list(order=c(0,1,3), period=7), method=""ML"")
</code></pre>

<p>Then I recover the estimated <code>theta</code> coefficients and the last 3 observed residuals. Note that the seasonality period is 7, so the last 3 residuals regarding this seasonality are as stated:</p>

<ul>
<li>Last residual is given by position <code>35 - 7 + 1 = 29</code></li>
<li>Before last residual is given by position <code>35 - 14 + 1 = 22</code></li>
<li>Before before last residual is given by position <code>35 - 28 + 1 = 15</code></li>
</ul>

<p>So that's the reason I have the funny indexes in line two of the following code:</p>

<pre><code>theta &lt;- as.vector(fit$coef)
e_t &lt;- fit$residuals[c(29,22,15)]
</code></pre>

<p>Finnaly, I also fetch the last observation (given seasonality period 7)</p>

<pre><code>z_t &lt;- data[29]
</code></pre>

<p>And when I compute the above formula:</p>

<pre><code>sum(e_t * theta) + z_t)
</code></pre>

<p>I get the value of <code>4613.141</code> which is different from </p>

<pre><code>predict(fit)$pred[1]
</code></pre>

<p>which returns the value <code>4671.607</code>.</p>

<p>Can you please explain where is my error? I've tried this procedure with several different samples and sample sizes and I never get the same forecast as the R function.</p>
"
"NaN","NaN","221160","<p>After running my auto.arima model I'm getting coefficients ar1, ar2 &amp; sar1. What do these coefficients mean?</p>
"
"0.0667780563294178","0.0993399267798783","223297","<p>I am trying to understand the coefficients retrieved from running <code>auto.arima</code> in R on my monthly time series of the annual change in House prices. When doing so, I obtain the following outcome:</p>

<pre><code>Series: AC.HousePrices 
ARIMA(1,1,1)(0,0,1)[12] with drift         

Coefficients:
         ar1      ma1     sma1   drift
      0.3243  -0.6592  -0.7892  -6e-04
s.e.  0.1733   0.1333   0.1161   4e-04

sigma^2 estimated as 0.0008257:  log likelihood=275.22
AIC=-540.44   AICc=-539.96   BIC=-526.07
</code></pre>

<p>To be honest I do not understand why I have two sets of parameters (p,d,q) and (P,D,Q)? The first set (1,1,1) seems to indicate that the series is first-order autoregressive model, nonstationary and with a simple exponential smoothing with drift? What are the second set of values (0,0,1)[12], is it telling me that my series looks yearly seasonal [12]?</p>
"
"0.131149499096392","0.130066495428618","223379","<p>I'm fitting an <code>arima</code>(1,0,0) model using the <code>forecast</code> package in R on the <code>usconsumption</code> dataset. However, when I mimic the same fit using <code>lm</code>, I get different coefficients. My understanding is that they should be the same (in fact, they give the same coefficients if I model an <code>arima</code>(0,0,0) and <code>lm</code> with only the external regressor, which is related to this post: <a href=""http://stats.stackexchange.com/questions/28472/regression-with-arima0-0-0-errors-different-from-linear-regression"">Regression with ARIMA(0,0,0) errors different from linear regression</a>). </p>

<p>Is this because <code>arima</code> and <code>lm</code> use different techniques to calculate coefficients? If so, can someone explain the difference?  </p>

<p>Below is my code.</p>

<pre><code>&gt; library(forecast)
&gt; library(fpp)
&gt; 
&gt; #load data
&gt; data(""usconsumption"")
&gt; 
&gt; #create equivalent data frame from time-series
&gt; lagpad &lt;- function(x, k=1) {
+   c(rep(NA, k), x)[1 : length(x)] 
+ }
&gt; usconsumpdf &lt;- as.data.frame(usconsumption)
&gt; usconsumpdf$consumptionLag1 &lt;- lagpad(usconsumpdf$consumption)
&gt; 
&gt; #create arima model
&gt; arima(usconsumption[,1], xreg=usconsumption[,2], order=c(1,0,0))

Call:
arima(x = usconsumption[, 1], order = c(1, 0, 0), xreg = usconsumption[, 2])

Coefficients:
         ar1  intercept  usconsumption[, 2]
      0.2139     0.5867              0.2292
s.e.  0.0928     0.0755              0.0605

sigma^2 estimated as 0.3776:  log likelihood = -152.87,  aic = 313.74
&gt; 
&gt; #create lm model
&gt; lm(consumption~consumptionLag1+income, data=usconsumpdf)

Call:
lm(formula = consumption ~ consumptionLag1 + income, data = usconsumpdf)

Coefficients:
    (Intercept)  consumptionLag1           income  
         0.3779           0.2456           0.2614  
</code></pre>
"
"0.141657649394966","0.140487871737254","223457","<p>Suppose I have a training dataset, I use <code>auto.arima</code> (from ""forecast"" package in R) to fit the training data. As a result I get the lag and integration orders $(p, d, q)$ and the corresponding coefficients $\psi_i$ and $\theta_i$.</p>

<pre><code>ytrain = c(0.435477843, 0.435394762, 0.195528995, 1.451623315, 1.740084831 2.379904714, 1.092366508, 0.001031411, 0.592164090, 0.670323418)

fit &lt;- auto.arima(ytrain)
</code></pre>

<p>Now I have new data </p>

<pre><code>ytest = c(-0.1349199  0.9001208 -0.5171740 -0.9958452  0.4125953 -0.3320575  0.1633313  0.2890109 -0.4284824  0.7902680)
</code></pre>

<p>I want to fit this new data by using the model from training data (using the same $(p, d, q)$ and also the same corresponding coefficients). I.e. I want to use the model I have from <code>ytrain</code> to make prediction based on <code>ytest</code>. As a result I can know if there are any points in the new data looking like anomaly points (compared to the training data)</p>

<p>I have searched long time and haven't find a R function to implement it. I know I can compute this by hand, e.g. for ARMA(1,2):</p>

<p>$\hat{Y}_n =  \hat{\mu} + \hat{\psi}_1 Y_{n-1} - \hat{\theta}_{1} \epsilon_{n-1} - \hat{\theta}_2 \epsilon_{n-2} $</p>

<p>But if I do this, I am not sure how to start to get $\epsilon_1 = Y_1 - \hat{Y}_1$ and $\epsilon_2 = Y_2 - \hat{Y}_2$ to start since I don't have $\hat{Y}_1$ and $\hat{Y}_2$. </p>

<ul>
<li>Could anyone suggest an R function for doing this? Or if not,  </li>
<li>Could anyone help me with this question if there is no R function doing this?</li>
</ul>
"
"0.115662986393248","0.114707866935281","224078","<p>I have three related questions on the package CausalImpact in R. The package can be found <a href=""https://github.com/google/CausalImpact"" rel=""nofollow"">here</a> and a reproducible example is below.</p>

<ol>
<li>Do I basically understand correctly, that the model makes ""1-step ahead""
predictions? I assume it works like a simple lm model that makes
lots of regressions for t+1 with predictors values from t-1 and then looks for the most contributory predictors?</li>
<li>When talking about ""coefficients"", does that mean they are (Pearson)
correlation coefficients?</li>
<li>The function <code>plot(impact$model$bsts.model,""coefficients"")</code> produces
a plot with inclusion probabilities ranging from 0 to 1. Is there
any way to access the actual values in a table? I found
that <code>colMeans(impact$model$bsts.model$coefficients)</code> provides some
values but I'd like to have a confirmation for this.</li>
<li>In my code, I changed <code>bsts.model &lt;- bsts(y ~ x1, ss, niter = 1000)</code> to <code>bsts.model &lt;- bsts(y ~ x1 + x2 + x3 + x4 + x5, ss, niter = 1000)</code> in order to get values for different variables that I defined before. I did not change the cbind functions for that, as I weren't sure if that was necessary. Now I wonder what to do when I do have a table with -let's say- 200 predictors? Do I have to enter x1 to x200 after <code>bsts(y ~</code> to find the best predictors?</li>
</ol>

<p>R code below:</p>

<pre><code>install.packages(""devtools"")
library(devtools)
devtools::install_github(""google/CausalImpact"")
#Download the tar from the git and then install the package in RStudio.

library(CausalImpact)

set.seed(1)
x1 &lt;- 100 + arima.sim(model = list(ar = 0.999), n = 100)
x2 &lt;- 50 + arima.sim(model = list(ar = 0.899), n = 100)
x3 &lt;- 80 + arima.sim(model = list(ar = 0.799), n = 100)
x4 &lt;- 1.25 * x1 + rnorm(100)
x5 &lt;- 101 + arima.sim(model = list(ar = 0.999), n = 100)
y &lt;- 1.2 * x1 + rnorm(100)
y[71:100] &lt;- y[71:100] + 10
data &lt;- cbind(y, x1)

dim(data)
head(data)
data
matplot(data, type = ""l"")

time.points &lt;- seq.Date(as.Date(""2014-01-01""), by = 1, length.out = 100)
data &lt;- zoo(cbind(y, x1), time.points)
head(data)

pre.period &lt;- as.Date(c(""2014-01-01"", ""2014-03-11""))
post.period &lt;- as.Date(c(""2014-03-12"", ""2014-04-10""))

impact &lt;- CausalImpact(data, pre.period, post.period)
plot(impact)

summary(impact)
summary(impact, ""report"")
impact$summary

post.period &lt;- c(71, 100)
post.period.response &lt;- y[post.period[1] : post.period[2]]
y[post.period[1] : post.period[2]] &lt;- NA

ss &lt;- AddLocalLevel(list(), y)

bsts.model &lt;- bsts(y ~ x1 + x2 + x3 + x4 + x5, ss, niter = 1000)

impact &lt;- CausalImpact(bsts.model = bsts.model,post.period.response =     post.period.response)

plot(impact)
summary(impact)
summary(impact, ""report"")

plot(impact$model$bsts.model,""coefficients"")
plot(impact$model$bsts.model, ""coef"", inc = .1)
plot(impact$model$bsts.model, ""coef"", inc = .05)

colMeans(impact$model$bsts.model$coefficients)
</code></pre>
"
"0.129315150027968","0.128247294010644","224380","<p>I have a dataset which contains data from a sensor for every 5 minutes and am trying to predict for example 10 future values based on the first 500 values. My data looks like the following and could be downloaded <a href=""https://github.com/numenta/NAB/blob/master/data/artificialWithAnomaly/art_daily_flatmiddle.csv"" rel=""nofollow"">here</a>:</p>

<pre><code>timestamp,value
2014-04-01 00:00:00,-21.0483826823
2014-04-01 00:05:00,-20.2954768676
2014-04-01 00:10:00,-18.127229468299998
2014-04-01 00:15:00,-20.1716653997
2014-04-01 00:20:00,-21.223761612
2014-04-01 00:25:00,-19.1044911334
</code></pre>

<p><a href=""http://i.stack.imgur.com/iw6O3.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/iw6O3.png"" alt=""enter image description here""></a></p>

<p>I am taking the following steps:</p>

<pre><code># Read data from file and create time series    
myData &lt;- read.zoo(file=""filePath"", sep = "","", header = TRUE,index = 1, tz = """", format = ""%Y-%m-%d %H:%M:%S"", nrows=500)

# Fit ARIMA model to the data
fit &lt;- auto.arima(z, stepwise=FALSE, trace=TRUE, approximation=FALSE)

# Predict 10 timesteps ahead
pred &lt;- predict(fit, n.ahead = 10)
</code></pre>

<p>But when I print the prediction results they do not seem promising and model always converges to a single value:</p>

<pre><code>$pred
Time Series:
Start = 1396474800 
End = 1396477500 
Frequency = 0.00333333333333333 
 [1] 81.62789 81.62789 81.62789 81.62789 81.62789 81.62789 81.62789 81.62789 81.62789 81.62789

$se
Time Series:
Start = 1396474800 
End = 1396477500 
Frequency = 0.00333333333333333 
 [1]  7.136100  9.728122 11.762177 13.493007 15.025767 16.416032 17.697417 18.892088 20.015580 21.079276
</code></pre>

<p>And here is the summary of fit:</p>

<pre><code>&gt; summary(fit)
Series: z 
ARIMA(0,1,1)                    

Coefficients:
          ma1
      -0.0735
s.e.   0.0463

sigma^2 estimated as 50.92:  log likelihood=-1688.17
AIC=3380.34   AICc=3380.37   BIC=3388.77

Training set error measures:
                    ME     RMSE      MAE     MPE    MAPE       MASE        ACF1
Training set 0.2215984 7.121813 3.141386 1592726 1592732 0.07197436 0.001426353
</code></pre>

<p>This is my first day with R and I think I might be doing something wrong. Any help would be much appreciated.</p>

<p>Thanks</p>
"
"0.153007748945791","0.130066495428618","225094","<p>In the <code>Arima()</code> method, in the <code>forecast</code> package in R, I can provide a vector of parameters to the <code>fixed</code> argument, and the model is estimated while ensuring the provided parameters are fixed to the supplied values.</p>

<p>However, when I do this, the model returns no standard errors for these coefficients. Why is this the case? Is it not possible to estimate standard errors of coefficients that are manually provided? Would love an explanation as to why this might be the case.</p>

<p>Moreover, the <code>forecast</code> method still calculates confidence intervals when forecasting from a model that has fixed parameters. Are these intervals still statistically valid? I would have thought such would rely on the standard errors of the estimated coefficients, which it seems we may not know in the case of manually-entered parameters?</p>
"
"0.057831493196624","0","226323","<p>The estimates by function <code>Arima</code> from the ""forecast"" package in R are as follows:</p>

<pre><code>ARIMA(1,0,0) with non-zero mean   

Coefficients:

             ar1   intercept  SEASONAL.. 1MO_LIBOR... GDP_GOODS... CORP...                 

          0.3950   0.0464    -0.0783    -0.0220       1.8730       0.0679 

    s.e.  0.1463   0.0068     0.0083     0.0115       0.8527       0.0323 
</code></pre>

<p>Meanwhile, the EViews estimates are</p>

<p><a href=""http://i.stack.imgur.com/3IgIT.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/3IgIT.png"" alt=""enter image description here""></a></p>

<p>Why do the standard error differ in EViews vs. R even though the coefficients coincide?</p>

<p>By the way, could any body help me to calculate the $p$-values of the coefficients? Is this function correct?</p>

<pre><code>P_Value &lt;- function(fit)
{
  if(inherits(fit,""lm"")){
    res=summary(fit)$coef[-1,4]
  }else
  {
    vars=colnames(fit$xreg)
    n=nobs(fit)
    df=nobs(fit)-length(fit$coef)
    res=(1-pt(abs(fit$coef)/sqrt(diag(fit$var.coef)*n/df),df))*2
  }
  return (res[vars])
}
</code></pre>
"
"0","0","228667","<p>Here is the summary of my SARIMA model.  I want to be able to put all the coefficients of ma1 ma2 sma1 sma2 and the coefficients of the exogenous variables into an equation:  I saw post with the same topic but none with the exogeous varaibles part 
$$
Y_t= ?
$$
        ARIMA(0,0,2)(0,0,2)[4] with non-zero mean </p>

<pre><code>Coefficients:
          ma1     ma2     sma1     sma2  intercept  exogeneous_var1  exogeneous_var2
      -0.7756  0.2152  -0.5155  -0.4023     0.0413           -1e-04           0.0028
s.e.   0.1358  0.1782   0.2985   0.2311     0.0068            0e+00           0.0347
      exogeneous_var3  exogeneous_var4
              -0.0054           0.0012
s.e.           0.0035           0.0049

sigma^2 estimated as 0.0001283:  log likelihood=182.13
AIC=-344.26   AICc=-339.68   BIC=-323.49

Training set error measures:
                        ME       RMSE         MAE      MPE     MAPE      MASE        ACF1
Training set -0.0002763522 0.01042586 0.008296043 83.07064 116.4007 0.4182354 0.006248187
</code></pre>
"
"NaN","NaN","229123","<p>Below is the summary of my SARIMA model: </p>

<pre><code>Series: diff(log(data_final_ts)) 
ARIMA(0,0,2)(0,0,2)[4] with non-zero mean 

Coefficients:
          ma1     ma2     sma1     sma2  intercept  exogeneous_var1  exogeneous_var2
      -0.7756  0.2152  -0.5155  -0.4023     0.0413           -1e-04           0.0028
s.e.   0.1358  0.1782   0.2985   0.2311     0.0068            0e+00           0.0347
      exogeneous_var3  exogeneous_var4
              -0.0054           0.0012
s.e.           0.0035           0.0049

sigma^2 estimated as 0.0001283:  log likelihood=182.13
AIC=-344.26   AICc=-339.68   BIC=-323.49

Training set error measures:
                        ME       RMSE         MAE      MPE     MAPE      MASE        ACF1
Training set -0.0002763522 0.01042586 0.008296043 83.07064 116.4007 0.4182354 0.006248187
</code></pre>

<p>I want to know if the following model equation is correct:</p>

<p>$$(1-B)(1-B^4)Y_t=(1+\phi_1 B^4+\phi_2 B^8)(1+\theta_1 B+\theta_2 B^2)e_t+\text{const}+\beta X_t$$</p>

<p>with $\text{const}$ being the mean of $Y_t$ and with $X_t$ including an intercept and a few exogenous variables.</p>
"
"0.139494810181231","0.190221477563171","229721","<p>I have 4 years electrical load data. I split the data into 3 years (75%) training data, 1 year for testing (25%). Also I have the temperature data for each day during the previous period. (The link to the dataset: <a href=""https://drive.google.com/open?id=0B08HdcWBksWcTUxqc1ByOW1UVEU"" rel=""nofollow"">here</a>.) </p>

<p>I want to make use of the temperature data to enhance the forecasting using argument <code>xreg</code> in <code>arima</code> function. </p>

<p>Here is my code:</p>

<pre><code>mydata1&lt;-read.csv(""1st pape/kaggle_data.csv"");
mydata&lt;-ts(mydata1[,2],start = c(2004),frequency = 365)

#split the data into trainData and test data
trainData = window(mydata, end=c(2007))
testData = window(mydata, start=c(2007))
temp&lt;-ts(mydata1[,3],start = c(2004),frequency = 365)

#split the temperature into trainData and test data
trainReg = window(temp, end=c(2007))
testReg = window(temp, start=c(2007))
</code></pre>

<p>Apply ARIMA model without using <code>xreg</code>:</p>

<pre><code>mod_arima &lt;- auto.arima(trainData, ic='aicc', stepwise=FALSE)
summary(mod_arima)
Series: trainData 
ARIMA(1,0,3) with non-zero mean 

Coefficients:
         ar1      ma1      ma2      ma3  intercept
      0.9642  -0.2098  -0.2157  -0.1693  24008.122
s.e.  0.0110   0.0322   0.0330   0.0325   1018.007

sigma^2 estimated as 9318421:  log likelihood=-10347.38
AIC=20706.75   AICc=20706.83   BIC=20736.75

Training set error measures:
                   ME     RMSE      MAE       MPE     MAPE      MASE
Training set 6.102332 3045.638 2293.946 -1.519484 9.625694 0.5151126
                    ACF1
Training set 0.004483007

plot(forecast(mod_arima)); lines(testData , col=""red"", start= c(2007,1,1)); 
legend(""topleft"", lty=1,col=c(4,2),legend=c(""forecasted data"",""real data""))

y &lt;- msts(trainData, c(7,365)) # multiseasonal ts
x &lt;- msts(trainReg, c(7,365)) # multiseasonal ts

fit &lt;- auto.arima(y, xreg=(fourier(y, K=c(3,30))))
fit_f &lt;- forecast(fit, xreg= fourier(y, K=c(3,30), 365), 365)
plot(fit_f)
</code></pre>

<p>the red line is the actual data, while the blue is the foretasted data. The left plot is appeared before using fourier function, while the right after using it. </p>

<p><a href=""http://i.stack.imgur.com/QxvKC.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/QxvKC.png"" alt=""enter image description here""></a></p>

<p>Apply ARIMA model using <code>xreg</code>:</p>

<pre><code>mod_arima2 &lt;- auto.arima(trainData ,xreg = trainReg, ic='aicc', stepwise=FALSE)
summary(mod_arima2)
Series: trainData 
ARIMA(1,0,3) with non-zero mean 

Coefficients:
         ar1      ma1      ma2      ma3  intercept  trainReg
      0.9709  -0.2403  -0.2108  -0.1609  29984.188  -88.3976
s.e.  0.0094   0.0320   0.0330   0.0321   1468.108   13.1966

sigma^2 estimated as 8955023:  log likelihood=-10325.13
AIC=20664.26   AICc=20664.36   BIC=20699.26

Training set error measures:
                   ME     RMSE      MAE       MPE     MAPE      MASE
Training set 6.030471 2984.292 2267.803 -1.464553 9.529988 0.5092422
                    ACF1
Training set 0.005526977

plot(forecast(mod_arima2,xreg = testReg)); lines(testData , col=""red"", start= c(2007,1,1)); 
legend(""topleft"", lty=1,col=c(4,2), legend=c(""forecasted data"",""real data""))

l = (fourier(y, K=c(3,30)))
z = cbind(l,x)
fit2 &lt;- auto.arima(y, xreg=z)
fit_f2 &lt;- forecast(fit, xreg= z, 365)
plot(fit_f2)
</code></pre>

<p><a href=""http://i.stack.imgur.com/TgJE5.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/TgJE5.png"" alt=""enter image description here""></a>
<strong>Questions</strong>:</p>

<ol>
<li>Did I use <code>xreg</code> correctly?</li>
<li>If yes, why is the summary the same without using <code>xreg</code>?</li>
<li>Why are the forecasts far away from the real data?</li>
</ol>
"
"0.0817860820109531","0.0811107105653813","230269","<p>I am sitting with a couple of time-series that I am analysing using ARIMA models. I have a question regarding prediction intervals. When predicting using a model that takes a first difference (a SARIMA(1,1,0)x(1,0,0) model), I get an increasing size of the prediction interval. Without I get a very constant and narrow band (see below):</p>

<p><a href=""http://i.stack.imgur.com/UaHX6.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/UaHX6.png"" alt=""Graphs""></a></p>

<p>The corresponding results are as follows:</p>

<p><a href=""http://i.stack.imgur.com/Fu2nU.png"" rel=""nofollow""><img src=""http://i.stack.imgur.com/Fu2nU.png"" alt=""Results""></a></p>

<p>Can anyone explain why the band is so constant? First I thought it was because of a large significant MA coefficient. This, however, I removed and the ""problem"" persisted. Then I though it was because the ARIMA without differencing automatically included an intercept. However, again, when I specified <code>include.mean = FALSE</code>, nothing changed.</p>

<p>Any help would be appreciated.</p>
"
"NaN","NaN","232322","<p>I have a little stupid question about <code>forecast</code> package. I want to get information about model formula. For example:</p>

<pre><code>library(forecast)
fit &lt;- auto.arima(WWWusage)
print(fit)
</code></pre>

<p>This produces: </p>

<pre><code>Series: WWWusage 
ARIMA(1,1,1)                    

Coefficients:
         ar1     ma1
      0.6504  0.5256
s.e.  0.0842  0.0896

sigma^2 estimated as 9.995:  log likelihood=-254.15
AIC=514.3   AICc=514.55   BIC=522.08
</code></pre>

<p>So in this case I can see that the model is <code>ARIMA(1,1,1)</code>. But I can't find how to extract this directly.</p>
"
"0.129315150027968","0.128247294010644","232590","<p>I have a number of groups with monthly data from 2010 to 2016. It's over 80 groups. I succesfully ran an ARIMA model with the montly data but with the sales data summed up (without groups). </p>

<p>Now I'd like to compare the performance with a per group model that runs an ARIMA model for each group and maybe later consider another type of grouping (geographical location, clustering, etc.)</p>

<p>I ran my original model with the following code:</p>

<pre><code>        Datos &lt;- read.csv(""C:/Users/borja.sanz/Desktop/Borja/Forecasting/V`enter code here`entas/Datos para Forecast.csv"")
        options(scipen=999)
        library(lubridate)
        Datos$Fecha = dmy(Datos$Fecha)

        #Declare time series
        tsDatos&lt;-ts(Datos$VentaLocal,start = c(2010,1),frequency = 12)
        plot(tsDatos)
        library(forecast)
        library(dplyr)

        #AutoArima Model
        m_aa = auto.arima(tsDatos)
        f_aa = forecast(m_aa, h=36)
        plot(f_aa)

#Create the forecasts along with the lower and upper bound
    forecast_df = data.frame(prediction=f_aa$mean,
                             abajo=f_aa$lower[,2],
                             arriba=f_aa$upper[,2],
                             date=last_date + seq(1/12, 3, by=1/12))
    forecast_df
</code></pre>

<p>This is how my data looks like:</p>

<pre><code>       Group    Year    Month   Date    Sales
1   2010    1   1/01/2010   134536.625
1   2010    2   1/02/2010   117506.625
1   2010    3   1/03/2010   132153.75
1   2010    4   1/04/2010   129723.125
1   2010    5   1/05/2010   135834.5
1   2010    6   1/06/2010   130115.375
1   2010    7   1/07/2010   144716
1   2010    8   1/08/2010   137195
1   2010    9   1/09/2010   137522.875
1   2010    10  1/10/2010   187063
1   2010    11  1/11/2010   162002.75
1   2010    12  1/12/2010   262297.375
1   2011    1   1/01/2011   177291.25
1   2011    2   1/02/2011   154816
1   2011    3   1/03/2011   171231.125
1   2011    4   1/04/2011   217717
1   2011    5   1/05/2011   178767.75
1   2011    6   1/06/2011   180817.75
1   2011    7   1/07/2011   216927.125
1   2011    8   1/08/2011   204509.125
1   2011    9   1/09/2011   199449.5
1   2011    10  1/10/2011   243812.125
1   2011    11  1/11/2011   232135.875
1   2011    12  1/12/2011   330854.75
1   2012    1   1/01/2012   217123.875
1   2012    2   1/02/2012   200558
1   2012    3   1/03/2012   215689.5
1   2012    4   1/04/2012   245500.25
1   2012    5   1/05/2012   219687.25
1   2012    6   1/06/2012   243345.625
1   2012    7   1/07/2012   249042
1   2012    8   1/08/2012   198443.75
1   2012    9   1/09/2012   209157.375
1   2012    10  1/10/2012   234089
1   2012    11  1/11/2012   237531
1   2012    12  1/12/2012   365301.25
1   2013    1   1/01/2013   211129.375
1   2013    2   1/02/2013   185249.625
1   2013    3   1/03/2013   256565.625
1   2013    4   1/04/2013   183549.5
1   2013    5   1/05/2013   189698.25
1   2013    6   1/06/2013   207955.625
1   2013    7   1/07/2013   230764.125
1   2013    8   1/08/2013   212551.625
1   2013    9   1/09/2013   201329.5
1   2013    10  1/10/2013   242745.125
1   2013    11  1/11/2013   261893.375
1   2013    12  1/12/2013   418313.25
1   2014    1   1/01/2014   205532.75
1   2014    2   1/02/2014   170487.75
1   2014    3   1/03/2014   196077
1   2014    4   1/04/2014   221760.875
1   2014    5   1/05/2014   198185
1   2014    6   1/06/2014   204919.25
1   2014    7   1/07/2014   218972.75
1   2014    8   1/08/2014   221439.875
1   2014    9   1/09/2014   195888.375
1   2014    10  1/10/2014   234595.75
1   2014    11  1/11/2014   259712.875
1   2014    12  1/12/2014   355691.875
1   2015    1   1/01/2015   205156.25
1   2015    2   1/02/2015   185358.875
1   2015    3   1/03/2015   218555.75
1   2015    4   1/04/2015   204233.625
1   2015    5   1/05/2015   212160.625
1   2015    6   1/06/2015   207217.25
1   2015    7   1/07/2015   225723.75
1   2015    8   1/08/2015   205902.625
1   2015    9   1/09/2015   196940.625
1   2015    10  1/10/2015   250916
1   2015    11  1/11/2015   236835.125
1   2015    12  1/12/2015   358327.625
2   2010    1   1/01/2010   227175.875
2   2010    2   1/02/2010   205042
2   2010    3   1/03/2010   239206.375
2   2010    4   1/04/2010   212059.875
2   2010    5   1/05/2010   232789
2   2010    6   1/06/2010   247876.125
2   2010    7   1/07/2010   278557
2   2010    8   1/08/2010   270410.125
2   2010    9   1/09/2010   251060.375
2   2010    10  1/10/2010   302738.625
2   2010    11  1/11/2010   266869.75
2   2010    12  1/12/2010   272978.75
2   2011    1   1/01/2011   238614.5
2   2011    2   1/02/2011   224240.375
2   2011    3   1/03/2011   245457.375
2   2011    4   1/04/2011   238583.5
2   2011    5   1/05/2011   252392.75
2   2011    6   1/06/2011   256749.5
2   2011    7   1/07/2011   264736.125
2   2011    8   1/08/2011   256414
2   2011    9   1/09/2011   242335.125
2   2011    10  1/10/2011   305224.75
2   2011    11  1/11/2011   289199.875
2   2011    12  1/12/2011   281807.75
2   2012    1   1/01/2012   244886.125
2   2012    2   1/02/2012   232062.375
2   2012    3   1/03/2012   264991.75
2   2012    4   1/04/2012   232750.5
2   2012    5   1/05/2012   248498.375
2   2012    6   1/06/2012   264290.875
2   2012    7   1/07/2012   272689.75
2   2012    8   1/08/2012   260441.25
2   2012    9   1/09/2012   251852.375
2   2012    10  1/10/2012   305929.625
2   2012    11  1/11/2012   276711.625
2   2012    12  1/12/2012   278672.875
2   2013    1   1/01/2013   242613.875
2   2013    2   1/02/2013   227575.75
2   2013    3   1/03/2013   250318.875
2   2013    4   1/04/2013   250150.375
2   2013    5   1/05/2013   258467.25
2   2013    6   1/06/2013   261359.25
2   2013    7   1/07/2013   279113.75
2   2013    8   1/08/2013   258699
2   2013    9   1/09/2013   244841.375
2   2013    10  1/10/2013   308197.25
2   2013    11  1/11/2013   284195.5
2   2013    12  1/12/2013   287718.75
2   2014    1   1/01/2014   239510.375
2   2014    2   1/02/2014   216338.125
2   2014    3   1/03/2014   245626.75
2   2014    4   1/04/2014   230619.875
2   2014    5   1/05/2014   251758.875
2   2014    6   1/06/2014   254946.75
2   2014    7   1/07/2014   276268.75
2   2014    8   1/08/2014   266151.75
2   2014    9   1/09/2014   245859.375
2   2014    10  1/10/2014   317797.5
2   2014    11  1/11/2014   283786.625
2   2014    12  1/12/2014   289767.875
2   2015    1   1/01/2015   244008
2   2015    2   1/02/2015   228638
2   2015    3   1/03/2015   260056
2   2015    4   1/04/2015   232560.875
2   2015    5   1/05/2015   252642.125
2   2015    6   1/06/2015   249018.5
2   2015    7   1/07/2015   278113.125
2   2015    8   1/08/2015   255851
2   2015    9   1/09/2015   263046.625
2   2015    10  1/10/2015   344240.75
2   2015    11  1/11/2015   295486.125
2   2015    12  1/12/2015   293499.375
</code></pre>

<p>I only included two groups in the sample. I would like to use a function like one of the apply (tapply, lapply, sapply, etc.) that can run an AUTO.ARIMA model per group. Then I would like to obtain the forecast for each group for x number of months and also if I could visualize the model coefficients.</p>
"
